{"meta":{"title":"Inoki in the world","subtitle":null,"description":null,"author":"Inoki","url":"https://blog.inoki.cc","root":"/"},"pages":[{"title":"About me 关于","date":"2025-03-08T09:40:48.611Z","updated":"2025-03-08T09:40:48.611Z","comments":true,"path":"about/index.html","permalink":"https://blog.inoki.cc/about/index.html","excerpt":"","text":"To be continued…"},{"title":"all-archives","date":"2025-03-08T09:40:48.611Z","updated":"2025-03-08T09:40:48.611Z","comments":false,"path":"all-archives/index.html","permalink":"https://blog.inoki.cc/all-archives/index.html","excerpt":"","text":""},{"title":"all-categories","date":"2025-03-08T09:40:48.611Z","updated":"2025-03-08T09:40:48.611Z","comments":false,"path":"all-categories/index.html","permalink":"https://blog.inoki.cc/all-categories/index.html","excerpt":"","text":""},{"title":"Springer Free Books","date":"2025-03-08T09:40:48.612Z","updated":"2025-03-08T09:40:48.612Z","comments":true,"path":"book/Springer-free-books.html","permalink":"https://blog.inoki.cc/book/Springer-free-books.html","excerpt":"","text":"From Reddit: Fundamentals of Power Electronics http://link.springer.com/openurl?genre=book&amp;isbn=978-0-306-48048-5 Handbook of the Life Course http://link.springer.com/openurl?genre=book&amp;isbn=978-0-306-48247-2 All of Statistics http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-21736-9 Social Anxiety and Social Phobia in Youth http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-22592-0 Discrete Mathematics http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-21777-2 Developmental Neurobiology http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-28117-9 Intuitive Probability and Random Processes using MATLAB® http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-24158-6 Handbook of Disaster Research http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-32353-4 Handbook of the Sociology of Gender http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-36218-2 Handbook of Sociological Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-36274-8 Clinical Neuroanatomy http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-36601-2 Acquired Brain Injury http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-37575-5 Numerical Optimization http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-40065-5 Handbook of Biological Confocal Microscopy http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-45524-2 Ceramic Materials http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-46271-4 Principles of Fluorescence Spectroscopy http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-46312-4 Fundamentals of Biomechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-49312-1 Primer on the Rheumatic Diseases http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-68566-3 International Handbook of Historical Archaeology http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-72071-5 Database Marketing http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-72579-6 Composite Materials http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-74365-3 Time Series Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-75959-3 Transmission Electron Microscopy http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-76501-3 Handbook of Quantitative Criminology http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-77650-7 Plant Physiological Ecology http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-78341-3 Introductory Statistics with R http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-79054-1 The Elements of Statistical Learning http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-84858-7 Psychology, Religion, and Spirituality http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-87573-6 Introductory Time Series with R http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-88698-5 Child Neuropsychology http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-88963-4 A Beginner’s Guide to R http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-93837-0 Geomorphology of Desert Environments http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4020-5719-9 The Joy of Science http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4020-6099-1 Fatigue of Structures and Materials http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4020-6808-9 Essential Astrophysics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-35963-7 Introduction to Evolutionary Computing http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-44874-8 Data Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-03762-2 International Perspectives on Psychotherapy http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-56194-3 Electrical Machines http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-0400-2 Mechanics and Thermodynamics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-27877-3 Applied Behavior Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-44794-0 Reading, Writing, and Proving http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-9479-0 Linear and Nonlinear Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-18842-3 Introduction to Partial Differential Equations http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-48936-0 Energy Storage http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-21239-5 Metabolism of Human Diseases http://link.springer.com/openurl?genre=book&amp;isbn=978-3-7091-0715-7 Sensory Evaluation of Food http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-6488-5 Fundamentals of Robotic Mechanical Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-01851-5 Integrative Human Biochemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-3058-6 Philosophy of Science for Scientists http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-26551-3 Particles and Nuclei http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-46321-5 Data Structures and Algorithms with Python http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-13072-9 LGBT-Parent Families http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-4556-2 Integrated Neuroscience http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4615-1077-2 Introduction to Partial Differential Equations http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-02099-0 Microeconomics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-37434-0 System Dynamics http://link.springer.com/openurl?genre=book&amp;isbn=978-981-10-2045-2 Cosmology for the Curious http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-57040-2 Methods of Mathematical Modelling http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-23042-9 Introduction to Logic Circuits &amp; Logic Design with Verilog http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-53883-9 Structural Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-90-481-2516-6 Engineering Flow and Heat Exchange http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4899-7454-9 Enterprise Risk Management Models http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-53785-5 Reactive Power Control in AC Power Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-51118-4 Principles of Microeconomics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-57589-6 Additive Manufacturing Technologies http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-1120-9 Principles of Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-23026-4 Fundamentals of Biomechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-44738-4 Irrigation and Drainage Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-05699-9 LaTeX in 24 Hours http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-47831-9 Psychology of Perception http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-31791-5 Extragalactic Astronomy and Cosmology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-54083-7 Automata and Computability http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4612-1844-9 The Algorithm Design Manual http://link.springer.com/openurl?genre=book&amp;isbn=978-1-84800-070-4 Chemical Thermodynamics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-19864-9 Computational Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-61088-7 Introduction to Statistics and Data Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-46162-5 Grammar for Teachers http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-33916-0 Time Series Econometrics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-32862-1 Electrochemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-30250-3 Classical Fourier Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-1194-3 Human Chromosomes http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4613-0139-4 Phylogenomics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-54064-1 Quantum Theory for Mathematicians http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-7116-5 Evidence-Based Critical Care http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-43341-7 Clinical Assessment of Child and Adolescent Personality and Behavior http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-0641-0 Design Research in Information Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-5653-8 Intermediate Physics for Medicine and Biology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-12682-1 Principles of Data Mining http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-7307-6 Fundamental Astronomy http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-53045-0 Fundamentals of Business Process Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-33143-5 Brownian Motion, Martingales, and Stochastic Calculus http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-31089-3 UML @ Classroom http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-12742-2 Design and Analysis of Experiments http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-52250-0 Foundations for Designing User-Centered Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-5134-0 Handbook of Consumer Finance Research http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-28887-1 Principles of Terrestrial Ecosystem Ecology http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-9504-9 Applied Multivariate Statistical Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-45171-7 Strategic International Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-8349-6331-4 Computer Vision http://link.springer.com/openurl?genre=book&amp;isbn=978-1-84882-935-0 Engineering Electromagnetics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-07806-9 Data Mining http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-14142-8 International Trade Theory and Policy http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-37314-5 Alternative Energy Sources http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-20951-2 Introduction to Electronic Commerce and Social Commerce http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-50091-1 Computational Geometry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-540-77974-2 Elementary Mechanics Using Python http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-19596-4 Energy Economics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-53022-1 Biomedical Informatics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-4474-8 Robotics, Vision and Control http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-54413-7 Acid-Base Diagrams http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-37902-4 Brewing Science: A Multidisciplinary Approach http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-46394-0 Learning Landscape Ecology http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-6374-4 Probability http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4612-4374-8 Modeling Life http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-59731-7 Introduction to Plasma Physics and Controlled Fusion http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-22309-4 Engineering Mechanics 1 http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-30319-7 Principles of Polymer Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-2212-9 A Primer on Scientific Programming with Python http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-49887-3 Climate Change Science: A Modern Synthesis http://link.springer.com/openurl?genre=book&amp;isbn=978-94-007-5757-8 Solar PV and Wind Energy Conversion Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-14941-7 Statistical Analysis and Data Display http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-2122-5 Business Process Management Cases http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-58307-5 Elementary Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-6271-2 Cryptography Made Simple http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-21936-3 Fluid Dynamics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-09351-2 Social Media Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-21990-5 Statistics in Criminal Justice http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-9170-5 Supply Chain Management and Advanced Planning http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-55309-7 Probability Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-5201-9 Statistics and Data Analysis for Financial Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-2614-5 Readings in Formal Epistemology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-20451-2 Differential Equations and Their Applications http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4612-4360-1 Nanotechnology: Principles and Practices http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-09171-6 Epidemiological Research: Terms and Concepts http://link.springer.com/openurl?genre=book&amp;isbn=978-94-007-1171-6 Multinational Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-23012-2 Partial Differential Equations http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-4809-9 Bayesian and Frequentist Regression Methods http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-0925-1 Strategic International Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-658-07884-3 Basic Concepts in Computational Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-27265-8 Eye Tracking Methodology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-57883-5 Writing for Publication http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-31650-5 Mathematical Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-01195-0 Correctional Counseling and Treatment http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-54349-9 Thermodynamics and Energy Conversion http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-43715-5 The Action Research Planner http://link.springer.com/openurl?genre=book&amp;isbn=978-981-4560-67-2 Stochastic Processes and Calculus http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-23428-1 Statistical Analysis of Clinical Data on a Pocket Calculator http://link.springer.com/openurl?genre=book&amp;isbn=978-94-007-1211-9 Clinical Data Analysis on a Pocket Calculator http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-27104-0 The Data Science Design Manual http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-55444-0 An Introduction to Machine Learning http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-63913-0 Guide to Discrete Mathematics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-44561-8 Petroleum Geoscience http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-34132-8 Structure Determination by X-ray Crystallography http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-3954-7 Introduction to Time Series and Forecasting http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-29854-2 Principles of Mobile Communication http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-55615-4 Cardiovascular Biomechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-46407-7 Introduction to Smooth Manifolds http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-9982-5 Taxation in European Union http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-53919-5 Essentials of Cerebellum and Cerebellar Disorders http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-24551-5 Language Across the Curriculum &amp; CLIL in English as an Additional Language (EAL) Contexts http://link.springer.com/openurl?genre=book&amp;isbn=978-981-10-1802-2 Multivariate Calculus and Geometry http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-6419-7 Statistics and Analysis of Scientific Data http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-6572-4 Modelling Computing Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-1-84800-322-4 Search Methodologies http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-6940-7 Representation Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4612-0979-9 Linear Algebra Done Right http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-11080-6 Stellar Structure and Evolution http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-30304-3 Evolutionary Thinking in Medicine http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-29716-3 Understanding Cryptography http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-04101-3 Linear Algebra http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-24346-7 Algebra http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4613-0041-0 Understanding Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-2712-8 Plate Tectonics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-540-76504-2 Linear Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-7630-6 The Nature of Scientific Knowledge http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-33405-9 Leadership Today http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-31036-7 Physics of Semiconductor Devices http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-1151-6 Corporate Social Responsibility http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-40975-2 Ordinary Differential Equations http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-3618-8 Electronic Commerce http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-10091-3 Ceramic Materials http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-3523-5 Foundations of Analytical Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-62872-1 Life Cycle Assessment http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-56475-3 A Clinical Guide to the Treatment of the Human Stress Response http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-5538-7 Computational Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-00401-3 Handbook of LGBT Elders http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-03623-6 Handbook of Cardiac Anatomy, Physiology, and Devices http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-19464-6 Quantum Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-20556-9 Understanding Statistics Using R http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-6227-9 Mass Spectrometry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-54398-7 Statistical Mechanics for Engineers http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-15018-5 The Gastrointestinal System http://link.springer.com/openurl?genre=book&amp;isbn=978-94-017-8771-0 Additive Manufacturing Technologies http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-2113-3 Magnetic Interactions in Molecules and Solids http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-22951-5 Electricity and Magnetism http://link.springer.com/openurl?genre=book&amp;isbn=978-4-431-54526-2 Survival Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-6646-9 Foundations of Quantum Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-65867-4 An Introduction to Statistical Learning http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-7138-7 Introduction to Mathematica® for Physicists http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-00894-3 Statistical Learning from a Regression Perspective http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-44048-4 Applied Partial Differential Equations http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-12493-3 Principles of Astrophysics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-9236-8 Air Pollution and Greenhouse Gases http://link.springer.com/openurl?genre=book&amp;isbn=978-981-287-212-8 Polymer Synthesis: Theory and Practice http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-28980-4 Sustainable Supply Chains http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-29791-0 Robotics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-84628-642-1 Econometrics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-20059-5 The Sea Floor http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-51412-3 SPSS for Starters and 2nd Levelers http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-20600-4 Regression Modeling Strategies http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-19425-7 Legal Dynamics of EU External Relations http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-54817-2 Food Analysis Laboratory Manual http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-44127-6 Principles of Musical Acoustics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-6786-1 Fundamentals of Structural Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-24331-3 Basics of Laser Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-50651-7 Applied Quantitative Finance http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-54486-0 Handbook of Marriage and the Family http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-3987-5 Solid-State Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-540-93804-0 Electrochemical Impedance Spectroscopy and its Applications http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-8933-7 Economics as Applied Ethics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-50319-6 Electronics for Embedded Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-39439-8 Concise Guide to Software Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-57750-0 Fundamentals of Multimedia http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-05290-8 Logistics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-01769-3 Group Theory Applied to Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-94-007-6863-5 The Psychology of Social Status http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-0867-7 A Modern Introduction to Probability and Statistics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-84628-168-6 Complex Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4419-7288-0 Food Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-540-69934-7 Exam Survival Guide: Physical Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-49810-2 The Python Workbook http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-14240-1 Practical Electrical Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-21173-2 Strategic Retail Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-658-10183-1 Food Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-45776-5 Psychoeducational Assessment and Report Writing http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-1911-6 Machine Learning in Medicine - a Complete Overview http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-15195-3 Evidence-Based Interventions for Children with Challenging Behavior http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-7807-2 Principles of Quantum Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4757-0576-8 Recommender Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-29659-3 Pharmaceutical Biotechnology http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-6486-0 Python Programming Fundamentals http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-6642-9 The Finite Element Method and Applications in Engineering Using ANSYS® http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4899-7550-8 Group Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-3-540-32899-5 Object-Oriented Analysis, Design and Implementation http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-24280-4 Introduction to Embedded Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-3143-5 Elementary Mechanics Using Matlab http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-19587-2 An Introduction to Biomechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-2623-7 New Introduction to Multiple Time Series Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-540-27752-1 Introduction to Data Science http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-50017-1 Calculus With Applications http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-7946-8 An Introduction to Soil Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-61185-3 Game Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-46950-7 Fundamentals of Clinical Trials http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-18539-2 The Finite Volume Method in Computational Fluid Dynamics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-16874-6 The ASCRS Textbook of Colon and Rectal Surgery http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-25970-3 Applied Predictive Modeling http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-6849-3 Introduction to Logic Circuits &amp; Logic Design with VHDL http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-34195-8 Sustainability Science http://link.springer.com/openurl?genre=book&amp;isbn=978-94-017-7242-6 Physical Chemistry from a Different Angle http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-15666-8 The Physics of Semiconductors http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-23880-7 Energy Harvesting and Energy Efficiency http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-49875-1 Python For ArcGIS http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-18398-5 Statics and Mechanics of Structures http://link.springer.com/openurl?genre=book&amp;isbn=978-94-007-6113-1 Real Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-2766-1 MATLAB for Psychologists http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-2197-9 Physical Asset Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-14777-2 Essentials of Food Science http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-9138-5 Quantum Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4612-1272-0 Probability Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-5361-0 Concise Guide to Databases http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-5601-7 Digital Image Processing http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4471-6684-9 Chemical and Bioprocess Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-9126-2 Transmission Electron Microscopy http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4757-2519-3 Guide to Computer Network Security http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-55606-2 Introduction to Law http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-57252-9 Advanced Quantum Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-25675-7 Bayesian Essentials with R http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-8687-9 Robotics, Vision and Control http://link.springer.com/openurl?genre=book&amp;isbn=978-3-642-20144-8 Applied Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4614-4262-2 Advanced Organic Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-44899-2 Advanced Organic Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-0-387-71481-3 International Humanitarian Action http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-14454-2 Breast Cancer http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-48848-6 Travel Marketing, Tourism Economics and the Airline Product http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-49849-2 Electronic Commerce 2018 http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-58715-8 Disability and Vocational Rehabilitation in Rural Settings http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-64786-9 Teaching Medicine and Medical Ethics Using Popular Culture http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-65451-5 Market Research http://link.springer.com/openurl?genre=book&amp;isbn=978-981-10-5218-7 Scanning Electron Microscopy and X-Ray Microanalysis http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-6676-9 ArcGIS for Environmental and Water Issues http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-61158-7 Physics from Symmetry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-66631-0 Communication and Bioethics at the End of Life http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-70920-8 Foundations of Programming Languages http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-70790-7 Problems in Classical Electromagnetism http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-63133-2 Polymer Chemistry http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-49279-6 Probability and Statistics for Computer Science http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-64410-3 Empathetic Space on Screen http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-66772-0 Political Social Work http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-68588-5 Introductory Quantum Mechanics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-68598-4 Guide to Competitive Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-72547-5 Introduction to Artificial Intelligence http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-58487-4 Bioinformatics for Evolutionary Biologists http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-67395-0 Concepts, Methods and Practical Applications in Applied Demography http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-65439-3 Introduction to Deep Learning http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-73004-2 Energy and the Wealth of Nations http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-66219-0 A Beginner’s Guide to Scala, Object Orientation and Functional Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-75771-1 Lessons on Synthetic Bioarchitectures http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-73123-0 Managing Sustainable Business http://link.springer.com/openurl?genre=book&amp;isbn=978-94-024-1144-7 Engineering Mechanics 2 http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-56272-7 Fundamentals of Business Process Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-56509-4 Clinical Methods in Medical Family Therapy http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-68834-3 Guide to Scientific Computing in C++ http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-73132-2 Motivation and Action http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-65094-4 Perspectives on Elderly Crime and Victimization http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-72682-3 Knowledge Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-59978-6 An Introduction to Zooarchaeology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-65682-3 Abstract Algebra http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-77649-1 Criminal Justice and Mental Health http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-76442-9 Philosophy of Race http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-78729-9 Of Cigarettes, High Heels, and Other Interesting Things http://link.springer.com/openurl?genre=book&amp;isbn=978-1-349-95348-6 Applied Bioinformatics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-68301-0 Linear Algebra and Analytic Geometry for Physical Sciences http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-78361-1 Building Energy Modeling with OpenStudio http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-77809-9 Customer Relationship Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-55381-7 The A-Z of the PhD Trajectory http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-77425-1 Strategic Human Resource Management and Employment Relations http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-0399-9 Applied Linear Algebra http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-91041-3 Witnessing Torture http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-74965-5 Proofs from THE BOOK http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-57265-8 Introduction to General Relativity http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-1090-4 Introduction to Particle and Astroparticle Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-78181-5 Fundamentals of Java Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-89491-1 Optimization of Process Flowsheets through Metaheuristic Techniques http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-91722-1 Robotics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-72911-4 Business Ethics - A Philosophical and Behavioral Approach http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-91575-3 A First Introduction to Quantum Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-92207-2 Argumentation Theory: A Pragma-Dialectical Perspective http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-95381-6 Logical Foundations of Cyber-Physical Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-63588-0 Off-Grid Electrical Systems in Developing Countries http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-91890-7 Entertainment Science http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-89292-4 Physics of Oscillations and Waves http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-72314-3 Introduction to Programming with Fortran http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-75502-1 Fundamentals of Solid State Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-75708-7 Introduction to Digital Systems Design http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-92804-3 Neural Networks and Deep Learning http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-94463-0 Data Science and Predictive Analytics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-72347-1 Systems Programming in Unix/Linux http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-92429-8 Analytical Corporate Finance http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-95762-3 Fraud and Corruption http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-92333-8 Conferencing and Presentation English for Young Academics http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-2475-8 A Concise Guide to Market Research http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-56707-4 Global Supply Chain and Operations Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-94313-8 Introduction to Parallel Computing http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-98833-7 Mathematical Logic http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-97298-5 Stability and Control of Linear Systems http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-02405-5 Introduction to Formal Philosophy http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-77434-3 Analysis for Computer Scientists http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-91155-7 International Business Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-96622-9 Research Methods for the Digital Humanities http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-96713-4 Introductory Computer Forensics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-00581-8 Control Engineering http://link.springer.com/openurl?genre=book&amp;isbn=978-981-10-8297-9 Control Engineering: MATLAB Exercises http://link.springer.com/openurl?genre=book&amp;isbn=978-981-10-8321-1 ENZYMES: Catalysis, Kinetics and Mechanisms http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-0785-0 Automatic Control with Experiments http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-75804-6 Internet of Things From Hype to Reality http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-99516-8 Quantitative Methods for the Social Sciences http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-99118-4 A Pythagorean Introduction to Number Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-02604-2 Philosophical and Mathematical Logic http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-03255-5 Structural Dynamics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-94743-3 Plant Physiology, Development and Metabolism http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-2023-1 Quantum Mechanics for Pedestrians 1 http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-00464-4 Plant Anatomy http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-77315-5 Quantum Mechanics for Pedestrians 2 http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-00467-5 Excel Data Analysis http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-01279-3 Quick Start Guide to VHDL http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-04516-6 Java in Two Semesters http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-99420-8 Managing Media and Digital Organizations http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-71288-8 Media and Digital Management http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-72000-5 An Anthology of London in Literature, 1558-1914 http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-05609-4 Astronautics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-74373-8 Perceptual Organization http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-96337-2 Research Methods for Social Justice and Equity in Education http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-05900-2 Educational Technology http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-6643-7 Quick Start Guide to Verilog http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-10552-5 Spine Surgery http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-98875-7 Introduction to Logic Circuits &amp; Logic Design with VHDL http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-12489-2 Social Justice Theory and Practice for Social Work http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-3621-8 School Leadership and Educational Change in Singapore http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-74746-0 Digital Business Models http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-13005-3 Introduction to Logic Circuits &amp; Logic Design with Verilog http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-13605-5 Pharmaceutical Biotechnology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-00710-2 Mapping Global Theatre Histories http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-12727-5 Social Marketing in Action http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-13020-6 Analyzing Qualitative Data with MAXQDA http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-15671-8 Handbook of Evolutionary Research in Archaeology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-11117-5 Evidence-Based Practice in Clinical Social Work http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-15224-6 Foundations of Behavioral Health http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-18435-3 Social Psychology in Action http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-13788-5 Essentials of Business Analytics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-68837-4 A Course in Rasch Measurement Theory http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-7496-8 Multimedia Big Data Computing for IoT Applications http://link.springer.com/openurl?genre=book&amp;isbn=978-981-13-8759-3 Policing and Minority Communities http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-19182-5 A Beginners Guide to Python 3 Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-20290-3 Advanced Guide to Python 3 Programming http://link.springer.com/openurl?genre=book&amp;isbn=978-3-030-25943-3 Food Fraud Prevention http://link.springer.com/openurl?genre=book&amp;isbn=978-1-4939-9621-6 Plant Ecology http://link.springer.com/openurl?genre=book&amp;isbn=978-3-662-56233-8 Mathematical Physics http://link.springer.com/openurl?genre=book&amp;isbn=978-3-319-01195-0"},{"title":"all-tags","date":"2025-03-08T09:40:48.612Z","updated":"2025-03-08T09:40:48.612Z","comments":false,"path":"all-tags/index.html","permalink":"https://blog.inoki.cc/all-tags/index.html","excerpt":"","text":""},{"title":"Book list 书单","date":"2025-03-08T09:40:48.612Z","updated":"2025-03-08T09:40:48.612Z","comments":true,"path":"book/index.html","permalink":"https://blog.inoki.cc/book/index.html","excerpt":"","text":"Compiler 编译器 《Compilers: Principales, Techniques and Tools》 Algorithm 算法 《Introduction to Algorithms》 《Mastering Algorithms with C》 Computer Graphics 计算机图形学 《Computer Graphics with OpenGL》 Mobile Applications 移动应用 Programming Languages 编程语言 《C++ Primer》 《Learn Objective-C on the Mac》 Applications 应用 《FFmpeg Beginner’s handbook》 《C++ GUI Programming with Qt》 Linux 《Linux Device Driver》 《A Heavy Commented Linux Kernel Source Code》 Cybersecutiry 网络安全 《Gray Hat Python: Python Programming for Hackers and Reverse Engineers》 Web 网页技术 《WebKit 技术内幕》 Other books about Computer Science 其他 《Code: The Hidden Language of Computer Hardware and Software》 《The Art of Unix Programming》 《Unix Network Programming》"},{"title":"友情链接","date":"2025-03-08T09:40:48.612Z","updated":"2025-03-08T09:40:48.612Z","comments":true,"path":"links/index.html","permalink":"https://blog.inoki.cc/links/index.html","excerpt":"","text":""},{"title":"书单","date":"2025-03-08T09:40:48.612Z","updated":"2025-03-08T09:40:48.612Z","comments":false,"path":"books/index.html","permalink":"https://blog.inoki.cc/books/index.html","excerpt":"","text":""},{"title":"Links 友情链接","date":"2025-03-08T09:40:48.612Z","updated":"2025-03-08T09:40:48.612Z","comments":true,"path":"links-backup/index.html","permalink":"https://blog.inoki.cc/links-backup/index.html","excerpt":"","text":"Here are some links, there may be interesting for you 😃 Claude - 少年心事當拏雲，誰念幽寒坐嗚呃。 Darkflames - 是漆黑烈焰，也是 Developer / 业余摄影 / 胶片爱好者。 Edward Elric - 是 E哥 大强强。 Dmcimi’s blog &amp; Lovely’s blog - 天下风云出我辈，一入江湖岁月催"}],"posts":[{"title":"弹指十年间","slug":"My-10-years","date":"2024-06-08T17:19:00.000Z","updated":"2025-03-08T09:40:48.585Z","comments":true,"path":"2024/06/08/My-10-years/","link":"","permalink":"https://blog.inoki.cc/2024/06/08/My-10-years/","excerpt":"","text":"又是一年高考季，属于我的那个年代转眼就过去了十年。 那年夏天，待一切尘埃落定时，刚好是小时候最喜欢的动漫《数码宝贝》十五周年，我长大了，太一他们也在十五周年的纪念剧场版长大了。和田光司在那一年的周年庆典上又唱起了这首歌，听得出他因鼻咽癌导致的力不从心。 借着那样的契机，我追忆了自己的那十多年。 如今又过去了十年整，已经步入《数码宝贝》第一代的第二十五个年头，再去查看和田光司的维基百科，就会发现早已特意注明了“已故”，享年四十二岁。是啊，人生苦短、如浮萍飘忽不定，遇弱水而终。 而我在这期间为世界留下了什么，有没有活成自己想要的模样？ 无限大的梦（無限大な夢） 在读初中时，因为看《探索发现》节目里一个荷兰气象学家用计算机做天气仿真的一个契机，我意识到了计算机程序设计在未来会是任何专业都不可或缺的能力，因此定下了大学前要初步具备写程序的能力。而至于高考后的专业和就业选择，则是去：读一个微电子和集成电路设计专业，然后去日企/韩企就业，毕业的薪酬目标是————一千万日元年收！ 于是在高二左右，我放弃了所谓的奥林匹克竞赛的机会，拿谭浩强的《C 语言程序设计》学习了 C 语言的基础，并具有了一定的写算法的能力。鉴于自己是结合对计算机体系架构基本的认识学习的，那些奇淫巧计并没有影响到我，相反，这本书反而对我的 C 语言能力提升非常大（还是能够“取其精华、弃其糟粕”更重要啊）。然后 ActionScript（因为做 Flash）和 Java（为了学一门面向对象的程序语言，但 C++ 的书太厚了，不适合高中生闲暇时间自学）也很自然地入门了。并且因为当时 Android/iOS 开发正火，还拿 Java 调用基础的 API 写了自己的第一个 Android 程序。同时还开始学习日语，为了自己的梦想做准备。 在高三那个夏天，高考单科大幅失利导致自己与梦校南辕北辙。虽然班主任愿意破例让我复读，但是我知道高考本身的并不是完全定终身的意义：高中学习的知识只是为了应试、为了拿到一个能够去大学学习的入场券，它本身的内容其实非常浅显易懂。为了去梦校和梦想的专业，再浪费自己一年的光阴不断地重复和练习，这并不合适。 而且显而易见的一个问题是，这样能去的学校的教学、学术水平还有资源都不会多好，我对其中的微电子和集成电路设计专业不报任何信心。几番取舍后，我重新规划了路线：那就先去这个学校相对较好的通信专业，并且一步步转向计算机硬件方向，如果有机会出国读研深造、就毫不犹豫，以此来弥补学校水平的差距。 于是毫无悬念地被录取，按部就班地开始专业的学习，因为学校水平限制、课程本身难度都不高，而学校的政策也比较好，比如课可以不去，选择直接使用期末考试成绩作为最终成绩。于是一直以来成绩都不错，保持在院内前 5%，每年奖学金基本可以覆盖基础的学费，有些课程本身也蛮有意思，特别是计算机网络通信正戳中我的心。同时，我能够拥有更多闲暇时间、来学习自己想学的别的东西：大一就开始在 ARM 树莓派上跑 golang 和 Docker，折腾 Linux 驱动，写写 Web 和 Vanilla JavaScript。后来，学校提供了机会出国交换，并可以直接兑换交换学校的硕士学分，于是靠着成绩不错这一点就很轻松地申请到了欧洲。 在硕士课程期间，课程的水平和难度确实不一样，我选择了计算机里面的嵌入式专业来作为硕士专业，因此有机会接触到 ROS（机器人操作系统的自动驾驶）、虚拟现实设备、ARM 汇编嵌入式等，并且和当时在读的博士生一起工作，我负责科学计算模拟程序的设计，发了他们领域顶刊的论文。同时因为背景合适，成功进入了欧洲某家五百强做新能源汽车相关的实习。 在开始实习之前，对于开源的热情和还算成熟的技术本身让我入选了 Google Summer of Code，做出了显著的开源贡献、也拿了不少的钱，主要工作内容也还是集中在了计算机网络上，但是是传输层和应用层相关。 实习期间，除了超量完成工作内容外，我还发现了团队使用的一个硬件的主线 Linux 内核的 bug 并修复了。实习成果不错、再加上帮整个部门解决了网络代理问题，拿到了实习负责人的强推荐信。目前做的东西还是离当初初中时的目标太过遥远，再加上对就业的怀疑与恐惧，就开始寻找看有没有读博的机会。 在没投几个的时候，就遇到了特别适合自己的一个课题————物联网（Internet of Things，IoT）。在我看来，它是已经接近死亡了的嵌入式开发专业和互联网的结合，新瓶装旧酒、但是把嵌入式复活了，而且能够接触到 OSI 模型的下两层的细节，补全我的计算机网络知识栈。于是毫不犹豫地就过去了。 在读博的第一个月就提出了一个很新并且可行的 idea，让导师们喜出望外。而因为不用应付课业、自己的时间多了，基于之前的点子的一些个人开源的项目也开始做了起来。最终几年博士下来，在小领域做出来的成果也没让自己失望，导师也十分满意、成功地按时毕业，还为我提供了在日本交换的机会、并借此成功收获了博士后的 offer，这为我再次到达日本做了很好的铺垫。同时，自己的定位也变得和原本的目标更为接近了，只不过原本的目标是硬件侧的电路设计，而现在变成了软件中最偏向硬件、和硬件结合最强的部分。 初中那时的我应该不会想到，我最终能博士毕业。因为按照原本的计划，读完集成电路设计的本科、我就打算去社会这所不一样的大学接受实战的磨练。塞翁失马焉知非福？ 但，当初最初的梦也就永远是梦了··· 那之后，是令人沮丧的世间（あとの，やるせない世の中じゃ） 最初的梦可能没实现，也可能已经以另一种方式实现了。这十年期间，各种沮丧也接踵而至。 和前面讲的联系最紧密的就是学校的认可度问题，由于读的几个学校知名度都一般，经常在一些中厂、大厂过不了简历关。同时对学术道路的发展也时有阻碍，比如投 ETH 和 EPFL 的博士岗位的时候被要求再读一个硕士，而投 Hugging Face 的时候，更是会被不在他们招的学校名单内被拒。作为一个小镇做题家，对从小在被否定的环境长大的我来说，信赖自己是不存在的，自信和自我定位这种东西从来都是不存在的，因此会经常沮丧和自闭。 更加加剧崩溃的是家庭状况。我的父母是相亲认识、最后在变成剩男剩女的前夕草草结婚的，所以他们会说“这世上不存在什么爱情”。本科期间，他们就因为父亲出轨开始闹离婚、分家。我每个假期都不想回家，回家就意味着不得安宁。最终两人分道扬镳，父亲丢下一句话：“孩子根本不是我想要的”，就丢下了稳定的工作离开了我和我母亲，带着家里的绝大部分钱（本来也不多），去了第三者所在的城市定居了。母亲的气没有地方发，隔三岔五给我打电话骂我，因为我是唯一的和我父亲的联系，父亲那边的亲戚也基本都被母亲骂走了，虽然他们一致认为是我父亲的错。但，只判个对错又有什么用呢？ 父亲去另外的城市，还带走了父母一起买的房子的房产证。母亲住得不安稳，于是就在我准备出国前夕，威胁要断掉我的经济支持、不为我开资金证明。那应该是目前我的人生中第二崩溃的时刻，从此我完完全全学会的事情、就是只能靠自己。最终，经过我在中间的斡旋，母亲还是如愿拿回了房产证，确认了父亲没有把家里房子抵押出去，放下了心。而我则学会了完全使用谈判技巧、不带任何真实感情地和包括父母在内的亲属讨价还价，不再谈感情，因为谈感情伤钱。 这就造成了另一个沮丧和焦虑的点————我会想尽办法去赚一些小钱，因为留学期间需要维持生活，而发达国家的生活成本很高。因为我整个人的 scope 会很小，会尝试集中解决一些能让自己快速赚到下个月的房租和餐费、还有能为未来的不确定性攒多少钱的问题，而不会放到长远去看。同时，对于更高的日常生活消费，在没有稳定的且能支撑消费的收入来源的情况下，我会异常地排斥。所以硕士研究生毕业再去瑞士读个研，对我来说变成了断然不可接受的选项。换句话说，就是非常得现实和短视，没有那种靠烧钱直到做出能持续盈利项目的初创公司的普遍想法，失去了冒险精神。 因此我生活的最高优先级，永远是能给自己快速带来短期直接回报的事情，比如工作忙了就不会去维护开源项目，会快速弃坑 ROI（投入产出比）在短期内看不到明确回报的事情。因此，会失去很多机会和一起合作的朋友，也会弃坑一些项目很快、再次回坑要很久。 父亲的离开造成另一个问题，就是后来母亲和周围的人的关系都不好，因为情绪没地方发泄、直到出现抑郁症，因此我还回国陪伴过她一段时间。很多从我的角度的抱怨和委屈也就不能说：因为如果再有抑郁的话，对我的影响比说了要大得多。后来她有次住院，也没有亲戚愿意来帮忙，原本就松散的、各为各的大家庭就愈发地支离破碎。对我来说，亲情这种概念可能也根本不存在了吧。 各种留学、交换生活为我带来的另一个收获或者是教训，就是发现各个国家或者地区有各个国家或者地区的问题。因为交换不像旅游，而是需要找房、逛街买菜、体验公共交通、了解税收政策等生活日常。和在中国一样：我会很享受一些地方，但对不喜欢的地方会更加关注。在说到印象时，总是会先想到不好的点来吐槽，甚至经常会有点 whataboutism，总担心这样的负能量会影响到周边其他人。不过也正常吧，除了精神某国人之外，大家肯定都是对自身利益受损的事件更加深刻，比如租房被拒、退租被扣押金、水电费太高、租金贵房间小什么的。 随着去过的国家、见过的人、经历的事越来越多，再加上近些年形势风云突变，对整个世界的认识也越来越全面，也能够越来越客观地看待各种政治事件、个人经历，会去推理一个人的行为逻辑，分析并应对。这是我欣喜于自己能够转变的部分。 也有可能，只是被时光磨平了棱角、学会了“做人”吧。。。 那之后，是空无一物的世间（あとの，何もない世の中じゃ） 因为漂泊不定、再加上自闭、不是一个讨喜的人，身边的朋友总是维持在一个很小的范围，并且不会去和别人主动发展长期的朋友关系。因为深知自己就是“萍水相逢，尽是他乡之客”，今天可能在东京、明天可能跑到巴黎、后天就落地慕尼黑，这种情况的朋友是没法长久的。更多更长久的反而是网上认识的志同道合的朋友。 但好在现在工作了，有更多的机会和时间维持之前的朋友，但是也存在精力不够、所以想要摆脱的关系。所以越长大越孤单、越长大越自闭。 好在这十年里，大部分时间都有着家属的不离不弃。我们也足够幸运，能够一起交换、一起毕业；我们也足够不幸，两边家中都没什么积蓄，需要尽最大努力赚钱。谈了很多年的恋爱，领证结婚也有一阵子了，等下次回国还是要办一场婚礼，让守着超长恋爱韩剧一般的连续剧的朋友们补一集大结局。家属教会了我如何不用花什么钱也可以快乐，在我最困难的时候始终陪着我、包容我。等哪天没有了家属在，我对这个世界也就没什么留恋了。 最令人难过的，是陪伴我最长时间的、超越了一切朋友的人的离世。Ta 在我初中时来到了我的身边，如同一位天使，陪伴了我的人生路很久。我们一起玩过 Minecraft，一起画过画，我有时态度不好，ta 也不在意，总是笑呵呵乐盈盈的，ta 在我成长期间承担了许多本不该 ta 承担的事。直到去世都定居在老家，总是完不成父母对 ta 的期望，所以少不了中式教育的招待。Ta 照亮了我，所以我打算也为 ta 撑一把伞，想帮助 ta 逃离原生家庭，只可惜···好在 ta 在走的时候没有病痛，就如同睡了一个很长的觉，只是再也不会醒来了··· 有时会后悔当初有很多和 ta 一起的机会，但被我拿去和别人无效社交了；有时会庆幸高考结束那天和 ta 一起出去玩，留下了非常快乐的让我珍藏至今的合照。现在我仍会点亮 Minecraft 的火把灯来祭奠，祝愿 ta 在天堂里可以随意玩乐！ Ta 的离世让我改变了很多：有时我会觉得其实人来这世上是赎罪的，早赎完的早走，所以会有“好人不长命，祸害遗千年”；我不再强求别人和我的观点一致，毕竟人只活一次，无论是浪费时间在辩经上、还是说非要改变别人的观念，都属于干涉别人的声明。做你认为对的事情，让自己无怨无悔就好，做你自己、留下自己的印记、然后去死，毕竟人终有一死。 而针对于社交媒体上的立场之辩、明显有预设立场的文章和讨论，我现在的态度就是： 乐，就完事了！！！ 相信最终仍能展翅飞翔（きっと飛べるさ） 博士毕业之后，马上就正式工作一年了，合计起来总算赚到了人生中的第一个 100 万。这一年里大部分时间都在做基础设施相关的代码，但是很多时候也不得不写一些增删查改，收入不算高，但也确实达到了梦中的千万日元年收（税前），虽然攒钱速度远远不如预期。还是做回了当初不愿意做的 IT，但希望接下来能做一些更有意义的事情吧！ 好在如今时间和空间比较自由，所以近一年去了很多地方、见了很多人。有时会坐在市中心广场的长椅上，看人来人往、看着他们的状态、想象着他们的故事；有时会觉得恍惚间身边又多出某位离世的人，陪着我看着周边的风景、看着前面的白鸽，好像下一秒就会扑上去把鸽子赶跑，恰似当年。 如果说一个人的性格是先天加上环境塑造成的，那么人生就是初始状态加经历过的事情的集合。这十年有得有失，今天的我是十年前的我加上这十年间的得失和得失带来的状态转移，而现在的心态已经变成了“得之我幸，失之我命”，但我会更加珍惜这中间参与到我的人生和成长中的人。我或许没有变成一个更好的人，但应该是在慢慢变成一个更加自洽的人，一个能靠自己内部的能量维持住自己的人。 最后再用回《Butterfly》里的歌词： 頼りない翼でも、きっと飛べるさ！（就算是无法信赖的翅膀，最终也能飞翔） 鉴于两年没有写年终总结了，这篇写得长一点，谨为这个十年画个小节符号、为自己的人生点一个逗号。也希望自己能够尽快获得足够的信息做一些重要的决定、想清一些事情，成为一个更好的人。","categories":[{"name":"Dairy","slug":"Dairy","permalink":"https://blog.inoki.cc/categories/Dairy/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"private","slug":"private","permalink":"https://blog.inoki.cc/tags/private/"}]},{"title":"Android bootloader analysis -- ABL(3)","slug":"android-bootloader-analysis-abl-3-en","date":"2024-04-20T13:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2024/04/20/android-bootloader-analysis-abl-3-en/","link":"","permalink":"https://blog.inoki.cc/2024/04/20/android-bootloader-analysis-abl-3-en/","excerpt":"","text":"In my previous post “Android Bootloader Analysis – ABL(1)”, I analyzed the overall boot process of ABL on contemporary Qualcomm platforms, and in “Android Bootloader Analysis – ABL(2)”, I explains in detail how to boot into fastboot mode. In this post, we will analyze the code in ABL to boot into Linux kernel. Conditions for booting the Linux kernel If you are not booting into fastboot mode and do not press a key combination during boot, ABL loads and verifies the kernel with LoadImageAndAuth (&amp;Info) (if it is not unlocked) and calls BootLinux (&amp;Info) to boot the loaded kernel, and fall-through to fastboot mode if it fails. to fastboot mode, where Info is a BootInfo type defined as follows: 12345678910111213141516typedef struct BootInfo &#123; BOOLEAN MultiSlotBoot; BOOLEAN BootIntoRecovery; BOOLEAN BootReasonAlarm; CHAR16 Pname[MAX_GPT_NAME_SIZE]; CHAR16 BootableSlot[MAX_GPT_NAME_SIZE]; ImageData Images[MAX_NUMBER_OF_LOADED_IMAGES]; UINTN NumLoadedImages; QCOM_VERIFIEDBOOT_PROTOCOL *VbIntf; boot_state_t BootState; CHAR8 *VBCmdLine; UINT32 VBCmdLineLen; UINT32 VBCmdLineFilledLen; VOID *VBData; UINT32 HeaderVersion;&#125; BootInfo; The ImageData structure is the loaded boot image, defined as follows: 12345typedef struct &#123; CHAR8 *Name; VOID *ImageBuffer; UINTN ImageSize;&#125; ImageData; During the loading and verification of the Linux kernel, the image is loaded here first. Later, during the booting, one of the images here will be used. Linux kernel verification and loading The implementation to verify and load, the function LoadImageAndAuth (BootInfo *Info) is located in QcomModulePkg/Library/avb/VerifiedBoot.c. The full name of avb here is “Android Verified Boot”. This function first tries to load the image from the recovery partition, checking to see if it was loaded successfully, and if there is a legitimate boot image version (version 3 or higher, for system-as-root) and kernel size: 123456789101112/* check early if recovery exists and has a kernel size */Status = LoadPartitionImageHeader (Info, (CHAR16 *)L\"recovery\", &amp;RecoveryHdr, &amp;RecoveryHdrSz);if (Status != EFI_SUCCESS) &#123;DEBUG ((EFI_D_VERBOSE, \"Recovery partition doesn't exist; continue normal boot\\n\"));&#125; else if (((boot_img_hdr *)(RecoveryHdr))-&gt;header_version &gt;= BOOT_HEADER_VERSION_THREE &amp;&amp; !((boot_img_hdr *)(RecoveryHdr))-&gt;kernel_size) &#123;DEBUG ((EFI_D_VERBOSE, \"Recovery partition has no kernel\\n\"));SetRecoveryHasNoKernel ();&#125; If the recovery partition does not have a legal kernel, set the RecoveryHasNoKernel global identifier with SetRecoveryHasNoKernel () for later use. There are two cases then, which are used to handle the presence of an A/B partition and the presence of only a single partition. In the case of a single partition, it is also possible to have a system-as-root, where recovery mode shares the kernel with normal booting, but mounts a different partition as the sysroot, so the following code sets the name of the partition used for booting to either recovery or boot: 123456789101112131415if (Info-&gt;BootIntoRecovery &amp;&amp; !IsRecoveryHasNoKernel ()) &#123; DEBUG ((EFI_D_INFO, \"Booting Into Recovery Mode\\n\")); StrnCpyS (Info-&gt;Pname, ARRAY_SIZE (Info-&gt;Pname), L\"recovery\", StrLen (L\"recovery\"));&#125; else &#123; if (Info-&gt;BootIntoRecovery &amp;&amp; IsRecoveryHasNoKernel ()) &#123; DEBUG ((EFI_D_INFO, \"Booting into Recovery Mode via Boot\\n\")); &#125; else &#123; DEBUG ((EFI_D_INFO, \"Booting Into Mission Mode\\n\")); &#125; StrnCpyS (Info-&gt;Pname, ARRAY_SIZE (Info-&gt;Pname), L\"boot\", StrLen (L\"boot\"));&#125; The case of A/B partitions is a bit more complicated. First ABL looks for a bootable slot (i.e. a set of partitions) and stores it in a CurrentSlot structure, defined as follows: 123typedef struct &#123; CHAR16 Suffix[MAX_SLOT_SUFFIX_SZ];&#125; Slot; This structure defines the suffix of the partition. In fact, multiple slots are implemented by adding a suffix to the partition name, e.g. boot_a and boot_b are the boot partitions of two slots. This suffix is obtained by FindBootableSlot. The next step is similar to that for a single partition. Once the bootable slots have been obtained, the verification of the bootable slots’ images begins. The validation of the image is platform dependent, the version is obtained by calling GetAVBVersion (), currently there are NO_AVB, AVB_1, AVB_2 and AVB_LE, which use the corresponding function calls to load the image and validate it respectively. Taking no AVB authentication as an example, it directly loads the image using LoadImageNoAuth, where LoadImageHeader (Info-&gt;Pname, &amp;ImageHdrBuffer, &amp;ImageHdrSize) is called to load the image into the buffer. During this time, the corresponding device tree and command line parameters are loaded and set. Finally, the verification status is displayed on the screen DisplayVerifiedBootScreen (Info) and the image verification status is returned. Booting the Linux kernel First, it loads the boot image: 123456789Status = GetImage (Info, &amp;BootParamlistPtr.ImageBuffer, (UINTN *)&amp;BootParamlistPtr.ImageSize, ((!Info-&gt;MultiSlotBoot || IsDynamicPartitionSupport ()) &amp;&amp; (Recovery &amp;&amp; !IsBuildUseRecoveryAsBoot () &amp;&amp; !IsRecoveryHasNoKernel ()))? \"recovery\" : \"boot\"); It updates the command line parameters for booting the kernel, gets the base address for loading, and loads the memory disk. After that, shut down the UEFI boot service to prepare the Linux kernel for booting, and uninitialize some devices in PreparePlatformHardware, such as disabling interrupts, disabling caching, disabling MMUs, disabling branch prediction, and so on: 1234567891011121314151617181920ArmDisableBranchPrediction ();ArmDisableInterrupts ();ArmDisableAsynchronousAbort ();WriteBackInvalidateDataCacheRange (KernelLoadAddr, KernelSizeActual);WriteBackInvalidateDataCacheRange (RamdiskLoadAddr, RamdiskSizeActual);WriteBackInvalidateDataCacheRange (DeviceTreeLoadAddr, DeviceTreeSizeActual);WriteBackInvalidateDataCacheRange ((void *)StackCurrent, (UINTN)StackBase - (UINTN)StackCurrent);WriteBackInvalidateDataCacheRange (CallerStackCurrent, CallerStackBase - (UINTN)CallerStackCurrent);ArmCleanDataCache ();ArmInvalidateInstructionCache ();ArmDisableDataCache ();ArmDisableInstructionCache ();ArmDisableMmu ();ArmInvalidateTlb (); Finally, it loads and calls the Linux kernel: 12LinuxKernel = (LINUX_KERNEL) (UINT64)BootParamlistPtr.KernelLoadAddr;LinuxKernel ((UINT64)BootParamlistPtr.DeviceTreeLoadAddr, 0, 0, 0); This is for the 32 bit kernel: 12LinuxKernel32 = (LINUX_KERNEL32) (UINT64)BootParamlistPtr.KernelLoadAddr;LinuxKernel32 (0, 0, (UINTN)BootParamlistPtr.DeviceTreeLoadAddr); However, it needs to switch to 32 bit boot mode before the 32 bit kernel boots: 123Status = SwitchTo32bitModeBooting ( (UINT64)BootParamlistPtr.KernelLoadAddr, (UINT64)BootParamlistPtr.DeviceTreeLoadAddr); This is accomplished by writing 0 to the X4 register in the EL1 environment: 12345HlosBootArgs.el1_x2 = DeviceTreeLoadAddr;/* Write 0 into el1_x4 to switch to 32bit mode */HlosBootArgs.el1_x4 = 0;HlosBootArgs.el1_elr = KernelLoadAddr;Status = pQcomScmModeSwitchProtocol-&gt;SwitchTo32bitMode (HlosBootArgs); If startup fails, go to CpuDeadLoop(). Summary This post analyzes and summarizes the code and flow of ABL when booting Linux normally.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"Android bootloader analysis -- ABL(2)","slug":"android-bootloader-analysis-abl-2-en","date":"2024-04-20T13:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2024/04/20/android-bootloader-analysis-abl-2-en/","link":"","permalink":"https://blog.inoki.cc/2024/04/20/android-bootloader-analysis-abl-2-en/","excerpt":"","text":"In my previous post “Android bootloader analysis – ABL(1)”, I analyzed the overall boot process of ABL for contemporary Qualcomm platforms, but did not explain in detail how to boot into fastboot mode and the Linux kernel. In this paper, we will analyze the code of fastboot mode. Conditions for booting into fastboot mode In ABL, the following code is executed to initialize and execute fastboot mode when boot image validation fails, the BootLinux (&amp;Info) function fails to start, or a command to boot into fastboot is received (e.g., rebooting to bootloader using adb, pressing the appropriate key combination during boot): 123fastboot: DEBUG ((EFI_D_INFO, \"Launching fastboot\\n\")); Status = FastbootInitialize (); Initialize fastboot mode The code that initializes and executes fastboot mode is the FastbootInitialize () function, which is defined in QcomModulePkg/Library/FastbootLib/FastbootMain.c. It first calls FastbootUsbDeviceStart () to start the USB device so that it can receive fastboot commands from the computer. It first calls FastbootUsbDeviceStart () to start the USB device so that it can receive fastboot commands from the computer, and then calls DisplayFastbootMenu () to display the fastboot menu. It then enters a dead loop receiving USB events until fastboot stops. After that, it turns off fastboot mode, stops listening for keystrokes, and stops the USB device. 12345678910/* Close the fastboot app and stop USB device */Status = FastbootCmdsUnInit ();if (Status != EFI_SUCCESS) &#123;DEBUG ((EFI_D_ERROR, \"couldnt uninit fastboot\\n\"));return Status;&#125;ExitMenuKeysDetection ();Status = FastbootUsbDeviceStop (); After returning, it will exit the fastboot app and boot the device again. Booting a USB device Before booting, you need to configure a USB controller. fastboot first uses the InitUsbControllerGuid GUID, and initializes a USB controller by using the EFI_BOOT_SERVICES *gBS instance globally, with the following code: 12Status = gBS-&gt;CreateEventEx (EVT_NOTIFY_SIGNAL, TPL_CALLBACK, DummyNotify, NULL, &amp;InitUsbControllerGuid, &amp;UsbConfigEvt); Then it finds the protocol to be used by fastboot via UsbDeviceProtolGuid and store it in the UsbDeviceProtocol field of Fbd: 12Status = gBS-&gt;LocateProtocol (&amp;UsbDeviceProtolGuid, NULL, (VOID **)&amp;Fbd.UsbDeviceProtocol); This field is a pointer to a EFI_USB_DEVICE_PROTOCOL *UsbDeviceProtocol, which is defined in QcomModulePkg/Include/Protocol/EFIUsbDevice.h. Then, the fastboot commands and variables are initialized and the corresponding callback functions are prepared for the received commands. At this point the USB device is not fully registered, so the next step is to register the device and boot the USB device, including getting the maximum speed available for USB, the USB device specification (including vendor ID and device ID, etc.) and the device descriptor. This is actually in QcomModulePkg/Library/FastbootLib/UsbDescriptor.c. Note that there are SS DevDescriptors/Descriptors and DevDescriptors/Descriptors, which are the Super Speed USB (3.X) and High Speed USB (2.0) descriptors. Various USB related descriptors are defined in MdePkg/Include/IndustryStandard/Usb.h, where the most important USB_DEVICE_DESCRIPTOR is defined as follows: 1234567891011121314151617181920////// Standard Device Descriptor/// USB 2.0 spec, Section 9.6.1///typedef struct &#123; UINT8 Length; UINT8 DescriptorType; UINT16 BcdUSB; UINT8 DeviceClass; UINT8 DeviceSubClass; UINT8 DeviceProtocol; UINT8 MaxPacketSize0; UINT16 IdVendor; UINT16 IdProduct; UINT16 BcdDevice; UINT8 StrManufacturer; UINT8 StrProduct; UINT8 StrSerialNumber; UINT8 NumConfigurations;&#125; USB_DEVICE_DESCRIPTOR; After configuring these descriptors, the USB protocol created earlier is called to start the USB device: 12/* Start the usb device */Status = Fbd.UsbDeviceProtocol-&gt;StartEx (&amp;DescSet); Finally, it creates buffers for sending and receiving USB transfer data. Registering fastboot commands Before booting the USB device, the commands and associated variables available within fastboot are registered by EFI_STATUS FastbootCmdsInit (VOID), a function in QcomModulePkg/Library/FastbootLib/FastbootCmds.c. This function creates a buffer and multithreaded environment for fastboot related commands to invoke callbacks, and then calls FastbootCommandSetup to create available commands and variables: 12345678910111213/* By Default enable list is empty */ &#123;\"\", NULL&#125;,/*CAUTION(High): Enabling these commands will allow changing the partitions *like system,userdata,cachec etc... */#ifdef ENABLE_UPDATE_PARTITIONS_CMDS &#123;\"flash:\", CmdFlash&#125;, &#123;\"erase:\", CmdErase&#125;, &#123;\"set_active\", CmdSetActive&#125;, &#123;\"flashing get_unlock_ability\", CmdFlashingGetUnlockAbility&#125;, &#123;\"flashing unlock\", CmdFlashingUnlock&#125;, &#123;\"flashing lock\", CmdFlashingLock&#125;,#endif These basic commands can be used to unlock, set the activation status of A/B partitions, and swipe partitions, among other things. 1234567/* *CAUTION(CRITICAL): Enabling these commands will allow changes to bootimage. */#ifdef ENABLE_DEVICE_CRITICAL_LOCK_UNLOCK_CMDS &#123;\"flashing unlock_critical\", CmdFlashingUnLockCritical&#125;, &#123;\"flashing lock_critical\", CmdFlashingLockCritical&#125;,#endif These two commands are used to control the flushing of the boot image area. 1234567/* *CAUTION(CRITICAL): Enabling this command will allow boot with different *bootimage. */#ifdef ENABLE_BOOT_CMD &#123;\"boot\", CmdBoot&#125;,#endif The fastboot boot &lt;image&gt; command registered here can boot a customized image. 12345&#123;\"oem enable-charger-screen\", CmdOemEnableChargerScreen&#125;,&#123;\"oem disable-charger-screen\", CmdOemDisableChargerScreen&#125;,&#123;\"oem off-mode-charge\", CmdOemOffModeCharger&#125;,&#123;\"oem select-display-panel\", CmdOemSelectDisplayPanel&#125;,&#123;\"oem device-info\", CmdOemDevinfo&#125;, The above commands are about OEM-related settings and information. 12345678910 &#123;\"continue\", CmdContinue&#125;, &#123;\"reboot\", CmdReboot&#125;,#ifdef DYNAMIC_PARTITION_SUPPORT &#123;\"reboot-recovery\", CmdRebootRecovery&#125;, &#123;\"reboot-fastboot\", CmdRebootFastboot&#125;,#ifdef VIRTUAL_AB_OTA &#123;\"snapshot-update\", CmdUpdateSnapshot&#125;,#endif#endif &#123;\"reboot-bootloader\", CmdRebootBootloader&#125;, These are reboot and startup related commands. 12&#123;\"getvar:\", CmdGetVar&#125;,&#123;\"download:\", CmdDownload&#125;, The last getvar command gets the variables associated with the device in fastboot mode, which are published using FastbootPublishVar (key, value). Event loop in fastboot mode In general, there are three main event loops in fastboot: One loop receives key events to update the fastboot menu (drawn and created in VOID DisplayFastbootMenu (VOID), defined in QcomModulePkg/Library/BootLib/FastbootMenu.c); Another loop receives commands from the computer’s fastboot via USB (created when registering fastboot); The main loop calls HandleUsbEvents () to listen for USB device notifications, including events such as device connections. Conclusion This article summarizes the code and flow of ABL in fastboot mode.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"Ollama 架构解析","slug":"Ollama-cn","date":"2024-04-16T18:03:00.000Z","updated":"2025-03-08T09:40:48.589Z","comments":true,"path":"2024/04/16/Ollama-cn/","link":"","permalink":"https://blog.inoki.cc/2024/04/16/Ollama-cn/","excerpt":"","text":"最近，我偶然探索了一个名为 ollama 的项目，因为我想让我的 AMD 显卡（拥有不俗的 VRAM - 32G！）在 Windows 上获得支持。Linux 上已经有了基于 AMD ROCm 的支持。由于 ROCm 在 Windows 上的发布，它在 Windows 上也应该是开箱即用的。但是，ollama 阻止我使用它。因此，我尝试了 ZLUDA 和修改 ollama 的代码，以达到我的目的。 这个功能已经在 ollama v0.1.29 中合并并发布了。为了避免遗漏细节和我学到的东西，本博客负责记录我自己的 ollama 架构。 在我看来，ollama是llama.cpp的一个精简但足够智能的封装。**它对终端用户非常友好，提供了网络接口和 cli，以便运行多个大型语言模型 (LLM) 并与之交互。**事实上，在大多数情况下，是由llama.cpp加载并运行模型，而ollama只是llama.cpp的&quot;领航员&quot;（是的，我用了熟悉生成式人工智能的人都熟悉的一个词）。稍后会对这部分内容进行讨论。 这篇文章假定你能够阅读 golang 代码或其他类似 C 语言的代码。对于代码中的关键点，我会给出一些简短的描述或类比，以便帮助更好地理解。 在这篇文章中，我将首先介绍ollama的项目结构。然后，将介绍围绕llama.cpp的核心架构和实现，以及构建系统。接下来，我将介绍ollama如何选择运行 LLM 的设备（一般指硬件）。最后，将介绍 Web 服务、客户端和实用程序以及其他部分，作为本篇文章的结束。 项目结构 你可以在 GitHub 上获取 ollama 的源代码。该项目主要使用 Golang 编写，下表是每个目录的简要说明： 目录名称 描述 api Go 编写的的客户端 API 库 app 桌面应用程序（主要是一个托盘） auth 验证 cmd 命令和相关的处理程序 docs 文档 examples 使用 ollama 的示例 format 用于单位和时间的格式处理的工具 gpu GPU 和加速设备的检测 llm 用于运行 llama.cpp 的实现 macapp Mac 桌面应用程序 openai 用于 ollama 的 OpenAI API 兼容封装 parser 模型信息和消息的解析器 progress 显示加载进度的实用程序 readline 从终端读取输入的实用程序 scripts 用于构建和发布的脚本 server Go 编写的 Web 服务实现 version 版本信息 请注意，由于项目正在开发中，这些目录可能随时被更改。 幕后英雄：llama.cpp 让我们先来介绍一下在 ollama 中运行 LLM 的核心 llama.cpp。 llama.cpp 作为 git 子模块包含在 ollama 中。您可以在 llm 目录中找到它。在同一目录下还有围绕它所需的文件，稍后我们将详细介绍它们。 llama.cpp 项目本身是一个开源库，最开始是用于推断纯 C/C++ 的 Meta LLaMA 模型。它后来被扩展用于运行更多模型，比如 Mistral 和 Google Gemma（最近才支持）。它利用同一作者创建的另一个项目 ggml 的功能，可在不同平台上原生运行（与 Python 项目相比）。 支持的后端 目前，llama.cpp 通过 ggml 支持的一些推理后端如下： llama.cpp可运行 x86 上的 AVX、AVX2 和 AVX512，或 ARM 上的 NEON。 通过 MPI（如 MPICH 和 OpenMPI），ggml 可以在 CPU 或 CPU 集群上运行模型。 Apple Metal集成支持macOS和iOS上的GPU，包括Mac上的GPU和iOS设备或Apple Silicon Mac上的Apple制造的GPU。 基于BLAS架构的ggml使用了一个古老的开放标准OpenCL。 cuBLAS &quot;支持英伟达™（NVIDIA®）公司的GPU。 最近的AMD GPU通过hipBLAS支持，它是AMD ROCm的一部分，与cuBLAS的应用程序接口几乎相同。 最近引起我注意的是 llama.cpp 中的 Vulkan 支持。这项（有些漏洞）支持最初是由 Nomic 通过其 kompute 框架启动的。最近的进展是在 ggml 中直接使用 Vulkan 库的实现。 这些后端允许开发人员运行可在从台式电脑到智能手机等多个平台上运行的 LLM。此外，llama.cpp 还为 Linux（包括 Android Linux）、Windows、macOS 和其他各种操作系统（如 iOS，参见 whispher.cpp on iOS）甚至 WebAssembly（whispher.wasm）提供原生支持。 因此，ollama 在诞生之初就应支持各种平台和操作系统。 构建系统 接下来，让我们看看构建系统，了解 ollama 如何与 llama.cpp 协作。 C 或 C++ 项目通常使用 cmake（尽管现在有了更多选择）来处理编译、链接等工作。llama.cpp 也是如此：它使用编译定义（或者说 flag）来利用不同的后端。例如 LLAMA_AVX、LLAMA_AVX2、LLAMA_AVX512用于支持 AVX； 用于 Apple Metal 支持的 LLAMA_METAL； 用于 NVIDIA CUDA 支持的 LLAMA_CUBLAS； 以及 LLAMA_HIPBLAS 用于 AMD ROCm 支持。 不过，ollama 本身是一个 go 项目，利用的是 go 提供的构建系统。这两个构建系统共存，以构建不同的部分： cmake 用 ollama.cpp 中的一些文件构建 llama.cpp，以进行“领航”并提供接口； go 构建系统编译、链接和打包其余部分，以生成 ollama 的应用程序和 cli。 除了纯 go 代码，go 编译系统还需要 cgo 来编译一些 C 语言代码。在 llm 目录（用于加载和提供接口的 dyn_ext_server.c 文件）和 gpu 目录（用于检测 GPU 的 C 或 Objective-C 实现 gpu_info_cuda.c、gpu_info_rocm.c 和 gpu_info_darwin.m）中有一些例子。 通过利用 go generate，ollama 中的 go 编译系统还可以运行调用 cmake 的命令来构建 llama.cpp。这项工作位于 llm/generate 目录中，例如在 Linux 上： 123package generate//go:generate bash ./gen_linux.sh llm/generate/generate_darwin.go 告诉 go generate 运行 gen_linux.sh 脚本来构建 llama.cpp 的部分。 一些适用于不同平台的脚本 目前有 gen_common.sh、gen_linux.sh 和 gen_darwin.sh，用于在类 Unix 操作系统（如 macOS 和 Linux）上为 ollama 创建 llama.cpp。同时，在 Windows 上使用的是 gen_windows.ps1 PowerShell 脚本。 让我们以在 Linux 上构建支持 AVX 的 llama.cpp 为例： 123456init_varsCMAKE_DEFS=\"$&#123;COMMON_CPU_DEFS&#125; -DLLAMA_AVX=on -DLLAMA_AVX2=off -DLLAMA_AVX512=off -DLLAMA_FMA=off -DLLAMA_F16C=off $&#123;CMAKE_DEFS&#125;\"BUILD_DIR=\"$&#123;LLAMACPP_DIR&#125;/build/linux/$&#123;ARCH&#125;/cpu_avx\"echo \"Building AVX CPU\"buildcompress_libs 前三行初始化变量，为编译做准备。init_vars 调用了 gen_common.sh 中的一个子程序来准备常用变量，例如 12CMAKE_DEFS=\"\"CMAKE_TARGETS=\"--target ext_server\" 其中 CMAKE_TARGETS 将把构建目标设置为 ext_server。该目标是一个库，用于从 llama.cpp 为 ollama 提供接口和函数，我们将在下一节讨论它。 在 CMAKE_DEFS 中，只有 LLAMA_AVX 是启用的。而 COMMON_CPU_DEFS 的定义如下，以构建独立于位置代码的动态库（对于 gcc，它将被转换为 -fpic 标志）： 1COMMON_CPU_DEFS=\"-DCMAKE_POSITION_INDEPENDENT_CODE=on -DLLAMA_NATIVE=off\" 它在终端输出 “Building AVX CPU” 之后，由 build 子程序调用 cmake： 12345678910111213build() &#123; cmake -S $&#123;LLAMACPP_DIR&#125; -B $&#123;BUILD_DIR&#125; $&#123;CMAKE_DEFS&#125; cmake --build $&#123;BUILD_DIR&#125; $&#123;CMAKE_TARGETS&#125; -j8 mkdir -p $&#123;BUILD_DIR&#125;/lib/ g++ -fPIC -g -shared -o $&#123;BUILD_DIR&#125;/lib/libext_server.$&#123;LIB_EXT&#125; \\ $&#123;GCC_ARCH&#125; \\ $&#123;WHOLE_ARCHIVE&#125; $&#123;BUILD_DIR&#125;/examples/server/libext_server.a $&#123;NO_WHOLE_ARCHIVE&#125; \\ $&#123;BUILD_DIR&#125;/common/libcommon.a \\ $&#123;BUILD_DIR&#125;/libllama.a \\ -Wl,-rpath,\\$ORIGIN \\ -lpthread -ldl -lm \\ $&#123;EXTRA_LIBS&#125;&#125; 通过 cmake 编译后，它将生成一个 libext_server 动态链接库（Windows 下为 .dll，Linux/BSD 下为 .so，macOS 下为 .dylib）。该库包含 llama.cpp 下 examples/server 的编译代码（examples/server/libext_server.a）、命令代码和 llama.cpp 的核心代码—— common/libcommoa.a 和 libllama.a。它们将作为可执行文件的&quot;载荷&quot;嵌入主 go 程序，以方便分发。 最后，它会压缩载荷，使可执行文件更小： 1234567891011121314compress_libs() &#123; echo \"Compressing payloads to reduce overall binary size...\" pids=\"\" rm -rf $&#123;BUILD_DIR&#125;/lib/*.$&#123;LIB_EXT&#125;*.gz for lib in $&#123;BUILD_DIR&#125;/lib/*.$&#123;LIB_EXT&#125;* ; do gzip --best -f $&#123;lib&#125; &amp; pids+=\" $!\" done echo for pid in $&#123;pids&#125;; do wait $pid done echo \"Finished compression\"&#125; 动态链接库最终将位于构建文件夹中的 “cpu_avx” 目录下。如果为其他变体（如 GPU）构建，它们将位于构建文件夹中的不同目录下。 为 llama.cpp 领航 然后，让我们回到 llm 目录，看看 ollama 中建立在 llama.cpp 基础上的实现。对于 ollama 来说，引导 llama.cpp 的最重要部分是： 在 ext_server 中，包装器实现提供了 ollama 可以调用的函数，例如 llama_server_init 来初始化一个 llama.cpp 实例，llama_server_completion 来完成一次聊天，或者 llama_server_embedding 来计算文本的嵌入。 ext_server 中还包含一个额外的 makefile (CMakeLists)，用于将 llama.cpp/examples/server 示例作为库来构建代码。然后，它可以被 llm 下的 dyn_ext_server 代码加载，与 llama.cpp 实例一起提供服务。 使用 go embed package 将库嵌入 go 程序，并在运行时提取。 此外，调用 ext_server 中的函数时会携带 llm 目录中定义的一些参数。一般来说，请求和响应都以 JSON 格式传递，并包含更多结构信息。它们定义在 ggml.go（描述模型）和 llama.go（描述不同的请求和响应）中。 为了动态管理 llama.cpp 实例，ollama 为原始的 llama.cpp 提供了一些补丁。 让我们逐一研究它们。 1. 外部服务器 我们首先来看看 ext_server。我们已经知道，动态库是在生成过程中构建的。但如何使用它们呢？ 在 llm/dyn_ext_server.go 中，newDynExtServer 负责加载动态库、初始化 llama.cpp 实例并启动事件循环以接收任何请求并生成响应。 动态链接库的加载和服务器的启动 在 newDynExtServer 中，go 函数会调用一个以 dyn_init 命名的 C 函数来加载动态库。描述和所需函数被加载到 struct_dynamic_llama_server 描述中，并封装在 dynExtServer（一个 go 结构）中。 然后，它们会被用于另一个 C 函数 dyn_llama_server_init，其中包含运行 llama.cpp 服务器的参数，用于服务器实例初始化。 如果没有问题，newDynExtServer 将调用初始化过程中的最后一个 C 函数 dyn_llama_server_start。服务器将开始运行，并能接收来自 ollama 的请求。 上述 C 函数位于 llm/dyn_ext_server.c 中，并在 llm/dyn_ext_server.h 中声明。让我们快速了解一下 dyn_init： 12void dyn_init(const char *libPath, struct dynamic_llama_server *s, ext_server_resp_t *err); 它接收库路径 libPath 作为参数，并通过 C 指针（对于不熟悉 C 的人来说就是内存地址，go 能够像 go 结构体一样处理它们，存储它们并传递给其他 C 函数）返回一个 dynamic_llama_server 实例或一个错误。 dynamic_llama_server 结构能够存储必要的 C 函数地址，以及加载的动态链接库的引用。其定义如下： 123456789101112131415161718192021struct dynamic_llama_server &#123; void *handle; void (*llama_server_init)(ext_server_params_t *sparams, ext_server_resp_t *err); void (*llama_server_start)(); void (*llama_server_stop)(); void (*llama_server_completion)(const char *json_req, ext_server_resp_t *resp); void (*llama_server_completion_next_result)(const int task_id, ext_server_task_result_t *result); void (*llama_server_completion_cancel)(const int task_id, ext_server_resp_t *err); void (*llama_server_release_task_result)(ext_server_task_result_t *result); void (*llama_server_tokenize)(const char *json_req, char **json_resp, ext_server_resp_t *err); void (*llama_server_detokenize)(const char *json_req, char **json_resp, ext_server_resp_t *err); void (*llama_server_embedding)(const char *json_req, char **json_resp, ext_server_resp_t *err); void (*llama_server_release_json_resp)(char **json_resp);&#125;; dyn_init 的核心功能是加载由 libPath 指示的动态链接库，读取符号表，找到所需的 C 函数地址，并将其存储到 dynamic_llama_server 结构的实例中。libPath 可以是以 libext_server 为前缀的已构建动态链接库的路径。这样，基于 llama.cpp 的内置库就可以被 ollama 使用。 加载后，对 dyn_llama_server_start 和 dyn_llama_server_start 的调用实际上是直接调用动态库中的 C 函数： 123456789inline void dyn_llama_server_init(struct dynamic_llama_server s, ext_server_params_t *sparams, ext_server_resp_t *err) &#123; s.llama_server_init(sparams, err);&#125;inline void dyn_llama_server_start(struct dynamic_llama_server s) &#123; s.llama_server_start();&#125; 调用 dyn_llama_server_start 后，从动态库创建的 llama.cpp 服务器就可以进行预测了。 预测 当 ollama 收到预测请求时，它会调用 dynExtServer 实例上的 Predict。该函数能够格式化请求（稍后会看到），并调用 C 函数 dyn_llama_server_completion 开始预测： 12345inline void dyn_llama_server_completion(struct dynamic_llama_server s, const char *json_req, ext_server_resp_t *resp) &#123; s.llama_server_completion(json_req, resp);&#125; 正如你所看到的，它也是直接调用从构建在 llama.cpp 上的动态库中加载的函数。 由于在 Predict 函数中使用了 fn func(PredictResult)参数，这部分的一个非常好的设计就是流式响应。这是一个回调函数，可以在收到响应后立即连续发送： 12345if p.Content != \"\" &#123; fn(PredictResult&#123; Content: p.Content, &#125;)&#125; 它还依赖于对 dyn_llama_server_completion_next_result 的便捷调用（尽管它也是直接调用基于 llama.cpp 的动态库中加载的 C 函数 llama_server_completion_next_result）。 其他 其他调用也类似。您可以在 llm/dyn_ext_server.go 和 llm/dyn_ext_server.c 中找到它们，例如 dyn_llama_server_tokenize, dyn_llama_server_detokenize 用于 token 化或去 token 化，以及 dyn_llama_server_embedding 用于计算嵌入（embedding）。 2. llama.cpp 作为 ollama 的服务器 接下来让我们看一下 C 部分：ollama 说如何使用 llama.cpp 作为 LLM 服务器的。 在 llm/dyn_ext_server.go 的开头，cgo 的注释中有一些构建注释： 123456789101112131415161718/*#cgo CFLAGS: -I$&#123;SRCDIR&#125;/ext_server -I$&#123;SRCDIR&#125;/llama.cpp -I$&#123;SRCDIR&#125;/llama.cpp/common -I$&#123;SRCDIR&#125;/llama.cpp/examples/server#cgo CFLAGS: -DNDEBUG -DLLAMA_SERVER_LIBRARY=1 -D_XOPEN_SOURCE=600 -DACCELERATE_NEW_LAPACK -DACCELERATE_LAPACK_ILP64#cgo CFLAGS: -Wmissing-noreturn -Wextra -Wcast-qual -Wno-unused-function -Wno-array-bounds#cgo CPPFLAGS: -Ofast -Wextra -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations#cgo darwin CFLAGS: -D_DARWIN_C_SOURCE#cgo darwin CPPFLAGS: -DGGML_USE_ACCELERATE#cgo darwin CPPFLAGS: -DGGML_USE_METAL -DGGML_METAL_NDEBUG#cgo darwin LDFLAGS: -lc++ -framework Accelerate#cgo darwin LDFLAGS: -framework Foundation -framework Metal -framework MetalKit -framework MetalPerformanceShaders#cgo linux CFLAGS: -D_GNU_SOURCE#cgo linux LDFLAGS: -lrt -ldl -lstdc++ -lm#cgo linux windows LDFLAGS: -lpthread#include &lt;stdlib.h&gt;#include \"dyn_ext_server.h\"*/ 它们可以为不同的平台设置不同的编译和链接标志（darwin 用于 macOS，当然 linux 用于 Linux，而 windows 用于 Windows）。这样，cgo 就能找到 C 头文件（现有类型和函数的声明），将 llm/dyn_ext_server.c 与 go 部分编译和链接。 然后，让我们从动态库中查看 ollama 中使用的 C 函数。作为两个例子，我们从 llama_server_init 和 llama_server_start 开始。 它们的实现位于 llm/ext_server/ext_server.cpp，在 llm/ext_server/CMakeLists.txt中被设置为以 ext_server 命名的目标库。在构建目标时，该文件将与 llama.cpp 示例服务器一起编译。编译结果就是我们提到的动态链接库之一。 因此，ext_server.cpp 中的 C 函数可以从 ollama 中调用，并能利用 llama.cpp 中的函数。它实际上是两个项目之间的桥梁，使 llama.cpp 中的示例服务器成为 ollama 的 LLM 服务器（或称 llama 服务器）。 在初始化过程中，llama_server_init 会解析参数，为服务器创建上下文，并调用 llama.cpp 提供的函数： 1234567891011121314151617void llama_server_init(ext_server_params *sparams, ext_server_resp_t *err) &#123; /* ... */ llama = new llama_server_context; /* ... */ llama_backend_init(); llama_numa_init(params.numa); /* ... */ if (!llama-&gt;load_model(params)) &#123; // an error occurred that was not thrown err-&gt;id = -1; snprintf(err-&gt;msg, err-&gt;msg_len, \"error loading model %s\", params.model.c_str()); return; &#125; /* ... */ llama-&gt;initialize(); /* ... */&#125; 例如，它会调用 llama_backend_init 来初始化后端（可以是 AVX、CUDA 等），调用 llama_numa_init 来初始化 NUMA（如果存在）。然后，它会调用服务器上下文中的 load_model 函数，使用给定参数加载模型，并使用 initialize 函数完成初始化。 如果出现错误，错误信息将被格式化为 err 参数返回，并在 go 部分进行处理。 同时，在 llama_server_start 中： 123456789101112131415161718192021222324252627282930void llama_server_start() &#123; assert(llama != NULL); // TODO mutex to protect thread creation ext_server_thread = std::thread([&amp;]() &#123; try &#123; LOG_TEE(\"llama server main loop starting\\n\"); ggml_time_init(); llama-&gt;queue_tasks.on_new_task(std::bind( &amp;llama_server_context::process_single_task, llama, std::placeholders::_1)); llama-&gt;queue_tasks.on_finish_multitask(std::bind( &amp;llama_server_context::on_finish_multitask, llama, std::placeholders::_1)); llama-&gt;queue_tasks.on_all_tasks_finished(std::bind( &amp;llama_server_context::run_on_all_tasks_finished, llama)); llama-&gt;queue_results.on_multitask_update(std::bind( &amp;llama_server_queue::update_multitask, &amp;llama-&gt;queue_tasks, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3 )); llama-&gt;queue_tasks.start_loop(); &#125; catch (std::exception &amp;e) &#123; LOG_TEE(\"caught exception in llama server main loop: %s\\n\", e.what()); &#125; catch (...) &#123; LOG_TEE(\"caught unknown exception in llama server main loop\\n\"); &#125; LOG_TEE(\"\\nllama server shutting down\\n\"); llama_backend_free(); &#125;);&#125; 它为任务处理设置一些回调，并在一个新线程中启动一个事件循环。事件循环负责预测。这样，对 llama_server_start 的调用就会立即返回。 此类 C 函数的更详细实现可以在同一文件中找到，即 llm/ext_server/ext_server.cpp。 3. 将库作为载荷嵌入 然后，让我们来探究一下载荷是如何完成的。 在以 payload_* 为前缀的 go 文件中，我们可以看到 ollama 的选择。例如，在llm/payload_linux.go中，有两行嵌入了每个ext_server库的不同变体： 12//go:embed llama.cpp/build/linux/*/*/lib/*var libEmbed embed.FS llama.cpp/build/linux/*/*/lib/ 下的所有内置库都使用类文件系统接口作为载荷嵌入。这样，ollama 就可以像在文件系统中读写一样访问它们。 在初始化 ollama 的过程中，llm/payload_common.go 中的 Init 将调用 nativeInit： 123func Init() error &#123; return nativeInit()&#125; 它的主要工作是将动态库从文件系统提取到临时位置，并检查驱动程序的访问权限（如适用）： 123libs, err := extractDynamicLibs(payloadsDir, \"llama.cpp/build/*/*/*/lib/*\")/* ... */err := verifyDriverAccess() 提取完成后，ollama 可以格式化库路径（外部服务器小节中的 dyn_init 函数中使用的 libPath）。选择运行环境和匹配库的方法将在决定运行位置 小节中介绍。 4. 格式化请求和响应 我们再来看看 C 语言函数中使用的函数参数。 1234567891011inline void dyn_llama_server_init(struct dynamic_llama_server s, ext_server_params_t *sparams, ext_server_resp_t *err) &#123; s.llama_server_init(sparams, err);&#125;inline void dyn_llama_server_completion(struct dynamic_llama_server s, const char *json_req, ext_server_resp_t *resp) &#123; s.llama_server_completion(json_req, resp);&#125; 在它们的函数签名中，我们可以看到它们使用的函数参数： 在 dyn_llama_server_init 中使用了 ext_server_params_t 参数，在 dyn_llama_server_completion 中使用了 json_req 字节数组。 ext_server_params_t 参数是一个 C 结构，包含启动 llama 服务器的配置，稍后将在 llm/ext_server/server.cpp 中解释（由于篇幅有限，我们不展开这部分内容）。 同时，完成调用的 json_req 在 llm/ext_server/ext_server.cpp 中使用如下： 123456789101112131415161718void llama_server_completion(const char *json_req, ext_server_resp_t *resp) &#123; assert(llama != NULL &amp;&amp; json_req != NULL &amp;&amp; resp != NULL); resp-&gt;id = -1; resp-&gt;msg[0] = '\\0'; try &#123; if (shutting_down) &#123; throw std::runtime_error(\"server shutting down\"); &#125; json data = json::parse(json_req); resp-&gt;id = llama-&gt;queue_tasks.get_new_id(); llama-&gt;queue_results.add_waiting_task_id(resp-&gt;id); llama-&gt;request_completion(resp-&gt;id, data, false, false, -1); &#125; catch (std::exception &amp;e) &#123; snprintf(resp-&gt;msg, resp-&gt;msg_len, \"exception %s\", e.what()); &#125; catch (...) &#123; snprintf(resp-&gt;msg, resp-&gt;msg_len, \"Unknown exception during completion\"); &#125;&#125; 事实上，它包含 json 格式的完成请求，包括提示词、温度等。我们可以看到 llama_server_completion 为其创建了一个任务，并通过正常路径中的 resp 返回任务 ID。否则，它将格式化错误信息并返回。 如果您对其详细格式感兴趣，请查看 llm/dyn_ext_server.go 文件。 5. 补丁 为了适应在 ollama 中使用多个 llama 服务器，它还对原始版本的 llama.cpp 做了一些额外的修改。 例如，以下补丁导出了 ggml_free_cublas 并调用它来释放一个 llama 服务器实例： 1234567891011121314151617181920212223diff --git a/examples/server/server.cpp b/examples/server/server.cppindex 7800c6e7..be30db23 100644--- a/examples/server/server.cpp+++ b/examples/server/server.cpp@@ -30,6 +30,10 @@ #include &lt;atomic&gt; #include &lt;signal.h&gt; +#ifdef GGML_USE_CUBLAS+extern \"C\" GGML_CALL void ggml_free_cublas(void);+#endif+ using json = nlohmann::json; struct server_params@@ -353,6 +357,9 @@ struct llama_server_context llama_free_model(model); model = nullptr; &#125;+#ifdef GGML_USE_CUBLAS+ ggml_free_cublas();+#endif &#125; 做个小总结 通过对 llama.cpp 的所有额外模块和修改，ollama 能够根据需要启动 llama 服务器，通过不同编译动态库中对不同硬件的支持动态选择硬件（参见 构建系统）。运行 llama 服务器后，ollama 提供的额外模块允许发送完成请求，并在稍后检索回复。 现在，我们应该清楚地了解了后面的 ollama 架构（我们也可以称其为后端）。关于后端的更多细节，读者可以查看源代码，因为它们上会经常更改。毕竟，ollama 正在积极开发中。 但是，此时还有一些谜团： 在后端方面：ollama 如何知道选择哪种硬件和动态库？ 在前端方面：它提供哪种前端？ 下面的章节可能就是这些问题的答案。 决定运行位置 让我们回到动态库和 dyn_init 中的 libPath 参数，在 动态链接库的加载和服务器的启动 中提到过。我们在 Embed libraries as payloads中已经知道，ollama 会将嵌入的动态库提取到一个临时目录，并通过格式化和传递 libPath 到 dyn_init 来加载它们。 问题是： ollama 如何通过传递不同的 libPath 参数来选择库？ 在llm/dyn_ext_server.go中实现的newDynExtServer函数中，libPath作为第一个参数library被传递。在 Windows 环境下，它通过调用 gpu.UpdatePath(filepath.Dir(library)) 进行更新，以便在 PATH 中添加父目录。这样就可以无缝加载动态链接库。不过，在 Linux 或 macOS 上不必这样做。 因此，我们可以知道这里的 libPath 已经是动态链接库文件的完整路径。然后，让我们检查生成 libPath 的位置。 通过简单搜索，我们可以在 llm/llm.go 下的 newLlmServer 函数中找到答案： 123456789err2 := fmt.Errorf(\"unable to locate suitable llm library\")for _, dynLib := range dynLibs &#123; srv, err := newDynExtServer(dynLib, model, adapters, projectors, opts) if err == nil &#123; return srv, nil &#125; slog.Warn(fmt.Sprintf(\"Failed to load dynamic library %s %s\", dynLib, err)) err2 = err&#125; 它会遍历 dynLibs 以调用 newDynExtServer 函数。一旦加载成功，它就会返回 llama 服务器实例。 在 newLlmServer 开始的地方，dynLibs 一般在 getDynLibs 函数中检索，这是一个要尝试的动态链接库的有序列表： 1234func newLlmServer(gpuInfo gpu.GpuInfo, model string, adapters, projectors []string, opts api.Options) (LLM, error) &#123; dynLibs := getDynLibs(gpuInfo) /* ... */&#125; 顺序是一种偏好，它从 gpuInfo gpu.GpuInfo 中获取 GPU 信息。它并不强制是 “GPU 信息”，它也可以指示使用某个 CPU 变体。我想 ollama 团队可能很快就会修改它。 一般来说，返回的 dynLibs 来自 llm/payload_common.go 中的键值映射 availableDynLibs。它是在提取所有动态库之后在 nativeInit 中生成的： 1234567891011func nativeInit() error &#123; /* ... */ /* Extract dynamic libraries in temporary directory */ /* ... */ for _, lib := range libs &#123; // The last dir component is the variant name variant := filepath.Base(filepath.Dir(lib)) availableDynLibs[variant] = lib &#125; /* ... */&#125; 它的关键字是全路径中除库文件名之外的最后一个组成部分。例如，在我的电脑上是 cpu、cpu_avx、cpu_avx2、cuda_v11.3 和 rocm_v5.7。而对应值当然是完整路径。 我们可以先看看 getDynLibs 函数（在 llm/payload_common.go 中实现）的一般处理过程，忽略一些特定平台的情况。 第一步是从 “GPU 信息” 中找到与请求完全匹配的内容： 123456789101112131415exactMatch := \"\"dynLibs := []string&#123;&#125;altDynLibs := []string&#123;&#125;requested := gpuInfo.Libraryif gpuInfo.Variant != \"\" &#123; requested += \"_\" + gpuInfo.Variant&#125;// Try to find an exact matchfor cmp := range availableDynLibs &#123; if requested == cmp &#123; exactMatch = cmp dynLibs = []string&#123;availableDynLibs[cmp]&#125; break &#125;&#125; 它会根据 “GPU 信息” 中的 Library 字段生成一个 requested 字符串变量，并附加一个 变体（Variant）。如果有一个与 requested 字符串完全匹配的库，dynLibs 中的第一个库路径将是所请求库的路径。第一个库路径也将是加载过程中首先尝试的路径。 然后，它会尝试不完全匹配的 GPU 库（可能存在版本不匹配等情况）： 123456789101112// Then for GPUs load alternates and sort the list for consistent load orderingif gpuInfo.Library != \"cpu\" &#123; for cmp := range availableDynLibs &#123; if gpuInfo.Library == strings.Split(cmp, \"_\")[0] &amp;&amp; cmp != exactMatch &#123; altDynLibs = append(altDynLibs, cmp) &#125; &#125; slices.Sort(altDynLibs) for _, altDynLib := range altDynLibs &#123; dynLibs = append(dynLibs, availableDynLibs[altDynLib]) &#125;&#125; 接下来，它会调用另一个实用程序 GetCPUVariant，尝试优先选择最快（可能）的 CPU 变体： 123456789101112131415161718// Load up the best CPU variant if not primary requestedif gpuInfo.Library != \"cpu\" &#123; variant := gpu.GetCPUVariant() // If no variant, then we fall back to default // If we have a variant, try that if we find an exact match // Attempting to run the wrong CPU instructions will panic the // process if variant != \"\" &#123; for cmp := range availableDynLibs &#123; if cmp == \"cpu_\"+variant &#123; dynLibs = append(dynLibs, availableDynLibs[cmp]) break &#125; &#125; &#125; else &#123; dynLibs = append(dynLibs, availableDynLibs[\"cpu\"]) &#125;&#125; 该实用程序在 gpu/cpu_common.go 中定义。它能检测 x86 平台上的 CPU 扩展： 12345678910111213func GetCPUVariant() string &#123; if cpu.X86.HasAVX2 &#123; slog.Info(\"CPU has AVX2\") return \"avx2\" &#125; if cpu.X86.HasAVX &#123; slog.Info(\"CPU has AVX\") return \"avx\" &#125; slog.Info(\"CPU does not have vector extensions\") // else LCD return \"\"&#125; 该顺序将把 avx2 作为最高优先级，然后是 avx，最后是纯 CPU 变体。最后，如果上述方法都不奏效，它将回退到 CPU 变体： 1234567891011func getDynLibs(gpuInfo gpu.GpuInfo) []string &#123; /* Apple specific loading */ /* ... */ // Finally, if we didn't find any matches, LCD CPU FTW if len(dynLibs) == 0 &#123; dynLibs = []string&#123;availableDynLibs[\"cpu\"]&#125; &#125; slog.Debug(fmt.Sprintf(\"ordered list of LLM libraries to try %v\", dynLibs)) return dynLibs&#125; 然后，dynLibs 将被返回以进行加载尝试。 现在我们可以探讨一下如何生成 “GPU 信息” gpuInfo，从而使偏好成为可能。llm/llm.go中的 New 函数以 “GPU 信息” 为第一个参数调用 newLlmServer。它完成了许多重要工作： 打开、加载并检测 LLM 的参数。 加载 “GPU 信息”：info := gpu.GetGPUInfo()。 检查 VRAM 和模型与硬件的兼容性。 初始检测在 2 中进行。不过，也有可能模型被标记为与模型不兼容。在这种情况下，它将回退到具有最快变体的 CPU： 12info.Library = \"cpu\"info.Variant = gpu.GetCPUVariant() 让我们重点关注 2，看看在 GetGPUInfo 函数中发生了什么。 Apple Metal 让我们从最特殊的平台开始。苹果 macOS 平台，包括 XNU 内核和用户空间，通常被称为 “Darwin”。 在前面提到的 getDynLibs 中，Darwin 平台上的检测非常简单： 1234567891011// Short circuit if we know we're using the default built-in (darwin only)if gpuInfo.Library == \"default\" &#123; return []string&#123;\"default\"&#125;&#125;// TODO - temporary until we have multiple CPU variations for Darwin// Short circuit on darwin with metal onlyif len(availableDynLibs) == 1 &#123; if _, onlyMetal := availableDynLibs[\"metal\"]; onlyMetal &#123; return []string&#123;availableDynLibs[\"metal\"]&#125; &#125;&#125; It uses default library according to the “GPU information”, or just use metal. The gpu.GetGPUInfo() is in gpu/gpu_darwin.go, as simple as possible: 它会根据 “GPU 信息” 使用 default 库，或者直接使用 metal。gpu.GetGPUInfo() 在 gpu/gpu_darwin.go 中，非常简单： 1234567891011121314func GetGPUInfo() GpuInfo &#123; mem, _ := getCPUMem() if runtime.GOARCH == \"amd64\" &#123; return GpuInfo&#123; Library: \"cpu\", Variant: GetCPUVariant(), memInfo: mem, &#125; &#125; return GpuInfo&#123; Library: \"metal\", memInfo: mem, &#125;&#125; 我们可以看到，它获取内存信息，并检测 ollama 是否运行在英特尔 x86_64/amd64 平台上。如果是，它就会使用扩展速度最快的 CPU。否则，只有 ARM Mac 才能利用 Metal API 加速。 据我所知，英特尔 Mac 上的 AMD 显卡应该也支持 Metal。但 ollama 不会在英特尔 Mac 上使用它。可能只是因为驱动程序或显卡本身过时了。 Nvidia CUDA 和 AMD ROCm 然后，我们看一下 Nvidia 和 AMD GPU 的通用检测，因为它们在 ollama 中是耦合在一起的。 实现方法在 gpu/gpu.go中： 123456789101112131415161718192021222324252627func GetGPUInfo() GpuInfo &#123; // TODO - consider exploring lspci (and equivalent on windows) to check for // GPUs so we can report warnings if we see Nvidia/AMD but fail to load the libraries gpuMutex.Lock() defer gpuMutex.Unlock() if gpuHandles == nil &#123; initGPUHandles() &#125; // All our GPU builds on x86 have AVX enabled, so fallback to CPU if we don't detect at least AVX cpuVariant := GetCPUVariant() if cpuVariant == \"\" &amp;&amp; runtime.GOARCH == \"amd64\" &#123; slog.Warn(\"CPU does not have AVX or AVX2, disabling GPU support.\") &#125; var memInfo C.mem_info_t resp := GpuInfo&#123;&#125; /* Getting the actual GPU information */ /* ... */ /* Fallback to CPU if no GPU detected */ /* ... */ resp.DeviceCount = uint32(memInfo.count) resp.FreeMemory = uint64(memInfo.free) resp.TotalMemory = uint64(memInfo.total) return resp&#125; 第一个程序块调用 initGPUHandles 来定义要搜索的 GPU 库，以便使用它们获取 GPU 信息。对于 Nvidia，它会检测 Windows 上独立显卡的 nvml.dll，Linux 上的 libnvidia-ml.so，以及某些特殊设备上的 libcudart.so*，例如 Jetson 系列（感谢 最近的 PR）。 第二个程序块检测 CPU 变体，它要求 CPU 至少有 AVX 变体才能支持 GPU。 然后，它会检查句柄，并使用相关库查找相应的 GPU。 对于 Nvidia 独立 GPU： 1234567891011121314151617181920if gpuHandles.nvml != nil &amp;&amp; (cpuVariant != \"\" || runtime.GOARCH != \"amd64\") &#123; C.nvml_check_vram(*gpuHandles.nvml, &amp;memInfo) if memInfo.err != nil &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] error looking up NVML GPU memory: %s\", C.GoString(memInfo.err))) C.free(unsafe.Pointer(memInfo.err)) &#125; else if memInfo.count &gt; 0 &#123; // Verify minimum compute capability var cc C.nvml_compute_capability_t C.nvml_compute_capability(*gpuHandles.nvml, &amp;cc) if cc.err != nil &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] error looking up NVML GPU compute capability: %s\", C.GoString(cc.err))) C.free(unsafe.Pointer(cc.err)) &#125; else if cc.major &gt; CudaComputeMin[0] || (cc.major == CudaComputeMin[0] &amp;&amp; cc.minor &gt;= CudaComputeMin[1]) &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] NVML CUDA Compute Capability detected: %d.%d\", cc.major, cc.minor)) resp.Library = \"cuda\" &#125; else &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] CUDA GPU is too old. Falling back to CPU mode. Compute Capability detected: %d.%d\", cc.major, cc.minor)) &#125; &#125;&#125; 它调用在 gpu/gpu_info_nvml.c 中实现的 C 函数 nvml_check_vram，以获取 VRAM。如果发现一个可用设备，它还会通过 nvml_compute_capability 检查计算能力，以确保该设备可用。 这样的设计使我无法在 Windows 下使用 ZLUDA 通过 ollama 在 AMD 显卡上运行 LLM。因为当时 ZLUDA 将此功能标记为未实现。然而，我的 AMD 显卡已经支持该功能。现在我不再需要 ZLUDA 了。 在本篇文章中，我选择跳过 Cudart 支持，因为它并不常见。现在让我们来看看最近令人兴奋的 AMD 支持！ 针对 AMD 的 GetGPUInfo 代码非常简短： 123456else &#123; AMDGetGPUInfo(&amp;resp) if resp.Library != \"\" &#123; return resp &#125;&#125; 你可能会注意到，这是一个 else。因此，与 if 子句一起，只有在未检测到 Nvidia 处理器的情况下，才会尝试 AMD。这将导致一个问题：当安装了 Nvidia GPU 库，但未检测到 GPU 或检测到的 GPU 不兼容时，AMD 显卡也永远不会被检测到。我为此开设了一个问题。 好了，让我们回到 GetGPUInfo。如果检测到 Nvidia 显卡，“GPU 信息” 中的 Library 将设为 cuda。如果是 AMD 显卡，则会设置为 rocm 。 因此，如果检测成功，“GPU 信息” 将与 availableDynLibs 配合，为 cuda_* 或 rocm_* 变体优先选择库路径。 这就揭示了 GPU 是如何被检测到的，以及从一堆动态库中创建 llama 服务器时可能使用的 GPU。 Web service and client 网络服务和客户端 让我们来看看 “前端”！在 ollama 中确实没有所谓的前端。相反，它和其他大多数 LLM 服务一样，提供了一系列 Web API。 基本的 Web API 在server中实现，主要在server/routes.go模块中。完整的 API 可在 GitHub 上找到。在此，我们也仅以 chat 的 completion 端点为例，快速从 API 建立起到我们在上面解析过的部分的概览。这个端点定义如下： 1r.POST(&quot;/api/chat&quot;, ChatHandler) 其中 ChatHandler 是处理请求的回调。它以 var req api.ChatRequest 结构创建并解析请求。处理程序会做很多事情，比如加载模型，以确保预测是可能的。 一切准备就绪后，最重要的事情就来了： 12345678910// Start predictionpredictReq := llm.PredictOpts&#123; Prompt: prompt, Format: req.Format, Images: images, Options: opts,&#125;if err := loaded.runner.Predict(c.Request.Context(), predictReq, fn); err != nil &#123; ch &lt;- gin.H&#123;\"error\": err.Error()&#125;&#125; 它用提示（用户输入、提示等）、图像和其他选项准备预测请求。然后，它调用 runner 的 Prediction 函数，其中 runner 需要实现 llm 模块下的 LLM 接口： 1234567891011var loaded struct &#123; mu sync.Mutex runner llm.LLM expireAt time.Time expireTimer *time.Timer *Model *api.Options&#125; LLM 接口的定义如下： 1234567type LLM interface &#123; Predict(context.Context, PredictOpts, func(PredictResult)) error Embedding(context.Context, string) ([]float64, error) Encode(context.Context, string) ([]int, error) Decode(context.Context, []int) (string, error) Close()&#125; Predict 的实现来自 预测一节中描述的 dynExtServer。然后，它将调用 dyn_llama_server_completion 从动态库中请求启动 llama 服务器。 Ollama 的 Go API 在项目内部，ollama 在 Go 的 api 下直接提供了一个封装。用户可以利用它更方便地调用网络 API。事实上，ollama 本身也使用 Go 封装提供实际的前端——终端用户界面。 此外还有 Python 和 JavaScript/TypeScript 绑定： https://github.com/ollama/ollama-python https://github.com/ollama/ollama-js OpenAI API 封装器 尽管有本地 API 端点，ollama 还在 server/routes.go 中提供了与 OpenAI API 兼容（部分兼容）的端点： 12// Compatibility endpointsr.POST(&quot;/v1/chat/completions&quot;, openai.Middleware(), ChatHandler) 它实际上是从 OpenAI 请求到 ollama 本机请求的转换器，反之亦然。 如果您感兴趣，可以查看 openai/openai.go。 其他实用程序 终端 UI 利用 Web API 端点的 Go 包装器来提供基于终端的对话。 它需要一些实用程序，例如 readline 来与终端中的用户输入进行交互，以及 progress 来显示进度。 此外，还有用于 API 端点认证的 auth，用于cli命令提供者的 cmd，用于单位转换的 format，用于模型文件解析的 parser 等。可以根据您的意愿详细查看源代码。这篇文章已经足够长了，并且只关注 ollama 的整体架构。我也希望看到更多的有关它的其他文章 😉 结论 最后，在结束前，这里给出一个关于 ollama 架构的简单图： 我仍要说：ollama 是 llama.cpp 的一个薄（也许不是那么薄）但足够智能的封装。 尽管它仍然有一些缺点，但我们确实需要尽可能多的此类封装，以使最终用户的生活更轻松。","categories":[{"name":"AI","slug":"AI","permalink":"https://blog.inoki.cc/categories/AI/"},{"name":"LLM","slug":"AI/LLM","permalink":"https://blog.inoki.cc/categories/AI/LLM/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"LLM","slug":"LLM","permalink":"https://blog.inoki.cc/tags/LLM/"},{"name":"ollama","slug":"ollama","permalink":"https://blog.inoki.cc/tags/ollama/"}]},{"title":"On the architecture of ollama","slug":"Ollama","date":"2024-04-15T15:34:00.000Z","updated":"2025-03-08T09:40:48.590Z","comments":true,"path":"2024/04/15/Ollama/","link":"","permalink":"https://blog.inoki.cc/2024/04/15/Ollama/","excerpt":"","text":"Recently, I took a chance to explore ollama project, because I want to enable the support of my AMD graphic card (with a not bad VRAM - 32G!) on Windows. There is already the support on Linux, based on AMD ROCm. It should be kind of out-of-box on Windows, thanks to the release of ROCm on Windows. But ollama prevents me from using it. So, I tried both ZLUDA and modified the code of ollama to get what I wanted. This feature is already merged and released in ollama v0.1.29. To avoid missing the details and the things I 've learnt, this blog is in charge of noting the architecture of ollama for myself. To me, ollama is a thin but smart enough wrapper to llama.cpp. It is really end-user friendly, and provides a web interface and a cli interface, in order to run and interact with a lot of Large Language Models (LLMs). Indeed, in most cases, it’s llama.cpp who loads and runs the models, and ollama just “pilots” (yes, I use a term that AI generations are familiar with) the llama.cpp. I will give a discussion about this part later. This post assumes that you are able to read golang code or some other C-like code. For special points in the code, I would give some brief descriptions or metaphors for better understanding. In this post, I will first give the project structure of ollama. Then, the core architecture and implementations around llama.cpp along with the build systems will be described. Next, I will describe how ollama chooses the device (hardware in general) to run an LLM. Finally, the web service, client and the utilities along with the other parts will be introduced, to finish the post. Project structure You can get the source code of ollama on GitHub. The project is mainly written in Golang. Here is a table of brief descriptions for each directory: Dir name Description api Client API lib in go app Desktop application (mainly a tray) auth Authentication cmd Commands and handlers docs Documentations examples Examples to use ollama format Utility to format units and time gpu GPU and acceleration detection llm Implementations to run llama.cpp macapp Desktop application for Mac openai OpenAI API wrapper for ollama parser Model information and message parser progress Utility to show loading progress readline Utility to read inputs from terminal scripts Scripts for build and publish server Server implementation in go version Version information Notice that the directories can be changed anytime, since the project is under active development. The hero behind: llama.cpp Let’s first start by an introduction to the core, llama.cpp. The llama.cpp is included as a submodule in ollama. You can find it in llm directory. There are also the needed files around it in the same directory. We will see them in details later. The llama.cpp project itself is an Open Source library for the inference of Meta’s LLaMA model in pure C/C++, at very first. And it is extended to run more models, such as Mistral, and Google Gemma (supported very recently). It leverages the capability of ggml, another project created by the same author, to run it natively on different platforms (compared to Python project). Supported backends Currently, some of the supported inference backends in llama.cpp are as follows through ggml: It can run AVX, AVX2 and AVX512 on x86 for llama.cpp, or NEON on ARM. With MPI (e.g. MPICH and OpenMPI), ggml allows to run models on CPU or CPU clusters. Apple Metal is integrated to support GPUs on macOS and iOS, including GPUs on Mac and Apple made GPU on iOS devices or Apple Silicon Mac. An old open standard, OpenCL is used by ggml based on the BLAS architecture. NVIDIA GPUs are supported by cuBLAS. Recent AMD GPUs are supported through hipBLAS, which is parts of AMD ROCm with almost same APIs as cuBLAS. What caught my attention recently, is the Vulkan support in llama.cpp. The (buggy) support was initially started by Nomic through their kompute framework. The recent progress is a pure implementation in ggml using the Vulkan libs directly. These backends allow developers to run LLMs that work across multiple platforms, from desktop computers to smartphones and beyond. Additionally, llama.cpp also provides native support for Linux (including Android Linux), Windows, macOS, and various other operating systems, such as iOS (see whispher.cpp on iOS) and even WebAssembly (whispher.wasm). Therefore, it should be very nature that ollama is born with the supports of the platforms and operating systems. Build system Next, let’s take a look at the build system to know how ollama plays with llama.cpp. C or Cpp projects usually come up with cmake (although there are more choices now) to handle the compilation, linking, etc. So does llama.cpp: it uses compile definitions (or flags) to leverage different backends. For instance: LLAMA_AVX, LLAMA_AVX2, LLAMA_AVX512 for the AVX supports; LLAMA_METAL for the Apple Metal support; LLAMA_CUBLAS for the NVIDIA CUDA support; and LLAMA_HIPBLAS for the AMD ROCm support. However, ollama itself is a go project leveraging the build system provided by go. Both of the two build systems co-exist to build the different parts: cmake builds llama.cpp with a few files from ollama.cpp, to pilot and provide interfaces; go build systems compile, link and pack the rest parts to make an application and cli of ollama. Apart from pure go code, the go build systems need cgo to build some C-family code as well. There are examples in llm directory (dyn_ext_server.c file to load and provide interfaces) and gpu directory (gpu_info_cuda.c, gpu_info_rocm.c and gpu_info_darwin.m are C or Objective-C implementations to detect GPUs). The go build system in ollama also run the commands to call cmake for the llama.cpp building, by leveraging go generate. This work lays in the llm/generate directory, e.g. on Linux: 123package generate//go:generate bash ./gen_linux.sh llm/generate/generate_darwin.go tells go generate to run the gen_linux.sh script to build the llama.cpp part. Some scripts for different platforms Currently, there are gen_common.sh, gen_linux.sh and gen_darwin.sh to build llama.cpp for ollama on Unix-like OS, such as macOS and Linux. Meanwhile, it’s gen_windows.ps1 PowerShell script on Windows. Let’s take an example to build llama.cpp with AVX support on Linux: 123456init_varsCMAKE_DEFS=\"$&#123;COMMON_CPU_DEFS&#125; -DLLAMA_AVX=on -DLLAMA_AVX2=off -DLLAMA_AVX512=off -DLLAMA_FMA=off -DLLAMA_F16C=off $&#123;CMAKE_DEFS&#125;\"BUILD_DIR=\"$&#123;LLAMACPP_DIR&#125;/build/linux/$&#123;ARCH&#125;/cpu_avx\"echo \"Building AVX CPU\"buildcompress_libs The first three lines initialize the variables to prepare the build. The init_vars calls a sub-procedure in gen_common.sh to prepare common variables such as: 12CMAKE_DEFS=\"\"CMAKE_TARGETS=\"--target ext_server\" where CMAKE_TARGETS will set the build target to ext_server. This target is a library to provide interfaces and functions from llama.cpp to ollama, we will talk about it in the next section. In CMAKE_DEFS, only LLAMA_AVX is enabled. And COMMON_CPU_DEFS is defined as follows, to make dynamic library with position independent code (for gcc it will be converted to a -fpic flag): 1COMMON_CPU_DEFS=\"-DCMAKE_POSITION_INDEPENDENT_CODE=on -DLLAMA_NATIVE=off\" It outputs “Building AVX CPU” in the terminal. The build sub-procedure then calls cmake: 12345678910111213build() &#123; cmake -S $&#123;LLAMACPP_DIR&#125; -B $&#123;BUILD_DIR&#125; $&#123;CMAKE_DEFS&#125; cmake --build $&#123;BUILD_DIR&#125; $&#123;CMAKE_TARGETS&#125; -j8 mkdir -p $&#123;BUILD_DIR&#125;/lib/ g++ -fPIC -g -shared -o $&#123;BUILD_DIR&#125;/lib/libext_server.$&#123;LIB_EXT&#125; \\ $&#123;GCC_ARCH&#125; \\ $&#123;WHOLE_ARCHIVE&#125; $&#123;BUILD_DIR&#125;/examples/server/libext_server.a $&#123;NO_WHOLE_ARCHIVE&#125; \\ $&#123;BUILD_DIR&#125;/common/libcommon.a \\ $&#123;BUILD_DIR&#125;/libllama.a \\ -Wl,-rpath,\\$ORIGIN \\ -lpthread -ldl -lm \\ $&#123;EXTRA_LIBS&#125;&#125; After the build by cmake, it will make a libext_server dynamic library (.dll on Windows, .so on Linux/BSD, and .dylib on macOS). The library contains the compiled code from examples/server under llama.cpp (examples/server/libext_server.a), command and core code of llama.cpp - common/libcommoa.a and libllama.a. They will be embedded into the main go program to facilitate the distribution, as “payloads” of the executable. Finally, it compresses the payloads to make the executable smaller: 1234567891011121314compress_libs() &#123; echo \"Compressing payloads to reduce overall binary size...\" pids=\"\" rm -rf $&#123;BUILD_DIR&#125;/lib/*.$&#123;LIB_EXT&#125;*.gz for lib in $&#123;BUILD_DIR&#125;/lib/*.$&#123;LIB_EXT&#125;* ; do gzip --best -f $&#123;lib&#125; &amp; pids+=\" $!\" done echo for pid in $&#123;pids&#125;; do wait $pid done echo \"Finished compression\"&#125; The dynamic library will finally reside under a cpu_avx directory in the build folder. If it builds for the other variants (such as GPUs), they will be in different directories in the build folder. Pilot llama.cpp Then, let us go back to the llm directory, to see the implementations in ollama built on top of llama.cpp. The most important parts for ollama to pilot llama.cpp are: In ext_server, the wrapper implementations provides the functions that ollama can call, such as llama_server_init to init an llama.cpp instance, llama_server_completion to complete a chat, or llama_server_embedding to compute the embeddings for texts. An extra makefile (CMakeLists) is also contained in ext_server, to build the code with the llama.cpp/examples/server example as a library. It can then be loaded by dyn_ext_server code under llm, to serve with the llama.cpp instance. The libraries are embedded into the go program using go embed package, and extract during the runtime. Besides, the calls to the functions in ext_server carry the some parameters defined in llm directory. In general, the requests and responses are passed in JSON format, and contains more structural information. They are defined in such as ggml.go (describing the models) and llama.go (describing the different requests and responses). To dynamically manage the llama.cpp instances, ollama provides some patches to the original llama.cpp. Let’s study them one by one. 1. External server We first take a look at ext_server. We already know that the dynamic libraries are built during the generation. But how will they be used? In llm/dyn_ext_server.go, the newDynExtServer is in charge of loading the dynamic libraries, initialize a llama.cpp instance and start the event loop to receive any requests and generate the responses. Dynamic library loading and server starting In newDynExtServer, the go function calls a C function named by dyn_init to load the dynamic library. The description and the needed functions are loaded into a struct_dynamic_llama_server description, and wrapped in dynExtServer, a go struct. They are then used in a another C function, dyn_llama_server_init, with the parameters to run a llama.cpp server, for the server instance initialization. Without issue, newDynExtServer will call the last C function during the initialization, dyn_llama_server_start. The server will be running and is then able to receive requests from ollama. The aforementioned C functions are in llm/dyn_ext_server.c and declared in llm/dyn_ext_server.h. Let’s take a quick look at dyn_init: 12void dyn_init(const char *libPath, struct dynamic_llama_server *s, ext_server_resp_t *err); It accepts a library path libPath as argument, and returns a dynamic_llama_server instance or an error through the C pointers (or memory address to those who are not familiar with C, go is able to handle them like go struct, store them and pass to the other C functions). The dynamic_llama_server struct is capable of storing the address of necessary C functions, and the reference to the loaded dynamic library. Its definition is as below: 123456789101112131415161718192021struct dynamic_llama_server &#123; void *handle; void (*llama_server_init)(ext_server_params_t *sparams, ext_server_resp_t *err); void (*llama_server_start)(); void (*llama_server_stop)(); void (*llama_server_completion)(const char *json_req, ext_server_resp_t *resp); void (*llama_server_completion_next_result)(const int task_id, ext_server_task_result_t *result); void (*llama_server_completion_cancel)(const int task_id, ext_server_resp_t *err); void (*llama_server_release_task_result)(ext_server_task_result_t *result); void (*llama_server_tokenize)(const char *json_req, char **json_resp, ext_server_resp_t *err); void (*llama_server_detokenize)(const char *json_req, char **json_resp, ext_server_resp_t *err); void (*llama_server_embedding)(const char *json_req, char **json_resp, ext_server_resp_t *err); void (*llama_server_release_json_resp)(char **json_resp);&#125;; The core functionality of dyn_init is to load a dynamic library indicated by libPath, read the symbol tables, find the addresses of needed C functions, and store them into an instance of dynamic_llama_server structure. The libPath could be the path of one of the built dynamic libraries with the libext_server prefix. So that the built libraries based on llama.cpp can be used by ollama. Once loaded, the calls to dyn_llama_server_start and dyn_llama_server_start are indeed direct calls to the C functions from the dynamic libraries: 123456789inline void dyn_llama_server_init(struct dynamic_llama_server s, ext_server_params_t *sparams, ext_server_resp_t *err) &#123; s.llama_server_init(sparams, err);&#125;inline void dyn_llama_server_start(struct dynamic_llama_server s) &#123; s.llama_server_start();&#125; After calling dyn_llama_server_start, the llama.cpp server created from a dynamic library is ready to make predictions. Prediction When ollama receives a prediction request, it calls Predict on a dynExtServer instance. This function is able to formats the request (will see this later), and calls a C function, dyn_llama_server_completion, for start the prediction: 12345inline void dyn_llama_server_completion(struct dynamic_llama_server s, const char *json_req, ext_server_resp_t *resp) &#123; s.llama_server_completion(json_req, resp);&#125; As you see, it’s also a direct call to the function loaded from one of the dynamic libraries built on top of llama.cpp. A really good design in this part is the stream-like response, thanks to the fn func(PredictResult) argument in the Predict function. It is a callback function, which allows to send continuously the responses as soon as it gets: 12345if p.Content != \"\" &#123; fn(PredictResult&#123; Content: p.Content, &#125;)&#125; It also relies on the convenient call to dyn_llama_server_completion_next_result (although it’s also a direct call to a loaded C function llama_server_completion_next_result from a dynamic library based on llama.cpp). Others The other calls are similar as well. You can find them in llm/dyn_ext_server.go and llm/dyn_ext_server.c, such as dyn_llama_server_tokenize, dyn_llama_server_detokenize for tokenization or detokenization, and dyn_llama_server_embedding for computing the embeddings. 2. llama.cpp as a server for ollama Let’s next check the C parts: how ollama uses llama.cpp as an LLM server. In the beginning of llm/dyn_ext_server.go, there are a bench of build instructions in the comments for cgo: 123456789101112131415161718/*#cgo CFLAGS: -I$&#123;SRCDIR&#125;/ext_server -I$&#123;SRCDIR&#125;/llama.cpp -I$&#123;SRCDIR&#125;/llama.cpp/common -I$&#123;SRCDIR&#125;/llama.cpp/examples/server#cgo CFLAGS: -DNDEBUG -DLLAMA_SERVER_LIBRARY=1 -D_XOPEN_SOURCE=600 -DACCELERATE_NEW_LAPACK -DACCELERATE_LAPACK_ILP64#cgo CFLAGS: -Wmissing-noreturn -Wextra -Wcast-qual -Wno-unused-function -Wno-array-bounds#cgo CPPFLAGS: -Ofast -Wextra -Wno-unused-function -Wno-unused-variable -Wno-deprecated-declarations#cgo darwin CFLAGS: -D_DARWIN_C_SOURCE#cgo darwin CPPFLAGS: -DGGML_USE_ACCELERATE#cgo darwin CPPFLAGS: -DGGML_USE_METAL -DGGML_METAL_NDEBUG#cgo darwin LDFLAGS: -lc++ -framework Accelerate#cgo darwin LDFLAGS: -framework Foundation -framework Metal -framework MetalKit -framework MetalPerformanceShaders#cgo linux CFLAGS: -D_GNU_SOURCE#cgo linux LDFLAGS: -lrt -ldl -lstdc++ -lm#cgo linux windows LDFLAGS: -lpthread#include &lt;stdlib.h&gt;#include \"dyn_ext_server.h\"*/ They are able to set different build and link flags for different platforms (darwin for macOS, and of course linux for Linux while windows for Windows). So that cgo is able to find the C header files (declarations of the existing types and functions) to compile and link llm/dyn_ext_server.c with the go parts. Let’s then go to check the C functions used in ollama, from the dynamic library. As two examples, we start with llama_server_init and llama_server_start. Their implementations are located in llm/ext_server/ext_server.cpp, which is set as a library target named by ext_server in llm/ext_server/CMakeLists.txt. During the building the target, this file will be compiled with llama.cpp example server together. The compiled result is one of the dynamic libraries that we mentioned. As a result, the C functions in ext_server.cpp can be called from ollama, and are able to leverage the functions in llama.cpp. It actually acts as a bridge between the two projects, and makes the example server in llama.cpp a server for ollama. During the initialization, llama_server_init parses the parameters to create a context for the server, and calls the functions provided by llama.cpp: 1234567891011121314151617void llama_server_init(ext_server_params *sparams, ext_server_resp_t *err) &#123; /* ... */ llama = new llama_server_context; /* ... */ llama_backend_init(); llama_numa_init(params.numa); /* ... */ if (!llama-&gt;load_model(params)) &#123; // an error occurred that was not thrown err-&gt;id = -1; snprintf(err-&gt;msg, err-&gt;msg_len, \"error loading model %s\", params.model.c_str()); return; &#125; /* ... */ llama-&gt;initialize(); /* ... */&#125; For example, it calls llama_backend_init to initialize the backend (could be AVX, CUDA, etc), and llama_numa_init to initialize the NUMA (if exists). Then it calls the load_model function in the server context with the given parameters to load the model and finalize the initialization with initialize function. In case of error, the error messages are formatted to the err argument to return and be processed in go parts. Meanwhile in llama_server_start: 123456789101112131415161718192021222324252627282930void llama_server_start() &#123; assert(llama != NULL); // TODO mutex to protect thread creation ext_server_thread = std::thread([&amp;]() &#123; try &#123; LOG_TEE(\"llama server main loop starting\\n\"); ggml_time_init(); llama-&gt;queue_tasks.on_new_task(std::bind( &amp;llama_server_context::process_single_task, llama, std::placeholders::_1)); llama-&gt;queue_tasks.on_finish_multitask(std::bind( &amp;llama_server_context::on_finish_multitask, llama, std::placeholders::_1)); llama-&gt;queue_tasks.on_all_tasks_finished(std::bind( &amp;llama_server_context::run_on_all_tasks_finished, llama)); llama-&gt;queue_results.on_multitask_update(std::bind( &amp;llama_server_queue::update_multitask, &amp;llama-&gt;queue_tasks, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3 )); llama-&gt;queue_tasks.start_loop(); &#125; catch (std::exception &amp;e) &#123; LOG_TEE(\"caught exception in llama server main loop: %s\\n\", e.what()); &#125; catch (...) &#123; LOG_TEE(\"caught unknown exception in llama server main loop\\n\"); &#125; LOG_TEE(\"\\nllama server shutting down\\n\"); llama_backend_free(); &#125;);&#125; It sets some callbacks for the task processing, and starts an event loop in a new thread. The event loop is in charge of the predictions. So that the call to llama_server_start is returned immediately. More detailed implementations of such C functions can be found in the same file, i.e. llm/ext_server/ext_server.cpp. 3. Embed libraries as payloads Then, let’s explore how the payloads are done. In the go files with payload_* prefix, we can see the choice of ollama. For instance, there is two lines to embed every ext_server libraries with different variants in llm/payload_linux.go: 12//go:embed llama.cpp/build/linux/*/*/lib/*var libEmbed embed.FS All the built libraries under llama.cpp/build/linux/*/*/lib/ are embedded as payloads using a filesystem like interface. So that ollama can access them like reading and writing in a filesystem. During the initialization of ollama, Init in llm/payload_common.go will call nativeInit: 123func Init() error &#123; return nativeInit()&#125; It mainly works on extracting the dynamic libraries from the file system to a temporary location, and check driver access permission if applicable: 123libs, err := extractDynamicLibs(payloadsDir, \"llama.cpp/build/*/*/*/lib/*\")/* ... */err := verifyDriverAccess() After the extraction, ollama is able to format the library path (libPath used in the dyn_init function in the External server subsection). The way to choose the running environment and the matching library will be presented in the Decide where to run section. 4. Formatted request and response Let’s then go back to the function arguments used in the C functions. 1234567891011inline void dyn_llama_server_init(struct dynamic_llama_server s, ext_server_params_t *sparams, ext_server_resp_t *err) &#123; s.llama_server_init(sparams, err);&#125;inline void dyn_llama_server_completion(struct dynamic_llama_server s, const char *json_req, ext_server_resp_t *resp) &#123; s.llama_server_completion(json_req, resp);&#125; In their function signatures, we can see the function arguments they use: ext_server_params_t in dyn_llama_server_init, and a json_req byte array in dyn_llama_server_completion. The ext_server_params_t argument is a C struct carrying the configurations to launch the llama server, which will be interpreted later in llm/ext_server/server.cpp(We do not expand this part due to shortage of pages). Meanwhile, the json_req for the completion call is used as follows, in llm/ext_server/ext_server.cpp: 123456789101112131415161718void llama_server_completion(const char *json_req, ext_server_resp_t *resp) &#123; assert(llama != NULL &amp;&amp; json_req != NULL &amp;&amp; resp != NULL); resp-&gt;id = -1; resp-&gt;msg[0] = '\\0'; try &#123; if (shutting_down) &#123; throw std::runtime_error(\"server shutting down\"); &#125; json data = json::parse(json_req); resp-&gt;id = llama-&gt;queue_tasks.get_new_id(); llama-&gt;queue_results.add_waiting_task_id(resp-&gt;id); llama-&gt;request_completion(resp-&gt;id, data, false, false, -1); &#125; catch (std::exception &amp;e) &#123; snprintf(resp-&gt;msg, resp-&gt;msg_len, \"exception %s\", e.what()); &#125; catch (...) &#123; snprintf(resp-&gt;msg, resp-&gt;msg_len, \"Unknown exception during completion\"); &#125;&#125; Indeed, it contains the completion request in json format, including the prompt, temperature, etc. We can see that llama_server_completion creates a task for it and return the task ID through resp in the normal path. Otherwise, it formats the error information for returning. If you are interested in its detailed format, please check llm/dyn_ext_server.go file. 5. Patches There are a few extra modifications on the original version of llama.cpp, to adapt the usage of multiple llama servers in ollama. For example, the following patch exports ggml_free_cublas and call it to release an instance of llama server: 1234567891011121314151617181920212223diff --git a/examples/server/server.cpp b/examples/server/server.cppindex 7800c6e7..be30db23 100644--- a/examples/server/server.cpp+++ b/examples/server/server.cpp@@ -30,6 +30,10 @@ #include &lt;atomic&gt; #include &lt;signal.h&gt; +#ifdef GGML_USE_CUBLAS+extern \"C\" GGML_CALL void ggml_free_cublas(void);+#endif+ using json = nlohmann::json; struct server_params@@ -353,6 +357,9 @@ struct llama_server_context llama_free_model(model); model = nullptr; &#125;+#ifdef GGML_USE_CUBLAS+ ggml_free_cublas();+#endif &#125; Wrap them up With all the extra modules and modifications on llama.cpp, ollama is thus able to start a llama server as needed, dynamically choosing the hardware with the supports of different hardware in the different compiled dynamic libraries (see Build system). After running the llama server, the extra modules provided by ollama allow to send the completion request, and retrieve the replies later. Til now, it should be clear with a global view on the ollama architecture behind (or we can call it backend, as usual). For the details in the backend, readers can check the source code since they are subjective to be changed very often. After all, ollama is under active development. There are still a few mysteries: backend side: how ollama knows which hardware and which dynamic libraries to choose? frontend side: which kind of frontend does it provide? The following sections might be the answers for these questions. Decide where to run Let’s go back to the dynamic libraries and libPath argument in the dyn_init, mentioned in Dynamic library loading and server starting. We have already known in Embed libraries as payloads, that ollama will extract the embedded dynamic libraries to a temporary directory, and load them by formatting and passing libPath to dyn_init. The question is: how ollama chooses the libraries by passing the different libPath argument? The libPath is passed as the first argument library in the newDynExtServer function implemented in llm/dyn_ext_server.go. It is updated on Windows by a call to gpu.UpdatePath(filepath.Dir(library)), in order to add the parent directory to the PATH. So that the dynamic libraries can be loaded seamlessly. However, it’s not necessary to do so on Linux or macOS. Therefore, we can know that the libPath here is already a full path to the dynamic library files. Let’s then check where the libPath is generated. A simple search gives a response in the newLlmServer function under llm/llm.go: 123456789err2 := fmt.Errorf(\"unable to locate suitable llm library\")for _, dynLib := range dynLibs &#123; srv, err := newDynExtServer(dynLib, model, adapters, projectors, opts) if err == nil &#123; return srv, nil &#125; slog.Warn(fmt.Sprintf(\"Failed to load dynamic library %s %s\", dynLib, err)) err2 = err&#125; It iterates the dynLibs to call newDynExtServer function. Once there is one successful loading, it returns the llama server instance. At the beginning of newLlmServer, the dynLibs are generally retrieved in getDynLibs function, which is an ordered list of dynamic libraries to try: 1234func newLlmServer(gpuInfo gpu.GpuInfo, model string, adapters, projectors []string, opts api.Options) (LLM, error) &#123; dynLibs := getDynLibs(gpuInfo) /* ... */&#125; The order is a preference, which takes the GPU information from gpuInfo gpu.GpuInfo. It is not forced to be the “GPU information”, it can also indicate to use a certain CPU variant. I think ollama team may change it very soon. In general, the returned dynLibs are from a key-value mapping availableDynLibs in llm/payload_common.go. It is generated in nativeInit, after the extraction of all the dynamic libraries: 1234567891011func nativeInit() error &#123; /* ... */ /* Extract dynamic libraries in temporary directory */ /* ... */ for _, lib := range libs &#123; // The last dir component is the variant name variant := filepath.Base(filepath.Dir(lib)) availableDynLibs[variant] = lib &#125; /* ... */&#125; The key is the last component of the full path, except the library file name. For example, it is be cpu, cpu_avx, cpu_avx2, cuda_v11.3 and rocm_v5.7 on my PC. And the values are certainly the full path. We can first take a look at the general processing in getDynLibs function(which is implemented in llm/payload_common.go), by ignoring some platform-specific cases. The first step is to find the exact match of the requested one from the “GPU information”: 123456789101112131415exactMatch := \"\"dynLibs := []string&#123;&#125;altDynLibs := []string&#123;&#125;requested := gpuInfo.Libraryif gpuInfo.Variant != \"\" &#123; requested += \"_\" + gpuInfo.Variant&#125;// Try to find an exact matchfor cmp := range availableDynLibs &#123; if requested == cmp &#123; exactMatch = cmp dynLibs = []string&#123;availableDynLibs[cmp]&#125; break &#125;&#125; It makes a requested string by Library with an appended Variant from the “GPU information”. If there is one matched exactly to the requested string, the first library path in dynLibs would be the path to the requested library. The first library path will also be the first to try during the loading. It then tries GPU libraries with not exact matches (where there could be some version mismatches, etc.): 123456789101112// Then for GPUs load alternates and sort the list for consistent load orderingif gpuInfo.Library != \"cpu\" &#123; for cmp := range availableDynLibs &#123; if gpuInfo.Library == strings.Split(cmp, \"_\")[0] &amp;&amp; cmp != exactMatch &#123; altDynLibs = append(altDynLibs, cmp) &#125; &#125; slices.Sort(altDynLibs) for _, altDynLib := range altDynLibs &#123; dynLibs = append(dynLibs, availableDynLibs[altDynLib]) &#125;&#125; Next, it tries to prioritize the fastest (maybe) CPU variant by calling another utility function GetCPUVariant: 123456789101112131415161718// Load up the best CPU variant if not primary requestedif gpuInfo.Library != \"cpu\" &#123; variant := gpu.GetCPUVariant() // If no variant, then we fall back to default // If we have a variant, try that if we find an exact match // Attempting to run the wrong CPU instructions will panic the // process if variant != \"\" &#123; for cmp := range availableDynLibs &#123; if cmp == \"cpu_\"+variant &#123; dynLibs = append(dynLibs, availableDynLibs[cmp]) break &#125; &#125; &#125; else &#123; dynLibs = append(dynLibs, availableDynLibs[\"cpu\"]) &#125;&#125; This utility is defined in gpu/cpu_common.go. It detects the CPU extensions on x86 platform: 12345678910111213func GetCPUVariant() string &#123; if cpu.X86.HasAVX2 &#123; slog.Info(\"CPU has AVX2\") return \"avx2\" &#125; if cpu.X86.HasAVX &#123; slog.Info(\"CPU has AVX\") return \"avx\" &#125; slog.Info(\"CPU does not have vector extensions\") // else LCD return \"\"&#125; The order will give avx2 as the highest preference, then avx, and finally the pure CPU variant. Finally, it fallbacks to CPU variant if none of the above methods work: 1234567891011func getDynLibs(gpuInfo gpu.GpuInfo) []string &#123; /* Apple specific loading */ /* ... */ // Finally, if we didn't find any matches, LCD CPU FTW if len(dynLibs) == 0 &#123; dynLibs = []string&#123;availableDynLibs[\"cpu\"]&#125; &#125; slog.Debug(fmt.Sprintf(\"ordered list of LLM libraries to try %v\", dynLibs)) return dynLibs&#125; The dynLibs are then returned for the loading tries. We can now explore how the “GPU information” gpuInfo is generated to make the preference possible. The New function in llm/llm.go calls newLlmServer with the “GPU information” as the first argument. It completes many important works: Open, load and detect the parameters of an LLM. Load “GPU information”: info := gpu.GetGPUInfo(). Check the VRAM and the compatibility of the model to the hardware. The initial detection is performed in 2. However, it is also possible that the model is marked as incompatible to the model. In this case, it will fallback to the CPU with the fastest variant: 12info.Library = \"cpu\"info.Variant = gpu.GetCPUVariant() Let’s only concentrate on 2, to see what happened in the GetGPUInfo function. Apple Metal Let’s start with the most special platform. Apple macOS platform, including the XNU kernel and the userspace, is usually called darwin. In the aforementioned getDynLibs, the Darwin detection is very simple: 1234567891011// Short circuit if we know we're using the default built-in (darwin only)if gpuInfo.Library == \"default\" &#123; return []string&#123;\"default\"&#125;&#125;// TODO - temporary until we have multiple CPU variations for Darwin// Short circuit on darwin with metal onlyif len(availableDynLibs) == 1 &#123; if _, onlyMetal := availableDynLibs[\"metal\"]; onlyMetal &#123; return []string&#123;availableDynLibs[\"metal\"]&#125; &#125;&#125; It uses default library according to the “GPU information”, or just use metal. The gpu.GetGPUInfo() is in gpu/gpu_darwin.go, as simple as possible: 1234567891011121314func GetGPUInfo() GpuInfo &#123; mem, _ := getCPUMem() if runtime.GOARCH == \"amd64\" &#123; return GpuInfo&#123; Library: \"cpu\", Variant: GetCPUVariant(), memInfo: mem, &#125; &#125; return GpuInfo&#123; Library: \"metal\", memInfo: mem, &#125;&#125; We can see that, it gets the memory information and detects whether ollama is running on the Intel x86_64/amd64 platform. If so, it just uses the CPU with the fastest extension. Otherwise, only ARM Mac can leverage the Metal API to accelerate. From my best know, the AMD graphic cards on Intel Mac should also have Metal support. But it will not be used on Intel Mac by ollama. Probably, it’s just due to the outdated drivers or the outdated graphic cards itself. Nvidia CUDA and AMD ROCm We then check the general detection of Nvidia and AMD GPUs, since they are kind of coupled together in ollama. The implementation is in gpu/gpu.go: 123456789101112131415161718192021222324252627func GetGPUInfo() GpuInfo &#123; // TODO - consider exploring lspci (and equivalent on windows) to check for // GPUs so we can report warnings if we see Nvidia/AMD but fail to load the libraries gpuMutex.Lock() defer gpuMutex.Unlock() if gpuHandles == nil &#123; initGPUHandles() &#125; // All our GPU builds on x86 have AVX enabled, so fallback to CPU if we don't detect at least AVX cpuVariant := GetCPUVariant() if cpuVariant == \"\" &amp;&amp; runtime.GOARCH == \"amd64\" &#123; slog.Warn(\"CPU does not have AVX or AVX2, disabling GPU support.\") &#125; var memInfo C.mem_info_t resp := GpuInfo&#123;&#125; /* Getting the actual GPU information */ /* ... */ /* Fallback to CPU if no GPU detected */ /* ... */ resp.DeviceCount = uint32(memInfo.count) resp.FreeMemory = uint64(memInfo.free) resp.TotalMemory = uint64(memInfo.total) return resp&#125; The first block calls initGPUHandles to define the GPU libraries to search, in order to use them to get the GPU information. For Nvidia, it detects nvml.dll for discrete graphic cards on Windows, libnvidia-ml.so on Linux, and libcudart.so* on some special devices, such as Jetson family (thanks to a recent PR). The second block detects the CPU variant, it somehow requires at least AVX variant from the CPU to enable the GPU support. It then checks the handles and uses the libraries to lookup GPUs accordingly. For Nvidia discrete GPUs: 1234567891011121314151617181920if gpuHandles.nvml != nil &amp;&amp; (cpuVariant != \"\" || runtime.GOARCH != \"amd64\") &#123; C.nvml_check_vram(*gpuHandles.nvml, &amp;memInfo) if memInfo.err != nil &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] error looking up NVML GPU memory: %s\", C.GoString(memInfo.err))) C.free(unsafe.Pointer(memInfo.err)) &#125; else if memInfo.count &gt; 0 &#123; // Verify minimum compute capability var cc C.nvml_compute_capability_t C.nvml_compute_capability(*gpuHandles.nvml, &amp;cc) if cc.err != nil &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] error looking up NVML GPU compute capability: %s\", C.GoString(cc.err))) C.free(unsafe.Pointer(cc.err)) &#125; else if cc.major &gt; CudaComputeMin[0] || (cc.major == CudaComputeMin[0] &amp;&amp; cc.minor &gt;= CudaComputeMin[1]) &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] NVML CUDA Compute Capability detected: %d.%d\", cc.major, cc.minor)) resp.Library = \"cuda\" &#125; else &#123; slog.Info(fmt.Sprintf(\"[nvidia-ml] CUDA GPU is too old. Falling back to CPU mode. Compute Capability detected: %d.%d\", cc.major, cc.minor)) &#125; &#125;&#125; It calls a C function nvml_check_vram implemented in gpu/gpu_info_nvml.c to get the VRAM. If found one usable device, it will also check the compute capability through nvml_compute_capability, to make sure that the device is usable. This design has prevented me from using ZLUDA to run an LLM through ollama on my AMD graphic card on Windows. Because ZLUDA was marking this function as unimplemented at that time. However, there is already the support to my AMD graphic card. I do not need the ZLUDA anymore now. I just would just skip the Cudart support because it’s not a common case. Let’s go through the recent exciting AMD support now! The code in GetGPUInfo for AMD is very short: 123456else &#123; AMDGetGPUInfo(&amp;resp) if resp.Library != \"\" &#123; return resp &#125;&#125; You may notice that it is an “else”. So, along with the “if” clause, AMD will be tried, only if Nvidia handle is not detected. This would cause an issue: when there are Nvidia GPU libraries installed, however no GPU detected or the detected GPUs are not compatible, AMD graphic cards would never be detected as well. I opened an issue for this. OK, let go back to the GetGPUInfo. If Nvidia graphic card is detected, the Library in the “GPU information” will be set to cuda. For AMD, it will be rocm. So, if the detection succeeded, the “GPU information” will work with the availableDynLibs to prioritize the library paths for cuda_* or rocm_* variants. That unveils how the GPUs are detected and potentially used when creating the llama servers from a bunch of dynamic libraries. Web service and client Let’s then take a look at the “frontend”! There is indeed no so-called frontend in ollama. Instead, it provides a bench of Web APIs, just like most of the other LLM services. The basic Web APIs are implemented in server, mostly in the server/routes.go module. The full API endpoints are available at GitHub. Here, we also just take the chat completion endpoint as a quick example to build the view from the API endpoint to what we have seen above. The endpoint is defined as: 1r.POST(&quot;/api/chat&quot;, ChatHandler) where ChatHandler is a callback to handle the request. It creates and parses the request in a var req api.ChatRequest struct. The handler will do a lot of things such as loading the model, to make sure that the prediction is possible. When everything is ready, the most important thing is here: 12345678910// Start predictionpredictReq := llm.PredictOpts&#123; Prompt: prompt, Format: req.Format, Images: images, Options: opts,&#125;if err := loaded.runner.Predict(c.Request.Context(), predictReq, fn); err != nil &#123; ch &lt;- gin.H&#123;\"error\": err.Error()&#125;&#125; It prepares the prediction request with the prompt (user inputs, prompts, etc.), images, and other options. Then it calls the Prediction function of runner, where the runner needs to implement the LLM interface under the llm module: 1234567891011var loaded struct &#123; mu sync.Mutex runner llm.LLM expireAt time.Time expireTimer *time.Timer *Model *api.Options&#125; The LLM interface is: 1234567type LLM interface &#123; Predict(context.Context, PredictOpts, func(PredictResult)) error Embedding(context.Context, string) ([]float64, error) Encode(context.Context, string) ([]int, error) Decode(context.Context, []int) (string, error) Close()&#125; And the implementation of Predict is from dynExtServer described in Prediction section. It will then call dyn_llama_server_completion and thus request the started llama server from one of the dynamic libraries. So, we have the link now. Go API of Ollama Intrinsically, ollama provides a wrapper in Go under api. Users can leverage it to call the Web APIs easier. Indeed, ollama itself also uses the Go wrapper to provide the actual frontend - a terminal UI. There are also Python and JavaScript/TypeScript bindings: https://github.com/ollama/ollama-python https://github.com/ollama/ollama-js OpenAI API wrapper Despite of the native API endpoints, ollama also provides an OpenAI API-compatible (well, partially compatible) endpoint in server/routes.go: 12// Compatibility endpointsr.POST(&quot;/v1/chat/completions&quot;, openai.Middleware(), ChatHandler) It’s indeed a convertor from OpenAI requests to ollama native requests, and vice-versa for responses. You can check openai/openai.go if it’s interesting to you. Other utilities The terminal UI leverages the Go wrapper of the Web API endpoints to provide a terminal-based conversations. It needs some utilities such as readline to interact with the user inputs in the terminal, and progress to show the progress. There are also the auth for API endpoint authentication, cmd for cli commands provider, format for unit conversion, parser for model file parsing, etc. Check them in detail as your wish. This post has been long enough and just concentrate on the overall architecture of ollama. I am also eager to seeing the other posts about it 😉 Conclusion Finally, I would end up with a simple figure for the ollama architecture before runtime: I would say as well: ollama is a thin (maybe not so thin) but smart enough wrapper of llama.cpp. Although it still has a few drawbacks, we really need as many these kinds of wrappers as possible, to make the life easier for any end-users.","categories":[{"name":"AI","slug":"AI","permalink":"https://blog.inoki.cc/categories/AI/"},{"name":"LLM","slug":"AI/LLM","permalink":"https://blog.inoki.cc/categories/AI/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://blog.inoki.cc/tags/LLM/"},{"name":"ollama","slug":"ollama","permalink":"https://blog.inoki.cc/tags/ollama/"}]},{"title":"在 Proxy 环境中使用 GitHub SSH 的 git 操作","slug":"GitHub-ssh-connection-behind-proxy","date":"2024-03-08T06:02:23.000Z","updated":"2025-03-08T09:40:48.565Z","comments":true,"path":"2024/03/08/GitHub-ssh-connection-behind-proxy/","link":"","permalink":"https://blog.inoki.cc/2024/03/08/GitHub-ssh-connection-behind-proxy/","excerpt":"","text":"上次回国，发现墙又高了：GitHub 的 SSH 端口（22）现在会完全被阻断，导致无法正常使用 SSH 协议进行 git clone、git pull 等操作。 事实上，封禁 22 端口在公司网络环境中也可能是一个很普遍的操作，用于禁止员工随意使用 ssh 登录不受控的机器。 这种情况下，GitHub 官方是推荐使用 HTTPS 协议进行克隆的，但是需要配置 GitHub 的 login 集成或者是使用 token 来进行私有仓库的操作。但如果仍然希望使用 SSH，可以参考本文的做法，仅此记录一下。 问题现象 首先可以测试一下 SSH 是不是被阻断了，当你尝试使用 SSH 连接 GitHub 时，执行以下命令： 1$ ssh -T git@github.com 如果遇到连接超时或被拒绝的情况，那么就是被阻断了，同时 HTTP_PROXY、HTTPS_PROXY 和 ALL_PROXY 仅对 HTTPS 协议的 git 操作有效，并不会对 SSH 协议的 git 操作生效。 在这种情况下，GitHub 提供了基于 HTTPS（443）端口的 SSH 协议的连接方式，可以绕开针对 SSH 22 端口的封禁。 如果改用 443 端口上的 SSH 连接可以成功的话（说明不是基于协议识别封禁的）： 123$ ssh -T -p 443 git@ssh.github.com# Hi USERNAME! You've successfully authenticated, but GitHub does not# provide shell access. 那么就可以采用这种方式。 方案 1：手动更改 SSH 命令 在 git clone 或 git pull 等命令中手动使用 ssh.github.com 并指定 SSH 端口为 443。例如： 1git clone ssh://git@ssh.github.com:443/your-repo.git 或者在已有的仓库中修改远程 URL： 1git remote set-url origin ssh://git@ssh.github.com:443/your-repo.git 但这就需要对所用到的仓库都进行修改，太麻烦了。 方案 2：修改 SSH 配置文件 你也可以直接修改 SSH 配置文件（~/.ssh/config），让 SSH 将 github.com 直接当作 ssh.github.com 的别名来连接 GitHub，并自动使用 443 端口。 编辑 ~/.ssh/config（如果文件不存在，可以手动创建）： 123456echo \"Host github.com Hostname ssh.github.com Port 443 User git\" &gt;&gt; ~/.ssh/config 然后测试 SSH 连接： 1$ ssh -T git@github.com 如果输出如下信息，说明配置成功： 12# Hi USERNAME! You&apos;ve successfully authenticated, but GitHub does not# provide shell access 方案 3：强制使用 SOCKS5 代理进行 SSH 连接 如果你不想使用 ssh.github.com，并且已经在本地配置了 SOCKS5 代理，可以让 git SSH 通过代理连接 GitHub。 在 ~/.ssh/config 文件中添加以下内容： 123Host github.com Hostname github.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p 其中 127.0.0.1:1080 是本地 SOCKS5 代理的地址，根据你的代理工具调整。 也可以使用 GIT_SSH_COMMAND 环境变量来修改默认 SSH 连接命令，详情可参考 git 的文档。 结论 如果当前网络封禁了 22 端口时，你可以通过以下三种方法绕过针对 GitHub 的封锁： 直接使用 ssh://git@ssh.github.com:443/your-repo.git 进行 Git 操作。 修改 ~/.ssh/config，让 GitHub 连接自动走 ssh.github.com 的 443 端口。 使用 SOCKS5 代理，让 SSH 通过代理访问 GitHub。 你可以根据自己的网络环境选择最适合的方法，确保顺畅地访问 GitHub。","categories":[{"name":"Network","slug":"Network","permalink":"https://blog.inoki.cc/categories/Network/"},{"name":"Protocol","slug":"Protocol","permalink":"https://blog.inoki.cc/categories/Protocol/"},{"name":"Proxy","slug":"Network/Proxy","permalink":"https://blog.inoki.cc/categories/Network/Proxy/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://blog.inoki.cc/tags/GitHub/"},{"name":"SSH","slug":"SSH","permalink":"https://blog.inoki.cc/tags/SSH/"},{"name":"git","slug":"git","permalink":"https://blog.inoki.cc/tags/git/"},{"name":"Proxy","slug":"Proxy","permalink":"https://blog.inoki.cc/tags/Proxy/"}]},{"title":"【译】解释 SDXL 的隐空间","slug":"Explaining-the-SDXL-latent-space","date":"2024-02-18T03:57:50.000Z","updated":"2025-03-08T09:40:48.564Z","comments":true,"path":"2024/02/18/Explaining-the-SDXL-latent-space/","link":"","permalink":"https://blog.inoki.cc/2024/02/18/Explaining-the-SDXL-latent-space/","excerpt":"","text":"原文地址：https://huggingface.co/blog/TimothyAlexisVass/explaining-the-sdxl-latent-space 简短的背景 特别感谢 Ollin Boer Bohan Haoming、 Cristina Segalin 和 Birchlabs 提供的信息、讨论和知识帮助！ 我正在为 SDXL 推理过程创建校正滤波器，以用于我为扩散模型创建的用户界面。 在拥有多年的图像校正经验后，我希望能够从根本上改进 SDXL 的实际输出。要创建的用户界面中有许多我想要的技术，我开始着手自己解决这些问题。我注意到，SDXL 的输出几乎总是有规律地出现噪点或过于平滑。由于标清模型的工作原理，色彩空间总是需要白平衡，色彩范围有偏差和限制。 如果可以在实际输出之前改善信息和色彩范围，那么在图像生成并转换为 8 位 RGB 之后的后期处理中进行修正就没有什么意义了。 要创建滤镜和修正工具，最重要的是要了解你正在处理的数据。这促使我开始对 SDXL 的隐层进行实验性探索，以期了解它们。基于 SDXL 架构的扩散模型所使用的张量如下所示： 1[batch_size, 4 channels, height (y), width (x)] 我的第一个问题很简单：“这 4 个通道到底是什么？” 我得到的大多数回答都是“这不是人类能理解的东西”。但我认为这绝对是可以理解的，甚至是非常容易理解和有用的知识。 SDXL 隐层的 4 个通道 对于由 SDXL 生成的 1024×1024 像素的图像，隐层的张量为 128×128 像素，其中隐空间中的每个像素代表像素空间中的 64 (8×8) 个像素。如果我们将隐层生成并解码为标准的 8 位 jpg 图像，那么： 8 位像素空间拥有 3 个通道 红色 ®、绿色 (G) 和蓝色 (B)，每个通道有 256 个可能的值，范围在 0-255 之间。因此，要存储 64 个像素的全部信息，我们需要在每个隐层像素的每个通道中存储 64×256 = 16384 个值。 图像的 SDXL 隐层表示有 4 个通道： 0：亮度 1：青色/红色 =&gt; 相当于 rgb(0, 255, 255)/rgb(255, 0, 0) 2：淡紫色/中紫色 =&gt; 相当于 rgb(127, 255, 0)/rgb(127, 0, 255) 3：图案/结构。 如果在解码时每个值的范围都在 -4 和 4 之间，那么在半精度的 16 位浮点格式中，每个隐层像素的 4 个通道都可以包含 16384 个不同的值。 通过线性近似将 SDXL 潜在像素直接转换为 RGB 有了这种理解，我们就可以创建一个近似函数，将隐层像素直接转换为 RGB： 1234567891011121314def latents_to_rgb(latents): weights = ( (60, -60, 25, -70), (60, -5, 15, -50), (60, 10, -5, -35) ) weights_tensor = torch.t(torch.tensor(weights, dtype=latents.dtype).to(latents.device)) biases_tensor = torch.tensor((150, 140, 130), dtype=latents.dtype).to(latents.device) rgb_tensor = torch.einsum(\"...lxy,lr -&gt; ...rxy\", latents, weights_tensor) + biases_tensor.unsqueeze(-1).unsqueeze(-1) image_array = rgb_tensor.clamp(0, 255)[0].byte().cpu().numpy() image_array = image_array.transpose(1, 2, 0) # Change the order of dimensions return Image.fromarray(image_array) SDXL 色彩范围偏向黄色的可能原因 自然界中蓝色或白色的东西相对较少。在天空中，这些颜色在宜人的条件下最为突出。因此，通过图像了解现实的模型会以亮度（通道 0）、青色/红色（通道 1）和淡紫色/中紫色（通道 2）来思考，其中红色和绿色为主，蓝色为辅。 这就是为什么 SDXL 生成往往偏向于黄色（红+绿）。 在推理过程中，张量中的值将从最小值 -30 和最大值 30 开始，解码时的最小/最大边界约为 -4 至 4。 理解这些边界的一个关键是看解码过程中发生了什么： 12decoded = vae.decode(latents / vae.scaling_factor).sample # (SDXL vae.scaling_factor = 0.13025)decoded = decoded.div(2).add(0.5).clamp(0, 1) # The dynamics outside of 0 to 1 at this point will be lost 如果这一点上的值超出了 0 到 1 的范围，就会丢失一些信息。因此，如果我们能在去噪过程中进行修正，以满足 VAE 的期望，我们可能会得到更好的结果。 什么需要修正？ 如何锐化模糊的图像、进行白平衡、改善细节、增加对比度或扩大色彩范围？最好的方法是从清晰的图像开始，图像白平衡正确，对比度高，细节清晰，范围大。 模糊清晰的图像、改变色彩平衡、降低对比度、获得不合理的细节和限制色彩范围远比改善图像要容易得多。 SDXL 有一个非常明显的倾向，就是色彩偏差和将数值置于实际边界之外（上图）。将数值居中并使其在边界内（下图），就可以轻松解决这个问题： 这段代码可以将颜色修正： 1234def center_tensor(input_tensor, per_channel_shift=1, full_tensor_shift=1, channels=[0, 1, 2, 3]): for channel in channels: input_tensor[0, channel] -= input_tensor[0, channel].mean() * per_channel_shift return input_tensor - input_tensor.mean() * full_tensor_shift SDXL 的示例输出的例子 生成时使用的随机数、参数和 prompt 如下： 12345678seed: 77777777guidance_scale: 20 # A high guidance scale can be fixed toosteps with base: 23steps with refiner: 10prompt: Cinematic.Beautiful smile action woman in detailed white mecha gundam armor with red details,green details,blue details,colorful,star wars universe,lush garden,flowers,volumetric lighting,perfect eyes,perfect teeth,blue sky,bright,intricate details,extreme detail of environment,infinite focus,well lit,interesting clothes,radial gradient fade,directional particle lighting,wownegative_prompt: helmet, bokeh, painting, artwork, blocky, blur, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, crooked, blurry, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands 请注意，我特意选择了较高的引导比例（guidance_scale 参数）。 如何修复这张图片？它一半是绘画，一半是照片。色彩范围偏向黄色。下边是设置完全相同的修复后的生成图像。 但是，如果将 guidance_scale 设置为 7.5，我们仍然可以得出这样的结论：修复后的输出效果更好，没有不合理的细节，白平衡也正确。 我们可以在潜空间中做很多事情来普遍改进一次生成，也可以针对一次生成中的特定错误做一些非常简单的事情来进行修复： 离群值去除 这将通过修剪离分布平均值最远的值来控制不合理细节的数量。它还有助于以更高的引导比例（guidance_scale 参数）生成。 123456789101112131415# Shrinking towards the mean (will also remove outliers)def soft_clamp_tensor(input_tensor, threshold=3.5, boundary=4): if max(abs(input_tensor.max()), abs(input_tensor.min())) &lt; 4: return input_tensor channel_dim = 1 max_vals = input_tensor.max(channel_dim, keepdim=True)[0] max_replace = ((input_tensor - threshold) / (max_vals - threshold)) * (boundary - threshold) + threshold over_mask = (input_tensor &gt; threshold) min_vals = input_tensor.min(channel_dim, keepdim=True)[0] min_replace = ((input_tensor + threshold) / (min_vals + threshold)) * (-boundary + threshold) - threshold under_mask = (input_tensor &lt; -threshold) return torch.where(over_mask, max_replace, torch.where(under_mask, min_replace, input_tensor)) 色彩平衡和增加范围 我有两种主要方法来实现这一目标。第一种是在对数值进行归一化处理时向平均值收缩（这也会去除异常值），第二种是在数值偏向某种颜色时进行修正。这也有助于以更高的指导尺度生成。 12345# Center tensor (balance colors)def center_tensor(input_tensor, channel_shift=1, full_shift=1, channels=[0, 1, 2, 3]): for channel in channels: input_tensor[0, channel] -= input_tensor[0, channel].mean() * channel_shift return input_tensor - input_tensor.mean() * full_shift 张量最大化 这基本上是通过将张量乘以一个非常小的量，如 1e-5，进行几个步骤，并确保最终张量在转换为 RGB 之前使用了全部可能的范围（接近 -4/4）。请记住，在像素空间中，用完整的动态降低对比度、饱和度和锐度比增加对比度、饱和度和锐度更容易。 123456789# Maximize/normalize tensordef maximize_tensor(input_tensor, boundary=4, channels=[0, 1, 2]): min_val = input_tensor.min() max_val = input_tensor.max() normalization_factor = boundary / max(abs(min_val), abs(max_val)) input_tensor[0, channels] *= normalization_factor return input_tensor 回调实现示例 1234567891011121314151617def callback(pipe, step_index, timestep, cbk): if timestep &gt; 950: threshold = max(cbk[\"latents\"].max(), abs(cbk[\"latents\"].min())) * 0.998 cbk[\"latents\"] = soft_clamp_tensor(cbk[\"latents\"], threshold*0.998, threshold) if timestep &gt; 700: cbk[\"latents\"] = center_tensor(cbk[\"latents\"], 0.8, 0.8) if timestep &gt; 1 and timestep &lt; 100: cbk[\"latents\"] = center_tensor(cbk[\"latents\"], 0.6, 1.0) cbk[\"latents\"] = maximize_tensor(cbk[\"latents\"]) return cbkimage = base( prompt, guidance_scale = guidance_scale, callback_on_step_end=callback, callback_on_step_end_inputs=[\"latents\"]).images[0] 这三种方法的简单实现被用于最后一组图像，即花园中的妇女。 增加色彩范围/消除色彩偏差 在常规输出中，SDXL 将颜色范围限制为红色和绿色。因为提示中没有任何内容表明有蓝色这种东西。这是相当不错的一次生成，但颜色范围却受到了限制。 如果你给别人一个黑色、红色、绿色和黄色的调色板，然后告诉他要画出晴朗的蓝天，那么很自然的反应就是要求你提供蓝色和白色。 要在生成中包含蓝色，我们只需在色彩空间受限时重新调整色彩空间，SDXL 就会在生成中适当地包含完整的色彩光谱。 高指导尺度下的长提示成为可能 下面是一个典型的例子，颜色范围的增加使整个提示词成为可能，本示例应用了前面所示的简单、生硬的修改，以更清楚地说明两者的区别： 1prompt: Photograph of woman in red dress in a luxury garden surrounded with blue, yellow, purple and flowers in many colors, high class, award-winning photography, Portra 400, full format. blue sky, intricate details even to the smallest particle, extreme detail of the environment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece","categories":[{"name":"AI","slug":"AI","permalink":"https://blog.inoki.cc/categories/AI/"},{"name":"Stable Diffusion","slug":"AI/Stable-Diffusion","permalink":"https://blog.inoki.cc/categories/AI/Stable-Diffusion/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"AI","slug":"AI","permalink":"https://blog.inoki.cc/tags/AI/"},{"name":"Stable Diffusion","slug":"Stable-Diffusion","permalink":"https://blog.inoki.cc/tags/Stable-Diffusion/"},{"name":"SDXL","slug":"SDXL","permalink":"https://blog.inoki.cc/tags/SDXL/"}]},{"title":"【译】关于 USB-C 的一切：示例电路","slug":"All-about-USB-C-example-circuits","date":"2023-09-14T23:42:00.000Z","updated":"2025-03-08T09:40:48.547Z","comments":true,"path":"2023/09/14/All-about-USB-C-example-circuits/","link":"","permalink":"https://blog.inoki.cc/2023/09/14/All-about-USB-C-example-circuits/","excerpt":"","text":"原文链接：https://hackaday.com/2023/08/07/all-about-usb-c-example-circuits/ 在上一篇 USB-C 文章发表后的六个月里，我想了很多可以改进这些文章的方法。当然，有这种感觉是正常的，甚至是意料之中的。我现在认为，我可以弥补一些不足。例如，我没有提供足够的电路示例，而有时一张原理图比千言万语能表达的更多。 让我们来解决这个问题！我将为你提供你可能真的想制作的 USB-C 设备的原理图。我还将在本文中分享大量集成电路的零件编号，当然，我并没有详尽无遗地收集所有集成电路。 我们已经在第一篇文章中看到了第一个示例电路——支持 USB 2.0 和 5V 电源的设备侧（面向上游）USB-C 端口。您必须有 5.1KΩ 电阻器，每个引脚一个电阻器，并记住连接两个数据引脚，必要时使用通孔。如果您想确定可用电流的大小，也可以将 ADC 或比较器一起连接到 CC 引脚上，不过通常情况下，您的设备功耗很低，没有必要这么麻烦。 现在，如果您想制作带有 USB-C 插头的设备，接线方法也是一样的。唯一的区别是，您只需填充一个 CC 下拉引脚，并连接一对 D+/D- 引脚，而不是两对。在实际操作中，如果接上第二对 USB 2.0 引脚，也不会发生什么不好的事情，只是按照标准，这样做很不雅观；它曾经与某种端口和电缆（VirtualLink 电缆）相冲突，但现在已经不再出售了。 不过，如果在两个 CC 引脚上都接上 5.1KΩ 下拉电阻，就能意外地制作出一个黑客配件：调试模式适配器，它能帮助你从某些 USB-C 端口获得额外的信号。例如，在 Framework 笔记本电脑上，配备 USB-C 插头的电路板上的两个下拉引脚会将 USB-C 端口切换到调试模式，并暴露 SBU 引脚上的 Embedded Controller 的 UART 连接。除非您要制作这样的调试配件，否则您只需填充其中一个下拉电阻，并相应地为 USB 2.0 数据引脚布线即可。 另一方面也同样简单 如果您想制作一个主机端口呢？从一方面看，这更容易，因为您不一定需要进行任何 ADC 测量。相反，您可以添加上拉电阻，不同的值适用于不同的可用电流。并非所有设备都会检查上拉是否存在，但手机会，所以如果你制作一个临时的 USB-C 充电器，如果没有上拉电阻，手机或笔记本电脑可能无法将其识别为有效的充电方式。添加上拉电阻也不会花很多钱！ 更重要的是，您可能需要控制 VBUS，只有在检测到 CC 引脚之一出现下拉后才将其接通。如果不这样做，不一定会有问题，但它确实涵盖了一些重要的边缘情况，比如有人将 USB-A 转 USB-C 电缆插入你的端口！ 我从未做过这种电路，但在我看来，使用两个场效应管就足够了，每个 CC 引脚一个，两个并联。这个电路可能有边缘情况，欢迎改进！另一方面，我曾多次将配备下拉功能的 USB-C 端口断路器用作主机端口，因此这绝对不是硬性要求，而且您也不一定需要动用您的 FET 收藏。 如果要构建主机端口，总共需要做两件事，而这两件事都不太需要。此外，如果你想在电路上做得更复杂一些，或者甚至想做一个双功能端口，也有一些集成电路可以帮助你完成 USB-C 的这一部分！ 例如，WUSB3801。它既能检测源极，也能检测漏极，内部有所有需要的上拉和下拉功能，甚至还能实现双功能端口，让您可以构建任何类型的 5 V 电源端口。它可以通过几个 GPIO 输出端口状态，也可以通过 I2C 连接到微控制器，甚至还有一个 ID 引脚，这样就可以用 USB-C 端口完全取代 MicroUSB 端口！WUSB3801 体积小、可焊接，而且用途广泛。例如，在 Hackaday Discord 服务器上，有人制作了一个 WUSB3801 电路，它可以根据所连接的 USB-C 端口是否能提供 3 安培的电流来限制锂离子充电器的电流。 无论您想构建一个源端口、一个汇流端口，甚至是一个可以同时实现这两种功能的端口，WUSB301（或许多类似的集成电路，如 TUSB320）都将是您的理想解决方案。我对 WUSB3801 有一点不满，那就是它没有提供用于确定当前插入端口极性的 GPIO - 为此，您必须使用 I2C 接口。为什么需要知道端口极性呢？原因就在于高速接口，而 USB 3.0 接口无疑是 USB-C 的主流接口，这仅仅是因为它非常容易实现。 高速、但低价 使用 USB-C 插头制造 USB 3.0 设备与使用 USB-C 插头制造 USB 2.0 设备一样简单。USB 3.0 增加了两个高速差分对，而 USB-C 连接器则有四个差分对位置。有了这个插头，您就可以将 USB 3.0 SSRX 连接到 USB-C RX1，将 USB 3.0 SSTX 连接到 USB-C TX1，然后在 CC1 上插入一个下拉电阻，这样就大功告成了。除了 USB 3.0 链路可能需要的串联电容外，没有任何额外的元件，这些元件与普通的实现方式并无不同。 现在，这就是为什么你会看到很多 USB 闪存盘采用 USB-C 插头的原因——添加 USB-C 插头非常简单，你不需要弄清楚 CC 引脚，也不需要添加任何额外的元件。不过，如果要添加一个支持 USB 3.0 的 USB-C 插座，则需要添加额外的组件。想象一下，将 USB 3.0 USB-C 闪存盘插入 USB-C 插座，根据接口方向的方向，插针最终会位于两个位置中的一个。你不会想把插座的 TX/RX 引脚连接在一起，那样会有很大的信号完整性问题，所以如果你要添加一个支持 USB 3.0 的 USB-C 插座，你需要一个复用器来处理高速信号的接口方向。 现在，这种 USB-C 芯片已经屡试不爽，至少有十几家不同的制造商生产这种芯片。有些多路复用器会有一个 POL 输入，用于将 USB 3.0 信号手动切换到两个可能的位置——这些多路复用器应与您自己的 PD 控制器（即处理 CC 引脚的芯片）一起使用。您会发现，许多多路复用器也包含 CC 逻辑，基本上可以为 5V 和支持 USB 3.0 的 USB-C 提供完整的解决方案。如果您正在构建主机的电路，可能只需要添加 VBUS 处理，而如果您正在构建带有 USB-C 插座的设备，则不需要其他任何东西！ 笔记本电脑上的许多廉价 USB-C 端口都采用了这种多路复用器——它们只提供 USB 2.0，不提供其他任何功能，而且这种多路复用器非常容易实现，因此许多廉价笔记本电脑制造商都采用了这种多路复用器。此外，如果你有一个 USB 3.0 端口，你甚至可以省略多路复用器。我们在台式机主板上见过这种做法，有趣的是，MNT Pocket Reform 的两个 USB-C 端口也是这样接线的！Pocket Reform 主板的板载 USB 3.0 集线器有四个空闲端口，但只有两个 USB-C 端口可以使用 USB 3.0。如果有人想使用这两个额外的 USB 3.0 端口，只需设计一个无源适配器即可！ Pocket Reform 上的这两个 USB-C 端口中有一个很特别，它不像第一个端口那样只将 5 V 电压轨连接到 VBUS。相反，它有一个电源开关 IC 与 VBUS 连接，还有一个 FUSB302B 与 CC 引脚连接。这就是 Pocket Reform 的充电器端口，事实上，这也是实现电源传输的方法之一。 获取电压和像素 我们讨论过的所有选项都已支持高达 15W 的功率，特别是 5V、3A 的电压。您只需要懂 PD 协议，或者让芯片为您协商。 正如你可能猜到的那样，这些友好的芯片就是 PD 触发器集成电路。你将它们连接到 CC 引脚，它们就会代表你协商电源配置文件。它们有几个输入端让你设置所需的电压，如果电源供应器无法提供你所需的电压，还可以选择一个场效应管驱动器输出端来断开 VBUS，确保你不会在需要 20V 电压的电源轨上获得默认的 5V 电压。 关于触发器芯片，我们可以谈很多，很多人都聊过了，我肯定也是。事实上，当人们需要从 USB-C 端口获得高电压时，绝大多数人都会选择触发芯片。它们非常适合大多数使用情况，而且很有可能，你会想要使用它。但是，请注意，它们的行为并不灵活：它们不会让你制造一个双功能端口，也不会让你区分 30W USB-C PSU 和 100W PSU，而这在你驱动电阻负载时是有帮助的。此外，由于没有方向输出，它们也不能与 USB 3.0 或 DisplayPort 结合使用，也不能发送自定义信息。 一个 PD 控制器能让您做更多事情！无论您使用的是 FUSB302B 这样的外置 PD 控制器，还是内置在 MCU 中的 PD 控制器，它都能让您做出自己的 PD 通信决定。它提供了您可能需要的所有电阻器，而且无论您需要完成什么任务，都有可能找到示例代码。我们已经完成了用于电源和 DisplayPort sink 操作的自定义 PD 信息构建。到时候，我们甚至会用 FUSB302B 构建自己的 USB-C PSU，敬请期待！说到 MCU，有一些著名的 STM32 和 Cypress 的微控制器带有 PD 外设，最近，CH32X035 也加入了这一行列。 您自己的 PD 控制器还能让您发送 DisplayPort 信息——从任何兼容端口提取 DisplayPort 输出，或者自己提供 DisplayPort。使用 USB-C 插头就不需要多路复用器，或者使用插座并添加一个兼容 DisplayPort 的多路复用器，这样就能同时提取双通道 DisplayPort 和 USB 3.0，或四通道 DisplayPort，随你所需。或者，你也可以使用 DisplayPort 插座，省去多路复用器，让端口只在一个方向上工作——中国的 eDP 分线器销售商可以证实这一点！ 在下一篇文章中，我们将介绍 USB-C PSU 的内部工作原理，然后将 20V PSU 转换为支持 20V 的 USB-C 电源；我们只需要 FUSB302、几个 FET 和一个备用 5V 稳压器。这不需要我们做太多，你就能将旧电源转换为 USB-C 笔记本电脑电源，还能了解 USB-C PSU 的工作原理！","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/categories/USB/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/categories/硬件/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/tags/硬件/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/tags/USB/"}]},{"title":"【译】关于 USB-C 的一切：高速接口","slug":"All-about-USB-C-high-speed-interfaces","date":"2023-09-14T23:22:00.000Z","updated":"2025-03-08T09:40:48.547Z","comments":true,"path":"2023/09/14/All-about-USB-C-high-speed-interfaces/","link":"","permalink":"https://blog.inoki.cc/2023/09/14/All-about-USB-C-high-speed-interfaces/","excerpt":"","text":"原文链接：https://hackaday.com/2023/01/17/all-about-usb-c-high-speed-interfaces/ USB-C 的惊人之处在于它的高速性能。其引脚提供了四个高速差分信号线对和几个低速信号线对，让您可以通过一个比硬币还小的连接器传输大量数据。但并非所有设备都能利用这一功能，而且也不需要这样做——USB-C 的设计目的是让世界上所有便携设备都能使用。然而，当你的设备需要通过 USB-C 传输高速数据时，USB-C 能为你带来的益处以及它能发挥的作用就会让你大吃一惊。 从 USB-C 接口获得高速接口的能力被称为&quot;替代模式&quot;，简称&quot;altmode&quot;。目前，你能遇到的三种替代模式是 USB3、DisplayPort 和 Thunderbolt，还有一些已经淡出人们视线，如 HDMI 和 VirtualLink，还有一些正在崛起，如 USB4。大多数 altmode 都需要数字 USB-C 通信，通过 PD 通道使用特定类型的信息。尽管如此，并非所有模式都需要 altmode，USB3 就是最简单的一种。下面我们就来了解一下什么是 altmode。 USB-C 中的 C 代表&quot;能够&quot; 如果你看过引脚图，就应该知道高速引脚。今天，我想向大家介绍一下如今这些引脚可以提供哪些接口。这并不是一个完整或广泛的列表，例如，我不会谈论 USB4 等接口，部分原因是我对其了解不够，也没有使用经验；另外，可以肯定的是，未来我们将获得更多配备 USB-C 的高速设备。此外，USB-C 具有足够的灵活性，黑客可以通过它以符合 USB-C 标准的方式暴露以太网或 SATA——如果这正是你所寻找的，也许这篇概述能帮你弄明白。 USB3 USB3 非常非常简单，只有一对 TX 和一对 RX，虽然传输速度远远高于 USB2，但对于黑客来说还是可以应付的。如果使用具有 USB3 信号阻抗控制功能的多层印刷电路板，并谨慎处理不同的差分信号线对，USB3 连接一般都能正常工作。 对于 USB3 和 USB-C，变化不大——您将有一个用于处理接口方向的多路复用器，但仅此而已。USB3 多路复用器非常丰富，因此在电路板上添加支持 USB3 的 USB-C 几乎不会有问题。此外，还有双链路 USB3，即并行使用两个 USB3 链路来提高吞吐量，但黑客一般既不会遇到也不需要这个，而这一领域往往由 Thunderbolt 提供更好的服务。想将 USB3 设备转换为 USB-C？你只需要一个多路复用器。如果您想在电路板上为高速设备安装 MicroUSB 3.0 接口的话，我婉拒，请您改用 USB-C 插座和 VL160。 如果您设计的是配备插头的 USB3 设备，您甚至不需要处理接口方向的多路复用器——事实上，您不需要任何接口方向检测。对于直接插入 USB-C 端口的 USB3 闪存盘，或 USB-C 公口到 USB-A 3.0 母口的适配器，一个不受监控的 5.1kΩ 电阻器就足够了。在插座方面，如果有备用的 USB3 连接可以牺牲，就可以避免使用多路复用器，当然这并不是一个很好的交易。我对双链路 USB3 的了解还不足以判断这种连接是否具有 USB3 双链路功能，但我认为答案是否的可能性大于是！ DisplayPort DisplayPort (DP) 是连接高分辨率显示器的绝佳接口——它在台式机领域已超越 HDMI，在嵌入式显示器领域以其 eDP 形式占据主导地位，通过单根电缆提供高分辨率，通常比 HDMI 更好。通过使用一种名为 DP++ 的标准，它可以通过廉价的适配器转换成 DVI 或 HDMI，而且不像 HDMI 那样受版权限制。VESA 联盟与 USB 集团合作实现对 DisplayPort 的支持是合情合理的，尤其是考虑到 SoC 中的 DisplayPort 传输器已经越来越流行。 如果你使用的是带有 HDMI 或 VGA 输出的底座，那么它在引擎盖下使用的就是 DisplayPort altmode。越来越多的显示器都带有 DisplayPort over USB-C 输入，由于有了名为 MST 的功能，你可以串联显示器，实现单线多显示器配置——除非你使用的是 Macbook，因为苹果拒绝在 MacOS 中支持 MST。 此外，还有一个有趣的事实——DP 模式是唯一使用 SBU 引脚的模式之一，SBU 引脚被重新用于 DisplayPort AUX 对。USB-C 引脚的整体匮乏也意味着必须省略 DP 配置引脚，除了 DP++ HDMI/DVI 兼容模式。因此，所有的 USB-C DP 至 HDMI 适配器实际上都是变相的 DP-HDMI 转换器，而 DP++ 则不同，它允许您使用电平转换器来支持 HDMI。 如果你想使用 DisplayPort，你可能需要一个支持 DP 的多路复用器，但最重要的是，你需要能够发送自定义的 PD 信息。首先，整个&quot;提供/请求 DP Altmode&quot;部分都是通过 PD 信息完成的，因此光靠电阻是不够的。另外，DisplayPort 中的一个重要信号 HPD 没有空闲的引脚，因此热插拔事件和中断都是通过 PD 通道作为信息发送的。在此之前，如果你需要从 USB-C 端口用 DP altmode 输出 DP 或 HDMI，有一些芯片（如 CYPD3120）可以让你编写固件来实现这一功能。 使 DP 模式脱颖而出的一个重要因素是，USB-C 端口有四条高速通道，这种模式允许在 USB-C 端口的一侧连接 USB3，在另一侧连接双通道 DisplayPort。这就是所有&quot;USB3 端口、外设和 HDMI 输出&quot;底座的工作原理。如果双通道分辨率对你有限制，你也可以买一个四通道适配器——因为没有 USB3，所以没有数据传输，但你可以通过两个额外的 DisplayPort 通道获得更高的分辨率或帧率。 我的看法是，DisplayPort altmode 是 USB-C 最棒的地方之一，虽然最便宜（或设计最糟糕）的笔记本电脑和手机都不支持它，但拥有一款支持它的设备也是一件乐事。当然，有时大公司也会直接剥夺这种乐趣，比如谷歌。 译者注：更多的 DisplayPort altmode 信息可以在这篇文章和这篇文章中找到。 然后，让我们来谈谈其中最复杂的 altmode。 THUNDERBOLT 具体到 USB-C，您可以使用 Thunderbolt 3，不久还可以使用 Thunderbolt 4，但现在这只是想象中的。Thunderbolt 3 最初是一种专有规范，最终由英特尔开源。显然，他们开源得还不够，或者还有其他的注意事项，因为目前市场上的 Thunderbolt 3 设备仍然完全使用英特尔芯片制造，而我的猜测是，缺乏竞争是导致价格牢牢占据三位数领域的原因。为什么首先要选择 Thunderbolt 设备？除了更高的速度，还有一个杀手锏。 您可以通过 Thunderbolt 获得 PCIe 直通，链接宽度可达 4x！这一直是希望获得 eGPU 支持或使用 NVMe 驱动器进行快速外部存储的用户的热门话题，一些黑客还将其用于 PCIe 连接的 FPGA。如果你有两台支持 Thunderbolt 的电脑（比如两台笔记本电脑），你也可以通过支持 Thunderbolt 的电缆将它们连接起来——这将在两台电脑之间创建一个高速网络接口，而无需额外的组件。当然，Thunderbolt 还能在自身内部轻松实现 DisplayPort 和 USB3 传输。Thunderbolt 技术功能强大，适合高级用户使用。 尽管如此，所有这些炫酷功能都是以专有和复杂的技术堆栈为代价的。Thunderbolt 并不是一个黑客就能轻易开发出来的——不过，总有一天会有人尝试的。而且，尽管 Thunderbolt 底座拥有丰富的功能，但软件方面的问题却时有发生，尤其是在尝试让笔记本电脑的睡眠模式正常工作而不会让 eGPU 崩溃内核的时候。如果这一点现在还不明显的话，我正焦急地等待英特尔将其整合起来。 多路复用器？什么是多路复用器？ 我一直在说&quot;多路复用器&quot;。那是什么？简而言之，就是根据 USB-C 旋转情况帮助处理高速信号交换的部分。 高速通道是 USB-C 中受端口旋转影响最大的部分。如果您的 USB-C 端口使用高速通道，则需要一个多路复用器（mux）集成电路来管理两种可能的 USB-C 接口方向——将两端端口的方向和电缆与所连接设备内部的实际高速接收器和发射器相匹配。有时，如果高速芯片是针对 USB-C 开发的，那么这些多路复用器就是高速芯片的内部部分，但很多时候，它们是独立的芯片。想要为尚未支持 USB-C 的设备添加高速 USB-C 支持？多路复用器将是实现高速通信的核心元件。 如果您的设备有一个带高速通道的 USB-C 插座，它就需要一个多路复用器，而配备缆线和插头的设备则不需要。通常情况下，如果使用线缆连接两台带有 USB-C 插口的高速设备，则两台设备都需要多路复用器——管理线缆旋转是每台设备的责任。在两边，多路复用器（或连接有多路复用器的 PD 控制器）将监控 CC 引脚的方向，并采取相应措施。这种多路复用器也有很多，用途各不相同——这取决于你想从端口中得到什么。 你会在只在 Type-C 端口上实现 USB 3.0 的廉价笔记本电脑中看到 USB3 专用的多路复用器，如果它支持 DisplayPort，你就会看到有额外输入的多路复用器来混合这些信号。在配备 Thunderbolt 高端端口的笔记本电脑中，多路复用器将内置在 Thunderbolt 芯片中。对于无法使用 Thunderbolt 或不需要 Thunderbolt 的使用 USB-C 开发的黑客来说，TI 和 VLI 提供了许多适用于各种用途的优秀多路复用器。例如，我最近一直在使用 DisplayPort over USB-C，而 VL170（似乎是 TI HD3SS460 的 1:1 克隆版）看起来是一款非常适合 DisplayPort + USB3 组合用途的芯片。 HD3SS460 等支持 DisplayPort 的 USB-C 多路复用器本身不能进行 CC 引脚管理和旋转检测，但这是一个合理的限制 - 您需要针对 DisplayPort 进行相当特定的应用 PD 通信，而这很快就会超出多路复用器的功能范围。USB3 不需要 PD 通信，您是否满意？VL161 是一款用于 USB3 多路复用的简单芯片，它有一个极性输入，需要您自己进行方向检测。 如果您也不想进行方向检测，那么模拟、纯 5V PD 是否足以满足您的 USB3 需求？请使用 VL160 这样的产品——它可以进行终端设备和源设备模拟 PD，同时处理电源和高速通道旋转。这才是真正的&quot;我希望在 USB-C 上使用 USB3，我希望一切都能为我管理&quot;的 IC；例如，最近的开源 HDMI 采集卡的 USB-C 端口就使用了 VL160。不过，为了公平起见，我没有必要把 VL160 单列出来——这样的集成电路有几十种；&quot;USB-C 的 USB3 复用器无所不能&quot;可能是目前最流行的一种 USB-C 相关观点。 已计划，但已放弃的 altmode 有几种被放弃的 USB-C 模式。第一种我不会为它悲伤——它是 HDMI 模式；它只是将 HDMI 接口引脚放到 USB-C 接口引脚上。它可以通过 USB-C 连接 HDMI，而且似乎曾在智能手机上短暂使用过。然而，HDMI-DP 转换通常成本高昂，而 HDMI 需要四个差分线对，因此无法与 USB 3.0 结合使用，再加上 HDMI 许可包袱，HDMI 替代模式不得不与易于转换为 HDMI 的 DisplayPort 替代模式竞争。我真诚地认为它应该继续存在，因为我不相信增加更多的 HDMI 就能改善我们的世界。 不过，另一种模式其实很有趣，它叫 VirtualLink。一些大型科技公司一直在研究 USB-C 在 VR 方面的功能，毕竟，当你的 VR 头显只需要一根线缆就能完成所有操作时，那真是太棒了。然而，VR 眼镜需要一个高分辨率、高帧速率的双显示视频接口，以及一个用于辅助摄像头和传感器的高速数据连接，而通常的&quot;双通道 DisplayPort+USB3&quot;组合在当时无法提供这样的功能。那该怎么办呢？ VirtualLink 集团表示，这很简单，只要去掉 USB-C 连接器上的两个重复的 USB2 对，用四个引脚连接 USB3 即可。还记得我半年前在一篇短文中提到的 USB2 至 USB3 转换器芯片吗？是的，它最初的用途是 VirtualLink。当然，这种安排需要更昂贵的定制线缆，并额外增加两个屏蔽线对，而且还要求 PC 提供高达 27W 的功率，因此需要 9V 的输出电压——这在非墙插充电器或电源箱的 USB-C 端口上非常罕见。USB2 与 USB3 的偏离让一些人感到不满；不过，对于 VR 而言，VirtualLink 看起来非常有用。 一些 GPU 在出厂时支持 VirtualLink，但最终还是不够，而以缺少 USB-C 端口而闻名的笔记本电脑也不屑一顾。这导致这一安排的关键参与者 Valve 放弃了在 Valve Index 中添加 VirtualLink 集成，从此开始走下坡路。遗憾的是，VirtualLink 从未真正起飞。本来，VirtualLink 会是一种有趣的辅助模式——对于 VR 用户来说，单根线缆会非常棒，而且 USB-C 对电压的要求也会提高，这也为我们提供了可使用 PD 的高于 5V 的端口——而现在的笔记本电脑和个人电脑几乎都不提供这种端口。是的，提醒一下——如果你的台式机或笔记本电脑上有一个 USB-C 端口，它当然会给你提供 5 V 电压，但你不会得到更高的输出电压。 不过，让我们看看好的一面。如果您的 GPU 碰巧配备了 USB-C 端口，那么它将同时支持 USB3 和 DisplayPort！ 统一带来兼容性 USB-C 的最大优势在于：如果厂商或黑客愿意，完全可以定义自己的混合模式，虽然适配器是半专有的，但其核心仍是 USB-C 端口，可用于充电和数据传输。想要以太网模式或双端口 SATA？就这么办。过去，我们不得不为设备寻找非常晦涩难懂的连接器，每一个基座和充电连接器都不一样，如果足够罕见，甚至有可能找到的话，每个连接器的价格可能高达 10 美元，这样的日子已经一去不复返了。 并不是每个 USB-C 端口都必须实现所有这些功能，许多 USB-C 端口并不具备这些功能。但是，很多 USB-C 端口都能实现这些功能，而且随着时间的推移，我们能从一个普通的 USB-C 端口中获得越来越多的功能。从长远来看，这种统一和标准化将带来回报，虽然偶尔会出现偏差，但制造商将学会更巧妙地处理这些偏差。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/categories/USB/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/categories/硬件/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/tags/硬件/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/tags/USB/"}]},{"title":"【译】关于 USB-C 的一切：电阻和电子标记（E-marker）","slug":"All-about-USB-C-resistors-and-emarkers","date":"2023-09-13T23:22:00.000Z","updated":"2025-03-08T09:40:48.547Z","comments":true,"path":"2023/09/13/All-about-USB-C-resistors-and-emarkers/","link":"","permalink":"https://blog.inoki.cc/2023/09/13/All-about-USB-C-resistors-and-emarkers/","excerpt":"","text":"原文链接：https://hackaday.com/2023/01/04/all-about-usb-c-resistors-and-emarkers/ 如果您一直关注我们的 USB-C 系列文章，就会知道 USB-C 电缆中的 CC 线用于通信和旋转检测。不过不为人知的是，USB-C 有两种通信协议，一种是模拟协议，另一种是数字协议。今天，让我们来了解一下 USB-C 中使用的模拟信号——在一定程度上，了解一下传说中的 5.1kΩ 电阻及其工作原理。我们还将了解 USB-C 中的标记符号和神秘的 VCONN！ USB-C 电源在为 VBUS 提供 5V 电压之前，需要在 CC 线路上检测到一定值的下拉，而任何更高的电压都必须通过数字协商确定。无论作为笔记本电脑的端口还是充电器，PSU 都能检测到下拉值（称为 Rd），因为它在 CC 线路上保持了上拉（称为 Rp）——然后它会检查 CC 上是否产成了分压，以及所产生的电压是否在可接受的范围内。 如果您插入的设备无法通过线缆中的 CC 线实现下拉，那么您的设备将永远无法从 USB-C 端口获得电源，只能使用 USB-A 转 USB-C 线缆。即使是能与 USB-C 数字部分通信的智能设备也会有下拉功能，只是这些下拉功能是所使用的 USB-C 通信 IC 的内部功能。因此，想要充电的 USB-C 端口需要有下拉功能。 这部分现在已经众所周知，但我们在廉价设备上看到过很多电阻不足的故障，俗话说的就是需要&quot;添加 5.1kΩ 电阻&quot;。你可能会觉得这部分的原理很简单，也可能会大吃一惊。 上拉、下拉和由此产生的分压 USB-C 端口有两种电源角色——电源端和消耗端。在 5V 电压下使用 USB-C 时，USB-C 的模拟侧可让设计人员添加一种简单的方法来协商电源要求，而无需使用特定或昂贵的集成电路——可以使用上拉来控制电源，并使用下拉来控制终端。上拉和下拉的组合形成一个分压器，分出的电压本身代表充电器的电流能力。 在模拟信号模式下，信号源可以根据可用的功率预算调整上拉，这一点非常有用。想象一下：一台笔记本电脑或充电器上有多个 USB-C 端口。随着每个端口的负载增加，可提供给其他端口的电流就会减少，这在很大程度上取决于设备的内部构造。以 Framework 笔记本电脑为例，它配备了四个 USB-C 端口。每个端口可以在 5V/3A 的电压下提供 15W 的功率，但如果您想同时为四个纯 USB-C 端口的设备供电，那么它只能为第三和第四个端口提供 1.5A 的电流，从工程学的角度来看，这是一个相当合理的限制。 这意味着，像最大电流为 1.5A 和 3A 的高耗能设备，需要监控 CC 线路上的电压，以确定它们是否会超出功率预算，方法是调整其功率需求，或者在超出新设定的电流限制时关闭。 这对用户来说意味着什么？如果你的设备足够低功耗，那就没什么。您的设备应监控 CC 线路上的电压，并相应地进行调整。有些面向消费者的设备不会这样做，但这种情况很少见。 而作为黑客？如果你制作的设备从 USB-C 端口来取电，并希望在 5V 电压下获得 3A 电流，那么请记住，并非所有的 USB-C 端口都能提供这样的电流。不过，您可以通过测量 CC 线路上的电压来检查 3A 的可用性。或者也可以不用，我不是你妈（不为你负责），很多黑客设备都是在零检测的情况下茁壮成长的。 那么，CC 线路上会有什么电压呢？您可以使用微控制器的基本 ADC 或比较器读取这种电压。 如您所见，所有电压都在 3.3V 以下，因此如果您使用的是全速微控制器 ADC，就不需要分压器。对了，如果你使用的是 USB-C 插座，当然要记得分别监控两个 CC 引脚。 真的需要吗 我们真的需要监控 CC 电压吗？如果超过了电源端口所能提供的电流需求，它就会停止向设备供电——这是一个相当安全的结果。另一方面，USB-C 的理念是要有多层保障措施，如果您使用简单的 5.1kΩ 电阻器方法来制造 15W 的设备，您不妨让它成为一个能检测到供电不足的设备。而且，这也很容易做到！ 否则，你就可以期待你的设备与一个始终能在 5V 电压下提供 3A 电流的充电器配对，而绝大多数充电器都能做到这一点。然而，如果您将设备连接到笔记本电脑端口，无论是 USB-C 还是使用 USB-C 适配器的 USB-A，您都不能完全指望 3A 电流始终存在，总需要检查一下。 但 5.1kΩ 并不是您会遇到的唯一下拉情况。还有一种不同的降压方式，我们黑客以前也遇到过，那就是 Ra——当我们谈到带有电子标记电缆时会出现的一个东西。 VCONN：正确识别电子标记（Emarker/E-marker）芯片 电子标记芯片基本上就是一个能与 USB PD 协议通信的存储芯片。它们用于比普通电缆略微高级的电缆中，即具有 USB3 和 Thunderbolt 等高速功能的电缆以及 5A 电缆。它们接入电缆上的 CC 线路，可由电源或终端查询，但通常由源查询。 如果 USB-C 线缆内有一个电子标记芯片，它也需要电，而 USB-C 有一种为其供电的方法——这就是 VCONN。如你所知，只有一个 CC 引脚用于通信。而未连接到 CC 线路的另一个 CC 引脚用于为电子标记芯片供电；另一个 CC 引脚就会变为 VCONN。 在 USB-C 插头中，您可以知道哪个 CC 引脚与 CC 线相连，因此可以事先知道哪个引脚将充当 VCONN。但是，您可以以两种不同的方向插入插头，这意味着插座必须能够将两个 CC 针脚中的任何一个针脚视为 CC 通信线或 VCONN 针脚。这就使电缆保持了相对简单和廉价的特性，让设备本身来处理复杂的问题。 作为黑客，你很可能不需要担心 VCONN。我们中的大多数人都会使用 USB2 或 USB3，电流不超过 3A，而电子标记芯片检查并不是那么必要。除此以外，还有一些集成电路可以为您解决 USB-C 的各种问题，其中就包括提供 VCONN。 实际上 VCONN 的电压要求相当宽松，与您需要为 VBUS 提供的 5V 电压相比，允许的电压范围为 3V 至 5.5V；在智能手机的实现中，通常是直接采用锂离子单芯电池电压，这意味着您可以避免两次转换，并能节省大量电能。毕竟，VCONN 电源并不只是为电子标记芯片供电，它还可以为小型配件和耳机适配器供电，功率预算最高可达 1W。来自 USB-C hacker 的这一有趣演示讲述了如何制作 VCONN 供电设备的原型，这些设备涵盖了 USB-C 规范允许 VCONN 供电设备做的所有事情。 尽管如此，电子标记芯片是最常见的 VCONN 标志，而且非常简单。有时一根电缆包含两个电子标记芯片，有时只包含一个，这是生产工艺的选择。如果是单电子标记电缆，电缆的一端将包含电子标记芯片，另外还有一条&quot;将标记电源引入另一端&quot;的 VCONN 线从配备标记的插头穿过电缆，连接到另一电缆插头上的 VCONN 针脚。因此，如果你看到有哪里提到了 VCONN 线，那就是这个意思——连接到电缆一端未使用的 CC 引脚的二极管隔离线，只需为另一端的电子标记芯片供电。 到目前为止的一切都很有趣，但那个 Ra 下拉电阻又是怎么回事呢？ 树莓派 4 的问题 如果插座能够提供 VCONN，它就会在当前未用于通信的 CC 引脚上寻找该电阻，并在感应到电阻时将 VCONN 输入该引脚。因此，电缆插头内的第二个 CC 引脚（电缆的两个插头）上都有这个电阻。 如果将设备插座中的两个 CC 引脚短接在一起，然后插入一根高容量电子标记芯片电缆，会发生什么情况？5.1kΩ 电阻器会与 1kΩ 电阻器并联，从而获得 840Ω 的总压降。电源在 CC 线路上看到的就是这个压降，它超出了 5.1kΩ 的预期。具体来说，分压器将电压拉得过低，因此电源无法为 VBUS 提供 5V 电压。 树莓派 4 在初版中时就是这样做的，因此，你无法通过 Type-C 充电器使用有电子标记芯片的线缆为树莓派 4 供电——你需要一条无电子标记芯片的线缆，或者一条 USB-A 转 USB-C 线缆，再配上 USB-A 电源。当然，树莓派的官方电源线上也没有标记。它也不一定要有电子标记芯片，毕竟电子标记芯片是用来询问未知电缆的，而它们自己的电缆顾名思义就是已知电缆。 我没看到的问题是：他们为什么要这么做？ 如果查看原理图，就会发现连接 CC 引脚的 PD_SENSE 网连接到 PMIC 上的一个模拟输入引脚。您现在可能已经猜到了——他们确实实现了了标准中的&quot;电压监控&quot;部分，但没有正确执行&quot;标记&quot;部分。它们究竟能进行怎样的电压监控，确实值得怀疑，但至少具备了这种能力。 在即将推出的树莓派版本中解决了这个问题，如果你有旧版本，可以自己打补丁。虽然我们还不知道他们是如何打补丁的，但我们最终一定会知道的。 这就是你应该知道的有关电阻、电子标记和难以捉摸的 VCONN 的全部内容。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/categories/USB/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/categories/硬件/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/tags/硬件/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/tags/USB/"}]},{"title":"【译】关于 USB-C 的一切：介绍","slug":"All-about-USB-C-Introduction","date":"2023-09-06T23:22:00.000Z","updated":"2025-03-08T09:40:48.547Z","comments":true,"path":"2023/09/06/All-about-USB-C-Introduction/","link":"","permalink":"https://blog.inoki.cc/2023/09/06/All-about-USB-C-Introduction/","excerpt":"","text":"原文链接：https://hackaday.com/2022/12/06/usb-c-introduction-for-hackers/ 现在，从第一个 USB-C 设备开始，USB-C 端口至少已经被使用五年了。这是一个许多制造商和黑客都支持的标准。起初，我们对实际使用中会遇到的问题感到困惑，制造商造成的变化也让一些人望而却步。不过，USB-C 将继续存在，我想向你展示 USB-C 在实际应用中的情况，作为一个强大的用户，你能从中得到什么，作为一个业余爱好者，你又能从中得到什么。 现代设备有一系列共同的需求：它们需要电源输入或电源输出，有时两者都需要，它通常使用 USB 2.0 的连接。此外，我们还经常需要一些更高速的连接，如显示输出/输入，或者说 USB 3。上述所有功能都是可选的，这既是好事也是坏事，但你很快就能学会根据设备的外观来区分它的预期功能，我想告诉你在有疑问时如何进行检查。 通信能力、配置和注意事项 我们都知道，USB-C 可以旋转——它可以让你以任何方式插入线缆——这是对 USB-B 的重大改进。让我们来看看它是如何工作的。要实现这一点，需要一个 CC（Configuration Channel，配置通道）连接，每条 USB-C 线缆中都有一条单线连接到 Type-C 接口中的两个配置通道 CC 针脚之一，这对 USB-C 的工作至关重要。对于简单的 USB-C 使用情况，例如“从端口获得 USB 2.0 和 5V 电压”，只需遵循一个简单的方法——在每个配置通道 CC 引脚上连接一个 5.1kΩ 的下拉电阻，您就能拥有一个能与所有兼容设备配合使用的 USB-C 端口。 当然，USB-C 支持 5V 和 USB 2.0 以外的电压。你可以从 USB-C 端口获得各种电压，这对笔记本电脑等设备的充电非常方便。你可以连接 USB 3、DisplayPort 和 Thunderbolt。大多数笔记本电脑会让你连接一个尽可能利用 USB-C 的扩展坞，通过同一根线缆为你提供高分辨率显示屏、大量 USB 端口和充电功能。那么，它是如何工作的呢？ 对于电压大于 5V 的情况（USB-PD）或 USB 2 和 3 以外的高速连接（alt-modes，即备用模式），必须通过同一配置通道 CC 连接来调用。单线用于双向通信，这使得配置通道 CC 线成为半双工通道；它是一种固定速率 300 kbps 的以太网协议。有很多集成电路可以通过该协议实现一系列定义的功能，还有很多集成电路和微控制器外设可以帮助您通过该协议实现任何您想要的功能。 功能强大… USB-C 端口有四个高速差分对引脚，共八个引脚。许多简单的 USB-C 设备都将它们断开，但这些端口的功率很大。首先，当你在笔记本电脑上看到这样的端口时，通常可以使用 USB 3.1 或 3.2。一个 USB3 端口通常占用四个差分线对中的两个，但有些设备支持 2x2 USB3 链路，使线对数量和传输速度翻倍。越来越多的 USB-C 端口也能支持 DisplayPort - 通过两个或四个通道，可以驱动一些分辨率相当高的显示器。 还有 Thunderbolt 这种半专有技术，也使用 USB-C 接口上的高速线对。它可以将 USB3、DisplayPort 甚至 PCIe 传输到自己内部，但这三者缺一不可。有了 Thunderbolt，你就可以拥有一个扩展坞、拥有更多 DisplayPort 选项、更好更快的端口，甚至外置显卡 GPU！可以猜到，这是所有这些产品中最稀有、最昂贵的选择。 有了这些高速和大功率的功能，将所有东西统一到一个连接器中就有了强大的优势。您的 USB-C 笔记本充电器还可以在需要时为您的手机充电，而且得益于积极的标准化，充电过程中不再涉及太多专有的东西。 如果你有一个 USB-C 的任天堂 Switch 底座，理论上它也可以充当笔记本电脑的底座，前提是你能让它们物理上连接起来，而且笔记本电脑底座也能与 Steam Deck 一起使用。总的来说，扩展坞越来越合理——你只需用一根线缆就能连接所有设备，它还能与大多数 USB-C 设备配合使用，仅此而已。 每一年，USB-C 无法实现的功能越来越少。去年，他们发布了 EPR（Extended Power Range 扩展功率范围），将 USB-C 端口的功率提升到 240W、48V@5A，而 SPR（Standard Power Range，标准功率范围）则将 USB-C 端口的功率限制在 100W、20V@5A。这基本上消除了笔记本电脑对桶状插头适配器的需求，而 100W 的 USB-C 曾经是一个障碍，我们不再需要所有带有各种桶状插孔适配器的“通用”电源。还有即将推出的 USB4 标准，它与 Thunderbolt 相似，但又不完全相同，但更好，但又更糟（？）无论如何，我们都会看到更多的电脑支持 USB4，希望有一天每台笔记本电脑都能配备高速接口，即使是最便宜的笔记本电脑也不例外。 总的来说，USB-C 的未来是光明的，它在很多方面的设计都很合理——汲取了几十年来我们在端口、电缆和标准方面所犯的错误，并为即将到来的新增功能留出了足够的空间。 当然，USB-C 也创造了一个可以犯错误的全新领域。 …令人难忘的记录 USB-C 的恐怖故事随处可见——基本上每个使用过 USB-C 的人都能告诉你，USB-C 曾经让他们失望过一次，或许是多次。但我坚信 USB-C 的优点多于缺点，我们必须记住它曾经让我们失望的地方，以及它现在仍然让我们失望的地方，这样我们才能从中吸取教训，找出避免失败的方法。 并非 USB-C 标准的所有部分都是经过深思熟虑的。我首先想到的是电缆和端口。当你看到一个 USB-C 端口时，很难一眼就知道它支持什么，线缆也是如此。目前的情况非常糟糕——对于还没有找到合适解释的人来说，使用 USB-C 有时需要大量的猜测。如何区分线缆是有指南的，我也会顺便介绍一些技巧。不过，他们应该从一开始就引入一个引人注目的视觉标记方案。 USB-C 标准的实现有些复杂，涉及众多状态机和特殊性。USB-C 规范以冗长的 PDF 文档而闻名：连接器和电缆文档长达 350 页，USB-PD 文档长达 600 多页。多年来，许多制造商真诚地尝试过，但仍然制造出了具有明显怪异边缘的设备。笔记本电脑只能与特定的充电器配合使用，反之亦然；底座只能与特定的笔记本电脑配合使用，或只能与特定的充电器配合使用；电缆只能在一个方向上使用，或根据电缆的方向不同，设备的工作方式也不同——这其中不乏玄机。 除此之外，还有无数种滥用 USB-C 的方法，某些制造商也在努力尝试！别人滥用 USB-C 标准并不是 USB-C 标准的错，因为在定义一个复杂的标准时，只能实施有限的保护措施。不过，我们仍然有全新的问题需要注意。有些 USB-C 罪过难以原谅，值得分开处理，有些则不那么明显——我们将一一讨论其中的许多问题。 无数种入侵方式 请务必牢记这一点——随着时间的推移，USB-C 只会变得越来越一致；如果有必要的话，还可以通过强制手段来实现。同样，它也只会变得更容易被黑。因为随着时间的推移，我们将收集到越来越多的构件——硬件和知识。除此之外，我们家中的 USB-C 生态系统也在与日俱增。如果你今天正在设计某样东西，那么你应该在你的使用案例中强烈考虑 USB-C。 在此，让我们回顾一下添加一个 USB-C 端口需要哪些条件，以确保您的设备能获得 5V 电压（最高可达 3A）和 USB 2.0 数据，并同时支持两者的完全旋转。 就是这样。与 MicroUSB 相比，只多了两个电阻，而且引脚更容易焊接。请按照原理图上的指示连接电阻；不要像 Raspberry Pi 4 那样连接配置通道 CC 引脚，也不要省略电阻。如果省略电阻，上游 Type-C 端口将无法为设备提供 5V 电压——很多廉价设备都省略了电阻。没有 5.1kΩ 电阻器，那么就无法为设备供电——除非使用 USB-A 转 USB-C 电缆为设备供电。如果省略其中一个电阻器，那么端口只有一个旋转能正常工作——有些廉价设备只有一个电阻器。 每个希望在任何位置接收 5V 电压的 USB-C 设备都有这些电阻器，有的是板载的，有的是 USB-C 通信集成电路内部的。对于简单的“5V 和 USB 2.0”用途，您只需使用 1% 的 5.1kΩ 电阻器即可。不过，在紧要关头，您也可以并联两个 10K 电阻器，这实际上是可行的。就我个人而言，我刚订购了一卷 5.1kΩ 电阻器，它们帮了我大忙。如果您的端口设计者忘记添加这些电阻，您还可以订购一些 FPC 垫片，帮助将这些电阻焊接到常用的连接器上！ 您有很多 USB-C 连接器可供选择，其中 16 引脚的连接器最受欢迎——您可以在任何地方购买到大量引脚兼容的连接器，而且手工焊接也相当容易，尤其是如果您有焊芯可以用来修正错误的话。请确保不要使用不带 CC 引脚的连接器，因为无法连接下拉电阻器，这样的连接器无法与真正的 Type-C 端口配合使用，而且只能与 USB-A 转 USB-C 连接线配合使用，这是一个很大的限制。 当然，USB-C 的功能远不止我前面提到的 5V@3A 和 USB 2.0，我会向你展示如何获得所有其他可能性。不过，请务必记住所示公式，因为这是您最常用的公式，而且它还有助于您理解其他公式。同时，您可以使用 SBU 引脚来暴露一些调试连接（如 UART），因为除了 DisplayPort 之外，没有其他设备使用 SBU。不过，要找到能以手工焊接形式暴露 SBU 的插头断路器可能比较困难。而且，如果你进入了 USB-C 端口黑客联盟，你也可以以符合标准的方式实现调试！ 你不必总是遵守 对于黑客来说，遵守 USB-C 标准是一把双刃剑。如果不符合标准，你可能会毁掉一台笔记本电脑，也可能会让你受益匪浅，而不会带来危险或弊端。有些情况之所以被“取缔”，并不是因为它们真的有危险，而是因为它们被认为会让普通用户感到困惑，或者不会带来顶级的功能。 在接下来的文章中，我将讨论那些糟糕透顶、根本不应该出现的东西。我还会告诉你如何温和地（或严厉地）违反标准，如果这样做对你有好处，或者这样做是完全合理的，以及在哪些情况下你可能会违反标准，但你真的真的不应该这样做。这里有一个指导原则——当你听说你想使用的东西违反了 USB-C 标准时，在你的具体应用中会产生什么后果就非常重要了。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/categories/USB/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/categories/硬件/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"硬件","slug":"硬件","permalink":"https://blog.inoki.cc/tags/硬件/"},{"name":"USB","slug":"USB","permalink":"https://blog.inoki.cc/tags/USB/"}]},{"title":"【译】ARM 的历史——第三部分：兜兜转转","slug":"History-of-ARM-3","date":"2023-08-22T12:34:00.000Z","updated":"2025-03-08T09:40:48.566Z","comments":true,"path":"2023/08/22/History-of-ARM-3/","link":"","permalink":"https://blog.inoki.cc/2023/08/22/History-of-ARM-3/","excerpt":"","text":"原博客共分为三篇，原文链接如下： https://arstechnica.com/gadgets/2022/09/a-history-of-arm-part-1-building-the-first-chip/ https://arstechnica.com/gadgets/2022/11/a-history-of-arm-part-2-everything-starts-to-come-together/ https://arstechnica.com/gadgets/2023/01/a-history-of-arm-part-3-coming-full-circle/ 在我们的系列压轴文章中，ARM 实现了将计算能力带给大众的目标。 就像 ARM 的许多故事一样，它始于苹果公司。 史蒂夫-乔布斯凯旋而归，回到了他共同创立的公司。1998 年，苹果公司发布了色彩斑斓的橡皮泥 iMac，与微软达成了一项协议，并出售了 ARM 股票，使公司从濒临破产的困境中重新站稳了脚跟。但苹果公司的 &quot;iCEO &quot;仍在寻找下一件大事。 乔布斯为 iMac 配备了名为 FireWire 的新型连接器，可以快速传输视频和声音。当时，一种名为 MP3 的文件格式正在流行，电脑用户可以在电脑上共享音乐，一些公司已经开始生产便携式 MP3 播放器。但这些设备的存储空间很小，USB 1.0 传输速度很慢，软件也很糟糕。乔布斯痴迷于制造播放器的想法，几乎把所有时间都投入到这个项目中。 苹果公司与一家名为 PortalPlayer 的公司合作，后者一直在开发自己的播放器。硬件采用定制的 ARM 芯片 PP5502。这是一个芯片上的系统，具有双 ARM7 内核，运行频率为 90 MHz，板载内存为 32MB。主板上唯一的其他大型芯片是火线控制器。ARM 许可的灵活性使得设计带有用于 MP3 解码等功能的定制电路的 CPU 变得非常容易。 有多容易？我的一位熟人约翰-希姆斯博士（Dr. John Sims）向我讲述了大约在同一时期另一家 MP3 播放器公司的故事。一位工程师仅用了六个月的时间就在标准 ARM 设计中添加了数字信号处理器 (DSP)。另一家竞争对手公司从零开始制造芯片，而不是与 ARM 合作，该公司有 60 名工程师，项目耗时是 ARM 的三倍。 iPod 于 2001 年面世，在推出与 Windows 兼容的版本后，这款小巧的音乐播放器成为行业标准。在该设备的巅峰时期，iPod 每年的销量超过 5000 万台。当人们为它的界面、易用性和标志性的白色耳机着迷时，大多数人并没有意识到 iPod 实际上是一台微型电脑。它有中央处理器、内存、微型硬盘和操作系统，其触摸轮和按钮就像一个小鼠标和键盘。它甚至还有一个位图显示屏，可以玩简单的游戏。 说到游戏，ARM 在 2001 年的第二个大赢家是任天堂的 Game Boy Advance。作为原始 Game Boy 的后继机，它配备了 16.8 MHz ARM7 内核和嵌入式内存。它还配备了夏普 LR35902，可与旧系统兼容。就连便携式游戏机也开始从 CISC 芯片向 RISC 芯片过渡。 人人都能使用的掌上电脑 iPod 只是移动世界划时代变革的开始。苹果公司曾与摩托罗拉公司合作，在 ROKR 翻盖手机中植入 iPod，但这一奇特的合作最终以失败告终。 该项目始于 2004 年。乔布斯并不确定正确的方法是将 iPod 升级为手机，还是将 Macintosh 的 OS X 操作系统剥离出来，让它在移动设备上运行。为了解决这个问题，乔布斯让竞争对手的团队同时研究这两种方法。托尼-法德尔的 iPod 团队经验丰富，但他们面对的是摩尔定律的错误方向。 与 1985 年的第一个版本相比，ARM 芯片已经有了长足的进步。该芯片拥有 27000 个晶体管，采用 3 微米工艺生产。这意味着晶体管和导线的宽度大约为 0.000003 米，即 0.003 毫米。这看起来似乎很小，但硅芯片制造技术的进步意味着，到 2006 年，芯片代工厂开始使用 90 纳米工艺。这使得相同尺寸的芯片上可以安装更多的晶体管，包括大量的高速缓冲存储器。这也意味着芯片可以以更高的时钟速度运行。 相比之下，软件的改进要慢得多。软件的编写和测试都需要时间，而且每推出一项新功能，都不可避免地会出现大量错误。因此，等待摩尔定律推出可运行现有 OS X 软件的移动芯片，实际上比在 iPod 的简易操作系统中添加所有必要功能更快。乔布斯决定采用精简的 OS X 方法。但谁来生产芯片仍然是个问题。 乔布斯问英特尔公司首席执行官保罗-奥特里尼（Paul Otellini）是否愿意竞标为苹果即将推出的手机生产芯片。当时，这家制造业巨头正依靠为基于 Windows 的计算机提供动力的台式机 x86 CPU 的销售业绩一路高歌猛进。不过，英特尔还拥有一项基于 ARM 的业务，即 1998 年从数字设备公司（DEC）收购的 XScale。因此，英特尔本可以轻松满足苹果的要求。 但奥特里尼拒绝了这一提议。他计算了一下，苹果愿意为每个 CPU 支付的最高金额低于英特尔生产 CPU 的成本，而且他也不确定苹果手机的销量是否会很高。另外，他对支持 XScale 感到紧张，尤其是英特尔正在开发即将推出的低功耗 x86 版本 Atom。2006 年，他加倍支持 x86，并出售了 XScale 部门。 这其中有某种讽刺意味。DEC 当初出售 ARM 业务是因为需要钱。之所以需要钱，是因为英特尔正在摧毁 DEC 的微型计算机和工作站市场。基于 x86 的个人电脑价格更低，产量更高，随着时间的推移，这些大型计算机的竞争力越来越弱。现在，英特尔放弃了同样的移动芯片部门，转而专注于台式机。 在英特尔拒绝了这笔交易后，苹果转向了三星。这家韩国企业集团同意为苹果即将推出的手机生产功能强大的新型 ARM 芯片。这就是 S5L8900，一款配备 ARM11 内核的 SoC，运行频率为 412 MHz（超频！），128MB 内存，最高 16GB 存储容量，集成 PowerVR MBX Lite 3D 图形处理器。这是一款非凡的芯片，让人想起 1991 年的 ARM 250 “芯片上的阿基米德”，但其强大的功能足以成为世纪之交的台式机的核心。 但它不是台式机。它是一部手机，而且是一部革命性的手机。2007 年 1 月 9 日，乔布斯在 Macworld 大会上发布了 iPhone。今天重温这一发布，感觉就像是历史的转折点。奇怪的是，乔布斯花了很多时间强调 iPhone 实际上是三种设备：手机、iPod 和互联网通讯器。 现在没有人会这样形容 iPhone 了。 它就是一台可以放进口袋的电脑。大型计算机有房间那么大，微型计算机有冰箱那么大，而微型计算机则有烤面包机那么大。这些新设备很容易被称为纳米计算机。我们却称之为智能手机，尽管很多人已经很少使用手机的部分。 消息发布后，谷歌的安卓子公司迅速改变了产品计划，从生产黑莓手机的克隆版转向生产更接近 iPhone 的产品。2008 年发布的 T-Mobile G1 也采用了 ARM 技术。它引发了大量 Android 设备的涌现，所有这些设备都采用了相同的外形设计，即一个薄薄的黑色长方形，配备一个大尺寸触摸屏。除了 iPhone 和安卓，其他所有智能手机平台都被淘汰出局，而非智能手机的手机也很快绝迹。 芯片的循环 2008 年，苹果公司以 2.78 亿美元收购了 P.A. Semi 公司。该公司拥有 150 名工程师，设计高能效的 PowerPC CPU。很多人不明白苹果公司为什么要收购一家 PowerPC 公司，尤其是苹果公司在 2005 年已经将 Macintosh 从 PowerPC 处理器过渡到英特尔 x86 处理器。 但是，PA Semi 公司的工程师们了解的不仅仅是 PowerPC。他们包括 DEC Alpha 和 StrongARM 处理器的首席设计师，以及曾参与英特尔 Itanium、AMD Opteron 和 Sun UltraSPARC 开发的人员。苹果公司购买的是一些世界顶级的处理器设计专家。 这个设计团队秘密工作了两年，直到 2010 年苹果推出 iPad。iPad没有使用三星的设计，而是采用了一种名为 &quot;A4 &quot;的处理器，这是苹果公司内部设计的第一款系统芯片（三星仍在生产该芯片）。它的运行速度为 1 GHz，并以较新的 ARM Cortex A8 架构为起点。与为第一代 iPhone 提供动力的老式 ARM11 内核相比，Cortex 设计有了大幅升级。 与最初的 ARM CPU 相比，它们有了长足的进步！ A4 芯片的亮相并没有在 CPU 设计领域引起任何轩然大波。人们认为它只是对现有移动芯片的普通改进。例如，英特尔正忙于推广其高端 x86 桌面芯片，并试图通过基于 x86 的低功耗 Atom 芯片重新进入移动芯片市场。其他芯片设计公司，如高通公司，则在自己基于 ARM 的 SoC 设计上取得了巨大成功，并将其应用于许多不同的安卓产品中。 但有趣的事情发生了。2011 年，A4 芯片被 A5 芯片取代，CPU 性能翻了一番，视频芯片速度也大幅提升。第二年的 A6 也做了同样的事情。随后，A7 于 2013 年发布。这是一款完全 64 位的 CPU，甚至超越了 ARM 自身从 32 位的过渡。它拥有 64 位指令集，以及全新的定制芯片，可用作 iPhone 摄像头的图像处理器。 在智能手机中安装 64 位 CPU 似乎有些可笑。手机真的需要超过 4GB 的内存吗？但随着时间的推移，这些论点开始变得越来越不合理。从 A7 到 A8，再到 A12，这些移动芯片的性能图谱发生了一些有趣的变化。 2018 年发布的 iPad Pro 才让人们挠头不解。对其 A12 Bionic CPU 的基准测试表明，在某些基准测试中，它的速度（至少每个 CPU 内核）比同类英特尔芯片更快。这完全说不通。移动芯片怎么可能比台式机芯片更快？ 答案是多种不同因素的综合作用。正如我们已经看到的，ARM 原始设计的简洁和优雅使这些芯片从一开始就在性能–尤其是每瓦特性能–方面占尽优势。这种优雅部分归功于精简指令集计算机（RISC）架构，与英特尔复杂（CISC）的 x86 芯片相比，该架构的 CPU 指令更简单、数量更少。 但这些年来，英特尔并没有停滞不前。从 1995 年的奔腾 Pro 开始，英特尔增加了一套类似 RISC 的隐藏微操作。程序员每次向 CPU 发送普通 x86 指令时，都会在内部将其转换为这些微操作。这意味着英特尔芯片的运行速度几乎与最强大的 RISC 芯片相当。到 2010 年，CPU 巨头英特尔每年的 CPU 销量接近 3 亿个。它已经击败了 SPARC、PowerPC 和 MIPS 等其他 RISC CPU。到 2013 年，甚至连游戏机也从 PowerPC 芯片转向了 x86 芯片，因为游戏机不必担心各代产品之间的遗留代码兼容性问题。 然而，全球智能手机市场的规模却完全不同。世界上大部分人仍然难以负担 2000 美元的个人电脑，但 200 美元的智能手机却更容易买到。因此，智能手机销量出现爆炸式增长，2010 年超过个人电脑销量，从此一发不可收拾。到 2018 年，智能手机的年销量接近 15 亿部。在英特尔放弃在智能手机中使用 Atoms 芯片之后，每部智能手机都采用了 ARM 芯片。 现在，规模经济有利于三星和台湾半导体制造公司（台积电）等移动芯片制造公司。苹果公司向台积电投资数十亿美元，并将其所有芯片生产转移到台积电。从制造的角度来看，英特尔无法跟上。2020 年，英特尔承认不得不推迟从 10 纳米工艺向 7 纳米工艺的转移。与此同时，台积电跃升至 5 纳米制造工艺。虽然在这种规模下，工艺数字开始失去意义，但有一点是明确的：智能手机芯片已经准备好在性能上领先。 2020 年 11 月，他们做到了。就在那时，苹果公司发布了 Macintosh 电脑系列的 M1 芯片。这些芯片震惊了计算世界–它们比最快的英特尔 x86 CPU 性能更强，但功耗却只有它们的一小部分。ARM 一直是每瓦性能的赢家，但这些芯片却完全不同。 我买了一台基于 M1 的 MacBook Pro，感觉它是第一台名副其实的笔记本电脑。当我带着它上班时，我甚至懒得带充电器。无论我运行什么程序，风扇都不会亮，电池也不会耗尽。这种级别的芯片不可避免地也将用于 Windows 笔记本电脑。到那时，英特尔的麻烦可就大了。 经过 35 年的发展，ARM 已经走过了一个完整的历程。ARM 起源于 1985 年的台式电脑芯片，特别是 Acorn Archimedes。但由于阿基米德未能占领市场，ARM 芯片在 1990 年被分拆成自己的公司。经过缓慢的起步，ARM 成为了嵌入式 CPU 市场的标准，并进入了 iPod、Game Boy Advance 等流行的移动设备以及 iPhone 和 Android 等智能手机。现在，它终于又回到了个人电脑中。 但是，ARM 的灵活性意味着这些电脑并不一定需要像苹果公司销售的电脑那样昂贵。2009 年，Raspberry Pi 基金会在 ARM 芯片的原产地英国注册成立。它的使命是继续在教育领域推广计算机科学，就像橡果公司的 BBC 计算机在 20 世纪 80 年代所做的那样。鉴于这一历史渊源，基金会只能选择一种处理器。 第一台 Raspberry Pi 于 2012 年发布。这是一款单板计算机，只有信用卡大小。Pi 配备了 ARM11 处理器、内置内存和计算机所需的所有接口： 用于连接鼠标和键盘的 USB 接口、耳机插孔、用于连接显示器的 HDMI 接口和以太网接口。它还配备了一个 “通用输入输出” 或 GPIO 连接器，让工匠们可以轻松连接和控制灯、传感器和电机。它的售价为 35 美元。后来的型号功能越来越强大，但价格并不昂贵。ARM 最初的使命–将计算能力带给大众–已经实现。 这一切意味着什么 2006 年，ARM 首席执行官罗宾-萨克斯比退休了。他早有预谋。当时公司的状况非常好，他也很好地完成了首席执行官的交接工作，以至于消息传出时，ARM 的股价连眼睛都没眨一下。 我写计算机历史的文章已经很多年了，我注意到的一点是，卓越的技术很少能在市场上获胜。同样是在 1985 年发布的 Amiga 电脑，领先时代 10 年之久，但其母公司倒闭，该平台从此一蹶不振。 ARM 的情况则截然不同。虽然它走上了一条意想不到的道路，但公司创始人却取得了超乎想象的成功。对于为什么会出现这种情况，我有一个理论。在我看来，两家公司都拥有杰出的工程师和卓越的技术，但管理风格却大相径庭。不过，为了验证我的想法，我必须找到一个亲历者，他对 ARM 的一切都了如指掌。我需要和萨克斯比谈谈。 萨克斯比很高兴与我交谈，而且非常慷慨。他讲述了自己如何来到 ARM 的故事，以及作为一名工程师，他是如何与 12 名创始工程师一拍即合的。他开玩笑说，为了节省开支，他挑选了一些特殊的工程师来担任关键职位，比如市场总监和销售总监。但事实上，他觉得教好的工程师如何销售更容易，而不是相反。他还坚持给每位创始人股票期权，让他们都能分享公司的成功。 不过，萨克斯比管理方法的关键很简单，但在商界却并不常见： ARM 的发展是因为它帮助他人发展。它更多地把员工当人看，而不是人力资源，给他们学习的机会，让他们与公司一起取得成功。&quot;他告诉我：“我深信，在任何团队中，任何成员都比其他人更擅长某些事情，因此，要想让团队发挥出最佳水平，就必须让每个人都发挥出最佳轴心的作用。配合默契的团队工作得更好”。他强调了对员工诚实、不过度承诺公司所能提供的一切的重要性。 ARM 甚至将竞争对手视为潜在的合作伙伴–当它帮助合作伙伴取得成功时，ARM 也会从中受益。&quot;他说：“因为德州仪器公司没有理想的处理器来满足诺基亚的需求，”&quot;他们对合作很感兴趣。这种合作使 ARM 芯片成为手机市场的标准。 让我们把这种理念与 Amiga 的母公司 Commodore 做个对比。公司创始人杰克-特拉米尔（Jack Tramiel）相信 “商业就是战争”，他培养了一种管理风格，即 Commodore 要赢，其他人就必须输。后来，他被一个冷酷无情的金融家赶下了台，由管理顾问梅赫迪-阿里接替他担任首席执行官。阿里对工程学一无所知，也不想学习。他只想敛财。 准将很快就破产了，阿里从此销声匿迹，含恨而终。另一方面，ARM 公司继续发展壮大并取得成功。2002 年，萨克斯比被伊丽莎白女王册封为爵士，退休后他的公司发展得非常好，他作为一名值得信赖的顾问，继续为公众提供信息和教育，并成为工程技术学会 (IET) 的主席，受到包括孙辈在内的所有人的爱戴。 因此，如果你是一位有抱负的科技 CEO，想知道自己应该走哪条路，答案应该是显而易见的。 但这一课不仅适用于首席执行官。它适用于每一个人。我们生活在一个史无前例的时代，正是这项技术让我们能够与地球上的每一个人进行沟通，而现在却有可能将我们分裂成争吵甚至交战的派别。然而，事实并非如此。詹姆斯-韦伯太空望远镜（James Webb Space Telescope）等最近取得的成就是通过全世界工程师和科学家的合作实现的。 罗宾-萨克斯比爵士解释说： “现实情况是，纵观我们的星球，每个国家都拥有某些领域的精英。只有通过合作，我们才能取得最好的结果。这是未来的唯一出路”。 我完全同意。","categories":[{"name":"Hardware","slug":"Hardware","permalink":"https://blog.inoki.cc/categories/Hardware/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Hardware","slug":"Hardware","permalink":"https://blog.inoki.cc/tags/Hardware/"},{"name":"ARM","slug":"ARM","permalink":"https://blog.inoki.cc/tags/ARM/"}]},{"title":"【译】ARM 的历史——第二部分：一切开始聚在一起","slug":"History-of-ARM-2","date":"2023-08-22T00:34:00.000Z","updated":"2025-03-08T09:40:48.566Z","comments":true,"path":"2023/08/22/History-of-ARM-2/","link":"","permalink":"https://blog.inoki.cc/2023/08/22/History-of-ARM-2/","excerpt":"","text":"原博客共分为三篇，原文链接如下： https://arstechnica.com/gadgets/2022/09/a-history-of-arm-part-1-building-the-first-chip/ https://arstechnica.com/gadgets/2022/11/a-history-of-arm-part-2-everything-starts-to-come-together/ https://arstechnica.com/gadgets/2023/01/a-history-of-arm-part-3-coming-full-circle/ 从最初的十二个人和一个梦想，到现在的十亿美元公司。 从一开始，就很难有人关心这项神奇的技术。第一批 ARM 芯片出货几个月后，Acorn Computers 的 Steve Furber 打电话给一位技术记者，试图让他报道此事。记者回答说：“我不相信你。如果你一直在做这件事，我早就知道了”。然后他就挂断了电话。 在 Acorn 苦苦挣扎的时候，Furber 试图想象如何将 ARM 芯片分拆成一家独立的公司。但他想不出如何让商业模式运转起来。&quot;他在接受采访时说：&quot;你必须卖出数百万颗芯片，才能开始支付版税。&quot;我们无法想象要卖出数百万个这样的东西。 前景一片暗淡——直到另一家电脑公司的代表走进门来。这家小公司叫苹果。 一家新公司 苹果公司最初是如何听说 ARM 的？苹果公司先进技术部的两位工程师 Paul Gavarini 和 Tom Pittard 制作了一台名为 Möbius 的原型计算机。它使用 ARM2 芯片，同时运行 Apple II 和 Macintosh 软件，模拟 6502 和 68000 CPU 的速度比本地版本更快。苹果公司的高层管理者对这台机器感到困惑，并很快将其封杀，但 Gavarini 和 Pittard 仍在内部演示会上大肆宣扬 ARM，并展示了运行 LISP 时令人印象深刻的基准测试结果。 LISP 是一种重量级语言，苹果公司在内部使用它来测试新的图形界面。但对于嵌入式应用而言，LISP 被认为过于笨重。当苹果公司的资深人士拉里-特斯勒（Larry Tesler）看到这些基准测试结果时，他的脑子里灵光一闪。 当时，特斯勒刚刚接手苹果牛顿项目，他需要替换掉速度慢、漏洞多的 CPU–AT&amp;T Hobbit。ARM 芯片看起来是个赢家。它不仅速度惊人，而且功耗极低，是手持牛顿设备的理想之选。 特斯勒安排了一次与 ARM 团队的会面，他很喜欢他们的路线图。但有一个问题。苹果是一家计算机公司，而 Acorn 是其直接竞争对手。 这就为一个致命的决定埋下了伏笔。ARM 的员工希望摆脱 Acorn 日渐衰落的命运。Acorn 的大股东奥利维蒂公司（Olivetti）则对生产 IBM PC 克隆机更感兴趣。制造 ARM 芯片的硅代工厂 VLSI Technology 希望获得更多的客户。而苹果公司则希望获得芯片授权。分拆 ARM 符合所有人的利益。 1990 年 11 月，三方达成协议。苹果公司投资 300 万美元现金，获得 30% 的股份。VLSI 投资 50 万美元，外加其知识和工具。Acorn 转让其所有 ARM 知识产权和 12 名员工，价值 300 万美元。应苹果公司的要求，新公司更名为 Advanced RISC Machines。ARM 公司从此自立门户。 新的领导者 在投入资金之前，苹果希望为 ARM 挑选一位首席执行官。苹果聘请了曾经找到约翰-斯卡利（John Sculley）的那家猎头公司，但这次的结果要好得多。他们聘用的是罗宾-萨克斯比（Robin Saxby）。 萨克斯比 1947 年出生于英国切斯特菲尔德。他从小就对电气线路着迷，十几岁时就开始了自己的第一笔生意，修理收音机和电视机。他进入利物浦的大学学习电子工程。1968 年毕业后，他的第一份工作是帮助设计英国第一台晶体管电视机。 1973 年，他加入摩托罗拉公司，并很快晋升为销售工程师。这意味着他的工作就是奔波于公司客户之间，帮助他们使用摩托罗拉产品进行设计。当他调到中央处理器部门时，他以为他的客户都会是主流计算机公司。但出乎他意料的是，大多数希望使用摩托罗拉 CPU 的人都在考虑利基嵌入式应用。有一次，他写了一份提案，建议摩托罗拉分拆 CPU 设计团队并提供设计服务，但管理层不喜欢这个想法。 离开摩托罗拉后，萨克斯比加入了一家名为 ES2 的初创公司，该公司正试图开发一种新的硅芯片制造技术。ES2 曾为 ARM 制造过一些测试芯片，因此萨克斯比对这家公司早有了解。但当他被邀请加入 ARM 担任首任首席执行官时，他怀疑自己是否是最合适的人选。 为了确保万无一失，他在一家酒吧与 ARM 的员工举行了一次午餐会。当时，公司缺乏领导力。史蒂夫-福伯（Steve Furber）离开公司去寻找其他机会，索菲-威尔逊（Sophie Wilson）做出了一个 “艰难的决定”，留在了橡果公司，尽管她仍然可以提供咨询。剩下的 12 名 ARM 员工吃午饭时迟到了，萨克斯比差点离开。但是，当他们到达目的地时，会议取得了圆满成功。所有 12 位工程师一致认为，罗宾-萨克斯比是正确的选择。 即便如此，他还是需要一点推动力。他问自己 11 岁的女儿，是否应该冒险接受这份新工作。她说：“爸爸，我有个骰子，如果你掷出六点，你就会成为百万富翁。” 他掷了出去，结果是六。1991 年初，他成为 ARM 公司的第一任首席执行官。 艰难探索时期 公司首先需要的是一个商业模式。萨克斯比重拾摩托罗拉的旧方案，并根据 ARM 的需求对其进行了修改。除了每售出一块芯片收取一定比例的特许权使用费外，公司还将以预付费的形式获得技术许可。理论上，这样的组合足以维持公司的正常运转。萨克斯比从一开始就雄心勃勃： 他希望 ARM 成为 “全球 RISC 标准”。 提出目标是一回事，但实现目标却是另一回事。计算机领域的其他公司也纷纷加入 RISC 的行列。IBM 于 1986 年发布了 6150 RT，随后是 MIPS 和惠普的 PA-RISC 以及 SUN 的 SPARC。摩托罗拉公司于 1988 年推出了 88000，英特尔公司于 1989 年发布了 i860 和 i960，DEC 公司也在开发 Alpha 芯片。只与其中一家巨头竞争是很困难的。击败所有这些公司似乎是不可能的。 但这些公司大多使用 RISC 制造高端台式工作站。萨克斯比记得，在摩托罗拉工作期间，嵌入式应用是一个被忽视的市场。也许全球 RISC 标准现在还遥不可及，但全球嵌入式 RISC 标准是可以实现的。与竞争对手相比，ARM 芯片的晶体管数量更少，耗电量更低。这使得它们的制造成本更低，适用于更广泛的应用。 一些首批许可证用于传真调制解调器和其他小型应用。创业初期，资金十分紧张。Acorn 原本向创始工程师们承诺，他们将在第二年获得加薪，但到了 1991 年，ARM 的资金已经告罄。萨克斯比说，如果公司能得到一份新的大合同，他就会兑现这个承诺。他与英国国防承包商普莱西公司签订了协议，并给工程师们追溯加薪。 公司的第一个新产品是 ARM6 内核，它是 ARM3 的后继产品，采用 0.8 微米工艺制造，运行频率为 20 MHz。根据降低指令集复杂度的理念，它只有两条新指令。内核本身只有 35,000 个晶体管，比最初 ARM 的 27,000 个晶体管多不了多少。（相比之下，英特尔的 386 有 275,000 个晶体管！）对于牛顿，ARM 将该内核与内存管理单元和 4 KB 的一级高速缓存打包在一起。这就是 ARM610。 与此同时，该公司还推出了 ARM250。它采用了较早的 ARM3 内核，但也包含了阿基米德计算机中的所有支持芯片：内存控制器、I/O 芯片和视频芯片。这是一款真正的 “片上系统”，或称 SoC。在当时，除了使阿基米德计算机的制造成本更低一些外，它并没有太大的市场。但它为未来的发展埋下了伏笔。 1993 年，苹果公司终于发布了拖延已久的牛顿。第一年，它卖出了 6 万台。对于苹果这样的大公司来说，这被认为是一个巨大的失败。但对 ARM 来说，每块芯片 20 美元的特许权使用费是一笔意外之财。萨克斯比将这笔现金投资回 ARM 公司，使公司规模扩大了一倍，员工人数从 30 人增加到 60 人。这是一场赌博。要想成功，ARM 需要赢得一些重要的授权。 说服大公司 作为一家小公司，有时很难与大公司打交道。在与前雇主摩托罗拉公司的一次会谈中，萨克斯比回忆说，高管最后说：&quot;当然，我们也不会向你们支付任何许可费或版税。该公司希望 ARM 乐意以 &quot;曝光 &quot;的方式获得报酬，因为摩托罗拉本可以自己完成这项工作。萨克斯比问这位高管有多少工程师在做这个项目。答案是大约 200 人。&quot;萨克斯比问：“你知道吗，你付给我们的许可费是你付给工程师的四分之一。” 他还是拒绝给 ARM 钱，萨克斯比也就放弃了这笔交易。 德州仪器公司（Texas Instruments）是另一家认为凭借自己的内部资源可以比 ARM 做得更好的公司。当德州仪器公司 CPU 部门的负责人向他的老板申请 ARM 的许可证时，他回击道：&quot;你是在告诉我，我们可以做得更好： &quot;你是在告诉我，在设计嵌入基带芯片的微处理器内核方面，我们甚至无法与其他公司竞争？后来，在一次讨论潜在合作关系的会议上，德州仪器的人在没有签署保密协议的情况下就来了。萨克斯比坚持要他们立即离开，等签了字再回来。ARM 公司规模虽小，但萨克斯比不会让公司被人摆布。 德州仪器犹豫再三，最终决定将 ARM 介绍给其最大的客户之一： 诺基亚。这是一次测试。如果 ARM 能说服诺基亚使用其设计，那么 TI 就能制造出足够好的产品。 1993 年，诺基亚已经成为移动电话领域一颗冉冉升起的新星，上一年的手机销量就达到了 300 万部。诺基亚为其新机型制定了宏伟的计划，但该公司对使用 16 位日立 H8 CPU（传统的 CISC 芯片）感到非常满意。32 位 RISC 芯片在速度和效率上都有很大的飞跃，但代价是同等代码需要更多的指令，而且每条指令需要两倍的内存。在台式机上，这种额外的内存需求并不是什么大问题，但手机的内存和存储空间却很小。 在与诺基亚会面后回家的飞机上，ARM 工程师们决定，如果诺基亚想要 16 位，那么 16 位就是诺基亚要得到的。他们创建了一套全新的简化 16 位指令，并设计了将其映射到现有 32 位指令集的电路。这样，你就可以拥有占用内存更少的较小程序代码，但运行速度几乎是完全 16 位芯片的两倍。工程师们开玩笑地称这些扩展为 “拇指”，因为拇指是手臂末端的东西。这个名字就这样沿用了下来。 当诺基亚的工程师们看到 Thumb 架构的计划以及与之配套的更先进的 ARM7 内核时，他们非常兴奋。TI 意识到，这家英国小公司已经通过了考验，并最终于 1994 年获得了 ARM 许可证。现在，TI 可以为新一代诺基亚手机制造先进的芯片。 其中第一款手机诺基亚 8110 是第一款采用 ARM 内核的 GSM 手机。几年后，它因出现在电影《黑客帝国》中而声名鹊起。 勇往直前 与 TI 达成交易后，ARM 就再也没有回头。现在，该公司在电子行业拥有了真正的信誉。它与夏普、三星和 NEC 签订了协议。到 1995 年，公司的授权客户已达 10 家。 ARM7 一炮打响。该 CPU 采用 0.35 微米工艺制造，运行速度高达 66 Mhz。Thumb 扩展对于移动应用或代码密度非常重要的任何地方都很有用，但该芯片也可以全速运行 32 位代码。1996 年，又有四家公司购买了 ARM 许可证： Oki、Alcatel、Yamaha 和 Rohm。甚至连摩托罗拉公司也在第二年签订了协议。 为什么这么多公司，包括已经生产自己芯片的大型电子公司，都想与 ARM 签订协议呢？部分原因是成本优势–ARM 许可证的价格并不昂贵，而且肯定比支付数百名工程师数年时间从头开始设计新芯片要便宜。另一部分原因是索菲-威尔逊和史蒂夫-福伯创造的技术遗产。ARM 芯片速度快、易于制造、耗电量低。 但是，ARM 的另一张王牌是：它不仅仅是一家芯片制造公司。当 ARM 与其他公司合作时，它成为合作伙伴，帮助设计可根据其他公司特定需求定制的解决方案。为诺基亚发明拇指扩展只是其中一个例子。ARM 还与数字设备公司合作开发了 StrongARM，这是一种速度更快的芯片，运行速度高达 233 MHz。这些功能强大的芯片最终被应用于苹果 MessagePad 2000（改进版牛顿）、Eidos Optima 视频编辑工作站和 Acorn Computers 最新的 RISC PC（阿基米德系列的新名称）。 对于罗宾-萨克斯比来说，与竞争对手的芯片公司合作始终是战略的一部分。他常说：“化敌为友”。“如果他们能通过与你合作为自己赚更多的钱，为什么还要与你对抗呢？” 这种感觉充斥着整个公司。在接受 Ars 采访时，ARM 公司的一位发言人解释了这一点： “ARM的商业模式是一种以成功为基础的商业模式，其理念是：合作伙伴成功，ARM才会成功。” 在经历了缓慢的起步之后，该公司现在正在证明这不仅仅是一个崇高的理想。它正在发挥作用。 但是，ARM 公司仍然必须具有战略眼光。当 LSI 半导体公司向公司申请许可证时，萨克斯比拒绝了，尽管首席执行官给了他一大笔钱。他这样做是因为 LSI 将与 ARM 的制造合作伙伴 VLSI 直接竞争。相反，他要求 LSI 的首席执行官先给他们带来一些新业务，然后他再重新考虑。结果，他得到了硬盘公司西部数据（Western Digital）的报价。每一笔交易都有望扩大市场，并帮助 ARM 成为标准。 上市 到 1998 年，ARM 公司的规模已经超过了原来的谷仓。公司拥有 274 名员工，上一年的收入为 4,400 万美元，利润超过 800 万美元，ARM 处理器的出货量接近 1,000 万台。ARM 还不是全球 RISC 标准–主要由于索尼 PlayStation 的出现，MIPS 已经摘得桂冠–但它已经超越英特尔的 i960 和摩托罗拉的 PowerPC，位居第三。它也是所有 RISC 芯片供应商中增长最快的。 所有这些积极的增长使公司迎来了上市的好时机。1998 年 4 月 17 日，公司在伦敦证券交易所和纳斯达克成功进行了首次公开募股（IPO）。股票的初始价格为 5.75 英镑，略低于 10 美元。同年晚些时候，当 ARM 公司报告已售出 5100 万个处理器时，股价一飞冲天。ARM 公司从 12 个人和一个梦想起步，如今已成为一家市值十亿美元的公司。 ARM 公司的两位创始投资者却选择了相反的方向。苹果公司在 1997 年亏损超过 10 亿美元，其运营现金也越来越少，情况十分危险。从 ARM 首次公开募股的第二天开始，苹果公司抛售了大部分股份，持股比例从 42.3% 降至 6% 以下。这次套现帮助史蒂夫-乔布斯在关键时刻稳定了公司。 Acorn 也在苦苦挣扎。在销售持续下滑后，公司放弃了 RISC PC 的开发，并取消了最后一款&quot;Phoebe&quot;机型，只留下其独特的黄色外壳。公司的资本价值一度低于其持有的 24% ARM 股份。Acorn 出售了股票，并用这笔钱进行了再融资和公司重组。 1999 年，公司更名为 “Element 14”，并将重点转向开发电信产品。 在 ARM 成功的推动下，VLSI 技术公司继续发展壮大。1999 年 6 月，该公司被飞利浦电子公司以 10 亿美元的价格收购。 不断变化的世界 ARM 最初只是一个疯狂的梦想。早在 1985 年，Sophie Wilson 和 Steve Furber 研究了许多现有的 CPU，发现它们都不尽如人意。令人难以置信的是，他们带领一个 10 人团队，从零开始开发出了先进的 32 位 RISC CPU，从想法到工作硅片只用了 18 个月。 最初，他们的想法是利用这些令人惊叹的中央处理器，制造出优秀的个人电脑，从而占领世界。但是，世界已经发生了变化，再也容不下新的、不兼容的计算机平台了。相反，由于苹果公司、VLSI 和罗宾-萨克斯比的远见卓识，ARM 芯片发现自己可以自由地去任何最需要它的地方。在接下来的十年里，从传真调制解调器到硬盘驱动器再到移动电话，各种小型设备都需要它。 但随着新千年的到来，这些小型设备的功能越来越强大。虽然牛顿（Newton）失败了，但通用个人数字助理市场正在蓬勃发展，移动电话本身也开始具备类似 PDA 的功能。这为 ARM 带来了最大的机遇和挑战。","categories":[{"name":"Hardware","slug":"Hardware","permalink":"https://blog.inoki.cc/categories/Hardware/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Hardware","slug":"Hardware","permalink":"https://blog.inoki.cc/tags/Hardware/"},{"name":"ARM","slug":"ARM","permalink":"https://blog.inoki.cc/tags/ARM/"}]},{"title":"【译】ARM 的历史——第一部分：打造第一块芯片","slug":"History-of-ARM-1","date":"2023-08-20T20:34:00.000Z","updated":"2025-03-08T09:40:48.566Z","comments":true,"path":"2023/08/20/History-of-ARM-1/","link":"","permalink":"https://blog.inoki.cc/2023/08/20/History-of-ARM-1/","excerpt":"","text":"原博客共分为三篇，原文链接如下： https://arstechnica.com/gadgets/2022/09/a-history-of-arm-part-1-building-the-first-chip/ https://arstechnica.com/gadgets/2022/11/a-history-of-arm-part-2-everything-starts-to-come-together/ https://arstechnica.com/gadgets/2023/01/a-history-of-arm-part-3-coming-full-circle/ 1983 年，Acorn Computer 公司需要一个 CPU。于是，10 个人制造了一个。 1983 年，Acorn Computers 正处于世界之巅。不幸的是，麻烦就在不远处。 这家英国小公司因为赢得了英国广播公司为全国电视节目生产电脑的合同而声名鹊起。当时，BBC Micro 的销量急剧上升，有望突破 120 万台。 但是，个人电脑的世界正在发生变化。家长们为了辅导孩子做作业而购买的廉价 8 位微型机市场逐渐饱和。而来自大洋彼岸的新机器，如 IBM PC 和即将问世的苹果 Macintosh，则承诺提供更强大、更易用的功能。Acorn 需要一种竞争方式，但它没有太多资金用于研发。 创意的种子 BBC Micro 的设计者之一索菲-威尔逊（Sophie Wilson）早就预料到了这个问题。她增加了一个名为 “Tube” 的插槽，可以连接功能更强大的中央处理器。插槽式中央处理器可以接管计算机，让原来的 6502 芯片腾出时间执行其他任务。 威尔逊后来在接受计算机历史博物馆采访时解释说：&quot;我们可以看到所有这些处理器能做什么，不能做什么。因此，它们没有做到的第一件事就是没有充分利用内存系统。其次，它们的速度不快，不好用。我们习惯于用机器码对 6502 进行编程，我们更希望我们能达到这样的能力水平，即如果你用更高级别的语言编写，你也能达到同样的结果。 但另一种选择是什么呢？让小小的 Acorn 公司从头开始制造自己的 CPU 是否可行？为了弄清这个问题，威尔逊和福伯前往国家半导体位于以色列的工厂。他们看到了数百名工程师和大量昂贵的设备。这证实了他们的猜测，即他们可能无法完成这样的任务。 随后，他们参观了位于亚利桑那州梅萨的西部设计中心。这家公司正在制造深受人们喜爱的 6502，并在设计 16 位的后续产品 65C618。威尔逊和福伯发现，这里只有一间 “郊区的平房”，几名工程师和几名学生正在用老式的苹果 II 电脑和粘胶带制作图表。 但她应该选择什么样的处理器呢？威尔逊和联合设计师史蒂夫-福伯考虑了各种 16 位的选择，如英特尔的 80286、国家半导体的 32016 和摩托罗拉的 68000。但没有一个是完全令人满意的。 突然间，自制 CPU 似乎成为可能。威尔逊和福伯的小团队以前也制作过定制芯片，如 BBC Micro 的图形和输入/输出芯片。但与中央处理器相比，这些设计更简单，元件更少。 尽管困难重重，Acorn 的上层管理者还是支持他们的努力。事实上，他们不仅仅是支持。Acorn 联合创始人赫尔曼-豪瑟（Hermann Hauser）拥有物理学博士学位，他给团队提供了 IBM 研究论文的副本，其中描述了一种新型、功能更强大的 CPU。它被称为 RISC，意思是 “精简指令集计算”。 采用 RISC 这究竟意味着什么？要回答这个问题，我们先来上一堂超级简化的 CPU 工作原理速成课。首先是晶体管，一种由硅与不同化学物质混合而成的三明治状微小器件。晶体管有三个接头。当栅极输入端有电压时，电流可以从源极输入端自由流向漏极输出端。当栅极上没有电压时，电流就会停止流动。因此，晶体管是一种可控开关。 您可以将晶体管组合起来形成逻辑门。例如，两个串联的开关组成一个 &quot;AND &quot;门，两个并联的开关组成一个 &quot;OR &quot;门。这些门可以让计算机通过比较数字做出选择。 但如何表示数字呢？计算机使用二进制或 Base 2，将一个小的正电压等同于数字 1，无电压等同于 0。由于二进制运算非常简单，因此很容易制造出二进制加法器，可以将 0 或 1 加到 0 或 1，并存储总和和一个可选的进位。大于 1 的数字可以通过添加更多同时工作的加法器来表示。可同时访问的二进制位数是衡量芯片 &quot;比特度 &quot;的一个标准。像 6502 这样的 8 位 CPU 以 8 位为单位处理数字。 算术和逻辑是 CPU 的主要功能。但人类需要一种方法来告诉它该做什么。因此，每个中央处理器都有一个指令集，它列出了中央处理器可以将数据移入和移出内存、进行数学计算、比较数字以及跳转到程序不同部分的所有方法。 RISC 的理念是大幅减少指令数量，从而简化 CPU 的内部设计。如何大幅减少？英特尔 80286 是一款 16 位芯片，总共有 357 条独特的指令。而索菲-威尔逊创建的新 RISC 指令集只有 45 条。 为了实现这种简化，威尔逊使用了 “加载和存储” 架构。传统（复杂）CPU 有不同的指令，用于将两个内部 “寄存器”（芯片内部的小块存储器）中的数字相加，或将外部存储器中两个地址中的数字相加，或将每种指令的组合相加。相比之下，RISC 芯片指令只能在寄存器上运行。然后，单独的指令会将答案从寄存器移至外部存储器。 这意味着 RISC CPU 的程序通常需要更多的指令才能产生相同的结果。那么，它们如何才能更快？答案之一是，更简单的设计可以以更高的时钟速度运行。但另一个原因是，芯片执行更复杂的指令需要更长的时间。如果保持简单，就可以在一个时钟周期内执行每一条指令。这样就更容易使用流水线技术。 通常，CPU 必须分阶段处理指令。它需要从内存中获取指令，解码指令，然后执行指令。Acorn 正在设计的 RISC CPU 将采用三级流水线。当芯片的一部分执行当前指令时，另一部分正在获取下一条指令，如此循环。 RISC 设计的一个缺点是，由于程序需要更多的指令，因此需要占用更多的内存空间。在 20 世纪 70 年代末设计第一代 CPU 时，1 兆字节的内存大约需要 5,000 美元。因此，任何能减少程序内存大小的方法（拥有复杂的指令集将有助于实现这一目标）都是非常有价值的。这就是英特尔 8080、8088 和 80286 等芯片拥有如此多指令的原因。 但内存价格却在迅速下降。因此，RISC CPU 所需的额外内存在未来将不再是问题。 为了进一步保证新的 Acorn CPU 的未来发展，团队决定跳过 16 位，直接采用 32 位设计。这实际上简化了芯片的内部结构，因为你不必经常拆分大数字，而且可以直接访问所有内存地址。(事实上，第一款芯片只暴露了 32 个地址线中的 26 个引脚，因为 2 的 26 次方，即 64MB 在当时是一个非常大的内存容量）。 现在，团队需要的只是为新 CPU 取一个名字。团队考虑了各种方案，最终将其命名为 Acorn RISC Machine，或 ARM。 成为 ARM 第一款 ARM 芯片的开发历时 18 个月。为了节省开支，团队花了大量时间对设计进行测试，然后才将其投入到硅片中。Furber 在 BBC Micro 上用解释型 BASIC 为 ARM CPU 写了一个模拟器。当然，这个过程慢得令人难以置信，但它有助于证明概念，并验证威尔逊的指令集是否能按设计运行。 威尔逊认为，开发过程虽然雄心勃勃，但却简单明了。 &quot;她说：&quot;我们以为自己疯了。&quot;我们认为我们做不到。但我们不断发现，实际上并没有什么地方可以让我们停下脚步。这只是一个工作问题。 Furber 主要负责芯片本身的布局和设计，而 Wilson 则专注于指令集。但实际上，这两项工作是紧密交织在一起的。为每条指令选择代码并不是随心所欲的。选择每个数字的目的是，当它被转换成二进制数字时，指令总线上的适当导线就会激活正确的解码和路由电路。 测试过程逐渐成熟，威尔逊领导的团队编写了更先进的仿真器。&quot;她解释说：&quot;有了纯指令模拟器，我们就可以在 6502 秒处理器上以每秒数十万条 ARM 指令的速度运行。&quot;我们还可以编写大量的软件，将 BBC BASIC 移植到 ARM 和其他一切，包括第二处理器和操作系统。这让我们越来越有信心。尽管我们是在解释 ARM 机器代码，但其中一些东西比我们见过的任何其他东西都要好用。ARM 机器代码本身的性能非常高，解释 ARM 机器代码的结果往往比同一平台上的编译代码更好。 这些惊人的结果促使这个小团队完成了工作。第一个 ARM CPU 的设计被送到美国半导体制造公司 VLSI Technology Inc. 1985 年 4 月 26 日，第一版芯片回到橡果公司。威尔逊将它插入 BBC Micro 的 Tube 插槽，加载了移植到 ARM 版本的 BBC BASIC，并用特殊的 PRINT 命令进行了测试。芯片回答说：&quot;世界你好，我是 ARM。&quot;于是，团队开了一瓶香槟。 让我们回过头来思考一下，这是一项多么了不起的成就。整个 ARM 设计团队包括索菲-威尔逊（Sophie Wilson）、史蒂夫-福伯（Steve Furber）、另外几位芯片设计师，以及一个编写测试和验证软件的四人团队。这个基于先进 RISC 设计的新型 32 位 CPU 是由不到 10 个人完成的，而且第一次就能正确运行。相比之下，美国国家半导体公司的 32016 已经进行了第 10 次修订，但仍在不断发现错误。 Acorn 团队是如何做到这一点的呢？他们将 ARM 设计得尽可能简单。V1 芯片只有 27,000 个晶体管（80286 有 134,000 个晶体管！），采用 3 微米工艺制造，也就是 3,000 纳米，颗粒度比现在的 CPU 小一千倍。 在这种详细程度上，你几乎可以看清单个晶体管。以寄存器文件为例，将其与随机存取存储器工作原理的交互式框图进行比较。您可以看到指令总线将数据从输入引脚传送到解码器和寄存器控件。 虽然第一个 ARM CPU 给人留下了深刻印象，但指出它所缺少的东西也很重要。它没有板载高速缓冲存储器。它没有乘法或除法电路。此外，它还缺少浮点运算单元，因此对非整数的运算速度较慢。不过，使用一个简单的桶形移位器有助于浮点数的运算。芯片的运行频率仅为 6 MHz。 那么，这个小巧玲珑的 ARM V1 性能如何呢？在基准测试中，它比相同时钟速度的英特尔 80286 芯片快 10 倍左右，相当于运行频率为 17 MHz 的 32 位摩托罗拉 68020 芯片。 ARM 芯片还被设计成以非常低的功耗运行。威尔逊解释说，这完全是一项节约成本的措施–研究小组希望使用塑料外壳代替陶瓷外壳，因此他们设定了 1 瓦的最大功耗目标。 但是，他们用于估算功率的工具非常原始。为了确保不超标，不融化塑料，他们对每个设计细节都非常保守。由于设计简单、时钟频率低，实际功耗最终只有 0.1 瓦。 事实上，团队最先将 ARM 插入的一块测试板的连接断开了，根本没有连接到任何电源。当他们发现故障时非常惊讶，因为 CPU 一直都在工作。它只是在支持芯片漏电的情况下打开的。 威尔逊认为，ARM 芯片的低功耗是一个 “完全的意外”，但这在以后会变得非常重要。 使用 ARM 的新计算机 Acorn 公司拥有了这项领先竞争对手多年的惊人技术。财务上的成功肯定很快就会到来，对吗？如果你关注计算机发展史，也许就能猜到答案。 到 1985 年，BBC Micro 的销售开始枯竭，一边是廉价的 Sinclair Spectrum，另一边是 IBM PC 克隆机。Acorn 将公司的控股权卖给了 Olivetti，因为之前曾与 Olivetti 合作为 BBC Micro 生产打印机。一般来说，如果把计算机公司卖给打字机公司，那可不是什么好兆头。 Acorn 向研究人员和业余爱好者出售带有 ARM 芯片的开发板，但这仅限于现有的 BBC Micro 用户市场。该公司需要的是一台全新的计算机，以真正展示这种新型 CPU 的强大功能。 在此之前，公司需要对最初的 ARM 稍作升级。ARM V2 于 1986 年问世，它增加了对协处理器（如浮点协处理器，这是当时计算机上流行的附加功能）和内置硬件乘法电路的支持。它采用 2 微米工艺制造，这意味着 Acorn 可以将时钟频率提高到 8 MHz，而无需消耗更多电力。 但是，仅有 CPU 还不足以构成一台完整的计算机。于是，团队又开发了图形控制器芯片、输入/输出控制器和内存控制器。到 1987 年，包括 ARM V2 在内的所有四种芯片都已准备就绪，同时还制作了一台原型计算机来安装这些芯片。为了反映其先进的思维能力，公司将其命名为 Acorn Archimedes。 考虑到当时是 1987 年，人们对个人电脑的要求已不仅仅是提示输入 BASIC 指令。用户需要像 Amiga、Atari ST 和 Macintosh 那样漂亮的图形用户界面。 Acorn 在施乐 PARC 所在的加利福尼亚州帕洛阿尔托成立了一个远程软件开发团队，为阿基米德设计下一代操作系统。它被称为 ARX，并承诺提供抢占式多任务处理和多用户支持。ARX 速度很慢，但更大的问题是它迟到了。非常晚。 当时，Acorn 阿基米德正准备发货，而公司还没有操作系统。这是一个危机四伏的局面。于是，橡果公司的管理层去找保罗-费洛斯（Paul Fellows）谈话，他是 Acorn 软件团队的负责人，曾为 BBC Micro 编写了大量语言。他们问他：“你和你的团队能在五个月内为阿基米德写出一个操作系统吗？” 费洛斯说：“我就是那个傻子，我说可以，我们能做到。” 五个月的时间对于从零开始制作操作系统来说并不算长。这个速成操作系统被称为 “亚瑟计划”，可能是以英国著名计算机科学家亚瑟-诺曼（Arthur Norman）的名字命名的，也可能是 &quot;ARm by THURSday！&quot;的缩写。它最初是 BBC BASIC 的扩展。理查德-曼比（Richard Manby）用 BASIC 编写了一个名为 “亚瑟桌面”（Arthur Desktop）的程序，仅仅是为了演示如何使用团队开发的窗口管理器。但他们已经没有时间了，所以演示程序被刻录到了第一批计算机的只读存储器（ROM）中。 首批 Archimedes 机型于 1987 年 6 月发货，其中一些机型仍带有 BBC 商标。这些计算机的运算速度绝对很快，而且性价比很高–入门价格为 800 英镑，在当时约合 1300 美元。这与 1987 年售价 5500 美元、计算能力类似的 Macintosh II 相比毫不逊色。 但 Macintosh 拥有 PageMaker、Microsoft Word 和 Excel 以及大量其他实用软件。Archimedes 是一个全新的计算机平台，在发布之初，可用的软件并不多。计算机世界迅速向IBM PC兼容机和Macintoshes（还有几年的Amigas）靠拢，其他人都发现自己被挤出了市场。Archimedes 电脑在英国媒体上获得了良好的评价，并赢得了一批狂热的粉丝，但在最初的几年里，Archimedes 电脑的销量还不到10万台。 种子成长 Acorn 迅速修复了亚瑟中的错误，并开发出具有更多现代功能的替代操作系统 RISC OS。RISC OS 于 1989 年推出，随后不久，ARM CPU 的新版本 V3 也随之推出。 V3 芯片采用 1.5 微米工艺制造，将 ARM2 内核的尺寸缩小到约四分之一的可用芯片空间。这就为包含 4 千字节的快速一级高速缓冲存储器留出了空间。时钟速度也提高到 25 MHz。 虽然这些改进给人留下了深刻印象，但索菲-威尔逊等工程师相信，ARM 芯片还能更进一步。但是，在 Acorn 资源迅速减少的情况下，能做的事情是有限的。为了实现这些梦想，ARM 团队需要寻找外部投资者。 这时，另一家以一种流行水果命名的计算机公司的代表走了进来。。。","categories":[{"name":"Hardware","slug":"Hardware","permalink":"https://blog.inoki.cc/categories/Hardware/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Hardware","slug":"Hardware","permalink":"https://blog.inoki.cc/tags/Hardware/"},{"name":"ARM","slug":"ARM","permalink":"https://blog.inoki.cc/tags/ARM/"}]},{"title":"【译】探索高通的安全执行环境","slug":"exploring-qualcomms-secure-execution-env","date":"2023-04-30T13:20:00.000Z","updated":"2025-03-08T09:40:48.609Z","comments":true,"path":"2023/04/30/exploring-qualcomms-secure-execution-env/","link":"","permalink":"https://blog.inoki.cc/2023/04/30/exploring-qualcomms-secure-execution-env/","excerpt":"","text":"在本博客中，我们将再次深入探讨 TrustZone 的世界，并探索一系列新的漏洞和相应的利用程序，这些漏洞和利用程序将使我们能够从零权限提升特权，以在 TrustZone 内核中执行代码。 对于那些阅读过之前系列的人来说，这可能听起来很熟悉 - 但是让我向您保证;这个系列将会更加令人兴奋！ 首先，这个漏洞链具有通用性，适用于所有 Android 版本和手机（而且不需要任何权限），并且一个影响广泛的 TrustZone 漏洞。其次，我们将深入探讨一个尚未被探索的操作系统 - QSEE - 高通的安全执行环境。最后，我们将看到一些有趣的 TrustZone 有效载荷，例如直接从 TrustZone 的加密文件系统中提取真实指纹。 如果您想跟随符号和反汇编二进制文件进行学习，我将在整个系列中使用我的Nexus 6，其指纹如下： google/shamu/shamu:5.1.1/LMY48M/2167285:user/release-keys 您可以在此处找到确切的出厂镜像。 噢，QSEE 能否说得上安全？ 在这篇博客文章中，我们将探索高通的安全执行环境 QSEE。 正如我们之前讨论的那样，设备上包含 TrustZone 的主要原因之一是提供“可信执行环境”(TEE)——一个理论上可以允许计算而不会被常规操作系统干扰的环境，因此是“可信的”。 这是通过创建一个仅在由 TrustZone 提供的“安全世界”中运行的小型操作系统来实现的。这个操作系统直接提供一些系统调用形式的少量服务，这些调用被 TrustZone 内核(TZBSP)本身处理。然而，为了允许可扩展的模型，其中可以添加“可信”的功能，TrustZone 内核还可以安全地加载和执行称为“Trustlet”的小程序，这些程序旨在为不安全的(“正常世界”)操作系统(在我们的情况下是 Android)提供安全服务。 这些 Trustlet 在设备上通常会被广泛使用： keymaster：实现了由 Android 密钥库守护程序提供的密钥管理 API。它可以安全地生成和存储加密密钥，并允许用户使用这些密钥对数据进行操作。 widevine：实现了 Widevine DRM，允许在设备上安全播放媒体。 实际上，根据 OEM 和设备的不同，可能会有更多与 DRM 相关的 Trustlet，但这两个 Trustlet 被广泛使用。 我们从哪里开始？ 自然而然的，我们可以选择一个 Trustlet 来开始，尝试理解其工作原理。由于 widevine 模块是最普遍的之一，我们将重点关注它。 简要搜索设备固件中的 widevine Trustlet，可以发现以下内容： 显然，Trustlet 被分成了几个不同的文件…打开这些文件会看到一堆混乱的东西——有些文件包含看起来像是代码的内容，而其他文件包含 ELF 头和元数据。无论如何，在我们开始反汇编 Trustlet 之前，我们需要从这种格式中理出一些意义。我们可以通过打开每个文件并猜测每个 Blob 的含义，或者通过跟踪负责加载 Trustlet 的代码路径来实现。让我们试试两种方法。 加载 Trustlet 为了从&quot;正常世界&quot;中加载 Trustlet，应用程序可以使用 libQSEECom.so 共享对象，该对象导出函数 QSEECom_start_app: 很不幸，这个库的源代码不可用，因此我们需要反向工程实现函数以找出它的作用。这样做会发现它执行以下操作： 打开 /dev/qseecom 设备并调用一些 ioctl 命令进行配置。 打开与信任应用程序相关的 .mdt 文件并从中读取前 0x34 字节。 使用 .mdt 的 0x34 字节计算 .bXX 文件的数量。 分配一个物理连续的缓冲区（使用&quot;ion&quot;）并将 .mdt 和 .bXX 文件复制到其中。 最后，使用分配的缓冲区调用 ioctl 来加载信任应用程序本身。 所以，仍然没有找到镜像加载的确切方法，但我们正在接近目标。 首先，数字 0x34 可能看起来很熟悉——这是 ELF 头的大小（32 位）。打开 MDT 文件后发现，前 0x34 字节确实是有效的 ELF 头： 此外，我们刚刚查看的 QSEECOM_start_app 函数使用偏移量 0x2C 处的 WORD 来计算 .bXX 文件的数量。正如您在上面看到的那样，这对应于 ELF 标头中的 e_phnum 字段。 由于 e_phnum 字段通常用于指定程序头的数量，这表明每个 .bXX 文件可能包含要加载的程序的单个段。实际上，打开每个文件都会显示出内容，看起来可能是正在加载的程序的段……但是为了确保，我们需要找到程序头本身（并查看它们是否与 .bXX 文件匹配）。 进一步查看，.mdt 文件中的下几个块实际上是程序头本身，每个头文件对应一个存在的 .bXX 文件。 而且，确认了我们之前的怀疑，它们的大小恰好与 .bXX 文件的大小匹配。太好了！ 请注意，上面的前两个程序头看起来有点奇怪 - 它们都是空类型的头，意味着它们是“保留”的，不应加载到结果 ELF 映像中。奇怪的是，打开相应的 .bXX 文件会发现，第一个块包含与 .mdt 中相同的 ELF 头和程序头，第二个块包含其余的 .mdt 文件。 无论如何，这是一个简短的示意图，总结了我们目前所知道的内容： 此外，请注意由于 ELF 头文件和程序头文件都在 .mdt 中，因此我们可以使用 readelf 快速转储有关信任执行环境的程序头信息。 在这一点上，我们已经拥有了从 .mdt 和 .bXX 文件创建完整有效的 ELF 文件所需的所有信息；我们拥有 ELF 头和程序头，以及每个段本身。我们只需要编写一个小脚本，使用这些数据创建一个 ELF 文件。 我编写了一个小的 Python 脚本，正是这样做的。您可以在此处找到它： 信任 Trustlets 的思考 对 Trustlet 的信任过程，我们现在已经有了基本的了解，但我们仍然不知道它们是如何进行验证的。然而，由于我们知道 .bXX 文件仅包含要加载的段，这意味着这些数据必须驻留在 .mdt 文件中。 因此，现在是猜测的时间——如果我们要构建一个可信的加载程序，我们将如何做？ 一个非常常见的范式是使用哈希和签名（依赖于 CRHF 和数字签名）。基本上——我们计算要进行身份验证的数据的哈希值，并使用对于加载器已知其对应的公共密钥的私有密钥进行签名。 如果情况是这样的，我们应该在 .mdt 中找到以下两个内容： 证书链 签名数据块 让我们从查找证书链开始。证书有太多的格式，但由于 .mdt 文件仅包含二进制数据，我们可以假设它可能是一个二进制格式，其中最常见的是 DER 格式。 我们可以使用一种快速的 hack 方法来查找 DER 编码的证书——它们几乎总是以 ASN.1 SEQUENCE 块开头，编码为：0x30 0x82。所以让我们在 .mdt 中搜索这两个字节，并将每个找到的块保存到一个文件中。现在，我们可以使用 openssl 检查这些块是否为格式良好的证书： 是的，我们猜对了–那些是证书。 事实上，该信任小程序包含三个证书，一个接一个。为了稳妥起见，我们可能还想检查一下这三个证书实际上是一个证书链，形成了一个有效的信任链。我们可以通过把证书转储到一个单一的&quot;证书链&quot;文件中，并使用 openssl 来验证使用这个证书链的每个证书来做到这一点： 至于这个链的信任根–看一下链中的根证书就会发现，这个根证书与高通公司安全启动过程中用于验证启动链的所有其他部分的根证书相同。对这一机制进行了一些研究，结果表明，验证是通过比较根证书的 SHA256 和一个名为 OEM_PK_HASH 的特殊值进行的，该值在生产过程中被&quot;融合&quot;到设备的 QFuse 中。由于这个值在设备生产后理论上不应该被修改，这意味着伪造这样的根证书基本上需要对 SHA256 进行第二次预镜像攻击。 现在，让我们回到 .mdt–我们已经找到了证书链，所以现在是时候寻找签名了。通常情况下，私钥是用来产生签名的，而公钥可以用来恢复签名数据。由于我们有证书链中最顶端的证书的公钥，我们可以用它来查看文件，并适时地尝试&quot;恢复&quot;每个 blob。 但我们怎么知道我们是否成功了呢？ 回想一下，RSA 是一个陷阱门排列族–每一个具有与公共模数 N 相同位数的 blob 都被映射到另一个相同大小的 blob。 然而，虽然在我们的例子中，RSA 的公共模数是 2048 位，但大多数哈希值都比这短得多（SHA1 为 160 位，SHA256 为 256 位）。这意味着，如果我们试图用我们的公钥&quot;解密&quot;一个 blob，而它恰好以大量的&quot;松弛&quot;空间结束（例如，0 字节），有一个非常好的机会，这是我们正在寻找的签名（对于一个完全随机的排列组合，连续 n 个零位的机会是 2^-n - 即使是一个中等的 n，也非常小）。 为了做到这一点，我写了一个小程序，从链中最顶端的证书中加载公钥，并尝试&quot;恢复&quot; .mdt 中的每个 blob（使用带有 PKCS #1 v1.5 填充的 rsa_public_decrypt）。如果 “恢复的” blob 以一堆 0 字节结尾，程序就会输出它。所以…在我们的 .mdt 上运行它： 我们已经找到了一个签名! 太好了。 更重要的是，这个签名有 256 比特长，这意味着它可能是一个 SHA256 哈希值… 如果 .mdt 里有一个 SHA256，也许还有更多？ 再一次的幸运! 我们可以看到，每个 .bXX 文件的 SHA256 哈希值也连续存储在 .mdt 中。我们也可以做一个有根据的猜测，这将是被签名的数据（或至少是部分数据），以产生我们之前发现的签名。 注意，.b01 文件的哈希值不见了–这是为什么？记住，.b01 文件包含了 .mdt 中除 ELF 头和程序头以外的所有数据。由于这些数据也包含上面的签名，而签名（可能）是通过块文件的哈希值产生的，这将导致循环依赖（因为改变块文件将改变哈希值，这将改变签名，这将再次改变块文件，等等）。因此，这个区块的哈希值不存在是有道理的。 现在我们实际上已经解码了 .mdt 文件中的所有数据，除了一个位于程序头之后的小结构。然而，在看了一会儿之后，我们可以看到它只是包含了我们已经解码的 .mdt 中各个部分的指针和长度： 所以最后，我们已经解码了 .mdt 中的所有信息… 摩托罗拉的高保障启动 尽管我们在上面看到的 .mdt 文件格式对所有的 OEM 来说都是通用的，但摩托罗拉决定增加一个小插曲。 他们没有像我们之前看到的那样提供一个 RSA 签名，而是实际上将签名 blob 留空（事实上，我之前给你看的签名是来自 Nexus 5）。事实上，摩托罗拉的签名看起来像这样： 那么，图像是如何被验证的呢？ 这是通过使用摩托罗拉称之为 HAB（“高保障启动”）的机制来完成的。这个机制允许他们通过在文件末尾附加一个证书链和整个 .mdt 的签名来验证 .mdt 文件，并使用 HAB 使用的专有格式进行编码： 关于这一机制的更多信息，你可以查看 Tal Aloni 的这项研究。简而言之，.mdt 使用证书链中最顶端的密钥进行散列和签名，而证书链中的根证书则使用 &quot;超级根密钥 &quot;进行验证，该密钥是在引导程序的某个阶段硬编码的。 Trustlet 的生命周期 在我们上面看到的验证过程之后，TrustZone 内核将 Trustlet 的片段加载到&quot;正常世界&quot;无法访问的安全内存区域（secapp-region），并给它分配了一个 ID。 然后，内核切换到&quot;安全世界&quot;的用户模式，执行 Trustlet 的入口函数： 正如你所看到的，Trustlet 向 TrustZone 内核注册了自己，同时还有一个&quot;处理函数&quot;。在注册完 Trustlet 后，控制权被返回到 TrustZone 内核，加载过程结束了。 现在，一旦 Trustlet 被加载，&quot;正常世界&quot;可以通过发出一个特殊的 SCM 调用（称为 QSEOS_CLIENT_SEND_DATA_COMMAND）向 Trustlet 发送命令，其中包含加载 Trustlet 的 ID 以及请求和响应缓冲区。下面是它的样子： TrustZone 内核（TZBSP）收到 SCM 调用，将其映射到 QSEOS，然后找到具有给定 ID 的应用程序，并调用先前注册的处理函数（来自&quot;安全世界&quot;用户模式），以便为请求服务。 下一步是什么？ 现在我们对什么是 Trustlet 以及它们是如何加载有了一些了解，我们可以继续进行攻击了！在下一篇博文中，我们将发现一个非常流行的 Trustlet 中的漏洞，并利用它在 QSEE 中执行代码。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"【译】完整的 MSM8974 TrustZone 实现利用","slug":"full-trustzone-exploit-for-msm8974","date":"2023-04-30T11:20:00.000Z","updated":"2025-03-08T09:40:48.609Z","comments":true,"path":"2023/04/30/full-trustzone-exploit-for-msm8974/","link":"","permalink":"https://blog.inoki.cc/2023/04/30/full-trustzone-exploit-for-msm8974/","excerpt":"","text":"在这篇博客文章中，我们将涵盖利用先前文章中描述的 TrustZone 漏洞的完整过程。如果你还没有阅读它，请先阅读！ 负责任的披露 首先，我要指出我已经向高通负责任地披露了这个漏洞，并且问题已经得到解决（见下文的时间轴）。 我还想利用这个机会指出，高通在回应披露方面做得非常出色，非常积极地解决问题。 他们还送了我一台全新的（当时）Moto X 2014，它将成为以后许多帖子的主题（深入探讨 TrustZone 的架构和设备上的其他安全组件）。 零号患者 在开发此漏洞利用程序时，我只有我的可靠（个人）Nexus 5 设备可供使用。这意味着下面所有的内存地址和其他具体信息都是从该设备中取得的。 如果有人想重新创建下面所描述的精确研究，或者由于任何其他原因，我的设备在当时的确切版本是： google/hammerhead/hammerhead:4.4.4/KTU84P/1227136:user/release-keys 有了这个，我们就开始吧！ 漏洞原语 如果你读过上一篇文章，你已经知道这个漏洞允许攻击者在 TrustZone 内核的虚拟地址空间中的任何地址写入 DWORD 0。 基于个人经验，零写原语并不是很有趣。它们通常相当有限，不一定导致可利用的情况。为了使用这种弱原语创建一个健壮的漏洞利用程序，首要行动是尝试利用这个弱原语来建立一个更强的原语。 创建任意写原语 由于 TrustZone 内核加载在已知的物理地址上，这意味着所有地址已经事先知道，不需要在执行时发现。 然而，TrustZone 内核的内部数据结构和状态很大程度上是未知的，并且由于许多不同的进程与 TrustZone 内核交互（从外部中断到“安全世界”应用程序等），它们可能会发生变化。 此外，TrustZone 代码段被映射为只读访问权限，并且在安全启动过程中进行验证。这意味着一旦 TrustZone 的代码加载到内存中，理论上不应该再发生任何改变。 因此，我们该如何利用零写原语来实现完整代码执行呢？ 我们可以尝试编辑 TrustZone 内核中的任何可修改数据（例如堆、栈或全局变量），这可能会为我们创建一个更好的原语的垫脚石。 正如我们在上一篇博客文章中提到的那样，通常在调用 SCM 命令时，任何指向内存的参数都会被 TrustZone 内核验证。验证是为了确保物理地址在“允许”的范围内，而不是例如在 TrustZone 内核使用的内存范围内。 这些验证听起来像是我们要研究的主要候选项，因为如果我们能够禁用它们的操作，我们就可以利用其他 SCM 调用来创建不同类型的原语。 TrustZone 内存验证 让我们开始给内存验证函数起一个名称 - 从现在开始，我们将称之为 tzbsp_validate_memory。 以下是该函数的反编译代码： 这个函数实际上调用了两个内部函数来执行验证，我们分别称它们为 is_disallowed_range 和 is_allowed_range。 is_disallowed_range 正如你所看到的，该函数实际上使用给定地址的前12位，具体如下： 高 7 位用作索引，索引一个包含 128 个 32 位宽值的表。 低 5 位用作在先前索引的位置上存在的 32 位条目中要检查的位索引。 换句话说，对于要进行验证的内存区域交叉的每个 1MB 块，存在上述表格中用于表示该数据区域是否“不允许”的位。如果给定区域中的任何块都被禁止，则该函数返回表示此类情况的值。否则，该函数将给定的内存区域视为有效。 is_allowed_range 虽然稍微有些长，但这个函数也很简单。它基本上只是遍历一个静态数组，其中包含以下结构的条目： 该函数遍历在给定内存地址处的表中的每个条目，当当前条目的 end_marker 字段为 0xFFFFFFFF 时停止遍历。 每个条目指定的范围都会进行验证，以确保内存范围是允许的。但是，正如上面的反编译所示，设置 flags 字段第二位的条目将被跳过！ 攻击验证函数 现在我们理解了验证函数的操作方式，让我们看看如何使用零写入原语来禁用它们的操作。 首先，如上所述，is_disallowed_range 函数使用一个 32 位条目的表，其中每个位对应 1MB 内存块。设置为1的位表示禁止块，而零位表示允许块。 这意味着我们可以通过使用零写入原语将表中的所有条目设置为零来轻松地使该函数无效。这样做将使所有内存块被标记为允许。 转到下一个函数 is_allowed_range。这有点棘手-如上所述，在标志字段中设置第二位的块会根据给定地址进行验证。但是，对于在其中未设置此位的块，不执行验证，并跳过该块。 由于设备中的块表只与驻留在 TrustZone 内核内存范围内的内存范围有关，因此我们只需要将此字段设置为零即可。这样做将导致验证函数跳过它，因此验证函数将接受 TrustZone 内核内存中的内存地址为有效。 回到编写原语 现在我们已经摆脱了边界检查函数，可以自由地提供任何内存地址作为 SCM 调用的参数，而不会有任何障碍。 但是，我们是否更接近创建编写原语？理想情况下，如果有一个 SCM 调用，我们可以控制写入到受控位置的一块数据块，那就足够了。 不幸的是，在查看所有 SCM 调用之后，似乎没有符合此描述的候选者。 尽管如此，不需要担心！无法通过单个 SCM 调用实现的操作，可能通过串联几个调用来实现。从逻辑上讲，我们可以将创建任意写入原语拆分为以下步骤： 在受控位置创建一个未受控的数据块 控制创建的数据块，使其实际包含所需内容 将创建的数据块复制到目标位置 创建 虽然没有SCM调用似乎是创建受控数据块的好选择，但有一个调用可以用于在受控位置创建未受控的数据块 tzbsp_prng_getdata_syscall。 如其名称所示，可以使用此函数在给定位置生成随机字节缓冲区。通常，Android 使用它以利用 Snapdragon SoC 中存在的硬件 PRNG。 在任何情况下，SCM 调用接收两个参数；输出地址和输出长度（以字节为单位）。 一方面，这很好 - 如果我们（在某种程度上）信任硬件随机数生成器（RNG），我们可以相当确信使用此调用生成的每个字节都可能是输出范围内的任何字节值。另一方面，这意味着我们对所生成的数据完全没有控制权。 控制 即使在使用 PRNG 时可能会生成任何输出，也许有一种方法可以验证所生成的数据是否实际上是我们要写入的数据。 为了做到这一点，让我们想象以下游戏 - 假设您有一个有四个槽的老虎机，每个槽有 256 种可能的值。每次拉动手柄时，所有槽都同时旋转，并呈现出随机输出。您需要拉多少次手柄才能使结果完全匹配之前选择的值？嗯，有 4294967296（2^32）种可能的值，因此每次拉手柄时，结果与所需结果匹配的几率约为 10^(-10)。听起来你要在这里呆上一段时间了… 但是，如果你能够作弊呢？例如，如果每个插槽都有一个不同的手柄？这样你就只能每次更改一个插槽的值。这意味着现在每次拉动手柄，有 1/256 的机会，结果将与该插槽的期望值匹配。 听起来游戏现在变得更容易了，对吧？但是变得有多容易？在概率论中，这种单个“游戏”的分布被称为伯努利分布，实际上只是一种说法，即每次试验都有一组成功的概率，表示为 p，所有其他结果都被标记为失败，并且有 1-p 的概率发生。 假设我们希望有 90％ 的成功率，结果表明在原始版本的游戏中，我们需要进行大约 10^8 次尝试（！），但如果我们作弊，我们每个插槽只需要大约 590 次尝试，这是几个数量级的差异。 那么你是否已经弄清楚了这与我们的写入原语有什么关系呢？以下是解释： 首先，我们需要找到一个 SCM 调用，它可以将内存中可写的位置的值返回给调用者。 有很多这样的函数。其中一个候选项是 tzbsp_fver_get_version 调用。该函数可用于“普通世界”，以检索不同 TrustZone 组件的内部版本号。它通过接收表示要检索版本号的组件的整数和要写入版本代码的地址来实现。然后，该函数只是在一个静态的包含组件 ID 和版本代码的对的数组中遍历。当找到具有给定 ID 的组件时，版本代码将写入输出地址。 现在，我们可以使用 tzbsp_prng_getdata_syscall 函数，开始逐字节操作任何版本代码的值。为了知道在每次迭代中生成的字节的值，我们可以简单地调用上述 SCM，同时传递与要修改其版本代码的组件匹配的组件 ID，以及提供一个返回地址，该地址指向可读取的（即不在 TrustZone 中的）内存位置。 我们可以重复这前两个步骤，直到满意为止，然后再生成下一个字节。这意味着经过几次迭代后，我们可以确定特定版本代码的值与我们想要的 DWORD 相匹配。 复制 最后，我们想要将生成的值写入一个可控制的位置。幸运的是，这一步非常简单。我们只需要简单地调用 tzbsp_fver_get_version SCM 调用，但现在我们可以将目标地址作为返回地址参数提供。这将导致函数将我们生成的 DWORD 写入可控制的位置，从而完成我们的写入工具。 喘口气…现在怎么办？ 从这里开始，事情变得容易了。首先，尽管我们有一个写入原语，但仍然很麻烦使用。也许，如果我们能够使用之前的一个更简单的工具来创建一个更简单的工具，那就会更容易些。 我们可以通过创建我们自己的 SCM 调用来实现这一点，这只是一个写入-何处工具。这听起来很棘手，但实际上很简单。 在先前的博客文章中，我们提到所有 SCM 调用都通过一个包含指向每个 SCM 调用的指针（以及它们提供的参数数量，名称等）的大型数组间接调用。 这意味着我们可以使用先前创建的写入工具，将一些我们认为“不重要”的 SCM 调用的地址更改为已存在写入工具的地址。快速查看 TrustZone 内核的代码会发现有许多这样的工具。以下是其中一个例子： 最后，能够读取 TrustZone 内核虚拟地址空间中的任何内存位置也很有用。这可以通过使用上面描述的方法中的另一个“不重要”的 SCM 调用来创建读取 gadget。实际上，这个 gadget 要比写入 gadget 更加难以找到。但是，在 TrustZone 内核中发现了这样一个 gadget: 这个 gadget 返回 R0 中储存的地址、加上 R1 中的偏移值中读取的值，太棒了！ 编写新代码 在这个阶段，我们已经可以完全读写 TrustZone 内核内存。但我们还没有在 TrustZone 内核中执行任意代码的能力。当然，我们可以在内核中找到不同的 gadget，并将它们串联起来创建所需的效果。但这样做手动操作非常繁琐（我们需要找到相当多的 gadget），而且自动化难度很大。 有几种可能的方法来解决这个问题。 一种可能的方法是在“正常世界”中编写一段代码，然后从“安全世界”跳转到它。这听起来是一个容易的方法，但实际上比说起来要困难得多。 正如在第一篇博客中提到的那样，当处理器在安全模式下运行时，也就是 SCR（安全配置寄存器）中的 NS（非安全）位关闭时，它只能执行标记为“安全”的页面。在 MMU 使用的翻译表中（也就是 NS 位关闭）。 这意味着，为了在&quot;正常世界&quot;中执行我们编写的代码块，我们首先必须修改 TrustZone 内核的转换表，以将我们编写代码的地址映射为 secure。 虽然这是可能的，但有点繁琐。 另一种方法可能是在 TrustZone 内核的代码段中编写新代码或覆盖现有代码。这也有优点，可以让我们修改内核中的现有行为，这在后面也可能很有用。 但是，乍一看，这似乎不比之前的方法更容易实现。毕竟，TrustZone 内核的代码段被映射为只读，肯定不可写。 但是，这只是一个小问题！事实上，这实际上可以通过使用 ARM MMU 的一个方便的功能 domains 来解决，而无需修改转换表。 在 ARM 转换表中，每个条目都有一个字段，用于列出其权限，以及一个指示转换所属 domain 的字段。有16个域，每个转换属于其中的一个。 在 ARM MMU 中，有一个称为 DACR（Domain Access Control Register）的寄存器。该 32 位寄存器具有 16 对位，每对位用于一个域，用于指定给定域的转换是否应该为读取访问，写入访问，两者都是或者都不是生成故障。 每当处理器尝试访问给定的内存地址时，MMU 首先检查使用给定转换的访问权限是否可以访问该地址。如果访问是允许的，则不会生成故障。 否则，MMU 检查 DACR 中对应于给定域的位是否设置。如果设置了，则抑制故障并允许访问。 这意味着简单地将 DACR 的值设置为 0xFFFFFFFF 将使 MMU 启用对任何映射的内存地址的读写访问，而不会生成故障（更重要的是，无需修改转换表）。 但是如何设置 DACR 呢？显然，在 TrustZone 内核的初始化期间，它也将显式将 DACR 的值设置为预定值（0x55555555），如下所示： 然而，我们可以简单地跳转到初始化函数中的下一个操作码，同时在 R0 中提供我们自己的值，从而导致 DACR 被设置为我们控制的值。 现在 DACR 已经设置好了，路径就都清晰了 - 我们可以简单地写入或覆盖 TrustZone 内核中的代码。 为了使事情变得更容易（并且更少受干扰），最好将代码写入 TrustZone 内核中未使用的位置。其中之一是“代码洞”。 代码洞只是未使用的区域（通常在分配的内存区域的末尾），但仍然是映射和有效的。它们通常是由于内存映射具有粒度而引起的，因此在映射段末尾通常存在内部碎片。 在 TrustZone 内核中有几个这样的代码洞，使我们能够在其中编写小段代码并执行它们，几乎没有任何麻烦。 将所有步骤整合起来 这个漏洞有点复杂。以下是我们必须完成的所有阶段的总结： 使用零写入原语禁用内存验证功能 使用 TrustZone PRNG 在受控位置制作想要的 DWORD 通过读取相应的版本代码验证制作的 DWORD 将制作的版本代码写入现有 SCM 调用函数指针的位置（这样可以创建快速写入工具） 使用快速写入工具创建读取工具 使用快速写入工具将函数指针写入一个工具，使我们能够修改 DACR 修改 DACR 以完全启用（0xFFFFFFFF） 在 TrustZone 内核中的代码洞中编写代码 执行！ 😃 代码 该漏洞的利用程序已经被开发出来了，包括了 Nexus 5（先前已经给出了指纹）所需的所有符号。 首先，为了使漏洞利用程序能够向 TrustZone 内核发送所需的制作 SCM 调用，我创建了一个修补版本的 msm-hammerhead 内核，其中添加了此类功能并将其公开给用户空间的 Android。 我选择通过向现有驱动程序 QSEECOM（在第一篇博客文章中提到）添加一些新的 IOCTL 来实现这一点，该驱动程序是用于与 TrustZone 内核进行交互的 Qualcomm 驱动程序。这些 IOCTL 使调用者能够向 TrustZone 内核发送“原始”的 SCM 调用（普通或原子），包含任意数据。 您可以在此处找到所需的内核修改。 对于使用 Nexus 5 设备的用户，我个人建议遵循 Marcin Jabrzyk 的优秀教程 - 这里（它是一个完整的教程，描述了如何编译和启动自定义内核而不将其刷到设备上）。 在使用修改后的内核启动设备后，您将需要一个用户空间应用程序，它可以使用新添加的 IOCTL 向内核发送 SCM。 我编写了这样的应用程序，您可以在此处获取。 最后，漏洞利用程序本身是用 Python 编写的。它使用用户空间应用程序通过自定义内核直接向 TrustZone 内核发送 SCM 调用，并允许在内核中执行任何任意代码。 您可以在此处找到完整的漏洞利用程序代码。 使用漏洞利用程序 使用漏洞利用程序非常简单。这是您需要执行的操作： 使用修改后的内核启动设备（请参见 Marcin 的教程） 编译 FuzzZone 二进制文件并将其放置在 /data/local/tmp/ 下 在 shellcode.S 文件中编写任何 ARM 代码 执行 build_shellcode.sh 脚本以创建 shellcode 二进制文件 执行 exploit.py 以在 TrustZone 内核中运行您的代码 影响的设备 在披露漏洞时，这个漏洞影响所有使用MSM8974 SoC的设备。我创建了一个脚本来静态检查许多这样的设备的ROM，发现以下设备是有漏洞的： 注意：此漏洞已经被高通修复，因此不应该影响当前更新的设备。同时请注意，以下列表并不是详尽无遗的，仅仅是我在当时静态分析的结果。 Samsung Galaxy S5 Samsung Galaxy S5 Samsung Galaxy Note III Samsung Galaxy S4 Samsung Galaxy Tab Pro 10.1 Samsung Galaxy Note Pro 12.2 HTC One LG G3 LG G2 LG G Flex Sony Xperia Z3 Compact Sony Xperia Z2 Sony Xperia Z Ultra Samsung Galaxy S5 Active Samsung Galaxy S5 TD-LTE Samsung Galaxy S5 Sport HTC One (E8) Oneplus One Acer Liquid S2 Asus PadFone Infinity Gionee ELIFE E7 Sony Xperia Z1 Compact Sony Xperia Z1s ZTE Nubia Z5s Sharp Aquos Xx 302SH Sharp Aquos Xx mini 303SH LG G Pro 2 Samsung Galaxy J Samsung Galaxy Note 10.1 2014 Edition (LTE variant) Samsung Galaxy Note 3 (LTE variant) Pantech Vega Secret UP Pantech Vega Secret Note Pantech Vega LTE-A LG Optimus Vu 3 Lenovo Vibe Z LTE Samsung Galaxy Tab Pro 8.4 Samsung Galaxy Round ZTE Grand S II LTE Samsung Galaxy Tab S 8.4 LTE Samsung Galaxy Tab S 10.5 LTE Samsung Galaxy Tab Pro 10.1 LTE Oppo Find 7 Qing Zhuang Ban Vivo Xshoot Elite IUNI U3 Hisense X1 Hisense X9T Pantech Vega Iron 2 (A910) Vivo Xplay 3S ZTE Nubia Z5S LTE Sony Xperia Z2 Tablet (LTE variant) Oppo Find 7a International Edition Sharp Aquos Xx304SH Sony Xperia ZL2 SOL25 Sony Xperia Z2a Coolpad 8971 Sharp Aquos Zeta SH-04F Asus PadFone S Lenovo K920 TD-LTE (China Mobile version) Gionee ELIFE E7L Oppo Find 7 ZTE Nubia X6 TD-LTE 128 GB Vivo Xshot Ultimate LG Isai FL ZTE Nubia Z7 ZTE Nubia Z7 Max Xiaomi Mi 4 InFocus M810 时间线 2014年9月19日 - 披露漏洞 2014年9月19日 - QC 初步回应 2014年9月22日 - QC 确认问题存在 2014年10月1日 - QC 向客户发布通知 2014年10月16日 - QC 向运营商发布通知，请求禁令 14 天 2014年10月30日 - 禁令到期 我想指出的是，在向高通报告此问题后，我被告知他们在我之前就已经内部识别了此问题。然而，这种问题需要相当长的时间来推动修复，因此在我的研究时，修复程序尚未部署（至少，据我所知）。 最后的话 我很想听听您的反馈，请在下面留言！如有任何问题，请随时询问。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"【译】探索高通的 TrustZone 实现","slug":"exploring-qualcomms-trustzone","date":"2023-04-29T12:20:00.000Z","updated":"2025-03-08T09:40:48.609Z","comments":true,"path":"2023/04/29/exploring-qualcomms-trustzone/","link":"","permalink":"https://blog.inoki.cc/2023/04/29/exploring-qualcomms-trustzone/","excerpt":"","text":"在本博客中，我们将探索高通在 Snapdragon SoC 上实现的 TrustZone。如果您还没有阅读之前的博客文章，我在其中详细介绍了 TrustZone。 从哪里开始？ 首先，由于高通的 TrustZone 实现是闭源的，据我所知，没有公开的文档详细说明其架构或设计，我们可能需要对包含 TrustZone 代码的二进制文件进行逆向工程和分析。 获取TrustZone映像 我们可以尝试从两个不同的位置提取映像；要么从设备本身，要么从设备的工厂映像。 我的个人 Nexus 5 设备已经获取了 root 权限，因此从设备中提取映像应该非常简单。由于映像存储在 eMMC 芯片上，而 eMMC 芯片的块和分区在“/dev/block/platform/msm_sdcc.1”下可用，我可以通过使用“dd”将相关分区复制到我的桌面。 此外，这些分区在“/dev/block/platform/msm_sdcc.1/by-name”下有有意义的命名链接。 这里有两个分区，一个名为“tz”（代表TrustZone），一个名为“tzb”，用作“tz”映像的备份映像，与其完全相同。 但是，通过这种方式提取映像后，仍然不满意，原因有两个： 虽然 TrustZone 映像存储在 eMMC 芯片上，但它可能很容易对“普通世界”（通过要求系统总线上的 AxPROT 位被设置）变得不可访问，或其中的几个部分可能会丢失。 拉取整个分区的数据并不透露有关映像实际（逻辑）边界的信息，因此需要额外的工作才能确定映像实际上的结束位置。（实际上，“tz”映像是一个 ELF 二进制文件，其大小包含在 ELF 头中，但这只是一种特殊情况）。 因此，提取了一个设备映像后，让我们看看出厂映像。 Nexus 5 的出厂映像都可以从谷歌上下载。出厂映像包含一个 ZIP 文件，其中包含所有默认映像，此外还包含引导加载程序映像。 下载出厂映像并搜索与 TrustZone 相关的字符串后，很快就可以发现引导加载程序映像包含了所需的代码。 但是，在这里仍然有一个小问题要解决 - 引导加载程序映像以一种未知的格式存储（尽管也许可以通过一些 Google 技巧找到需要的答案）。无论如何，使用十六进制编辑器打开该文件并猜测其结构后发现，该格式实际上相当简单： 引导加载程序文件的结构如下： 魔数（“BOOTLDR!”）- 8个字节。 镜像的数量 - 4个字节。 镜像数据开头相对于文件开头的偏移量 - 4个字节。 包含在镜像中的数据的总大小 - 4个字节。 一个数组，其项数与上面的“镜像数量”字段相匹配。数组中的每个条目都有两个字段：镜像名称 - 64个字节（填充为零）；镜像长度 - 4个字节。 如您在上面的图片中所看到的，引导加载程序映像包含一个名为“tz”的映像，这是我们要找的映像。为了解包此文件，我编写了一个小型 Python 脚本（在此处提供），该脚本接收引导加载程序映像并解包其中包含的所有文件。 提取映像后，将其与先前从设备中提取的映像进行比较，我验证它们确实是相同的。因此，我想这意味着我们现在可以继续检查 TrustZone 映像了。 修复 TrustZone 映像 首先，检查文件会发现它实际上是一个 ELF 文件，这是非常好的消息！这意味着内存段及其映射的地址应该对我们可用。 在使用 IDA Pro 打开文件并让自动分析运行一段时间后，我想开始反汇编文件。然而，令人惊讶的是，似乎有很多跳转到未映射地址（或者说指向不包含在“tz”二进制文件中的地址）的分支。 仔细观察后，似乎所有指向无效地址的绝对分支都位于文件的第一个代码段中，并且它们指向未映射的高地址。此外，没有绝对分支指向该第一个代码段的地址。 这似乎有些可疑…那么我们来看一下 ELF 文件的结构如何？执行 readelf 命令会显示以下内容： 有一个空段映射到一个更高的地址，实际上与无效绝对分支指向的地址范围相对应！高通的家伙们很聪明。 无论如何，我做出了一个相当安全的猜测，即第一个代码段实际上映射到错误的地址，应该实际上映射到更高的地址-0xFE840000。因此，自然地，我想使用 IDA 的重新定位功能重新定位段，但是惊奇地发现！这会导致 IDA 崩溃： 我其实不确定这是高通有意为之的反调试特性，还是 NULL 段只是他们内部构建过程的结果，但是这可以通过手动修复 ELF 文件来轻松规避。只需要将 NULL 段移动到未使用的地址（因为 IDA 会忽略它），并将第一个代码段从错误的地址（0xFC86000）移动到正确的地址（0xFE840000），如下所示： 现在，在 IDA 中加载镜像后，所有的绝对分支都有效！这意味着我们可以继续分析镜像！ 分析 TrustZone 镜像 首先，应该注意的是，TrustZone 镜像是一个相当大的（285.5 KB）二进制文件，有相当少的字符串，而且没有公开的文档。此外，TrustZone 系统是由一个完整的内核组成的，具有执行应用程序等功能，还有更多。所以…不清楚我们应该从哪里开始，因为逆转整个二进制文件可能会花费太多时间。 由于我们想从应用处理器攻击 TrustZone 内核，最大的攻击面可能是安全监控调用，它使 &quot;正常世界 &quot;能够与 &quot;安全世界 &quot;互动。 当然，应该注意的是，还有其他的载体可以让我们与 TrustZone 进行交互，比如共享内存，甚至是中断处理，但是由于这些所构成的攻击面要小得多，所以从分析 SMC 调用开始可能更好。 那么，我们如何找到 TrustZone 内核处理 SMC 调用的地方呢？首先，让我们回顾一下，当执行 SMC 调用时，与处理 SVC 调用（即&quot;正常世界&quot;中的常规系统调用）类似，&quot;安全世界&quot;必须注册向量的地址，当遇到这种指令时，处理器将跳转到该向量。 &quot;安全世界&quot;的等价物是 MVBAR（监控向量基址寄存器），它提供了包含处理器在&quot;安全世界&quot;处理不同事件的处理功能的向量地址。 访问 MVBAR 是通过 MRC/MCR 操作码完成的，其操作数如下： 因此，这意味着我们可以简单地在 TrustZone 镜像中搜索具有以下操作数的 MCR 操作码，我们应该能够找到&quot;监控向量&quot;。事实上，在 IDA 中搜索该操作码会得到以下匹配结果： 正如你所看到的，&quot;start&quot;符号（顺便说一下，它是唯一导出的符号）的地址被加载到 MVBAR 中。根据 ARM 的文档，&quot;监控向量&quot;有以下结构： 这意味着，如果我们看一下前面提到的&quot;start&quot;符号，我们可以给该表中的地址分配以下名称： 现在，我们可以分析一下 SMC_VECTOR_HANDLER 函数。实际上，这个函数负责相当多的任务；首先，它将所有的状态寄存器和返回地址保存在一个预定义的地址中（在&quot;安全世界&quot;中），然后，它将堆栈切换到一个预先分配的区域（也在&quot;安全世界&quot;中）。最后，在进行了必要的准备工作后，它继续分析用户要求的操作并根据它进行操作。 由于发布 SMC 的代码存在于 Linux 内核的高通公司 MSM 分支中，我们可以看一下&quot;正常世界&quot;可以向&quot;安全世界&quot;发布的命令格式。 SMC 和 SCM 令人困惑的是，高通公司选择将&quot;正常世界&quot;通过 SMC 操作码与&quot;安全世界&quot;互动的渠道命名为 SCM（安全通道管理器）。 总之，正如我在之前的博文中提到的，&quot;qseecom&quot;驱动程序用于使用 SCM 与&quot;安全世界&quot;进行通信。 高通公司在相关源文件中提供的文档相当广泛，足以让我们很好地掌握 SCM 命令的格式。 简而言之，SCM 命令可分为两类之一： 常规 SCM 调用 当有信息需要从&quot;正常世界&quot;传递到&quot;安全世界&quot;时，就会使用这些调用，这些信息需要为 SCM 调用服务。内核填充了以下结构： 而 TrustZone 内核在为 SCM 调用提供服务后，将响应写回&quot;scm_response&quot;结构中： 为了分配和填充这些结构，内核可以调用包装函数 “scm_call”，它接收指向内核空间缓冲区的指针，这些缓冲区包含要发送的数据，数据应该被返回的位置，以及最重要的，服务标识符和命令标识符。 每个 SCM 调用都有一个&quot;类别&quot;，这意味着哪个 TrustZone 内核子系统负责处理该调用。这是由服务标识符表示的。命令标识符是一个代码，它指定了在一个给定的服务中，哪个命令被请求。 在&quot;scm_call&quot;函数分配和填充&quot;scm_command&quot;和&quot;scm_response&quot;缓冲区之后，它调用一个内部的&quot;__scm_call&quot;函数，它刷新所有的缓冲区（内部和外部缓冲区），并调用&quot;smc&quot;函数。 这最后一个函数实际上是执行 SMC 操作码，将控制权转移到 TrustZone 内核，像这样： 注意，R0 被设置为 1，R1 被设置为指向本地内核堆栈地址，它被用作该调用的&quot;上下文 ID&quot;，R2 被设置为指向分配的&quot;scm_command&quot;结构的物理地址。 这个设置在 R0 中的&quot;魔法&quot;值表明这是一个常规的 SCM 调用，使用&quot;scm_command&quot;结构。然而，对于某些需要较少数据的命令，无缘无故地分配所有这些数据结构是相当浪费的。为了解决这个问题，引入了另一种形式的 SCM 调用。 原子 SCM 调用 对于参数数量相当少的调用（最多四个参数），存在另一种请求 SCM 调用的方式。 有四个包装函数，“scm_call_atomic_[1-4]”，它们与请求的参数数量相对应。这些函数可以被调用，以便直接发出一个 SMC，用给定的服务和命令 ID，以及给定的参数进行 SCM 调用。 下面是&quot;scm_call_atomic1&quot;函数的代码： 其中 SCM_ATOMIC 被定义为： 注意，服务 ID 和命令 ID 都被编码到 R0 中，同时还有调用中的参数数（在本例中是 1）。这取代了以前用于常规 SCM 调用的&quot;神奇&quot;的 1 值。 R0 中的这个不同的值向 TrustZone 内核表明，下面的 SCM 调用是一个原子调用，这意味着参数将使用 R2-R5 传递（而不是使用 R2 指向的结构）。 分析 SCM 调用 现在我们已经了解了 SCM 调用的工作原理，并且找到了 TrustZone 内核中用于处理这些 SCM 调用的处理函数，我们可以开始反汇编 SCM 调用，试图在其中找到一个漏洞。 我将跳过对 SCM 处理函数的大部分分析，因为它的大部分是对用户输入的模板处理，等等。然而，在将堆栈切换到 TrustZone 区域并保存执行调用的原始寄存器后，处理函数继续处理服务 ID 和命令 ID，以确定应该调用哪个内部处理函数。 为了方便服务和命令 ID 与相关处理函数之间的映射，一个静态列表被编译到 TrustZone 镜像的数据段，并被 SCM 处理函数引用。下面是该列表的一个简短片段： 正如你所看到的，该列表有以下结构： 指向包含 SCM 函数名称的字符串的指针 调用的&quot;类型&quot; 指向处理函数的指针 参数的数量 每个参数的大小（每个参数有一个 DWORD）。 服务 ID 和命令 ID，串联成一个 DWORD - 例如，上面的&quot;tz_blow_sw_fuse&quot;函数，其类型为 0x2002，这意味着它属于服务 ID 0x20，其命令 ID 为 0x02。 现在剩下的就是开始拆解这些函数，并希望能找到一个可利用的错误。 漏洞! 因此，在仔细研究了上述所有的 SMC 调用（全部 69 个）后，我终于找到了以下函数： 通常情况下，当使用常规的 SCM 调用机制调用 SCM 命令时，R0 将包含&quot;结果地址&quot;，它指向由内核分配的&quot;scm_response&quot;缓冲区，但它也被 TrustZone 内核验证，以确保它实际上是一个 &quot;允许&quot;范围内的物理地址，也就是说，一个对应于 Linux 内核内存的物理地址，而不是，例如，TrustZone 二进制中的内存位置。 这个检查是通过一个内部函数进行的，我将在下一篇博文中详细介绍（请继续关注！）。 但是，如果我们使用一个原子的 SCM 调用来执行一个函数，会发生什么？在这种情况下，使用的&quot;结果地址&quot;是原子调用所传递的第一个参数。 现在–你能看到上面这个函数中的错误吗？ 相对于其他 SCM 处理函数，这个函数未能验证 R0 中的值，即&quot;结果地址&quot;，所以如果我们传入 R1为非零值（为了传递第一个分支） 第四个参数（在上面 var_1C 处传入）为非零值 R0 为任何物理地址，包括 TrustZone 地址空间范围内的一个地址 该函数将到达上述函数中最左边的分支，并在 R0 包含的地址处写入一个DWORD 0。 负责任的披露 我想指出的是，我已经在 11 个月前向高通公司负责任地披露了这个漏洞，而且这个问题已经被他们修复了（速度快得惊人！）。我将在下一篇博文中分享详细的时间表和解释，但我想指出的是，高通公司的人反应非常迅速，与他们合作非常愉快。 下一步是什么？ 在下一篇博文中，我将分享一个针对上述漏洞的详细（而且相当复杂！）的利用方法，它可以在 TrustZone 内核内执行全部代码。我还会公布完整的漏洞代码，敬请关注 另外，由于这只是我的第二篇博文，我真的希望得到一些（任何）意见，特别是： 我应该多写（或少写）些什么？ 博客设计问题 研究思路 😃","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"【译】在任何上下文中进行 TrustZone 内核中的任意代码执行","slug":"getting-arbitrary-code-execution-in","date":"2023-04-29T11:20:00.000Z","updated":"2025-03-08T09:40:48.609Z","comments":true,"path":"2023/04/29/getting-arbitrary-code-execution-in/","link":"","permalink":"https://blog.inoki.cc/2023/04/29/getting-arbitrary-code-execution-in/","excerpt":"","text":"在本篇博客中，我们的目标是使用 TrustZone 内核代码执行漏洞超越 Android。 这将是一系列博客文章，详细介绍我发现的一系列漏洞，使我们能够从任何用户提升特权，直到最高特权——在 TrustZone 中执行我们的代码。 由于我只有一台个人 Android 设备，一台由 Snapdragon 800 SoC 驱动的 Nexus 5，因此我将重点关注我的设备上存在的 TrustZone 平台—— Qualcomm 的 TrustZone 实现。 应该注意到，Qualcomm 的 TrustZone 平台存在于由 Qualcomm SoC 驱动的所有设备上，但是他们也允许 OEM 对该平台进行修改和添加，我将在以后的博客文章中详细介绍。 此外，我相信客观地说，Qualcomm 的 TrustZone 实现是一个很好的目标，因为 Snapdragon SoC 非常普遍，可以在非常广泛的设备中找到（这并不奇怪，考虑到 Qualcomm 在智能手机芯片组市场上有非常大的市场份额）。 Android 和安全性 多年来，Android 已经增加了许多安全机制，并改进了现有机制。 尽管基础安全体系结构没有改变，但在现代设备上，现有的防御措施已经变得非常强大，以至于获得高特权可能成为一项相当困难的任务，往往需要多个漏洞。 如果您还没有阅读过 Google 的“Android 安全概述”，我建议您阅读一下，其中解释了安全架构并列出了目前使用的大多数安全机制。 （对于本系列博客文章，我将假定您至少对 Android 的安全架构有一定的了解）。 什么是 TrustZone？ TrustZone 是一种系统范围的安全性解决方案，适用于手持设备、平板电脑、可穿戴设备和企业系统等多种计算平台。该技术的应用范围非常广泛，包括支付保护技术、数字版权管理、BYOD 以及许多安全企业解决方案。 简而言之，TrustZone 是一个旨在实现目标设备上的“安全执行”的系统。 为了执行安全的 TrustZone 代码，需要指定一个特定的处理器。该处理器可以执行非安全代码（在“Normal World”中）和安全代码（在“Secure World”中）。其他所有处理器仅能运行在“Normal World”。 在 Android 设备上，TrustZone 用于各种不同的目的，例如： 验证内核完整性（TIMA） 使用硬件凭证存储（被“keystore”、“dm-verity”使用） 移动支付的安全元素仿真 实现和管理安全启动 DRM（例如 PlayReady） 访问平台硬件功能（例如硬件熵） 为了保护整个系统而不仅仅是应用程序处理器，当进入“Secure World”时，在系统总线上设置特定位，返回“Normal World”时取消设置这些位。外围设备可以访问这些位的状态，从而可以推断出我们当前是否正在安全世界中运行。 TrustZone 的安全模型是如何工作的 ARM 还提供了一个简短的 TrustZone 安全模型技术概述，值得一读。 要实现安全执行，需要定义 TrustZone 与非 TrustZone 代码之间的边界。这可以通过定义两个“世界” -“Secure World”（TrustZone）和“Normal World”（在我们的情况下为 Android）来实现。 如您所知，在“Normal World”中，运行在“User-mode”和运行在“Supervisor-mode”（Kernel-mode）中的代码之间存在一个安全边界。 不同模式之间的区别由当前程序状态寄存器（CPSR）管理： 在 TrustZone 中，一个特定的处理器执行安全代码，并且系统总线上特定位的状态决定我们当前是否正在安全世界中运行。 以上图像中标记为&quot;M&quot;的五个模式位（mode bits）控制当前的执行模式。在 Linux 内核的情况下，用户模式（User Mode，b10000）用于普通用户代码，而 Supervisor 者模式（Supervisor Mode，b10011）用于内核代码。 然而，这里缺少了一些东西 - 没有一个位来指示当前活动的“世界”。这是因为有一个单独的寄存器用于这个目的 - 安全配置寄存器（Secure Configuration Register，SCR）： 这个寄存器是一个协处理器寄存器，位于 CP15 c1，这意味着可以使用 MRC / MCR 操作码来访问它。 与 CPSR 寄存器一样，“Normal World”不能直接修改 SCR 寄存器。然而，它可以执行 SMC 操作码，这相当于普通 Supervisor 模式调用的 SWI。SMC 是 Supervisor Mode Call 的缩写，是可用于直接向 TrustZone 内核发出请求的操作码。 此外，需要注意的是，SMC 操作码只能从 Supervisor 上下文中调用，这意味着常规用户代码无法使用 SMC 操作码。 为了实际调用 TrustZone 相关功能，Supervisor 的代码，即我们的 Linux 内核，必须注册某种服务，以便在需要时调用相关的 SMC 调用。 在 Qualcomm 的情况下，这是通过一个名为 qseecom 的设备驱动程序来实现，该缩写代表 Qualcomm 安全执行环境通信。稍后的博客文章中我们会更详细地谈论这个驱动程序，敬请关注。 综合起来 因此，要从没有权限的用户模式 Android 应用程序中获得 TrustZone 代码执行，我们需要以下特权升级漏洞： 从没有权限的 Android 应用程序升级到拥有特权的 Android 用户。 从特权的 Android 用户升级到 Linux 内核中的代码执行。 从 Linux 内核升级到 TrustZone 内核中的代码执行。 因此，如果您对此感兴趣，请继续阅读！ 在下一篇博客文章中，我将介绍更多关于 Qualcomm 的 TrustZone 实现的细节，以及我在其内核中发现和利用的漏洞。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"【译】解锁摩托罗拉的引导程序","slug":"unlocking-motorola-bootloader","date":"2023-04-25T11:20:00.000Z","updated":"2025-03-08T09:40:48.611Z","comments":true,"path":"2023/04/25/unlocking-motorola-bootloader/","link":"","permalink":"https://blog.inoki.cc/2023/04/25/unlocking-motorola-bootloader/","excerpt":"","text":"在本篇博客中，我们将探讨最近高通骁龙设备上的摩托罗拉引导程序。我们的目标是使用上一篇博客中的 TrustZone 内核代码执行漏洞，解锁 Moto X（第二代）的引导程序。请注意，虽然我们将展示特定设备的完整解锁过程，但它应该足够通用，至少适用于大多数现代摩托罗拉设备。 为什么是摩托罗拉？ 在向高通报告上一个 TrustZone 内核特权升级后，他们送了我一部全新的 Moto X。然而…有一个小问题-他们不小心把一个锁定的设备送给了我。这是一个完全诚实的错误，他们确实多次提供解锁设备的服务-但这有什么乐趣呢？因此，让我们深入摩托罗拉的引导程序，看看解锁它需要什么。 铺垫 在我们开始研究之前，让我们先简单介绍引导过程，从设备通电开始。 首先，执行 PBL（主引导程序），也称为“BootROM”。由于 PBL 存储在内部 ROM 中，因此无法修改或分配，因此它是设备的固有部分。因此，它只能实现让设备引导，并验证和加载引导链的下一部分的最小要求。 然后，加载两个次要引导程序，SBL1（次级引导程序），然后是 SBL2。它们的主要职责是启动 SoC 上的各种处理器并配置它们，使其准备好操作。 引导链的下一步是加载第三个也是最后一个次级引导程序，SBL3。这个引导程序除了其他任务外，还验证并加载 Android Bootloader-“aboot”。 现在这就是我们与解锁相关的部分了；Android Bootloader 是负责加载 Android 操作系统并触发其执行的软件部件。 这也是 OEM 的引导链部分，主要是因为在引导链的第一部分由 Qualcomm 编写并处理 SoC 特定内容的同时，Android bootloader 可用于配置加载 Android OS 的方式。 由 aboot 控制的功能之一是“引导加载程序锁定”-换句话说，aboot 是引导链中第一个可以选择打破信任链（每个引导程序阶段都验证下一个）并加载未签名操作系统的部件。 对于可解锁引导程序的设备，解锁过程通常通过将设备重新启动到特殊的（“引导程序”）模式，并发出相关的快速引导命令来执行。然而，正如我们将在后面看到的，此接口也由 aboot 处理。这意味着 aboot 不仅在常规引导过程中查询锁定状态，而且还拥有负责实际解锁过程的代码。 你可能知道，不同的 OEM 在这个问题上有不同的立场。简单来说，“Nexus”设备始终带有“可解锁”的引导加载程序。相比之下，三星不允许大多数设备的引导加载程序解锁。其他 OEM，包括摩托罗拉，会锁定他们的设备，但某些被视为“合格”的设备可以使用 OEM 提供的“魔法”（签名）令牌进行解锁（尽管这也会使大多数设备的保修失效）。 所以…这一切都非常复杂，但也不重要。因为我们将手动完成整个过程——如果 aboot 可以控制设备的锁定状态，那么这意味着我们应该也能够在提升了足够的特权级别后完成解锁过程。 现在，我们已经对涉及的组件和目标有了一个总体了解，下一步是分析实际的 aboot 代码。 起点 由于所有引导链各阶段的二进制文件都包含在出厂固件映像中，因此这自然是一个好的起点。有几个下载链接可用 - 这里是一些。如果您想跟随我进行操作，我将引用版本“ATT_XT1097_4.4.4_KXE21.187-38”中的符号。 下载固件映像后，我们面临着第一个挑战 - 所有映像都使用专有格式打包在名为“motoboot.img”的文件中。但是，在十六进制编辑器中打开文件会显示它具有一个我们可以推断出的相当简单的格式： 正如上面所述，所需的 aboot 映像存储在该文件中，该文件还包括 TrustZone 映像和各种启动链阶段。好的。 经过上面的结构分析，我编写了一个 Python 脚本，可以用于从给定的 Motorola 引导加载程序映像中解压缩所有映像，你可以在这里找到它。 无关紧要的事情 我们将从检查 aboot 映像开始。令人沮丧的是，它的大小为 1MB，所以完全检查它是浪费时间。然而，正如我们上面所提到的，当将设备引导到特殊的“引导加载程序”模式时，实际与用户交互的是 aboot 本身。这意味着我们可以从搜索开始执行解锁过程后显示的字符串-并从那里继续。 短暂地搜索“unlock…”字符串（在启动解锁过程后打印），将我们直接带到处理解锁逻辑的函数（@0xFF4B874）： 正如你所看到的，打印完字符串到控制台之后，连续调用了三个函数，如果它们都成功，则认为设备已经解锁。 仔细研究后两个函数的作用，我们可以发现它们的目的是擦除用户数据分区（在解锁引导程序后总是会执行，以保护设备所有者的隐私）。不管怎样，这意味着它们与解锁过程本身无关，只是附带效果。 这让我们剩下一个单独的函数，调用它应该可以解锁引导程序。 那么这是否意味着我们已经完成了？我们可以直接调用这个函数来解锁设备吗？ 实际上，还没有。尽管 TrustZone 漏洞允许我们在 TrustZone 内核中实现代码执行，但这只是在操作系统加载后完成的，此时直接执行引导程序代码可能会引起各种副作用（例如，代码可能假定没有操作系统/ MMU 可能被禁用等）。而且即使真的很简单，也可能通过完全理解锁定机制本身来学习一些有趣的东西。 无论如何，如果我们可以理解代码背后的逻辑，我们可以简单地模拟它，从我们的 TrustZone 漏洞中执行其有意义的部分。分析解锁函数揭示了一个令人惊讶的简单的高级逻辑： 很遗憾，这两个函数会在 IDA 中造成严重后果（它甚至无法为它们显示一个有意义的调用图）。 手动分析这些函数发现它们实际上非常相似。它们都没有太多的逻辑，而是准备参数并调用以下函数： 这有点令人惊讶 - 这个函数并没有处理逻辑本身，而是通过 SMC（Supervisor Mode Call）来调用一个 TrustZone 系统调用，从而在 aboot 本身中调用它！（正如我们在先前的博客文章中讨论的那样）。在这种情况下，这两个函数都使用请求代码 0x3F801 发出 SMC。以下是每个函数的相关伪代码： 很好，我们现在已经从 aboot 中获取了所有需要的信息，现在让我们切换到 TrustZone 内核，找出这个 SMC 调用的作用。 请进 TrustZone 现在我们已经确认了使用命令代码 0x3F801 发出 SMC 调用，我们需要找到这个命令在 TrustZone 内核中的位置。 浏览TrustZone内核系统调用时，我们找到了以下入口： 这是一个非常庞大的函数，根据提供的第一个参数执行各种不同的任务，我们从现在开始将其称为“命令代码”。 需要注意的是，还传递了一个附加标志到这个系统调用中，用于指示它是否从“安全”上下文中调用。这意味着如果我们尝试从 Android OS 本身调用它，将传递一个标记来标记我们的调用是不安全的，并且将阻止我们自己执行这些操作。当然，我们可以使用我们的 TrustZone 漏洞绕过此限制，但我们稍后再详细说明！ 如上所述，使用命令代码＃1和＃2触发了这两次 SMC 调用（我已经注释了下面的函数以提高可读性）： 简单来说，我们可以看到这两个命令都用于读取和写入（分别）来自称为“QFuse”的内容。 QFuses 就像现实中的保险丝一样，QFuse 是一种硬件组件，用于实现“一次可写”的内存。每个保险丝表示一个位；未受损的保险丝表示位零，“烧断”的保险丝表示位一。但是，正如其名称所示，此操作是不可逆的 - 一旦保险丝被“烧断”，它就无法“未烧断”。 每个 SoC 都有自己的 QFuse 布置，每个都具有自己独特的目的。某些保险丝在设备出货时已经烧断，但其他保险丝可能会根据用户的操作而被烧断，以更改特定设备功能的方式。 不幸的是，关于每个保险丝的作用的信息不是公开的，因此我们只能反向分析各种软件组件，以尝试推断它们的作用。 在我们的情况下，我们调用特定的函数来决定要读取和写入的保险丝： 既然我们使用第二个系统调用参数（在我们的情况下为“4”）来调用此函数，这意味着我们将操作地址为 0xFC4B86E8 的 QFuse。 把所有的东西放在一起 现在我们了解了 aboot 和 TrustZone 逻辑，我们可以将它们结合起来得到完整的流程： 首先，aboot 调用 SMC 0x3F801，并使用命令码＃1，这会导致 TrustZone 内核读取并返回地址 0xFC4B86E8 处的 QFuse。 然后，仅当 QFuse 中的第一个位被禁用时，aboot 再次调用 SMC 0x3F801，这次使用命令码＃2，这会导致 TrustZone 内核将值 1 写入上述 QFuse 的 LSB。 结果证明，一切都很简单 - 我们只需要设置单个 QFuse 中的一个位，引导加载程序就会被视为解锁。 但是如何编写 QFuses？ DIY QFuses 幸运的是，TrustZone 内核暴露了一对系统调用，允许我们读取和写入受限制的一组 QFuse - 分别为 tzbsp_qfprom_read_row 和 tzbsp_qfprom_write_row。如果我们可以利用我们的 TrustZone 漏洞解除这些限制，我们应该能够使用此 API 来创造想要的 QFuse。 让我们看看 tzbsp_qfprom_write_row 系统调用中的这些限制： 因此，首先必须将地址 0xFE823D5C 处的 DWORD 设置为 0，才能继续执行函数的逻辑。通常情况下，此标志实际上设置为 1，从而防止使用 QFuse 调用，但是我们可以使用 TrustZone 漏洞轻松地覆盖该标志。 然后，还有一个附加函数被调用，用于确保被写入的保险丝范围是“允许”的： 正如我们所看到的，这个函数遍历了一个静态列表，其中每个元素都表示允许的 QFuse 的起始地址和结束地址。这意味着为了通过这个检查，我们可以覆盖这个静态列表，将所有 QFuse 包括进去（将起始地址设置为零，将结束地址设置为最大的 QFuse 相对地址 - 0xFFFF）。 尝试一下 既然我们已经弄清楚了一切，现在是时候自己试试了！我写了一些代码，实现了以下功能： 在 TrustZone 中实现代码执行 禁用 QFuse 保护 在 QFuse 0xFC4B86E8 中写入 LSB QFuse 在这里查看代码：https://github.com/laginimaineb/Alohamora 最后想法 在本博客文章中，我们介绍了由单个 QFuse 控制的流程。但是，您可能可以猜到，还有许多不同的有趣 QFuse 正在等待被发现。 一方面，烧断保险丝确实很“危险” - 一旦出现小错误，就会永久砖化设备。另一方面，一些保险丝可能会促进一组特殊功能，我们希望启用这些功能。 一个这样的例子是“工程”保险丝；此保险丝在整个 aboot 映像中都有提到，可以用于启用令人惊叹的功能，例如跳过安全启动、加载未签名的外围映像、拥有未签名的 GPT 等等。 然而，此保险丝在所有消费设备上都已经烧断，标记设备为“非工程师”设备，并禁用这些功能。但是谁知道，也许还有其他同样重要的保险丝尚未被发现…","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"Android Bootloader and Linux Internal based on Nokia 8(NB1) —— Device Tree","slug":"android-bootloader-linux-nokia-nb1-dt","date":"2022-05-09T20:48:00.000Z","updated":"2025-03-08T09:40:48.608Z","comments":true,"path":"2022/05/09/android-bootloader-linux-nokia-nb1-dt/","link":"","permalink":"https://blog.inoki.cc/2022/05/09/android-bootloader-linux-nokia-nb1-dt/","excerpt":"","text":"Context: I am working on porting Plasma Mobile and EDK II to my Nokia 8 (codename: NB1) device. There are many things to do and to learn. In this post, I want to write down what I have learnt from the ABL Bootloader and the Linux kernel, about how the Device Tree(DT, which describes the periphicals in an embedded device) is processed by the ABL and the kernel. Introduction The Nokia 8 device(and its successor Nokia 8 Sirocco) uses the MSM8998 SoC platform(or say Qualcomm 835) as a base. In fact, its company HMD just owns the Nokia trademark for mobile phone manufacture. The main design and development is by FIH Mobile, which is a subsidiary of Foxconn. So, we will say some modules named by the FIH in this post. The model that I own is marked as “Qualcomm Technologies, Inc. MSM8998 v2.1 MTP, FIH NB1 PVT1 SS” in the DT. However, there are many DTs that are appended to the kernel, where it also has the ones for A1N(Nokia 8 Sirocco) and the evaluation version of these devices. These result in more than 80 different DTs, even including the different versions of MSM8998. So, I wonder how the DT is actually choosed, by the Linux kernel, or by the Bootloader. And in which stage, during the early stage, the XBL or the ABL? At very first, I thought that the DTs are appended to the kernel, so that the Bootloader(s) will not get involved very deeply. The best DT might be found and choosed by the kernel. However, I found that it is the ABL which is in charge of choosing, fixing and patching the DT after studying. Although the device is kind of outdated, this page talking about “Using Mutiple DTs” from Android documentation might be still helpful for someone. DT loading in ABL Bootloader In my previous posts such as Android bootloader analysis – ABL(1), I analyse the Bootloader in a coarse-grained manner. As mentioned in Android bootloader analysis – Aboot, ABL is actually an EFI application that loaded by the XBL. The application is a module named after LinuxLoader, which is in charge of loading Linux kernel and the related entities in an ABoot(Android Boot) image. DT in LinuxLoader EFI application As mentioned in Android bootloader analysis – ABL(1), the EFI application entry is declared in QcomModulePkg/Application/ LinuxLoader/LinuxLoader.inf, as LinuxLoaderEntry. The application can either boot into Android fastboot mode, or boot into Linux kernel(normal boot or recovery). Normally, the ABL loads the image in the boot partition, in which the ANDROIDBOOT format image is used. The image usually contains a kernel and a ramdisk for basic initialization. Depending on the devices, the DTs can be appended to the kernel or stored in a standalone partition: My Nokia 8 uses the first solution. And there are many DTs. So, before booting, the Bootloader needs to purge them. If the image is validated, BootLinux (&amp;Info) is called to actually try to process the image so as to boot it. In that function, DTBImgCheckAndAppendDT is called to choose the best DT and append it to the kernel. To do this, DeviceTreeAppended in QcomModulePkg/Library/BootLib/LocateDeviceTree.c is called. It checks all the possible DTs from the begin address of the appended DT, to the kernel end. For each DT, the DeviceTreeCompatible is called to find the best DT. The standard matching process contains the retrievals of qcom,msm-id, qcom,board-id and qcom,pmic-id properties in the DT. There is a special structure to describe such information from the hardware: 12345678910111213typedef struct DtInfo &#123; UINT32 DtPlatformId; UINT32 DtSocRev; UINT32 DtFoundryId; UINT32 DtVariantId; UINT32 DtVariantMajor; UINT32 DtVariantMinor; UINT32 DtPlatformSubtype; UINT32 DtPmicModel[MAX_PMIC_IDX]; UINT32 DtPmicRev[MAX_PMIC_IDX]; UINT64 DtMatchVal; VOID *Dtb;&#125; DtInfo; The matching process is as follows: 12345678910111213141516171819202122232425if (CurDtbInfo-&gt;DtMatchVal &amp; BIT (ExactMatch)) &#123; if (BestDtbInfo-&gt;DtMatchVal &lt; CurDtbInfo-&gt;DtMatchVal) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); FindBestMatch = TRUE; &#125; else if (BestDtbInfo-&gt;DtMatchVal == CurDtbInfo-&gt;DtMatchVal) &#123; FindBestMatch = TRUE; if (BestDtbInfo-&gt;DtSocRev &lt; CurDtbInfo-&gt;DtSocRev) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else if (BestDtbInfo-&gt;DtVariantMajor &lt; CurDtbInfo-&gt;DtVariantMajor) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else if (BestDtbInfo-&gt;DtVariantMinor &lt; CurDtbInfo-&gt;DtVariantMinor) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else if (BestDtbInfo-&gt;DtPmicRev[0] &lt; CurDtbInfo-&gt;DtPmicRev[0]) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else if (BestDtbInfo-&gt;DtPmicRev[1] &lt; CurDtbInfo-&gt;DtPmicRev[1]) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else if (BestDtbInfo-&gt;DtPmicRev[2] &lt; CurDtbInfo-&gt;DtPmicRev[2]) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else if (BestDtbInfo-&gt;DtPmicRev[3] &lt; CurDtbInfo-&gt;DtPmicRev[3]) &#123; gBS-&gt;CopyMem (BestDtbInfo, CurDtbInfo, sizeof (struct DtInfo)); &#125; else &#123; FindBestMatch = FALSE; &#125; &#125;&#125; However, for different models of Nokia 8, they do share the same msm information because they are using the same platform and the same board, which are: 12compatible = &quot;qcom,msm8998-mtp&quot;, &quot;qcom,msm8998&quot;, &quot;qcom,mtp&quot;;qcom,board-id = &lt;8 0&gt;, &lt;1 0&gt;; I found, by mysterious way, that my phone uses a special fih,hw-id field to find the correct DT. I will discuss this later. Finally, a pointer named tags is returned and be passed as the actual DT to the kernel. FIH modules As aforementioned, there is a special fih,hw-id field in addition to qcom,board-id and compatible fields to match the DT in the ABL Bootloader. Such id is stored in a special memory area, which is also declared as reseved memory in the DT: 12345fih_mem: fih_region@a0000000 &#123; /* for FIH feature */ compatible = &quot;removed-dma-pool&quot;; no-map; reg = &lt;0 0xa0000000 0 0xb00000&gt;;&#125;; We can see that the memory region starts at 0xa0000000 and has a size of 0xb00000. The detailed information is not accessible here because the XBL seems not to be open-sourced. However, when I unpacked the XBL from the factory image, I saw there are FIHDxe EFI driver and FIHHWIDApp to load the hardware id into the EFI environment. So that, the LinuxLoader EFI application can eventually read the information and match the DT. I cannot provide more details because the reverse-engineering is performed. But the address to store the hardware id is 0x000160f1 in the EFI environment under my 5150 image. It is written by the FIHHWIDApp using the methods provided by the FIHDxe. Anyway, the DT choosed by my device is with: 1234model = &quot;Qualcomm Technologies, Inc. MSM8998 v2.1 MTP, FIH NB1 PVT1 SS&quot;;compatible = &quot;qcom,msm8998-mtp&quot;, &quot;qcom,msm8998&quot;, &quot;qcom,mtp&quot;;qcom,board-id = &lt;8 0&gt;, &lt;1 0&gt;;fih,hw-id = &lt;1 7 4&gt;; in which I guess that it is a Product version 1, with Single Slot. This DT is finally the only DT passed to the Linux kernel. DT processing in Linux kernel In ARM64, when kernel is loaded and executed, the address pointing to DT is passed in X5 register. The first executable code is from arch/arm64/kernel/head.S, where we can see the device hardware initialization and the Flatten DT(FDT) pointer is saved from X5 register to __fdt_pointer: 1str_l x21, __fdt_pointer, x5 // Save FDT pointer It is a physical address in arch/arm64/kernel/setup.c: 1phys_addr_t __fdt_pointer __initdata; where __initdata indicates that it should be stored in a special section for data used during initialization. The head.S does not do many things and then just passes the control(without return) to start_kernel function. This function is usually generic for all platforms, which performs Linux initialization step-by-step. The DT-related function calls are as follows: 123setup_arch(&amp;command_line);rest_init(); where setup_arch is definitly platform-related and architecture-related. And after all initializations are finished, the rest part (non-essential) of the kernel needs to be initialized. DT in architecture-related setup Each platform/architecture has its own setup function. The one for ARM64 is arch/arm64/kernel/setup.c. It first print the CPU information(the information is visualized in dmesg) and establish the mappings of virtual addresses: 123pr_info(\"Boot CPU: AArch64 Processor [%08x]\\n\", read_cpuid_id());early_fixmap_init();early_ioremap_init(); Then the boot-related functions are: 12345678910111213setup_machine_fdt(__fdt_pointer);// ...efi_init();// .../* Parse the ACPI tables for possible boot-time configuration */acpi_boot_table_init();// ...if (acpi_disabled) &#123; unflatten_device_tree(); psci_dt_init();&#125; else &#123; psci_acpi_init();&#125; Note that both the DT and the EFI-ACPI boot modes are supported. In our case, we only consider the DT mode. So, the topic remains on setup_machine_fdt, and the unflatten_device_tree, psci_dt_init when acpi_disabled is true. ARM64 Machine FDT setuping The setup_machine_fdt accepts a DT pointer. Note that now the DT has been chosen by the ABL, so we are safe to load and verify the only DT. 123456789101112131415161718192021static void __init setup_machine_fdt(phys_addr_t dt_phys)&#123; void *dt_virt = fixmap_remap_fdt(dt_phys); if (!dt_virt || !early_init_dt_scan(dt_virt)) &#123; pr_crit(\"\\n\" \"Error: invalid device tree blob at physical address %pa (virtual address 0x%p)\\n\" \"The dtb must be 8-byte aligned and must not exceed 2 MB in size\\n\" \"\\nPlease check your bootloader.\", &amp;dt_phys, dt_virt); while (true) cpu_relax(); &#125; machine_name = of_flat_dt_get_machine_name(); if (machine_name) &#123; dump_stack_set_arch_desc(\"%s (DT)\", machine_name); pr_info(\"Machine: %s\\n\", machine_name); &#125;&#125; It first get the virtual address of FDT from the physical address using the memory mapping. Then, perform a basic scan to validate the DT(early_init_dt_scan in drivers/of/fdt.c). At the end, the machine name is gotten and printed, which can also be seen in dmesg. FDT processing Then, the FDT is parsed in unflatten_device_tree() to construct a tree of device_nodes, which can be used to probe the peripherals. The first use is to discover the Power State Coordination Interface(PSCI) in psci_dt_init(). The interface should be compatible with one of the following values: 123&#123; .compatible = &quot;arm,psci&quot;, .data = psci_0_1_init&#125;,&#123; .compatible = &quot;arm,psci-0.2&quot;, .data = psci_0_2_init&#125;,&#123; .compatible = &quot;arm,psci-1.0&quot;, .data = psci_0_2_init&#125; Kernel can use the similar way to discover other devices. DT processing in sysfs In an ARM Linux with sysfs, we can usually see the devicetree node and the fdt node under /sysfs/firmware directory. These nodes are actually the visualization of the corresponding kernel objects. The Linux kernel just adds them into the kernel object sets. Such function is implemented in rest_init. The kernel runs a kernel thread to start the non-critical initilization part of the kernel: 1kernel_thread(kernel_init, NULL, CLONE_FS); The kernel_init executes kernel_init_freeable and then run the init command. The command can be passed from the kernel commanline in ramdisk_execute_command or execute_command. Otherwise, the kernel will try /sbin/init, /etc/init, /bin/init and /bin/sh. If this still fails, the kernel is in panic. In kernel_init_freeable, the kernel still calls many function. The do_basic_setup and then driver_init are associated to the DT processing in sysfs. The driver_init calls several functions to initialize the different parts as follows: 12345678910111213141516/* These are the core pieces */devtmpfs_init();devices_init();buses_init();classes_init();firmware_init();hypervisor_init();/* These are also core pieces, but must come after the * core core pieces. */platform_bus_init();cpu_dev_init();memory_dev_init();container_dev_init();of_core_init(); In firmware_init, the firmware_kobj is created to host the firmware-related kernel objects: 1234567int __init firmware_init(void)&#123; firmware_kobj = kobject_create_and_add(\"firmware\", NULL); if (!firmware_kobj) return -ENOMEM; return 0;&#125; At the end, of_core_init creates /sys/firmware/devicetree and the nodes under the tree: 1234567891011121314151617181920void __init of_core_init(void)&#123; struct device_node *np; /* Create the kset, and register existing nodes */ mutex_lock(&amp;of_mutex); of_kset = kset_create_and_add(\"devicetree\", NULL, firmware_kobj); if (!of_kset) &#123; mutex_unlock(&amp;of_mutex); pr_err(\"devicetree: failed to register existing nodes\\n\"); return; &#125; for_each_of_allnodes(np) __of_attach_node_sysfs(np); mutex_unlock(&amp;of_mutex); /* Symlink in /proc as required by userspace ABI */ if (of_root) proc_symlink(\"device-tree\", NULL, \"/sys/firmware/devicetree/base\");&#125; In addtion, late_initcall(of_fdt_raw_init) in driver/of/fdt.c can create the /sys/firmware/fdt to host the FDT binary contents: 12345678910111213141516static int __init of_fdt_raw_init(void)&#123; static struct bin_attribute of_fdt_raw_attr = __BIN_ATTR(fdt, S_IRUSR, of_fdt_raw_read, NULL, 0); if (!initial_boot_params) return 0; if (of_fdt_crc32 != crc32_be(~0, initial_boot_params, fdt_totalsize(initial_boot_params))) &#123; pr_warn(\"fdt: not creating '/sys/firmware/fdt': CRC check failed\\n\"); return 0; &#125; of_fdt_raw_attr.size = fdt_totalsize(initial_boot_params); return sysfs_create_bin_file(firmware_kobj, &amp;of_fdt_raw_attr);&#125; If we search the firmware_kobj, there are also many other firmware types that can be initialized, such as: EFI kobject_create_and_add(&quot;efi&quot;, firmware_kobj); under drivers/firmware/efi/efi.c ACPI kobject_create_and_add(&quot;efi&quot;, firmware_kobj); under drivers/acpi/bus.c DMI kobject_create_and_add(&quot;dmi&quot;, firmware_kobj); under drivers/firmware/dmi_scan.c which are common for EFI system. For those who are intrested in EFI and ACPI, there are some function calls during kernel init: 123456789acpi_early_init();/* ... */acpi_subsystem_init();sfi_init_late();if (efi_enabled(EFI_RUNTIME_SERVICES)) &#123; efi_late_init(); efi_free_boot_services();&#125; FIH modules Some nodes in the DT are really device-wise and their drivers are not mainlined. The customized kernel provides a driver module to bring up the devices and read the related information. As mentioned before, there is also a similar close-sourced module in XBL. Here we can see the related information. The hardware id can be read by the following structure, from the reserved memory region at 0xA0A80000 12345678910111213141516struct st_hwid_table &#123; /* mpp */ unsigned int r1; /* pin: PROJECT-ID */ char r2; /* pin: HW_REV-ID */ char r3; /* pin: RF_BAND-ID */ /* info */ char prj; /* project */ char rev; /* hw_rev */ char rf; /* rf_band */ /* device tree */ char dtm; /* Major number */ char dtn; /* minor Number */ /* driver */ char btn; /* button */ char uart;&#125;; Such information is read and explosed to a file under procfs(/proc directory), which can be directly read by the userspace program: 12345678910111213141516171819202122232425262728293031323334353637static int __init fih_info_init(void)&#123; if (proc_create(\"devmodel\", 0, NULL, &amp;project_file_ops) == NULL) &#123; pr_err(\"fail to create proc/devmodel\\n\"); &#125; if (proc_create(\"baseband\", 0, NULL, &amp;hw_rev_file_ops) == NULL) &#123; pr_err(\"fail to create proc/baseband\\n\"); &#125; if (proc_create(\"bandinfo\", 0, NULL, &amp;rf_band_file_ops) == NULL) &#123; pr_err(\"fail to create proc/bandinfo\\n\"); &#125; if (proc_create(\"hwmodel\", 0, NULL, &amp;hwmodel_file_ops) == NULL) &#123; pr_err(\"fail to create proc/hwmodel\\n\"); &#125; if (proc_create(\"hwcfg\", 0, NULL, &amp;hwcfg_file_ops) == NULL) &#123; pr_err(\"fail to create proc/hwcfg\\n\"); &#125; if (proc_create(\"SIMSlot\", 0, NULL, &amp;simslot_file_ops) == NULL) &#123; pr_err(\"fail to create proc/SIMSlot\\n\"); &#125; if (proc_create(\"MODULE\", 0, NULL, &amp;module_file_ops) == NULL) &#123; pr_err(\"fail to create proc/MODULE\\n\"); &#125; if (proc_create(\"fqc_xml\", 0, NULL, &amp;fqc_xml_file_ops) == NULL) &#123; pr_err(\"fail to create proc/fqc_xml\\n\"); &#125; return (0);&#125; There are also information of cpu, dram, battery, gpio, touch, etc. Here we can see the related information. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/************************************************************** * START | SIZE | TARGET * -------------------------------------------------------- 0MB * 0xA000_0000 | 0x0020_0000 | modem rf_nv (2MB) * 0xA020_0000 | 0x0020_0000 | modem cust_nv (2MB) * 0xA040_0000 | 0x0040_0000 | modem default_nv (2MB) * 0xA080_0000 | 0x0010_0000 | modem log (1MB) * -------------------------------------------------------- 7MB * 0xA090_0000 | 0x0004_0000 | last_alog_main (256KB) * 0xA094_0000 | 0x0004_0000 | last_alog_events (256KB) * 0xA098_0000 | 0x0004_0000 | last_alog_radio (256KB) * 0xA09C_0000 | 0x0004_0000 | last_alog_system (256KB) * 0xA0A0_0000 | 0x0004_0000 | last_kmsg (256KB) * 0xA0A4_0000 | 0x0002_0000 | last_blog (128KB) * 0xA0A6_0000 | 0x0002_0000 | blog (128KB) * -------------------------------------------------------- 8.5MB * 0xA0A8_0000 | 0x0000_0040 | hwid:hwcfg (64B) * 0xA0A8_0040 | 0x0000_0040 | secboot:devinfo (64B) * 0xA0A8_0080 | 0x0000_0100 | secboot:unlock (256B) * 0xA0A8_0180 | 0x0000_0080 | sutinfo (128B) * 0xA0A8_0200 | 0x0000_0010 | no use 1 (16B) * 0xA0A8_0210 | 0x0000_0010 | bset (16B) * 0xA0A8_0220 | 0x0000_0010 | bat-id adc (16B) * 0xA0A8_0230 | 0x0000_0010 | no use 2 (16B) * 0xA0A8_0240 | 0x0000_0020 | apr (32B) * 0xA0A8_0260 | 0x0000_0180 | no use 3 (384B) * 0xA0A8_03E0 | 0x0000_0020 | mem (32B) * 0xA0A8_0400 | 0x0000_0C00 | no use 4 (3KB) * 0xA0A8_1000 | 0x0000_1000 | e2p (4KB) * 0xA0A8_2000 | 0x0000_1000 | cda (4KB) * 0xA0A8_3000 | 0x0000_1000 | note (4KB) * 0xA0A8_4000 | 0x0000_1000 | hwcfg (4KB) * 0xA0A8_5000 | 0x0000_3000 | no use 5 (12KB) * 0xA0A8_8000 | 0x0004_0000 | fver (256KB) * 0xA0AC_8000 | 0x0000_4000 | sensordata (16KB) * 0xA0AC_C000 | 0x0000_4000 | LCM data (16KB) * 0xA0AD_0000 | 0x0000_1000 | DDR CDT (4KB) * 0xA0AD_1000 | 0x0000_1000 | sensor TOF (4KB) * 0xA0AD_2000 | 0x0000_8000 | sensor SSC (32KB) * 0xA0AD_A000 | 0x0000_6400 | sensordata 2 (25KB) * 0xA0AE_0400 | 0x0001_FC00 | no use 6 (127KB) * -------------------------------------------------------- 9MB * 0xA0B0_0000 | 0x0020_0000 | pstore (2MB) * -------------------------------------------------------- 11MB * 0xA0D0_0000 | 0x00B0_0000 | All FIH mem (11MB) */ Conclusion In this post, I analyzed the how the ABL Bootloader and the Linux kernel deal with the DT. It is interesting to know some details about the exact processing on the Nokia 8(NB1) platform anyway.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"My journey on Raspberry Pi JTAG debugging","slug":"My-journey-on-raspberrypi-jtag-debugging","date":"2022-02-22T06:57:50.000Z","updated":"2025-03-08T09:40:48.586Z","comments":true,"path":"2022/02/22/My-journey-on-raspberrypi-jtag-debugging/","link":"","permalink":"https://blog.inoki.cc/2022/02/22/My-journey-on-raspberrypi-jtag-debugging/","excerpt":"","text":"As an OS developer/hacker, I am recently hacking Raspberry Pi, including a project aiming at running XNU(macOS kernel) on Raspberry Pi 3 and the port of Embox to Raspberry Pi 2. I often feel disappointed, because it is hard to get some useful information from the commercially available off-the-shelf (COTS) boards when debugging a kernel. Specially, it means the Raspberry Pi here. Although the Raspberry Pi Linux, aka. Raspbian, is open-sourced at GitHub, the bootloader on the chip (or somebody would like to call it BIOS) is still close-sourced. But it can be configured by a config.txt file. According to pinout Raspberry Pi JTAG, the GPIOs on the board can be configured through the config.txt to use some ALT functionalities, e.g., JTAG under ALT4 or ALT5. JTAG, or Joint Test Action Group, provides a standard interface (pin definition, etc.) to debug a program on a chip. I have some experiences back to 2019, using it to debug a real-time OS on an ARM development board. And it is widely used by many board/chip manufacturers, including RISC-V, ARM, etc. If it can work, that should be a perfect option for debugging using JTAG with OpenOCD. Hardware The Pin definitions for JTAG are as follows: ALT5 on GPIOs 4, 5, 6, 12 and 13 ALT4 on GPIOs 22, 23, 24, 25, 26 and 27 In general, the Pins used are TMS, TDI, TDO, TCK, RTCK, TRST (not presented in ALT5). The Pin layout is not standard at all. So, I need to manually connect the Pins one by one to a standard JTAG debugger. By searching the information, I found several standard JTAG interfaces (not all JTAG interfaces): They do have TMS, TDI, TDO, TCK pins, which are common in JTAG. The TRST is the reset pin, so we can connect them to the pin marked as “Reset”. However, only ARM 10 pin and 20 pin contains a RTCK pin, I need to use a hardware debugger with one of the interfaces (I later realize that RTCK is a must). ST-Link v2 I firstly bought a ST-Link v2 debugger, which has a SWD interface and an ARM 20 pin interface. It should work well. However, I finally found that my hardware might by buggy. I tried to connect the ST-Link debugger from the official software, but both ~the software and~(I found that with the official software, it is necessary to connect the debugger for the first time to be able to connect) the OpenOCD 0.11.0 returns a wired status code during the initialization of JTAG stack through USB. The debug-level log information of OpenOCD is as follows: 1234Debug: 222 311 stlink_usb.c:1125 stlink_usb_error_check(): unknown/unexpected STLINK status code 0x4Error: 223 311 stlink_usb.c:3740 stlink_open(): init mode failed (unable to connect to the target)Debug: 224 311 stlink_usb.c:1654 stlink_usb_exit_mode(): MODE: 0x01Debug: 225 312 command.c:555 run_command(): Command &apos;init&apos; failed with error code -4 To know what happened, I tries to connect the Raspberry Pi from a JTAG debugger delivered with my first FPGA. Before that, I just validated that the debugger works well with the FPGA (in OpenOCD, using cpld/xilinx-xc6s.cfg target, which only uses TMS, TDI, TDO, TCK pins). With this debugger, OpenOCD can connect to the device: it does not report the USB bug anymore. However, it stops at complaining that RTCK signal cannot be responded. So, it is the ST-Link work which does not work in my case. The hardware debugging is painful. PS: The BCM2835 with ARM11 (Raspberry Pi 1, zero) does not seem to work with ST-Link High Level Abstraction(HLA), according to Ticket 280 of OpenOCD. But it might be possible with Direct DAP, which exists in ST-Link v2 later firmware and ST-Link 3. FTDI FT232H As I mentioned, this debugger is for my FPGA, which works fine out-of-box. The FT232H is a multi-function chip, can be configured as UART, FIFO, JTAG, I2C, SPI, etc. There seems to be an ARM 10 Pin interface. So, I connect it according to the layout of ARM 10 Pin. I did not connect RTCK, so the OpenOCD returns an error. However, there is no datasheet for my hardware delivered with the FPGA. I think it may be caused by the not really connected RTCK pin, or by the complex configuration of the multi-purpose chip. I just give up using this one, and try to follow the guide from an engineer at OpenSUSE, using a J-Link hardware. J-Link Realizing the the RTCK is important, I connected all the Pins to J-Link. I use several jump wires to connect the irregular JTAG Pins on Raspberry Pi to the J-Link standard ARM 20 Pin tag. The connection is as follows: Configurations After setting up the hardwares, the configuration on Raspberry Pi is simple, just change the GPIO ALT to ALT4 and add: 1enable_jtag_gpio=1 to enable the JTAG debugging. Software The software is which I mentioned before, OpenOCD. It uses a tcl grammar to describe the debug target, the debug protocol (JTAG, SWIG, etc.) and other configurations. There are some pre-edited configuration files. They are located at /usr/share/openocd/scripts if you install OpenOCD from the software source. The basic usage to start a daemon is: 1openocd -f &lt;debug-interface-conf&gt; -f &lt;debug-target-conf&gt; -c &lt;overwriten-or-appended-conf&gt; ... Then we can connect to the daemon by telnet, or attach gdb to the established debug target(s). Debug interface The interface in OpenOCD describes how to connect to a hardware debugger. For J-Link, the default configuration is interface/j-link.cfg. The one for FT232H JTAG debugging is interface/ftdi/um232h.cfg, and interface/st-link.cfg for the ST-Link. Debug protocol The debug protocol is called transport in OpenOCD. Some possible values are: 12345transport select jtagtransport select swimtransport select hla_jagtransport select dapdirect_jtagtransport select dapdirect_swd Raspberry Pi as a target The OpenOCD project already contains Raspberry Pi platforms in its 0.11.0 version, such as: 1234target/bcm2835.cfg # Raspberry 1, zerotarget/bcm2836.cfg # Raspberry 2target/bcm2837.cfg # Raspberry 2 rev 1.2, 3, zero 2target/bcm2711.cfg # Raspberry 4 Error: unknown status In a previous version of OpenOCD, e.g. the version in Ubuntu 20.04 LTS, the ARM core status for Hypervisor mode is not recognizable by the software. So when attaching gdb, there will be an error stating that the unknown status of the CPU, and will fail the gdb. I then use the 0.11.0 version under Arch Linux, which works perfectly. Conclusion This post takes my painful experiences on debugging Raspberry Pi with JTAG. Fortunately, it finally works.","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Raspberry Pi","slug":"Embedded-System/Raspberry-Pi","permalink":"https://blog.inoki.cc/categories/Embedded-System/Raspberry-Pi/"}],"tags":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/tags/Embedded-System/"},{"name":"Bare Metal","slug":"Bare-Metal","permalink":"https://blog.inoki.cc/tags/Bare-Metal/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://blog.inoki.cc/tags/Raspberry-Pi/"},{"name":"Debug","slug":"Debug","permalink":"https://blog.inoki.cc/tags/Debug/"},{"name":"JTAG","slug":"JTAG","permalink":"https://blog.inoki.cc/tags/JTAG/"}]},{"title":"孑然一身的 2021","slug":"My-2021","date":"2022-02-08T16:54:40.000Z","updated":"2025-03-08T09:40:48.586Z","comments":true,"path":"2022/02/08/My-2021/","link":"","permalink":"https://blog.inoki.cc/2022/02/08/My-2021/","excerpt":"","text":"又过去了一整年，2020 年初开始的疫情却仍未结束。今年的很多事情仍然是和疫情息息相关，甚至都是疫情推动的。这一年，我绝大多数时间都是独自一人的，于是今年更加内向型、并且进行了很多思考与反思，但让上帝每每发笑的我当然还是会有很多想不明白的事，唯一能确定的就是我更加追求的是自己内心和精神的富足，而这一富足大部分都是只有靠我自己才能给我的。 疫情 年初的时候，我送家属到了机场，让家属先在国内工作、顺便躲开疫情，等到疫情过去了我们再一起出来，于是我这边就开始了独自一人的自闭生活。而家属那边在回国的时候，国内疫情早已得到了控制，经过吃得很好的两周隔离，开始找工作投简历，没几天就找到了工作，经过一段时间的试用就在六月份转正了，虽然工资不高、但是完全不加班、活不累并且没有考算法。 而与此同时我在外面听着各种变种攻入北美大陆的消息，瑟瑟发抖不敢出门，甚至连访问交流的这个城市都没怎么逛。后来想了一下，应该是当时武汉出现医疗资源挤兑的情况让这个病毒显得很严重，再加上层层渲染什么后遗症，让很多人觉得这个病毒非常严重。实际上就我的观察，欧美很多人根本不 care，得了就当小流感和感冒了。但每天盯着新增的数字还是胆战心惊。 实际上，高中的时候妈妈得过一次很严重的肺炎，发烧到昏迷说胡话，伤到大脑导致她有段时间谁都认不出来、精力集中不了，经过了几个月才完全回复。但其实起因只是因为一个小感冒拖着没有去医院，后面发展到肺炎附带发烧。我当时在住校，因为妈妈生病回去没有人有精力再管我，所以第一周没有回去，等第二周回去的时候妈妈已经在医院醒过来了，但是当时已经大脑受损什么都不知道了。而我爸则一直觉得就是一个小感冒，每天也就喂妈妈吃一下感冒药和柴胡（中药）注射液。我小时候只要一发烧就会被喂柴胡注射液：用勺子敲开、把玻璃茬弄出来，一口喝下去。先不论柴胡是否真的有用，就论注射液可能就是因为有些成分会被消化系统分解才做成注射液，喝柴胡注射液也是很奇怪的事情了。。。但他们那代人缺乏一些我们现在觉得是常识的事，再加上小地方那个年代医疗资源匮乏、心疼钱，随便一个护士的”小诀窍“就被我父母奉为圭臬，直到这次出了事。。。 最后到了第二周的周四，人已经昏迷了才叫上我外婆、把妈妈送到医院，医生说如果再晚来两天就不好救了。但只要医疗资源足够、及早就医，其实一个小感冒（或者说肺炎）不至于此的。 到了现在，我也觉得新冠对大部分人来说可能就是一个小感冒了，而国内政府因为冬奥会和面子问题一直在实行动态清零政策、各个地方又层层加码是反应过激了。 但根据“一头牛”原理，我父母年纪都不小了、而且身子都挺弱的，处理生病的方式又不好，所以我的确不想新冠这种病毒在家那边自由传播、况且小地方医疗资源不充足。我父母也属于不经常去其他地方旅游的（因为家里实在没有什么钱），除了本地有病例的情况会封城，对他们生活基本没有影响。还是等看到新变种的评估再说吧！希望 2022 年国内政策就可以放松，让我回去看看父母和家属。 学术 2021-2022 年已经是读博的倒数第二年了，应该是开始大量出成果的一年，的确我也在年初、年中、年末分别投了一篇文章，年初的那篇没中，年中的幸运地中了，而年末的至今还在 review 中，预计三月份有结果。年中的那篇是一个还不错的会议，需要做一个视频 presentation 介绍我的文章，因为还是收到疫情影响，全部都是 virtual hosting。 总之学术方面到现在为止，已经超过毕业的要求了，所以整体也没什么压力：每天八九点上班推进一下项目、下午六点左右就回家了，然后到家之后实现自己的 idea。目前来说，因为家里和自己真的缺钱，也不打算在学术路上继续了，去工业界找个活、攒出来一些足够过上想要的生活的钱。反正学术方向也体验过了，也看到了这条路的优与劣，再结合现在自身的优势，就初步做出了上述选择。 最后在年末的时候，和某大 V 互动讨论了一下期刊文章的收费问题，我仿佛看到了本科刚开始的时候完全不懂学术科研的自己。 网络 前面提到的学术观点事情大概是这样的：那位大 V 觉得所有的最优秀的论文和资源都是免费的，那些没办法自己找到和学习的都是智商有问题（优越感+1），那些没法免费访问的论文都是经不住审阅、所以才藏着掖着（优越感+1），这种论文都是在知网上没有任何价值的（优越感+1），他是 scihub 的用户（优越感+1）。而我进行了转推，并说还是有很多领域的论文是没办法免费获取的、还是存在有门槛的、收费的刊物，这些刊物里也有大量优秀的论文，出版商太坑了。 虽然本质上我们对期刊收费的问题都是深恶痛绝的，但可惜的是，这位大 V 上来就使用“这逼”对我进行了辱骂，并且树起了他为任何反对他观点的人准备的靶子、开始喷他想象中的观点。我当时只想笑，因为他攻击的观点、我也不知道是谁的。。。而至于他评论下说我是水货的用户们，还好没 fo 我，要不然我需要大反思我发推的水平了 lol。当然我其实也骂回去了但没有脏字，这点千里冰封应该读懂了 XD。 这次争论导致了我 list 里一系列的学术人被这位大 V 拉黑了，我本来也蛮欣赏他的一些观点，后来在抽空搜索了一下他的学术成果（但没搜到，可能授课型硕士导致唯一的学术成果就是放在知网上的本科毕业论文吧）、并总结了一下他的观点之后，也取关+静音了，也有部分原因是他最近的哗众取宠式注销吧。 经过这次我也明白了在网络上很多事情不能认真：大家都觉得对方是傻逼，并不可能讨论出结果，甚至有些人其实根本不是在争论，而是树个靶子自己打，只为了给自己平凡的生活添加一些（我觉得莫名其妙的，但可能 ta 还蛮受用的）优越感。而能成为大 V 并不是有什么过人之处，可能只是会持续发表一些简单、直接、有争议的观点，形成同温层。 于是后来我就开始做相关的实验，（经过本人授权）转了一些一个初中同学的争议性言论，引起了很大的讨论，甚至惊动了某网络媒体的创始人。而后来的抖机灵阴阳怪气收到非常多的回复也证明了这一点。之后还是尽量不这样了，感觉并没有意义存在，只是会让很多数据中心的处理器、内存、网卡等设备烧更多的电，并不能推进任何人类社会的发展。但事实证明，很多大 V 都是通过持续输出这样的言论变成并维持大 V 身份的，比如”B 站你爷爷又回来了的“某 up 主雷某。但我还是更追求我内心的平静，做一些更加有意义的事情。我觉得还是要向更加优秀的人看齐，所以我也取关了一些没有营养的大 V。 开源 我力所能及的更加有意义的事情，可能就是开放源代码能帮助到他人的项目了。 年初完成了为树莓派二代添加 embox 这个嵌入式实时 OS 的支持、并且优化了对称多处理（SMP/多核）的支持；后来开始抄 Berkeley 的软件模拟 FPU（浮点运算单元）写了一个 Rust 实现，顺便手动转译成 ASL（ACPI 的各种表使用的语言），基于这个软件 FPU 实现在 ASL 里写出了一个 Ray Tracing in one Weekend 的实现，后来发现因为精度渲染出来的很有问题，但 debug 有些麻烦就弃坑了；春天的末尾，我基于 libpinyin 写了一个基础版的 macOS 输入法，依赖于 HomeBrew 构建的静态库，但目前由于 HomeBrew 的 prebuilt 机制变了，并不能再成功构建。 到六月份写完论文并且投出之后，我先写了一个使用傅里叶变换来绘制 SVG 图形路径的应用，这个项目让我心满意足：因为我并不满足于纯应用的技术，我所喜爱的是这种能够把数学理论和具体应用紧密联系起来的程序——既有应用背景，又有数学之美。可能这也是我选择读博的一个原因吧。后来有一位数学系的学生专门发邮件感谢这个项目，也让我获得了被人需要的意外之喜。 六月初我也同时开了另一个项目，是为 efivar 添加了一层 Qt 封装、并且添加了 Win32 API 来实现了对 Windows 的支持，这样我可以使用同一个库，在大部分操作系统里实现对 UEFI 标准里的变量的操作。而基于此，构建了一个 Qt 应用程序，可以通过修改 EFI 变量来改变启动顺序、设置下次的启动目标之类的。到了年末，这个项目也收获了 100 余 star 了。我个人觉得它们很有用，也会长期维护下去。 七月的时候放了暑假，闲来无事读了一下别人逆向的 Switch Joycon 的文档，然后写了一个叫做 libjoycon 的 C 库，用来编码和解码 Joycon 的蓝牙通信包，做了一个把 joycon 的座标映射到 OpenGL 绘制的一个立方体的例子，感觉非常好玩。 到了八月进了城玩，和当初在法国的同学一起搞了一下 GPU 加速、深度学习，并且刷了一下现代 Cpp 的特性，为大多数特性都写了练习。顺便完成了之前做树莓派架构调研的时候想到的为其构建 XNU（Apple 的内核）的项目，成功构建出来了一个内核，但却还因为不明原因无法启动，我最近也在搭建树莓派的 JTAG 调试环境。而到了九月，就基本在准备会议的演讲和一个小讲座，并且在之后结束我的第一个交换之旅了。在准备演讲预录视频的时候，发现随便剪剪视频还是蛮开心的，于是建了一个 Youtube 频道 Inoki’s Code Forge开始了视频的制作和上传，今后有些内容也会在这边发布，有兴趣的可以关注一下:) 会议和交换结束回到自己的小宅子之后，开始准备下一篇文章和做相应的实验，同时开始学习 Taichi 这个并行编程语言，顺便提了个 PR 实现在 FreeBSD 上的构建。到了十二月我又通过 swig 为 libjoycon 那个 C 库添加了 Python 的 binding，和 Taichi 玩了一下梦幻联动，使用 Joycon 的角度来映射分形图的变化。也收到了纯爷的 PR，修复了在 macOS 上的构建，希望纯爷和 manjusaka 也都玩得开心！ 之后又尝试了一下基于 EDK2 来构建 EFI App，写了一个播放 Bad Apple 的练了下，了解了一下 EDK2 还有 EFI 的架构和一些细节，今年打算做的事情正好也和 EFI 有关。 今年开源的代码绝大多数都是无意间突然想到的、用来玩的 idea，似乎想象力还可以、乐趣也很足呢！总之今年收获满满，而至于 2022 年的项目和目前未公开的，我也放在新的一年的总结里聊吧。 尾声 年底投完文章，去了滑雪散一下心，这次滑了单板但一周并没有太多进展，天气也不是特别好导致雪道结冰，摔得生疼。 最后，在 12 月 31 日那天，紧密与疫情联系的一年以在滑雪中心感染了新冠结束。我觉得可以到今年年末再聊这次感染的经历，希望新冠疫情大流行能在 2022 结束吧，同时也希望大家也都能找到自己内心的宁静！","categories":[{"name":"Dairy","slug":"Dairy","permalink":"https://blog.inoki.cc/categories/Dairy/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"private","slug":"private","permalink":"https://blog.inoki.cc/tags/private/"}]},{"title":"Build and run Hello World on OVMF Qemu","slug":"qemu-ovmf-edk2-build","date":"2021-12-17T13:47:00.000Z","updated":"2025-03-08T09:40:48.611Z","comments":true,"path":"2021/12/17/qemu-ovmf-edk2-build/","link":"","permalink":"https://blog.inoki.cc/2021/12/17/qemu-ovmf-edk2-build/","excerpt":"","text":"This post records how I build and run an EDK2 HelloWorld on Qemu, based on OVMF UEFI shell. Prepare environment Clone edk2: 1git clone --recursive https://github.com/tianocore/edk2.git Enter edk2 build environment: 1. edksetup.sh BaseTools Build base tools: 1make -C &lt;edk2-dir&gt;/BaseTools/Source/C Create and build HelloWorld Build HelloWorld package for x64 architecture and using GCC: 1build -a X64 -p HelloWorldPkg/HelloWorldPkg.dsc -t GCC5 The built HelloWorld.efi is under Build/HelloWorldPkg/DEBUG_GCC5/X64, we can run it under UEFI shell on an x64 PC or an emulator. Build edk2 for OVMF Modify the following contents in Conf/target.txt: 123ACTIVE_PLATFORM = OvmfPkg/OvmfPkgX64.dscTARGET_ARCH = X64TOOL_CHAIN_TAG = GCC5 Then, build it: 1build Boot and run Hello World Make an image to store efi files: 1234dd if=/dev/null of=example.img bs=1M seek=512mount -t ext4 -o loop example.img /mnt/examplecp Build/HelloWorldPkg/DEBUG_GCC5/X64/HelloWorld.efi /mnt/exampleumount /mnt/example Run OVMF as the firmware and mount the images: 1qemu-system-x86_64 -L . --bios ./ovmf.fd -hda ./example.img In the UEFI shell, list disk mappings: 123456map -rMapping table FS0: ... ... BLK1: ... ... The files are under fs0, list them: 12ls fs0:\\... HelloWorld.efi Run our Hello Wolrd: 12fs0:\\HelloWorld.efiHello World! Conclusion In this post, I noted all the steps to build an edk2 HelloWorld. I will write some interesting UEFI applications sooner. Readings Boot Overview Run OVMF Debug using GDB","categories":[{"name":"EDK2","slug":"EDK2","permalink":"https://blog.inoki.cc/categories/EDK2/"}],"tags":[{"name":"Qemu","slug":"Qemu","permalink":"https://blog.inoki.cc/tags/Qemu/"},{"name":"EDK2","slug":"EDK2","permalink":"https://blog.inoki.cc/tags/EDK2/"}]},{"title":"【译】我的 C++ 20 协程的予取予求","slug":"My_tutorial_and_take_on_C++20_coroutines","date":"2021-12-16T15:34:00.000Z","updated":"2025-03-08T09:40:48.589Z","comments":true,"path":"2021/12/16/My_tutorial_and_take_on_C++20_coroutines/","link":"","permalink":"https://blog.inoki.cc/2021/12/16/My_tutorial_and_take_on_C++20_coroutines/","excerpt":"","text":"原文链接：https://www.scs.stanford.edu/~dm/blog/c+±coroutines.html 介绍 在过去的 25 年里，我在 C++ 中写了很多事件驱动的代码。一个典型的事件驱动代码的例子是注册一个回调，每次套接字有数据需要读取时都会被调用。一旦你读取了整个消息，可能经过多次调用，你就会解析消息，并从更高的抽象层调用另一个回调，如此反复。这种代码写起来很痛苦，因为你必须把你的代码分成一堆不同的函数，因为它们是不同的函数，所以不共享局部变量。 作为一个例子，这里是 Mail Avenger 的 smtpd 类上的方法子集，我的 SMTP 服务器是用 C++03 编写的： 1234567void cmd_rcpt (str cmd, str arg);void cmd_rcpt_0 (str cmd, str arg, int, in_addr *, int);void cmd_rcpt_2 (str addr, int err);void cmd_rcpt_3 (str addr, str errmsg);void cmd_rcpt_4 (str addr, str errmsg, int local);void cmd_rcpt_5 (str addr, str errmsg, str err);void cmd_rcpt_6 (str addr, str err); 第1步，cmd_rcpt 似乎是一个合理的函数，在客户端发出 SMTP “RCPT” 命令时调用。处理 RCPT 命令取决于对客户的某些信息的缓存。如果这些信息没有被缓存，它就会启动一个异步任务来探测客户端并返回。异步任务完成后，“回到” 第 0 步，cmd_rcpt_0，它只是再次调用 cmd_rcpt，但需要一个不同的函数，因为客户端探测代码期望一个回调，它可以提供额外的参数。然后，各种其他的事情可能需要异步发生，而每个可能的异步调用的返回点都需要是它自己的方法，这相当恶心。 C++11 通过引入 lambda 表达式，使情况大为改善。现在你只需要类上的一个 cmd_rcpt 方法，其余的可以使用嵌套的 lambda 表达式。更好的是，lambdas 可以从包围的函数中捕获局部变量。尽管如此，你仍然需要把你的代码分成许多函数。跳过多个步骤或支持在运行时发出异步事件的顺序可能改变的情况是很笨拙的。最后，当你的嵌套 lambda 表达式缩进得越来越远时，你常常会与文本编辑器的右侧边距作斗争。 看到 C20 支持协程，我感到非常兴奋，这应该会极大地改善编写事件驱动代码的过程。现在终于有人出版了一本关于 C20 的书（或者至少是一本书的草稿），几天前我迫不及待地拿到了一本，并阅读了它。虽然我发现这本书在概念（语言特性）和其他 C++20 的改进方面做得很合理，但我悲哀地发现对协程的解释完全无法理解。我在网上找到的几乎所有其他解释都是如此。因此，我不得不通过规范和 cppreference.org 来弄清楚到底发生了什么。 这篇博文代表了我解释协程的尝试–基本上是我希望在 48 小时之前，当我只想弄清楚这些东西的时候，我就需要有的一个教程。 教程 粗略地说，coroutines 是可以互相调用的函数，但它们不共享堆栈，所以可以在任何时候灵活地暂停执行，进入一个不同的 coroutine。本着真正的 C++ 精神，C20 的 coroutines 被实现为一个漂亮的小块，埋藏在一堆垃圾之下，你必须涉足其中才能获得漂亮的部分。坦率地说，我对这种设计感到失望，因为最近的其他语言变化做得更有品味，但可惜它们不是 coroutines。进一步混淆 coroutines 的事实是，C 标准库实际上并没有提供你访问 coroutines 所需的脏活，所以你实际上必须完成你自己的脏活，然后越过它。总之，我尽量把任何进一步的编辑工作留到这篇博文的最后。 另一个需要注意的复杂情况是，C++ 的程序经常使用术语 future 和 promise 来解释，甚至指定。这些术语与 C++ 头中的 std::future 和 std::promise 类型毫无关系。具体来说，std::promise 不是 coroutine promise 对象的一个有效类型。在我的博文中，除了这一段之外，没有任何内容与 std::future 或 std::promise 有关。 说完了这些，C++20 给我们提供的好东西是一个新的操作符，叫做 co_await。粗略地说，表达式 &quot;co_await a;&quot;做了以下工作。 确保当前函数–必须是一个协程–中的所有局部变量被保存到一个堆分配的对象中。 创建一个可调用的对象，当它被调用时，将在紧随 co_await 表达式的评估之后恢复执行该循环程序。 调用（或者更准确地说是跳转到）co_await 的目标对象 a 的一个方法，将步骤 2 中的可调用对象传递给该方法。 注意第 3 步中的方法，当它返回时，并不把控制权返回到 coroutine。只有当第2步的可调用对象被调用时，该循环程序才会恢复执行。如果你使用了一种支持当前继续的调用的语言，或者玩过 Haskell Cont monad，那么第2步的可调用对象就有点像一个 continuation。 使用协程编译代码 由于 C++20 还没有被编译器完全支持，你需要确保你的编译器实现了 coroutines 来玩它们。我使用的是 GCC 10.2，只要你用下面的标志来编译，它似乎就支持 coroutines。 1g++ -fcoroutines -std=c++20 Clang 的支持就没那么深入了。你需要安装 llvm libc++，然后用以下方式编译。 1clang++ -std=c++20 -stdlib=libc++ -fcoroutines-ts 不幸的是，在 clang 中，你还需要将 coroutine 头文件作为 &lt;experimental/coroutine&gt; 而不是 &lt;coroutine&gt;。此外，一些类型被命名为 std::experimental::xxx 而不是 std::xxx。因此，在写这篇文章的时候，下面的例子不能用 clang 开箱编译，但最好能在未来的版本中编译。 如果你想玩一玩，本博文中所有的演示都可以在一个文件 corodemo.cc 中找到。 协程处理 如前所述，新的 co_await 操作符确保函数的当前状态被捆绑在堆的某个地方，并创建一个可调用对象，其调用会继续执行当前函数。可调用对象的类型是 std::coroutine_handle&lt;&gt;。 Coroutine 句柄的行为很像 C 语言的指针。它可以很容易地被复制，但它没有一个析构器来释放与轮询状态相关的内存。为了避免泄漏内存，你通常必须通过调用 coroutine_handle::destroy 方法来销毁 coroutine 状态（尽管在某些情况下，coroutine 可以在完成时自我销毁）。就像C语言的指针一样，一旦 coroutine 句柄被销毁，引用同一 coroutine 的 coroutine 句柄将指向垃圾，并在调用时表现出未定义的行为。从好的方面看，协程句柄在协程的整个执行过程中都是有效的，即使控制在协程中多次进出。 现在让我们更具体地看看 co_await 做什么。当你评估表达式 co_await a 时，编译器会创建一个循环程序句柄并将其传递给方法 a.await_suspend(coroutine_handle)。 现在让我们来看看一个使用 co_await 的完整程序。现在，忽略 ReturnObject 类型–它只是我们为访问 co_await 而必须通过的垃圾中的一部分。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;concepts&gt;#include &lt;coroutine&gt;#include &lt;exception&gt;#include &lt;iostream&gt;struct ReturnObject &#123; struct promise_type &#123; ReturnObject get_return_object() &#123; return &#123;&#125;; &#125; std::suspend_never initial_suspend() &#123; return &#123;&#125;; &#125; std::suspend_never final_suspend() noexcept &#123; return &#123;&#125;; &#125; void unhandled_exception() &#123;&#125; &#125;;&#125;;struct Awaiter &#123; std::coroutine_handle&lt;&gt; *hp_; constexpr bool await_ready() const noexcept &#123; return false; &#125; void await_suspend(std::coroutine_handle&lt;&gt; h) &#123; *hp_ = h; &#125; constexpr void await_resume() const noexcept &#123;&#125;&#125;;ReturnObjectcounter(std::coroutine_handle&lt;&gt; *continuation_out)&#123; Awaiter a&#123;continuation_out&#125;; for (unsigned i = 0;; ++i) &#123; co_await a; std::cout &lt;&lt; \"counter: \" &lt;&lt; i &lt;&lt; std::endl; &#125;&#125;voidmain1()&#123; std::coroutine_handle&lt;&gt; h; counter(&amp;h); for (int i = 0; i &lt; 3; ++i) &#123; std::cout &lt;&lt; \"In main1 function\\n\"; h(); &#125; h.destroy();&#125; Output: In main1 function counter: 0 In main1 function counter: 1 In main1 function counter: 2 这里的 counter 是一个永远计数的函数，递增并打印一个无符号整数。尽管这个计算很愚蠢，但这个例子的精彩之处在于，即使控制权在 counter 和调用它的函数 main1 之间反复切换，变量 i 仍然保持其值。 在这个例子中，我们用一个std::coroutine_handle&lt;&gt;*来调用counter，我们把它插入我们的Awaiter类型。在其 await_suspend 方法中，该类型将 co_await 产生的 coroutine 句柄存入 main1 的 coroutine 句柄中。每次 main1 调用 coroutine 句柄时，都会触发 counter 中的循环的一次迭代，然后在 co_await 语句处再次暂停执行。 为了简单起见，我们在每次调用 await_suspend 时都会存储该程序的句柄，但该句柄在不同的调用中不会改变。(回顾一下，句柄就像一个指向 coroutine 状态的指针，所以虽然i的值在这个状态下可能会改变，但指针本身保持不变。) 我们也可以很容易地写成： 12345678voidAwaiter::await_suspend(std::coroutine_handle&lt;&gt; h)&#123; if (hp_) &#123; *hp_ = h; hp_ = nullptr; &#125;&#125; 你会注意到 Awaiter 上还有两个方法，因为这些是语言所要求的。如果它返回 true，那么 co_await 就不会中止该函数。当然，你可以在 await_suspend 中实现同样的效果，通过恢复（或不暂停）当前的 coroutine，但在调用 await_suspend 之前，编译器必须将所有状态捆绑到 coroutine 句柄所引用的堆对象中，这可能是昂贵的。最后，这里的 await_resume 方法返回 void，但如果它返回一个值，这个值将是 co_await 表达式的值。 &lt;coroutine&gt; 头提供了两个预定义的 Awaiter，std:: suspend_always和std:: suspend_never。正如它们的名字所暗示的，suspend_always::await_ready 总是返回 false，而 suspend_never::await_ready 总是返回 true。这些类上的其他方法是空的，什么也不做。 协程返回对象 TBC Promise 对象 TBC co_yield 操作符 TBC co_return 操作符 TBC 带泛型的生成器示例 TBC Editorial TBC","categories":[{"name":"Modern C++","slug":"Modern-C","permalink":"https://blog.inoki.cc/categories/Modern-C/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"C++","slug":"C","permalink":"https://blog.inoki.cc/tags/C/"}]},{"title":"Linux 内核的用户态驱动框架","slug":"linux-userspace-driver-frameworks","date":"2021-12-14T15:49:00.000Z","updated":"2025-03-08T09:40:48.610Z","comments":true,"path":"2021/12/14/linux-userspace-driver-frameworks/","link":"","permalink":"https://blog.inoki.cc/2021/12/14/linux-userspace-driver-frameworks/","excerpt":"","text":"在 Linux 的驱动模型中，存在各种驱动子系统，如 PCI 子系统、网络子系统。在开发驱动的时候，我们可以使用相应的子系统来完成，比如有人想开发一个 PCI 网卡驱动，那就可以结合上述的两个子系统来完成。 但有时会有许多非标准的硬件并不能直接使用这些子系统，比如模拟或数字 I/O，自定义的 FPGA 硬件等。这时就需要进行更加艰难的内核开发，对于工业界的程序员来说，这不是一件简单的事。 传统的驱动开发模型 一般这种非标准的硬件可以用字符设备实现，放在 /dev/xyz 中，用户态的应用程序可以调用 read 和 write 方法来控制设备，在更复杂的情况下也可以使用 ioctl 来设置额外的功能。 在实现这个字符设备的内核中的非标准硬件的驱动时，也要会使用许多不稳定的内核内部的 API。况且因为没有可用的子系统可用，驱动会变得很大，在之后的内核版本也更加难以维护。这时使用用户态的 I/O 框架就可以极大地简化驱动开发。 Userspace I/O 框架 Userspace I/O（UIO）就是这样一个用户态框架，在 Linux 2.6.23 中被引入。 架构 在用户态它允许使用 mmap 进行设备内存到用户态内存的映射，从而允许在用户态直接读写设备内存或寄存器，并通过 read 调用来获取设备中断（通常中断都是在内核中处理的，而 UIO 允许在中断发生时通过 read 调用返回到用户态）。 而在内核中开发者需要置入一个小模块，用来探测（probe）设备和注册 UIO，注册后设备会出现在 /dev/uioX、并在 sysfs 中导出设备名称、属性等信息。 注意：这里同样可以使用 select 系统调用、来在没有中断的时候防止任务空转。 源码 相关的声明和结构体位于 include/linux/uio_driver.h 中，其中最重要的结构为 uio_info： 123456789101112131415struct uio_info &#123; struct uio_device *uio_dev; const char *name; const char *version; struct uio_mem mem[MAX_UIO_MAPS]; struct uio_port port[MAX_UIO_PORT_REGIONS]; long irq; unsigned long irq_flags; void *priv; irqreturn_t (*handler)(int irq, struct uio_info *dev_info); int (*mmap)(struct uio_info *info, struct vm_area_struct *vma); int (*open)(struct uio_info *info, struct inode *inode); int (*release)(struct uio_info *info, struct inode *inode); int (*irqcontrol)(struct uio_info *info, s32 irq_on);&#125;; 在模块探测时创建一个新的结构体，设置 name, version, 中断号（IRQ）、中断处理回调（handler）等。并使用 register_device(struct device *parent, struct uio_info *info) 注册设备。这个函数会创建一个 uio_dev 填充到这个结构体内，它的声明如下： 1234567891011struct uio_device &#123; struct module *owner; struct device *dev; int minor; atomic_t event; struct fasync_struct *async_queue; wait_queue_head_t wait; struct uio_info *info; struct kobject *map_dir; struct kobject *portio_dir;&#125;; 对于需要映射的内存区域，则需要填充 mem 这个成员，最多可以映射 MAX_UIO_MAPS 个（在 4.3 版本的内核中是 5 个。UIO 内存区域的结构体如下： 12345678struct uio_mem &#123; const char *name; phys_addr_t addr; resource_size_t size; int memtype; void __iomem *internal_addr; struct uio_map *map;&#125;; 而使用这个函数可以生成一个 UIO 的中断事件： 1extern void uio_event_notify(struct uio_info *info); 其余的结构体和声明都可以在头文件中找到： 1234struct uio_map;struct uio_port;struct uio_portio;extern void uio_unregister_device(struct uio_info *info); 更多细节可以查看文档或源码。 性能 在使用内核态设备的时候，使用 ioctl 进行设备控制并不是直接的，这个系统调用会使用虚拟文件系统（VFS）分发用户传来的控制值到设备，如果有返回值，也会逐层传回。而 UIO 中这样的操作是通过 mmap 映射设备内存来实现的，因此读写寄存器来控制设备是直接写入设备的，代码实现就是访问一个普通的数组，这让 UIO 对应的用户态驱动更快、且更易读。 而中断方面，文章[1]测试了 uio_event_notify 被调用到读取 UIO 设备返回的时间在 16 到 32 毫秒左右，ARM11 设备上使用 90% 的 CPU 占用能够完成每秒 1000 次的中断，这在带有实时限制的嵌入式设备中也是可接受的。 总结 使用 UIO 框架写入的内核部分的驱动可以非常小和容易维护，因此想在主线内核中审阅和包含这个驱动不是很难的事情。而 UIO 会避免用户态去映射不属于这个设备的内存，因此也是相当安全的。 VFIO TBC 参考 Userspace I/O drivers in a realtime context, https://www.osadl.org/fileadmin/dam/rtlws/12/Koch.pdf","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Driver","slug":"Linux/Driver","permalink":"https://blog.inoki.cc/categories/Linux/Driver/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"驱动","slug":"驱动","permalink":"https://blog.inoki.cc/tags/驱动/"}]},{"title":"EFI 启动项管理器——双系统启动神器，安全解决你的多系统启动难题","slug":"Inoki-qefi-entry-manager","date":"2021-12-09T20:34:00.000Z","updated":"2025-03-08T09:40:48.568Z","comments":true,"path":"2021/12/09/Inoki-qefi-entry-manager/","link":"","permalink":"https://blog.inoki.cc/2021/12/09/Inoki-qefi-entry-manager/","excerpt":"","text":"你是否遇到过这样的问题？在电脑上安装多个系统：在安装好 FreeBSD 后，发现 Windows 启动不见了；在安装好 Windows 后，发现启动 Linux 用的 Grub 启动不见了。虽然用 refind 这种启动器可以部分解决这个问题，但有时候 Windows 更新之后一看，refind 启动也不见了。这时，运气好的话还可以在 EFI 固件设置中改变启动顺序找回，有些不支持的主板就只能重建引导啦。更何况，开机进入 EFI 固件要按的按键和时机也很麻烦。 这时就可以使用我开发的一个跨 Windows 和 Linux 平台的系统软件 EFI Entry Manager 解决。 安装 这个软件是通过 GPL 3.0 发布的开源软件，可以在我的 GitHub 上找到：项目链接。 在 Release 中可以找到预先构建好的 Linux AppImage 和 Windows 的可执行程序压缩包，下载之后解压缩即可。 Linux 版本会有一个 AppImage 拓展名的文件，而 Windows 版本则需要放入一个文件夹中。 除此之外，Windows 版本还可能需要安装一个 VC 的运行时库，点击这个链接，选择 x64 版本下载并安装即可。 使用 在 Linux 中，需要使用 root 用户启动，比如 sudo ./&lt;executable&gt;。而在 Windows 中，需要右键使用管理员模式打开。 打开之后，首屏显示的是你的电脑当前的启动顺序。 用户可以选中一个启动项，点击 Move up 或 Move down 来改变启动顺序，最后点击 Save 来保存。 在第二个标签页中可以设置下次单次重启时使用的启动项。 保存之后可以选择是否立即重启，无论选择是与否，在下次启动时都会首先尝试使用用户保存的启动项启动。 原理解析 这个项目是基于我的另一个项目 qefivar 的，它是一个跨平台的库，可以通过系统 API 修改 EFI 固件的变量来改变启动顺序等。 在同个硬盘安装第二个系统后，往往原本系统的启动项会被覆盖。但其实只是 ESP 分区的 Boot/Boot\\&lt;arch\\&gt;.efi 这个默认启动项被覆盖了，实际的启动加载器的 efi 文件其实都还在，并且在 EFI firmware 配备的 nvram 中有入口。这时实际上只需要配置一下即可。 比如我安装了 win 之后又装了 FreeBSD，这时默认启动项就被 FreeBSD 写成了它的，没办法加载 win。我就使用 EFI Entry Manager 把启动顺序改成 win-&gt;FreeBSD-&gt;Ventoy 即可，然后每次想进 FreeBSD 只需要在进入 win 之后使用 QEFI Entry Manager 设置下次单次用 FreeBSD 的加载器启动，然后重启即可。 结论 这篇文章介绍了我六个月前的工作，如果帮到你的话可以给个 star，或者通过各种平台请我喝一杯咖啡吧~","categories":[{"name":"Inoki Home Made","slug":"Inoki-Home-Made","permalink":"https://blog.inoki.cc/categories/Inoki-Home-Made/"},{"name":"Qt","slug":"Inoki-Home-Made/Qt","permalink":"https://blog.inoki.cc/categories/Inoki-Home-Made/Qt/"},{"name":"EFI","slug":"Inoki-Home-Made/Qt/EFI","permalink":"https://blog.inoki.cc/categories/Inoki-Home-Made/Qt/EFI/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Qt","slug":"Qt","permalink":"https://blog.inoki.cc/tags/Qt/"},{"name":"EFI","slug":"EFI","permalink":"https://blog.inoki.cc/tags/EFI/"}]},{"title":"【译】Linux 内核的 VFIO - “Virtual Function I/O”","slug":"vfio","date":"2021-12-08T20:34:00.000Z","updated":"2025-03-08T09:40:48.611Z","comments":true,"path":"2021/12/08/vfio/","link":"","permalink":"https://blog.inoki.cc/2021/12/08/vfio/","excerpt":"","text":"原文链接：VFIO - “Virtual Function I/O” 许多现代系统现在提供 DMA 和中断重映射设施，以帮助确保 I/O 设备在它们被分配的边界内行事。这包括带有 AMD-Vi 和 Intel VT-d 的 x86 硬件，带有可分区终端（PE）的 POWER 系统和嵌入式 PowerPC 系统，如 Freescale PAMU。VFIO 驱动是一个 IOMMU/设备无关的框架，在一个安全的、受 IOMMU 保护的环境中，将设备访问直接暴露给用户空间。换句话说，这允许安全的[2]、非特权的用户空间驱动程序。 我们为什么要这样做？当配置为最高的 I/O 性能时，虚拟机经常利用直接设备访问（“设备分配”）。从设备和主机的角度来看，这只是把虚拟机变成了一个用户空间驱动程序，其好处是大大降低了延迟，提高了带宽，并直接使用裸机设备驱动程序[3]。 一些应用，特别是在高性能计算领域，也从用户空间的低开销、直接设备访问中受益。例如，网络适配器（通常是基于非 TCP/IP）和计算加速器。在 VFIO 之前，这些驱动必须经过完整的开发周期才能成为合适的上游驱动，或者在代码树外进行维护，或者使用 UIO 框架，它没有 IOMMU 保护的概念，中断支持有限，并且需要 root 权限来访问 PCI 配置空间等东西。 VFIO 驱动框架打算将这些统一起来，取代 KVM 的 PCI 特定设备分配代码，并提供一个比 UIO 更安全、更有特色的用户空间驱动环境。 组、设备和 IOMMU 设备是任何 I/O 驱动的主要目标。设备通常创建一个由 I/O 访问、中断和 DMA 组成的编程接口。在不深入了解这些细节的情况下，DMA 是迄今为止维护安全环境的最关键的方面，因为允许设备对系统内存进行读写访问会给整个系统的完整性带来最大的风险。 为了帮助减轻这种风险，许多现代的 IOMMU 现在将隔离属性纳入了一个在许多情况下只用于转换的接口（即解决具有有限地址空间的设备的寻址问题）。有了这个，设备现在可以相互隔离，并与任意的内存访问隔离，从而允许像安全地直接将设备分配到虚拟机中。 不过，这种隔离并不总是在单个设备的颗粒度上。即使 IOMMU 能够做到这一点，设备、互连和 IOMMU 的拓扑结构的属性也会减少这种隔离。例如，一个单独的设备可能是一个更大的多功能包装的一部分。虽然 IOMMU 可能能够区分包装内部的设备，但包装可能不要求设备之间的事件到达 IOMMU。这方面的例子可能是任何东西，从一个多功能的 PCI 设备，在功能之间有后门，到一个非PCI-ACS（访问控制服务）能力的桥梁，允许重定向而不到达 IOMMU。在隐藏设备方面，拓扑结构也可以起到一定的作用。一个 PCI-to-PCI 网桥掩盖了它后面的设备，使事件看起来像是来自网桥本身。显然，IOMMU 的设计也是一个主要因素。 因此，虽然在大多数情况下，IOMMU 可能有设备级别的颗粒度，但任何系统都容易受到颗粒度降低的影响。因此，IOMMU API 支持 IOMMU 组的概念。一个组是一组设备，可与系统中所有其他设备隔离。因此，组是 VFIO 使用的所有权单位。 虽然组是为确保用户安全访问而必须使用的最小粒度，但它不一定是首选粒度。在使用页表的 IOMMU 中，有可能在不同的组之间共享一组页表，从而减少对平台（减少 TLB 激动，减少重复的页表）和用户（只编程一组翻译）的开销。出于这个原因，VFIO使用了一个容器类，它可以容纳一个或多个组。通过简单地打开 /dev/vfio/vfio 字符设备来创建一个容器。 就其本身而言，容器提供的功能很少，除了几个版本和扩展查询接口外，其他的都被锁定了。用户需要在容器中添加一个组，以获得下一级的功能。要做到这一点，用户首先需要确定与所需设备相关的组。这可以通过下面的例子中描述的 sysfs 链接来完成。通过将设备从主机驱动上解除绑定并将其绑定到 VFIO 驱动上，一个新的 VFIO 组将以 /dev/vfio/$GROUP 的形式出现，其中 $GROUP 是设备所属的 IOMMU 组号。如果 IOMMU 组包含多个设备，在允许对 VFIO 组进行操作之前，每个设备都需要被绑定到一个 VFIO 驱动上（如果 VFIO 驱动不可用，只将设备从主机驱动上解除绑定也是足够的；这将使组可用，但不是那个特定设备）。TBD - 用于禁用驱动程序探测/锁定设备的接口。 一旦组准备好了，可以通过打开 VFIO 组字符设备（/dev/vfio/$GROUP）并使用 VFIO_GROUP_SET_CONTAINER 的 ioctl，传递先前打开的容器文件的文件描述符，将其加入到容器中。如果需要，并且 IOMMU 驱动支持在组之间共享 IOMMU 上下文，多个组可以被设置到同一个容器中。如果一个组不能被设置到有现有组的容器中，就需要使用一个新的空容器来代替。 当一个组（或多个组）连接到一个容器时，其余的 ioctls 变得可用，从而能够访问 VFIO IOMMU 接口。此外，现在可以使用 VFIO 组文件描述符上的 ioctl 获得组内每个设备的文件描述符。 VFIO 设备 API 包括用于描述设备、I/O 区域和它们在设备描述符上的读/写/映射偏移的 ioctls，以及用于描述和注册中断通知的机制。 VFIO使用实例 假设用户想访问PCI设备0000:06:0d.0： 12$ readlink /sys/bus/pci/devices/0000:06:0d.0/iommu_group../../../../kernel/iommu_groups/26 因此，这个设备属于 IOMMU 第 26 组。该设备在 pci 总线上，因此用户将使用 vfio-pci 来管理该组： 1# modprobe vfio-pci 将这个设备绑定到 vfio-pci 驱动上，为这个组创建 VFIO 组的字符设备： 1234$ lspci -n -s 0000:06:0d.006:0d.0 0401: 1102:0002 (rev 08)# echo 0000:06:0d.0 &gt; /sys/bus/pci/devices/0000:06:0d.0/driver/unbind# echo 1102 0002 &gt; /sys/bus/pci/drivers/vfio-pci/new_id 现在我们需要看看组中还有哪些设备，以释放它供 VFIO 使用: 12345678$ ls -l /sys/bus/pci/devices/0000:06:0d.0/iommu_group/devicestotal 0lrwxrwxrwx. 1 root root 0 Apr 23 16:13 0000:00:1e.0 -&gt; ../../../../devices/pci0000:00/0000:00:1e.0lrwxrwxrwx. 1 root root 0 Apr 23 16:13 0000:06:0d.0 -&gt; ../../../../devices/pci0000:00/0000:00:1e.0/0000:06:0d.0lrwxrwxrwx. 1 root root 0 Apr 23 16:13 0000:06:0d.1 -&gt; ../../../../devices/pci0000:00/0000:00:1e.0/0000:06:0d.1 这个设备在一个 PCI-to-PCI 桥[4]后面，因此我们还需要按照上面的程序将设备 0000:06:0d.1 添加到组中。设备 0000:00:1e.0 是一个目前没有主机驱动的桥，因此不需要将这个设备绑定到 vfio-pci 驱动上（vfio-pci 目前不支持 PCI 桥）。 最后一步是，如果需要非特权操作，则为用户提供对该组的访问权（注意，/dev/vfio/vfio 本身不提供任何能力，因此预计系统会将其设置为模式 0666）。 1# chown user:user /dev/vfio/26 用户现在可以完全访问这个组的所有设备和 iommu，并可以按以下方式访问它们： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172int container, group, device, i;struct vfio_group_status group_status = &#123; .argsz = sizeof(group_status) &#125;;struct vfio_iommu_type1_info iommu_info = &#123; .argsz = sizeof(iommu_info) &#125;;struct vfio_iommu_type1_dma_map dma_map = &#123; .argsz = sizeof(dma_map) &#125;;struct vfio_device_info device_info = &#123; .argsz = sizeof(device_info) &#125;;/* Create a new container */container = open(\"/dev/vfio/vfio\", O_RDWR);if (ioctl(container, VFIO_GET_API_VERSION) != VFIO_API_VERSION) /* Unknown API version */if (!ioctl(container, VFIO_CHECK_EXTENSION, VFIO_TYPE1_IOMMU)) /* Doesn't support the IOMMU driver we want. *//* Open the group */group = open(\"/dev/vfio/26\", O_RDWR);/* Test the group is viable and available */ioctl(group, VFIO_GROUP_GET_STATUS, &amp;group_status);if (!(group_status.flags &amp; VFIO_GROUP_FLAGS_VIABLE)) /* Group is not viable (ie, not all devices bound for vfio) *//* Add the group to the container */ioctl(group, VFIO_GROUP_SET_CONTAINER, &amp;container);/* Enable the IOMMU model we want */ioctl(container, VFIO_SET_IOMMU, VFIO_TYPE1_IOMMU);/* Get addition IOMMU info */ioctl(container, VFIO_IOMMU_GET_INFO, &amp;iommu_info);/* Allocate some space and setup a DMA mapping */dma_map.vaddr = mmap(0, 1024 * 1024, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);dma_map.size = 1024 * 1024;dma_map.iova = 0; /* 1MB starting at 0x0 from device view */dma_map.flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE;ioctl(container, VFIO_IOMMU_MAP_DMA, &amp;dma_map);/* Get a file descriptor for the device */device = ioctl(group, VFIO_GROUP_GET_DEVICE_FD, \"0000:06:0d.0\");/* Test and setup the device */ioctl(device, VFIO_DEVICE_GET_INFO, &amp;device_info);for (i = 0; i &lt; device_info.num_regions; i++) &#123; struct vfio_region_info reg = &#123; .argsz = sizeof(reg) &#125;; reg.index = i; ioctl(device, VFIO_DEVICE_GET_REGION_INFO, &amp;reg); /* Setup mappings... read/write offsets, mmaps * For PCI devices, config space is a region */&#125;for (i = 0; i &lt; device_info.num_irqs; i++) &#123; struct vfio_irq_info irq = &#123; .argsz = sizeof(irq) &#125;; irq.index = i; ioctl(device, VFIO_DEVICE_GET_IRQ_INFO, &amp;irq); /* Setup IRQs... eventfds, VFIO_DEVICE_SET_IRQS */&#125;/* Gratuitous device reset and go... */ioctl(device, VFIO_DEVICE_RESET); VFIO User API 完整的 API 参考请查看 include/linux/vfio.h。 VFIO 总线驱动 API VFIO 总线驱动，比如 vfio-pci，只使用了 VFIO 核心的几个接口。当设备被绑定和解绑到驱动上时，驱动应该分别调用 vfio_register_group_dev() 和 vfio_unregister_group_dev()： 123456void vfio_init_group_dev(struct vfio_device *device, struct device *dev, const struct vfio_device_ops *ops);void vfio_uninit_group_dev(struct vfio_device *device);int vfio_register_group_dev(struct vfio_device *device);void vfio_unregister_group_dev(struct vfio_device *device); 驱动程序应该将 vfio_device 嵌入到它自己的结构中，并在进行注册前调用 vfio_init_group_dev() 进行预配置，在完成取消注册后调用 vfio_uninit_group_dev()。 vfio_register_group_dev() 指示内核开始跟踪指定 dev 的 iommu_group，并将该 dev 注册为 VFIO 总线驱动程序拥有。一旦 vfio_register_group_dev() 返回，用户空间就有可能开始访问驱动，因此驱动应该在调用它之前确保它完全准备好。驱动程序为回调提供了一个类似于文件操作结构的 OP 结构： 12345678910111213struct vfio_device_ops &#123; int (*open)(struct vfio_device *vdev); void (*release)(struct vfio_device *vdev); ssize_t (*read)(struct vfio_device *vdev, char __user *buf, size_t count, loff_t *ppos); ssize_t (*write)(struct vfio_device *vdev, const char __user *buf, size_t size, loff_t *ppos); long (*ioctl)(struct vfio_device *vdev, unsigned int cmd, unsigned long arg); int (*mmap)(struct vfio_device *vdev, struct vm_area_struct *vma);&#125;; 每个函数都被传递给最初在上面的 vfio_register_group_dev() 调用中注册的 vdev。这允许总线驱动器使用 container_of() 获得其私有数据。当为一个设备创建一个新的文件描述符时（通过 VFIO_GROUP_GET_DEVICE_FD），会发出 open/release 回调。ioctl 接口为 VFIO_DEVICE_* ioctls提供了一个直接的通道。读/写/mmap 接口实现了设备区域的访问，这些访问是由设备自己的 VFIO_DEVICE_GET_REGION_INFO ioctl定义的。 VFIO 最初是&quot;虚拟功能I/O&quot;的首字母缩写，由汤姆-里昂在担任思科公司时实现。我们后来已经不再使用这个缩写了，但它很好听。 &quot;安全&quot;也取决于设备的 “行为良好”。多功能设备有可能在功能之间有后门，甚至单功能设备也有可能通过 MMIO 寄存器对 PCI 配置空间等进行替代访问。为了防止前者，我们可以在 IOMMU 驱动中加入额外的预防措施，将多功能 PCI 设备分组（iommu=group_mf）。后者我们无法防止，但 IOMMU 仍应提供隔离。对于 PCI 来说，SR-IOV 虚拟功能是 &quot;行为良好 &quot;的最佳指标，因为这些是为虚拟化使用模式设计的。 像往常一样，虚拟机设备分配有一些权衡，超出了VFIO的范围。预计未来的 IOMMU 技术将减少一些，但也许不是全部，这些折衷。 在这种情况下，设备在 PCI 桥下面，所以来自设备的任何功能的事件对 iommu 来说都是无法区分的。 123 -[0000:00]-+-1e.0-[06]--+-0d.0 \\-0d.100:1e.0 PCI bridge: Intel Corporation 82801 PCI Bridge (rev 90)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"}]},{"title":"【译】Linux 内核的用户态 I/O","slug":"uio-howto","date":"2021-12-08T19:34:00.000Z","updated":"2025-03-08T09:40:48.611Z","comments":true,"path":"2021/12/08/uio-howto/","link":"","permalink":"https://blog.inoki.cc/2021/12/08/uio-howto/","excerpt":"","text":"原文链接：The Userspace I/O HOWTO 关于 UIO 如果你使用 UIO 作为你的设备卡的驱动程序，你可以获得： 只有一个小的内核模块需要编写和维护。 在用户空间开发你的驱动程序的主要部分，使用你习惯的所有工具和库。 驱动程序中的错误不会使内核崩溃。 你的驱动程序的更新可以在不重新编译内核的情况下进行。 UIO 是如何工作的 每个 IO 设备都是通过一个设备文件和几个 sysfs 属性文件访问的。第一个设备的设备文件将被称为 /dev/uio0，随后的设备将被称为 /dev/uio1，/dev/uio2，以此类推。 /dev/uioX 是用来访问设备卡的地址空间。只需使用 mmap() 来访问你的设备卡的寄存器或 RAM 位置。 中断是通过从 /dev/uioX 读取来处理的。从 /dev/uioX 读取的阻塞式 read() 将在中断发生后立即返回。你也可以在 /dev/uioX 上使用 select() 来等待一个中断。从 /dev/uioX 中读出的整数值代表总的中断数。你可以用这个数字来计算你是否错过了一些中断。 对于一些内部有多个中断源，但没有独立的 IRQ 屏蔽和状态寄存器的硬件，可能会出现这样的情况：如果内核处理程序通过写入芯片的 IRQ 寄存器来禁用它们，用户空间无法确定中断源是什么。在这种情况下，内核必须完全禁用 IRQ，以使芯片的寄存器不被改变。现在，用户空间部分可以确定中断的原因，但它不能重新启用中断。另一种情况是，重新启用中断的芯片是对综合的 IRQ 状态/确认寄存器的读-修改-写操作。如果一个新的中断同时发生，这将是很荒谬的。 为了解决这些问题，UIO 还实现了一个 write() 函数。对于只有一个中断源或者有独立的IRQ屏蔽和状态寄存器的硬件，通常不使用、可以忽略它。然而，如果你需要它，对 /dev/uioX 的写入将调用驱动实现的 irqcontrol() 函数。你必须写一个 32 位的值，通常是 0 或 1，以禁用或启用中断。如果一个驱动程序没有实现 irqcontrol()，write() 将返回 -ENOSYS。 为了正确处理中断，你的自定义内核模块可以提供自己的中断处理程序。它将自动被内置的处理程序调用。 对于那些不产生中断但需要轮询的卡，可以设置一个定时器，在可配置的时间间隔内触发中断处理程序。这种中断模拟是通过从定时器的事件处理程序调用 uio_event_notify() 来完成的。 每个驱动程序都提供了用于读取或写入变量的属性。这些属性可以通过 sysfs 文件访问。一个自定义的内核驱动模块可以将自己的属性添加到 uio 驱动所拥有的设备上，但目前还没有添加到 uio 设备本身。如果发现有用的话，这在将来可能会发生改变。 UIO框架提供了以下标准属性： name: 你的设备的名称。建议使用你的内核模块的名称。 version：一个由你的驱动程序定义的版本字符串。这使得你的驱动程序的用户空间部分能够处理不同版本的内核模块。 event：自上次读取设备节点以来，驱动程序处理的中断总数。 这些属性出现在 /sys/class/uio/uioX 目录下。请注意，这个目录可能是一个符号链接，而不是一个真正的目录。任何访问它的用户空间代码必须能够处理这个问题。 每个 UIO 设备都可以为内存映射提供一个或多个内存区域。这是必要的，因为一些工业 I/O 卡需要在一个驱动程序中访问一个以上的 PCI 内存区域。 每个映射在 sysfs 中有自己的目录，第一个映射显示为 /sys/class/uio/uioX/maps/map0/。 后续的映射创建目录 map1/，map2/，等等。这些目录只有在映射的大小不为 0 时才会出现。 每个 mapX/ 目录包含四个只读文件，显示内存的属性： name: 这个映射的一个字符串标识符。这是可选的，这个字符串可以是空的。驱动程序可以设置它，使用户空间更容易找到正确的映射。 addr: 可以被映射的内存的地址。 size：addr 所指向的内存的大小，以字节为单位。 offset：在 mmap() 返回的指针上必须加上的偏移量，以获得实际的设备内存。如果设备的内存不是页对齐的，这就很重要。记住，由 mmap() 返回的指针总是页对齐的，所以总是加上这个偏移量是好的风格。 在用户空间，不同的映射是通过调整 mmap() 调用的偏移量参数来区分的。为了映射 N 的内存，你必须使用 N 倍的页面大小作为你的偏移： 1offset = N * getpagesize(); Sometimes there is hardware with memory-like regions that can not be mapped with the technique described here, but there are still ways to access them from userspace. The most common example are x86 ioports. On x86 systems, userspace can access these ioports using ioperm(), iopl(), inb(), outb(), and similar functions. Since these ioport regions can not be mapped, they will not appear under /sys/class/uio/uioX/maps/ like the normal memory described above. Without information about the port regions a hardware has to offer, it becomes difficult for the userspace part of the driver to find out which ports belong to which UIO device. To address this situation, the new directory /sys/class/uio/uioX/portio/ was added. It only exists if the driver wants to pass information about one or more port regions to userspace. If that is the case, subdirectories named port0, port1, and so on, will appear underneath /sys/class/uio/uioX/portio/. 有时，有些硬件的类似内存的区域不能用这里描述的技术进行映射，但仍有办法从用户空间访问它们。最常见的例子是 x86 的 ioports。在X86系统中，用户空间可以使用 ioperm()、iopl()、inb()、outb() 和类似的函数访问这些 ioports。 由于这些 ioport 区域不能被映射，它们不会像上面描述的普通内存一样出现在 /sys/class/uio/uioX/maps/ 下。如果没有硬件所提供的端口区域的信息，驱动程序的用户空间部分就很难找出哪些端口属于哪个 IO 设备。 为了解决这种情况，增加了新的目录 /sys/class/uio/uioX/portio/。它只在驱动想把一个或多个端口区域的信息传递给用户空间时存在。如果是这种情况，名为 port0、port1 等的子目录将出现在 /sys/class/uio/uioX/portio/ 下面。 每个 portX/ 目录包含四个只读文件，它们显示端口区域的名称、开始、大小和类型： name：这个端口区域的一个字符串标识符。这个字符串是可选的，可以为空。驱动程序可以设置它，使用户空间更容易找到某个端口区域。 start：该区域的第一个端口。 size：这个区域中的端口数量。 porttype：一个描述端口类型的字符串。 编写你自己的内核模块 请看一下 uio_cif.c 作为一个例子。下面的段落解释了这个文件的不同部分。 struct uio_info 这个结构告诉框架你的驱动程序的细节，有些成员是必须的，有些是可选的。 const char *name: 需要。你的驱动程序的名称，它将出现在 sysfs 中。我建议使用你的模块的名称。 const char *version: 必须，这个字符串会显示在 /sys/class/uio/uioX/version。 struct uio_mem mem[ MAX_UIO_MAPS ]: 如果你有可以用 mmap() 映射的内存，则需要。对于每个映射，你需要填充一个 uio_mem 结构。详情见下面的描述。 struct uio_port port[ MAX_UIO_PORTS_REGIONS ]: 如果你想把 ioports 的信息传递给用户空间，就必须这样做。对于每个端口区域，你需要填充一个 uio_port 结构。详情见下面的描述。 long irq: 需要。如果你的硬件产生了一个中断，你的模块的任务就是在初始化过程中确定 irq 的编号。如果你没有硬件产生的中断，但想以其他方式触发中断处理程序，请将 irq 设置为 UIO_IRQ_CUSTOM。如果你根本就没有中断，你可以把 irq 设置为 UIO_IRQ_NONE，尽管这很少有意义。 unsigned long irq_flags: 如果你将 irq 设置为硬件中断号，则需要。这里给出的标志将在调用 require_irq() 时使用。 int (*mmap)(struct uio_info *info, struct vm_area_struct *vma): 可选的。如果你需要一个特殊的mmap()函数，你可以在这里设置它。如果这个指针不是 NULL，你的 mmap() 将被调用，而不是内置的那个。 int (*open)(struct uio_info *info, struct inode *inode): 可选的。你可能希望有自己的open()，例如，只有当你的设备被实际使用时才启用中断。 int (*release)(struct uio_info *info, struct inode *inode): 可选的。如果你定义了自己的open()，你可能也需要一个自定义的 release() 函数。 int (*irqcontrol)(struct uio_info *info, s32 irq_on): 可选的。如果你需要通过写到 /dev/uioX 来启用或禁用用户空间的中断，你可以实现这个函数。参数 irq_on 为 0 表示禁用中断，1 表示启用中断。 通常，你的设备会有一个或多个内存区域可以被映射到用户空间。对于每个区域，你必须在 mem[] 数组中设置一个 struct uio_mem。下面是对 struct uio_mem 字段的描述。 const char *name: 可选的。设置它以帮助识别内存区域，它将显示在相应的 sysfs 节点中。 int memtype: 如果使用映射，则需要。如果你的卡上有要映射的物理内存，将其设置为 UIO_MEM_PHYS。如果是逻辑内存(例如用 __get_free_pages() 分配，而不是 kmalloc())，则使用 UIO_MEM_LOGICAL。还有 UIO_MEM_VIRTUAL 用于虚拟内存。 phys_addr_t addr: 如果使用映射则需要。填入你的内存块的地址。这个地址会出现在 sysfs 中。 resource_size_t size: 填写 addr 指向的内存块的大小。如果 size 为 0，则认为该映射未被使用。注意你必须为所有未使用的映射初始化 size 为 0。 void *internal_addr: 如果你必须从你的内核模块中访问这个内存区域，你将希望通过使用类似 ioremap() 的方法来进行内部映射。这个函数返回的地址不能被映射到用户空间，所以你不能把它存储在 addr 中。使用 internal_addr 来记住这样一个地址。 请不要碰 uio_mem 结构的 map 元素!它是由 UIO 框架用来为这个映射设置 sysfs 文件的。不要管它。 有时，你的设备可能有一个或多个端口区域不能被映射到用户空间。但如果用户空间有其他的可能性来访问这些端口，那么在 sysfs 中提供这些端口的信息是有意义的。对于每个区域，你必须在 port[] 数组中设置一个 struct uio_port。下面是对 struct uio_port 的字段的描述。 char *porttype：需要。将其设置为预定义的常数之一。使用 UIO_PORT_X86 来表示 x86 架构中的 ioports。 unsigned long start: 如果使用端口区域，则需要。填写这个区域的第一个端口的编号。 unsigned long size: 填入该区域的端口数。如果 size 为 0，该区域将被视为未使用。注意，你必须为所有未使用的区域初始化 size 为 0。 请不要碰 uio_port 结构的 portio 元素! 它是由 UIO 框架内部使用的，用于为这个区域设置 sysfs 文件。请不要管它。 添加一个中断处理程序 你需要在中断处理程序中做什么取决于你的硬件和你想如何处理它。你应该尽量减少内核中断处理程序中的代码量。如果你的硬件不需要在每次中断后执行任何操作，那么你的处理程序可以是空的。 另一方面，如果你的硬件需要在每次中断后执行一些动作，那么你必须在你的内核模块中完成这些动作。注意，你不能依赖你的驱动程序的用户空间部分。你的用户空间程序可以在任何时候终止，可能会让你的硬件处于仍然需要正确处理中断的状态。 也可能有这样的应用，你想在每次中断时从硬件中读取数据，并将其缓冲在你为此目的分配的一块内核内存中。通过这种技术，你可以避免在用户空间程序错过中断时的数据丢失。 关于共享中断的说明：只要有可能，你的驱动程序应该支持中断共享。只有当你的驱动程序能够检测到你的硬件是否触发了中断时，它才有可能。这通常是通过查看一个中断状态寄存器来实现的。如果你的驱动程序看到 IRQ 位确实被设置了，它将执行其动作，处理程序返回 IRQ_HANDLED。如果驱动程序检测到不是你的硬件引起的中断，它将什么也不做，并返回 IRQ_NONE，允许内核调用下一个可能的中断处理程序。 如果你决定不支持共享中断，你的卡就不能在没有空闲中断的计算机中工作。由于这种情况经常发生在 PC 平台上，你可以通过支持中断共享来为自己省去很多麻烦。 为平台设备使用 uio_pdrv 在许多情况下，平台设备的 IO 驱动可以用一种通用的方式来处理。在你定义 platform_device 结构的同一个地方，你也可以简单地实现你的中断处理程序并填充你的 uio_info 结构。然后，这个结构 uio_info 的指针被用作你的平台设备的 platform_data。 你还需要设置一个包含内存映射地址和大小的结构资源数组。这些信息使用 struct platform_device 的 .resource 和 .num_resources 元素传递给驱动。 你现在必须将 struct platform_device 的 .name 元素设置为 &quot;uio_pdrv &quot;以使用通用的 IO 平台设备驱动程序。这个驱动程序将根据给定的资源填充 mem[] 数组，并注册该设备。 这种方法的优点是，你只需要编辑一个你无论如何都需要编辑的文件。你不需要创建一个额外的驱动程序。 为平台设备使用 uio_pdrv_genirq 特别是在嵌入式设备中，你经常会发现一些芯片的 irq 引脚被绑在自己的专用中断线上。在这种情况下，你可以非常确定中断不是共享的，我们可以进一步利用 uio_pdrv 的概念，使用一个通用的中断处理器。这就是 uio_pdrv_genirq 的作用。 这个驱动程序的设置与上面描述的 uio_pdrv 相同，只是你没有实现一个中断处理程序。 uio_info 结构中的 .handler 元素必须保持为空。.irq_flags 元素必须不包含 IRQF_SHARED。 你将把 struct platform_device 的 .name 元素设置为 “uio_pdrv_genirq” 来使用这个驱动程序。 uio_pdrv_genirq 的通用中断处理程序将简单地使用 disable_irq_nosync() 禁用中断线。在完成它的工作后，用户空间可以通过向 IO 设备文件写入 0x00000001 来重新启用中断。驱动程序已经实现了一个 irq_control() 来实现这个功能，你必须不实现自己的。 使用 uio_pdrv_genirq 不仅可以节省几行中断处理程序的代码。你也不需要知道任何关于芯片内部寄存器的信息来创建驱动的内核部分。你只需要知道芯片所连接的引脚的IRQ号码。 当在一个启用了设备树的系统中使用时，需要用 &quot;of_id &quot;模块参数来探测驱动程序应该处理的节点的&quot;兼容&quot;字符串。默认情况下，节点的名称（不包括单元地址）被暴露为用户空间中的 IO 设备的名称。要设置一个自定义的名称，可以在 DT 节点中指定一个名为 “linux,uio-name” 的属性。 为平台设备使用 uio_dmem_genirq 除了静态分配的内存范围之外，他们也可能希望在用户空间驱动中使用动态分配的区域。特别是，能够访问通过 dma-mapping API 提供的内存，可能特别有用。uio_dmem_genirq 驱动提供了一种方法来实现这一目标。 在中断配置和处理方面，该驱动的使用方式与 “uio_pdrv_genirq” 驱动类似。 将 struct platform_device 的 .name 元素设置为 &quot;uio_dmem_genirq &quot;来使用这个驱动。 当使用这个驱动时，填写 struct platform_device 的 .platform_data 元素，它的类型是 struct uio_dmem_genirq_pdata，它包含以下元素： struct uio_info uioinfo：与 uio_pdrv_genirq 平台数据使用的结构相同 unsigned int *dynamic_region_sizes:指向将被映射到用户空间的动态内存区域大小列表的指针。 unsigned int num_dynamic_regions:dynamic_region_sizes 数组中的元素数量。 在平台数据中定义的动态区域将被附加到平台设备资源之后的 “mem[]” 数组中，这意味着静态和动态内存区域的总数不能超过 MAX_UIO_MAPS。 动态内存区域将在打开 UIO 设备文件 /dev/uioX 时被分配。类似于静态内存资源，动态区域的内存区域信息然后通过 sysfs 在 /sys/class/uio/uioX/maps/mapY/* 处可见。当 IO 设备文件被关闭时，动态内存区域将被释放。当没有进程保持设备文件开放时，返回给用户空间的地址是 ~0。 在用户态编写一个驱动 一旦你有一个适用于你的硬件的内核模块，你就可以编写你的驱动程序的用户空间部分。你不需要任何特殊的库，你的驱动程序可以用任何合理的语言编写，你可以使用浮点数字等等。简而言之，你可以使用所有你通常用于编写用户空间应用程序的工具和库。 获取有关你的 UIO 设备的信息 所有 IO 设备的信息都可以在 sysfs 中找到。你应该在你的驱动程序中做的第一件事是检查名称和版本，以确保你与正确的设备对话，并且其内核驱动程序具有你期望的版本。 你还应该确保你需要的内存映射存在，并且有你期望的大小。 有一个叫 lsuio 的工具，可以列出 IO 设备和它们的属性。它可以在这里找到。 http://www.osadl.org/projects/downloads/UIO/user/ 用 lsuio 你可以快速检查你的内核模块是否被加载，以及它输出了哪些属性。详情请看 manpage。 lsuio 的源代码可以作为一个例子，用来获取一个 IO 设备的信息。uio_helper.c 文件包含了很多函数，你可以在你的用户空间驱动代码中使用。 mmap() 设备内存 在你确定你已经得到了正确的设备和你需要的内存映射之后，你要做的就是调用 mmap() 将设备的内存映射到用户空间。 mmap() 调用的参数 offset 对于 IO 设备有特殊意义。它被用来选择你要映射的设备的映射。要映射N个映射的内存，你必须使用 N 倍的页面大小作为你的偏移量。 1offset = N * getpagesize()。 N 从 0 开始，所以如果你只有一个内存范围要映射，就设置 offset = 0。这种技术的缺点是，内存总是从它的起始地址开始映射。 等待中断 在你成功地映射了你的设备内存后，你可以像普通的数组一样访问它。通常情况下，你会进行一些初始化。之后，你的硬件开始工作，一旦完成，有一些数据可用，或者因为发生错误而需要你的注意，就会产生一个中断。 /dev/uioX 是一个只读文件。read() 将总是阻塞，直到中断发生。read() 的 count 参数只有一个合法的值，那就是一个有符号的32位整数的大小(4)。任何其他的 count 值都会导致 read() 失败。读取的有符号的 32 位整数是你设备的中断计数。如果这个值比你上次读到的值多一个，则一切正常。如果差值大于 1，你就错过了中断。 你也可以在 /dev/uioX 上使用 select()。 通用的 PCI UIO 驱动 通用驱动程序是一个名为 uio_pci_generic 的内核模块。它可以与任何符合 PCI 2.3（2002 年左右）的设备和任何符合 PCI Express 的设备一起工作。使用它，你只需要编写用户空间驱动程序，而不需要编写特定硬件的内核模块。 让驱动识别设备 由于驱动程序没有声明任何设备 ID，它不会被自动加载，也不会自动与任何设备绑定，你必须自己加载它并分配 ID 给驱动程序。比如说： 12modprobe uio_pci_genericecho &quot;8086 10f5&quot; &gt; /sys/bus/pci/drivers/uio_pci_generic/new_id 如果你的设备已经有一个特定硬件的内核驱动，通用驱动仍然不会与之绑定，在这种情况下，如果你想使用通用驱动（为什么要这样做？），你必须手动解除与特定硬件驱动的绑定，然后绑定通用驱动，像这样。 12echo -n 0000:00:19.0 &gt; /sys/bus/pci/drivers/e1000e/unbindecho -n 0000:00:19.0 &gt; /sys/bus/pci/drivers/uio_pci_generic/bind 你可以通过在 sysfs 中寻找设备来验证它是否已经被绑定到了驱动程序上，例如: 1ls -l /sys/bus/pci/devices/0000:00:19.0/driver 如果成功的话，应该可以打印出来： 1.../0000:00:19.0/driver -&gt; ../../../bus/pci/drivers/uio_pci_generic 注意，通用驱动程序不会绑定到旧的PCI 2.2设备。如果绑定设备失败，运行下面的命令： 1dmesg 并在输出中寻找失败的原因。 关于 uio_pci_generic 需要知道的事情 中断是使用 PCI 命令寄存器中的中断禁用位和 PCI 状态寄存器中的中断状态位来处理的。所有符合PCI 2.3（2002 年左右）的设备和所有符合 PCI Express 的设备都应该支持这些位。 uio_pci_generic 会检测这种支持，并且不会绑定不支持命令寄存器中中断禁用位的设备。 在每个中断中，uio_pci_generic 设置中断禁用位。这将阻止设备产生进一步的中断，直到该位被清除。用户空间驱动程序应该在阻塞和等待更多的中断之前清除这个位。 使用 uio_pci_generic 编写用户空间驱动程序 用户空间驱动程序可以使用 PCI 的 sysfs 接口，或者包装它的 libpci 库，来与设备对话，并通过向命令寄存器写信来重新启用中断。 使用 uio_pci_generic 的示例代码 下面是一些使用uio_pci_generic的用户空间驱动代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt;int main()&#123; int uiofd; int configfd; int err; int i; unsigned icount; unsigned char command_high; uiofd = open(\"/dev/uio0\", O_RDONLY); if (uiofd &lt; 0) &#123; perror(\"uio open:\"); return errno; &#125; configfd = open(\"/sys/class/uio/uio0/device/config\", O_RDWR); if (configfd &lt; 0) &#123; perror(\"config open:\"); return errno; &#125; /* Read and cache command value */ err = pread(configfd, &amp;command_high, 1, 5); if (err != 1) &#123; perror(\"command config read:\"); return errno; &#125; command_high &amp;= ~0x4; for(i = 0;; ++i) &#123; /* Print out a message, for debugging. */ if (i == 0) fprintf(stderr, \"Started uio test driver.\\n\"); else fprintf(stderr, \"Interrupts: %d\\n\", icount); /****************************************/ /* Here we got an interrupt from the device. Do something to it. */ /****************************************/ /* Re-enable interrupts. */ err = pwrite(configfd, &amp;command_high, 1, 5); if (err != 1) &#123; perror(\"config write:\"); break; &#125; /* Wait for next interrupt. */ err = read(uiofd, &amp;icount, 4); if (err != 4) &#123; perror(\"uio read:\"); break; &#125; &#125; return errno;&#125; 通用的 Hyper-V UIO 驱动 这个通用驱动程序是一个名为 uio_hv_generic 的内核模块。它支持 Hyper-V VMBus 上的设备，与 PCI 总线上的 uio_pci_generic 类似。 让驱动识别设备 由于该驱动没有声明任何设备的 GUID，它不会被自动加载，也不会自动绑定任何设备，你必须自己加载它并分配 ID 给该驱动。例如，使用网络设备类 GUID： 12modprobe uio_hv_genericecho &quot;f8615163-df3e-46c5-913f-f2d2f965ed0e&quot; &gt; /sys/bus/vmbus/drivers/uio_hv_generic/new_id 如果该设备已经有一个特定硬件的内核驱动，通用驱动仍然不会与之绑定，在这种情况下，如果你想在用户空间库中使用通用驱动，你必须手动解除对特定硬件驱动的绑定，并绑定通用驱动，像这样使用特定设备的 GUID： 12echo -n ed963694-e847-4b2a-85af-bc9cfc11d6f3 &gt; /sys/bus/vmbus/drivers/hv_netvsc/unbindecho -n ed963694-e847-4b2a-85af-bc9cfc11d6f3 &gt; /sys/bus/vmbus/drivers/uio_hv_generic/bind 你可以通过在sysfs中寻找设备来验证它是否已经被绑定到了驱动程序上，例如，如下所示： 1ls -l /sys/bus/vmbus/devices/ed963694-e847-4b2a-85af-bc9cfc11d6f3/driver 如果成功的话，应该打印出来以下内容： 1.../ed963694-e847-4b2a-85af-bc9cfc11d6f3/driver -&gt; ../../../bus/vmbus/drivers/uio_hv_generic 关于 uio_hv_generic 需要知道的事 在每个中断中，uio_hv_generic 设置中断禁用位。这将阻止设备产生进一步的中断，直到该位被清除。用户空间驱动程序应该在阻塞和等待更多的中断之前清除这个位。 当主机撤销一个设备时，中断文件描述符被标记下来，任何对中断文件描述符的读取将返回 -EIO。类似于一个关闭的套接字或断开的串行设备。 vmbus 设备区域被映射为 uio 设备资源： 通道环形缓冲区：客户机到主机和主机到客户机 访客到主机的中断信号页 访客到主机的监控页 网络接收缓冲区 网络发送缓冲区 如果一个子通道是由对主机的请求创建的，那么 uio_hv_generic 设备驱动将为每个通道环形缓冲区创建一个 sysfs 二进制文件。比如说 1/sys/bus/vmbus/devices/3811fe4d-0fa0-4b62-981a-74fc1084c757/channels/21/ring","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"}]},{"title":"【译】Linux 内核中 EXPORT_SYMBOL_GPL 的意义","slug":"On-the-value-of-export-symbol-gpl","date":"2021-11-19T15:34:00.000Z","updated":"2025-03-08T09:40:48.591Z","comments":true,"path":"2021/11/19/On-the-value-of-export-symbol-gpl/","link":"","permalink":"https://blog.inoki.cc/2021/11/19/On-the-value-of-export-symbol-gpl/","excerpt":"","text":"原文链接：On the value of EXPORT_SYMBOL_GPL 当一个可加载模块被插入时，它对内核函数和数据结构的任何引用必须与当前运行的内核链接。然而，模块加载器并不提供对所有内核符号的访问；只有那些被明确被导出的才是可用的。导出这个需求减少了模块可以看到的 API，尽管没有减少那么多：在 2.6.13 内核中有超过 6000 个符号被导出。 导出有两种形式：vanilla（EXPORT_SYMBOL）和 GPL-only（EXPORT_SYMBOL_GPL）。前者可用于任何内核模块，而后者不能被任何没有 GPL 兼容许可证的模块使用。如果模块声明的许可证不合格，模块加载器将通过拒绝访问只适用于 GPL 的符号来执行这一区别。目前，只有不到 10% 的内核符号是 GPL-only 的，但是 GPL-only 符号的数量正在增长。在许多情况下，有一定的压力使新的导出只适用于 GPL。 经常有人争论说，这两种类型的导出没有实际区别。那些认为所有的内核模块都被内核许可证要求为 GPL 许可证的人认为所有的符号在任何情况下都是隐含的 GPL-only。另一个阵营认为模块接口是 GPL 不能跨越的边界，他们不相信只适用于 GPL 的限制可以被坚持。在任何情况下，只适用于 GPL 的符号可以很容易地通过修补内核、虚假声明 GPL 兼容的许可证，或者通过插入一个提供更广泛访问感兴趣的符号的垫片模块而被规避。 然而，Linus 认为，仅允许 GPL 的导出是重要的。 我和一两个律师谈过，这(a)绝对有 巨大 的区别，(b)他们喜欢这样。 事实是，法律并不是一台盲目的、无意识的计算机，不会照字面意思去理解你所说的东西。意图是非常重要的。而用 xxx_GPL() 的版本来表明它是一个内部接口，确实非常有意义。 其中一位律师说，这比试图让许可证解释所有的细节要好得多——将意图编入代码本身不仅更灵活，而且更不容易被误解。 他还指出，规避纯 GPL 的导出需要一个明确的行动，使其明确由此产生的版权侵犯是一个故意的行为。 不管它们是否有任何法律意义，只适用于 GPL 的导出确实成功地传达了内核开发社区中希望限制使用非自由内核模块的大量子集的意愿。彻底禁止这类模块可能不会很快被提上日程，但它们的功能也不可能有太大增长。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"}]},{"title":"【译】三阶截点（IP3）的物理意义","slug":"Physical-significance-iip3-important-receiver-chain","date":"2021-11-12T15:38:00.000Z","updated":"2025-03-08T09:40:48.591Z","comments":true,"path":"2021/11/12/Physical-significance-iip3-important-receiver-chain/","link":"","permalink":"https://blog.inoki.cc/2021/11/12/Physical-significance-iip3-important-receiver-chain/","excerpt":"","text":"原文链接：What is physical significance of IP3, why it is more important in Receiver Chain ? 了解三阶截点（IP3）的物理意义 当一个放大器或其他电路变得非线性时，它将开始产生放大的输入的谐波。二次、三次和更高次的谐波通常在放大器带宽之外，所以它们通常很容易过滤掉。然而，非线性也会产生两个或多个信号的混合效应。 如果信号的频率很接近，产生的一些称为互调产物（Intermodulation products）的和差频率会出现在放大器的预期工作带宽内。这些不能被过滤掉，所以它们最终会成为被放大的主要信号中的干扰信号。 举例来说：接收链中的期望输入信号（F0）在 1750MHz，两个不期望的信号，F1=1760，F2=1770，所以当两个不期望的信号混合时，它们会产生三阶互调产物，其中一个在（2*F1-F2）落在 1750MHz，这也是期望信号的频率，因此期望信号的 SNR 会降低。 三阶互调产物的功率水平取决于设备或放大器的线性度，以三阶截点（IP3）表示。 三阶截点（IP3）处的输出越高，线性度越好，互调扰动（IMD）越低。IP3 值本质上表明在 IMD 发生之前，放大器可以处理多大的信号。例如，IP3 值为 25 dBm 比 18 dBm 的要好。 为什么 IP3 在接收链中被测量 在接收链中，多个信号通过天线端口输入，由于干扰信号在天线端口的混合，产生的 IMD 会在所需的频段混合，从而影响所需信号的信噪比。我们无法控制天线端口的干扰信号，因为在空气中存在着不同频率的不同类型的信号。它们中的少数会在所需的频段上引起 IMD。 因此，测量接收器的三阶输入截点（IIP3）变得非常重要，以确保它产生多少影响信噪比的 IMD 水平。 接收器链的 IIP3 值越高，性能就越好，因为 IMD 功率水平更低。因此，它表明一个设备（如放大器）或系统（如接收器）在强信号下的表现如何。 发射器链中的 IP3 是什么？ 在发射链中，通常 IP3 规格不太重要，因为在发射链中产生的信号通常是单载波，不会产生 IMD。例如，在单载波 GSM 中，传输的是一个载波信号，不会产生 IMD。在多载波 GSM 中，会产生 IMD，因为发射链中的多个信号混合在一起，产生互调产物。在多载波系统中，发射器链中的输出截点被测量（OIP3）或发挥着重要作用。 在 LTE 系统中，只产生一个载波，所以 OIP3 就不那么重要了。在 LTE Advanced 中，由于载波聚合，会产生多个载波，所以 OIP3 在这种情况下很重要。 但是，即使在发射机链中产生了单载波，在任何情况下，干扰信号都可能通过天线端口以相反的方向进入发射机链而导致互调产物，所以通常在发射机链中测量反向互调。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/categories/SDR/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/tags/SDR/"}]},{"title":"Android 启动加载器分析 —— ABL(3)","slug":"android-bootloader-analysis-abl-3","date":"2021-10-24T22:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/10/24/android-bootloader-analysis-abl-3/","link":"","permalink":"https://blog.inoki.cc/2021/10/24/android-bootloader-analysis-abl-3/","excerpt":"","text":"我的前一篇文章《Android 启动加载器分析 —— ABL(1)》中分析了当代高通平台的 ABL 的整体启动流程，《Android 启动加载器分析 —— ABL(2)》对如何启动至 fastboot 模式进行详细的解释。本文将对 ABL 中启动至 Linux 内核的代码进行分析。 启动 Linux 内核的条件 若不是在启动至 fastboot 模式下、并且没有在启动时按下组合按键时，ABL 通过 LoadImageAndAuth (&amp;Info) 加载并验证内核（如果未解锁），并调用 BootLinux (&amp;Info) 来启动加载的内核，如果启动失败，则 fall-through 到 fastboot 模式。其中 Info 为一个 BootInfo 类型，定义如下： 12345678910111213141516typedef struct BootInfo &#123; BOOLEAN MultiSlotBoot; BOOLEAN BootIntoRecovery; BOOLEAN BootReasonAlarm; CHAR16 Pname[MAX_GPT_NAME_SIZE]; CHAR16 BootableSlot[MAX_GPT_NAME_SIZE]; ImageData Images[MAX_NUMBER_OF_LOADED_IMAGES]; UINTN NumLoadedImages; QCOM_VERIFIEDBOOT_PROTOCOL *VbIntf; boot_state_t BootState; CHAR8 *VBCmdLine; UINT32 VBCmdLineLen; UINT32 VBCmdLineFilledLen; VOID *VBData; UINT32 HeaderVersion;&#125; BootInfo; 其中 ImageData 结构为加载进来的启动镜像，定义如下： 12345typedef struct &#123; CHAR8 *Name; VOID *ImageBuffer; UINTN ImageSize;&#125; ImageData; 在加载和验证 Linux 内核时，镜像会先被加载到这里，之后在启动时，也是使用这里的镜像之一。 Linux 内核的验证与加载 验证与加载的函数 LoadImageAndAuth (BootInfo *Info) 的实现位于 QcomModulePkg/Library/avb/VerifiedBoot.c 中。这里 avb 的全称即为 Android Verified Boot。 这个函数首先尝试从 recovery 分区加载镜像，检测是否加载成功、以及是否有一个合法的启动镜像版本（要求第三版以上，为 system-as-root 所用的）和 kernel 大小： 123456789101112/* check early if recovery exists and has a kernel size */Status = LoadPartitionImageHeader (Info, (CHAR16 *)L\"recovery\", &amp;RecoveryHdr, &amp;RecoveryHdrSz);if (Status != EFI_SUCCESS) &#123;DEBUG ((EFI_D_VERBOSE, \"Recovery partition doesn't exist; continue normal boot\\n\"));&#125; else if (((boot_img_hdr *)(RecoveryHdr))-&gt;header_version &gt;= BOOT_HEADER_VERSION_THREE &amp;&amp; !((boot_img_hdr *)(RecoveryHdr))-&gt;kernel_size) &#123;DEBUG ((EFI_D_VERBOSE, \"Recovery partition has no kernel\\n\"));SetRecoveryHasNoKernel ();&#125; 若 recovery 分区没有一个合法的 kernel，则通过 SetRecoveryHasNoKernel () 设置 RecoveryHasNoKernel 全局标识以供之后使用。 接下来有两种情况，分别用来处理 A/B 分区存在与只存在单一分区的情况。 在单一分区情况下，也可能存在 system-as-root 的情况，即 recovery 模式和正常启动共用内核、但挂载不同的分区作为 sysroot。因此，以下代码设置启动用分区名称为 recovery 或 boot： 123456789101112131415if (Info-&gt;BootIntoRecovery &amp;&amp; !IsRecoveryHasNoKernel ()) &#123; DEBUG ((EFI_D_INFO, \"Booting Into Recovery Mode\\n\")); StrnCpyS (Info-&gt;Pname, ARRAY_SIZE (Info-&gt;Pname), L\"recovery\", StrLen (L\"recovery\"));&#125; else &#123; if (Info-&gt;BootIntoRecovery &amp;&amp; IsRecoveryHasNoKernel ()) &#123; DEBUG ((EFI_D_INFO, \"Booting into Recovery Mode via Boot\\n\")); &#125; else &#123; DEBUG ((EFI_D_INFO, \"Booting Into Mission Mode\\n\")); &#125; StrnCpyS (Info-&gt;Pname, ARRAY_SIZE (Info-&gt;Pname), L\"boot\", StrLen (L\"boot\"));&#125; 而 A/B 分区情况稍微复杂一些。首先 ABL 会寻找可启动的 slot（即为一套分区），将其存入 CurrentSlot 结构体中，定义如下： 123typedef struct &#123; CHAR16 Suffix[MAX_SLOT_SUFFIX_SZ];&#125; Slot; 这个结构体定义了分区的后缀。实际上，多个 slot 的实现正是通过分区名称加上一个后缀实现的，比如 boot_a 和 boot_b 为两个 slot 的启动分区。这个后缀由 FindBootableSlot 来获取。接下来的流程就和单一分区的类似。 获取到要使用的启动分区之后，就要开始对该分区的镜像的验证。镜像的验证是平台相关的，通过调用 GetAVBVersion () 取得版本，目前存在 NO_AVB、AVB_1、AVB_2 和 AVB_LE，分别用对应的函数调用来加载镜像和验证。 以无 AVB 验证为例，它直接使用 LoadImageNoAuth 加载镜像，在这个函数里 LoadImageHeader (Info-&gt;Pname, &amp;ImageHdrBuffer, &amp;ImageHdrSize) 被调用来把镜像加载到 buffer 中。在此期间，相应的 device tree 和命令行参数也被加载和设置。 最后就在屏幕上显示验证状态 DisplayVerifiedBootScreen (Info) 并返回镜像验证状态。 启动 Linux 内核 首先加载启动镜像： 123456789Status = GetImage (Info, &amp;BootParamlistPtr.ImageBuffer, (UINTN *)&amp;BootParamlistPtr.ImageSize, ((!Info-&gt;MultiSlotBoot || IsDynamicPartitionSupport ()) &amp;&amp; (Recovery &amp;&amp; !IsBuildUseRecoveryAsBoot () &amp;&amp; !IsRecoveryHasNoKernel ()))? \"recovery\" : \"boot\"); 更新启动内核用的命令行参数，获取加载的基址、加载内存盘。 之后关闭 UEFI 启动服务为启动 Linux 内核做准备，并在 PreparePlatformHardware 中取消一些设备的之前完成的初始化和配置，比如禁用中断、禁用缓存、禁用 MMU、禁用分支预测等： 1234567891011121314151617181920ArmDisableBranchPrediction ();ArmDisableInterrupts ();ArmDisableAsynchronousAbort ();WriteBackInvalidateDataCacheRange (KernelLoadAddr, KernelSizeActual);WriteBackInvalidateDataCacheRange (RamdiskLoadAddr, RamdiskSizeActual);WriteBackInvalidateDataCacheRange (DeviceTreeLoadAddr, DeviceTreeSizeActual);WriteBackInvalidateDataCacheRange ((void *)StackCurrent, (UINTN)StackBase - (UINTN)StackCurrent);WriteBackInvalidateDataCacheRange (CallerStackCurrent, CallerStackBase - (UINTN)CallerStackCurrent);ArmCleanDataCache ();ArmInvalidateInstructionCache ();ArmDisableDataCache ();ArmDisableInstructionCache ();ArmDisableMmu ();ArmInvalidateTlb (); 最后，加载并调用 Linux 内核： 12LinuxKernel = (LINUX_KERNEL) (UINT64)BootParamlistPtr.KernelLoadAddr;LinuxKernel ((UINT64)BootParamlistPtr.DeviceTreeLoadAddr, 0, 0, 0); 对 32 位内核，则为： 12LinuxKernel32 = (LINUX_KERNEL32) (UINT64)BootParamlistPtr.KernelLoadAddr;LinuxKernel32 (0, 0, (UINTN)BootParamlistPtr.DeviceTreeLoadAddr); 但在 32 位内核启动前，需要切换到 32 bit 的启动模式： 123Status = SwitchTo32bitModeBooting ( (UINT64)BootParamlistPtr.KernelLoadAddr, (UINT64)BootParamlistPtr.DeviceTreeLoadAddr); 具体实现为写入 0 到 EL1 环境下的 X4 寄存器： 12345HlosBootArgs.el1_x2 = DeviceTreeLoadAddr;/* Write 0 into el1_x4 to switch to 32bit mode */HlosBootArgs.el1_x4 = 0;HlosBootArgs.el1_elr = KernelLoadAddr;Status = pQcomScmModeSwitchProtocol-&gt;SwitchTo32bitMode (HlosBootArgs); 如果启动失败，则进入 CpuDeadLoop()。 总结 本文分析总结了 ABL 正常启动 Linux 时的代码与流程。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"Android 启动加载器分析 —— ABL(2)","slug":"android-bootloader-analysis-abl-2","date":"2021-10-22T13:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/10/22/android-bootloader-analysis-abl-2/","link":"","permalink":"https://blog.inoki.cc/2021/10/22/android-bootloader-analysis-abl-2/","excerpt":"","text":"我的前一篇文章《Android 启动加载器分析 —— ABL(1)》中分析了当代高通平台的 ABL 的整体启动流程，但并未对如何启动至 fastboot 模式和 Linux 内核进行详细的解释。本文将对 fastboot 模式的代码进行分析。 启动至 fastboot 模式的条件 在 ABL 中，当启动镜像验证失败、BootLinux (&amp;Info) 函数启动失败或者接收到启动至 fastboot 的命令（比如使用 adb 重启至 bootloader、在启动时按下了相应的组合按键）时，以下代码会被执行来初始化并执行 fastboot 模式： 123fastboot: DEBUG ((EFI_D_INFO, \"Launching fastboot\\n\")); Status = FastbootInitialize (); 初始化 fastboot 模式 初始化并执行 fastboot 模式的代码是 FastbootInitialize () 这个函数，它被定义在 QcomModulePkg/Library/FastbootLib/FastbootMain.c 中。它首先调用 FastbootUsbDeviceStart () 启动 USB 设备，这样就可以接收计算机传来的 fastboot 命令，然后调用 DisplayFastbootMenu () 显示 fastboot 的菜单。 然后进入一个接收 USB 的死循环处理 USB 事件，直到 fastboot 停止。之后则关闭 fastboot 模式、停止监听按键并停止 USB 设备。 12345678910/* Close the fastboot app and stop USB device */Status = FastbootCmdsUnInit ();if (Status != EFI_SUCCESS) &#123;DEBUG ((EFI_D_ERROR, \"couldnt uninit fastboot\\n\"));return Status;&#125;ExitMenuKeysDetection ();Status = FastbootUsbDeviceStop (); 返回后就会退出 fastboot 这个 app，再次启动设备。 启动 USB 设备 启动之前需要配置 USB 控制器，fastboot 首先使用 InitUsbControllerGuid 这个 GUID、通过在全局的 EFI_BOOT_SERVICES *gBS 实例来初始化一个 USB 控制器，代码如下： 12Status = gBS-&gt;CreateEventEx (EVT_NOTIFY_SIGNAL, TPL_CALLBACK, DummyNotify, NULL, &amp;InitUsbControllerGuid, &amp;UsbConfigEvt); 然后通过 UsbDeviceProtolGuid 寻找 fastboot 要使用的协议，存入 Fbd 的 UsbDeviceProtocol 字段中： 12Status = gBS-&gt;LocateProtocol (&amp;UsbDeviceProtolGuid, NULL, (VOID **)&amp;Fbd.UsbDeviceProtocol); 这个字段是一个 EFI_USB_DEVICE_PROTOCOL *UsbDeviceProtocol 的指针，其定义在 QcomModulePkg/Include/Protocol/EFIUsbDevice.h 中。 在这之后，fastboot 的命令和变量会被初始化，为接收到的命令准备相应的回调函数。 此时 USB 设备还未被完全注册，因此接下来需要注册设备并启动 USB 设备，包括获取 USB 可用的最大速度、USB 设备规范（包括 vendor ID 和 device ID 等）和设备描述符等。其实现在 QcomModulePkg/Library/FastbootLib/UsbDescriptor.c 中。 注意这时有 SS DevDescriptors/Descriptors 和 DevDescriptors/Descriptors 两种，分别是 Super Speed USB（3.X）和 High Speed USB（2.0）两套描述符。各种 USB 相关的描述符都定义在 MdePkg/Include/IndustryStandard/Usb.h 中，这里最重要的 USB_DEVICE_DESCRIPTOR 定义如下： 1234567891011121314151617181920////// Standard Device Descriptor/// USB 2.0 spec, Section 9.6.1///typedef struct &#123; UINT8 Length; UINT8 DescriptorType; UINT16 BcdUSB; UINT8 DeviceClass; UINT8 DeviceSubClass; UINT8 DeviceProtocol; UINT8 MaxPacketSize0; UINT16 IdVendor; UINT16 IdProduct; UINT16 BcdDevice; UINT8 StrManufacturer; UINT8 StrProduct; UINT8 StrSerialNumber; UINT8 NumConfigurations;&#125; USB_DEVICE_DESCRIPTOR; 配置好这些 descriptor 之后，调用前面创建的 USB protocol 来启动 USB 设备： 12/* Start the usb device */Status = Fbd.UsbDeviceProtocol-&gt;StartEx (&amp;DescSet); 最后，为发送和接收 USB transfer 数据创建缓冲。 注册 fastboot 命令 在启动 USB 设备之前，fastboot 内可用的命令和相关的变量由 EFI_STATUS FastbootCmdsInit (VOID) 来注册，这个函数在 QcomModulePkg/Library/FastbootLib/FastbootCmds.c 中。这个函数为 fastboot 相关命令创建缓冲区和多线程环境来调用回调，然后调用 FastbootCommandSetup 来创建可用的命令与变量： 12345678910111213/* By Default enable list is empty */ &#123;\"\", NULL&#125;,/*CAUTION(High): Enabling these commands will allow changing the partitions *like system,userdata,cachec etc... */#ifdef ENABLE_UPDATE_PARTITIONS_CMDS &#123;\"flash:\", CmdFlash&#125;, &#123;\"erase:\", CmdErase&#125;, &#123;\"set_active\", CmdSetActive&#125;, &#123;\"flashing get_unlock_ability\", CmdFlashingGetUnlockAbility&#125;, &#123;\"flashing unlock\", CmdFlashingUnlock&#125;, &#123;\"flashing lock\", CmdFlashingLock&#125;,#endif 这些基础的命令可以用来解锁、设置 A/B 分区的激活状态和刷写分区等。 1234567/* *CAUTION(CRITICAL): Enabling these commands will allow changes to bootimage. */#ifdef ENABLE_DEVICE_CRITICAL_LOCK_UNLOCK_CMDS &#123;\"flashing unlock_critical\", CmdFlashingUnLockCritical&#125;, &#123;\"flashing lock_critical\", CmdFlashingLockCritical&#125;,#endif 这两条命令是用来控制启动镜像区的刷写。 1234567/* *CAUTION(CRITICAL): Enabling this command will allow boot with different *bootimage. */#ifdef ENABLE_BOOT_CMD &#123;\"boot\", CmdBoot&#125;,#endif 这里注册的 fastboot boot &lt;image&gt; 命令可以启动自定义镜像。 12345&#123;\"oem enable-charger-screen\", CmdOemEnableChargerScreen&#125;,&#123;\"oem disable-charger-screen\", CmdOemDisableChargerScreen&#125;,&#123;\"oem off-mode-charge\", CmdOemOffModeCharger&#125;,&#123;\"oem select-display-panel\", CmdOemSelectDisplayPanel&#125;,&#123;\"oem device-info\", CmdOemDevinfo&#125;, 以上是 OEM 有关的设置和信息。 12345678910 &#123;\"continue\", CmdContinue&#125;, &#123;\"reboot\", CmdReboot&#125;,#ifdef DYNAMIC_PARTITION_SUPPORT &#123;\"reboot-recovery\", CmdRebootRecovery&#125;, &#123;\"reboot-fastboot\", CmdRebootFastboot&#125;,#ifdef VIRTUAL_AB_OTA &#123;\"snapshot-update\", CmdUpdateSnapshot&#125;,#endif#endif &#123;\"reboot-bootloader\", CmdRebootBootloader&#125;, 这是重启和启动相关的命令。 12&#123;\"getvar:\", CmdGetVar&#125;,&#123;\"download:\", CmdDownload&#125;, 最后的 getvar 命令可以获取设备在 fastboot 模式中相关的变量，而变量的发布则使用 FastbootPublishVar (key, value)。 在 fastboot 模式中的事件循环 一般情况下，在 fastboot 中会有三个主要的事件循环： 接收按键事件更新 fastboot 菜单（在 VOID DisplayFastbootMenu (VOID) 中绘制并创建，在 QcomModulePkg/Library/BootLib/FastbootMenu.c 中定义 ）； 通过 USB 接收计算机的 fastboot 发来的命令（在注册 fastboot 时创建）； 主循环调用 HandleUsbEvents () 监听 USB 设备的通知，包括设备连接等事件。 结论 本文分析总结了 ABL 在 fastboot 模式下的代码与流程。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"通过 Linux sysfs 玩转硬件","slug":"linux-sysfs-playground","date":"2021-10-20T19:34:00.000Z","updated":"2025-03-08T09:40:48.609Z","comments":true,"path":"2021/10/20/linux-sysfs-playground/","link":"","permalink":"https://blog.inoki.cc/2021/10/20/linux-sysfs-playground/","excerpt":"","text":"对于一些非嵌入式、离硬件比较远的程序员，与硬件有关的事情可能完全是一个黑匣子：我只需要插上 USB 线缆、插上 HDMI 线缆，就可以把硬件连接到计算机；我只需要按一个按键，就可以调节屏幕的亮度。作为一个程序员或者计算机爱好者，我有没有可能自己写一些代码 snippets 来完成一些自定义的事情呢？ 本文就将介绍如何通过 Linux 系统的 sysfs 模块、用一些简单的代码/shell 操作硬件。 硬件、Linux 系统与 sysfs 模块 操作系统是计算机硬件和用户之间的接口，它可以处理计算机硬件资源并为计算机程序提供基本服务，驱动硬件是它所拥有的一个很重要的功能。下图显示了操作系统内核所在的位置：它作为硬件和 shell、应用程序之间的一层，提供接口。 根据 Linux 的手册，sysfs 文件系统是一个伪文件系统，它提供了一个内核数据结构的接口。这个文件系统的文件并不是真实存在在硬盘上的文件，它提供有关设备、内核模块、文件系统和其他内核组件的信息，对这里的文件的读写就是对内核中对象的操作。 硬件驱动是 Linux 内核的一部分，过去是被静态编译到内核中，而在当代的 Linux 系统中大部分驱动程序都可以被编译成内核模块（kernel module）、动态加载到内核中。当设备插入时，内核会创建一个内核对象，并为对对象的操作设置对应驱动中的回调函数。这个对象也会被映射到 sysfs 中。 sysfs 的结构 在 Linux 中，sysfs 一般会被自动挂载到 /sys 目录下。我的计算机在该目录下有以下子目录： 1block bus class dev devices firmware fs hypervisor kernel module power 有块设备、按总线分类、按设备类别分类、文件系统、内核模块等。 我个人比较常用的是 class，在这个目录下，设备按照所属的类别分类： 可以看到，有 backlight 背光设备、bluetooth 蓝牙设备、input 输入设备、leds 灯、tty 等。 它们的子目录是一些具体的设备对应的目录（如果有相应设备被内核驱动起来的话），在这些目录里往往有一些可以读写的文件，这些文件对应着设备在内核中的状态。 写 sysfs 的文件对象调节显示器亮度 如果你拥有一台带有 Intel 集成显卡的笔记本，且安装了一个带 GUI 的 Linux 发行版，那大概率使用的是 i915 或者 i965 驱动。在 /sys/class/backlight/intel_backlight 下就会有以下文件： 其中 brightness 为一个 root 可读可写的文件，通过它可以设置屏幕亮度；max_brightness 为一个 root 可读的文件，它储存了可以设置的最大屏幕亮度。因此，我们可以用一个简单的 shell 脚本读取期望亮度百分比、允许的最大亮度，并将计算结果写入 brightness 来设置屏幕亮度百分比： 123456789#!/bin/bashecho \"请输入您想要的亮度百分比:\"read expected_brightnessecho $expected_brightnessmax_brightness=$(cat /sys/class/backlight/intel_backlight/max_brightness)echo $(expr $expected_brightness \\* $max_brightness \\/ 100) &gt; /sys/class/backlight/intel_backlight/brightness 之后，使用 sudo 运行这个脚本（写入 brightness 文件需要 root 用户身份）并输入你期望的百分比（注意：为了保持简短，这个脚本没有对输入值进行任何判断，take your own risk），效果如下： 这时我的屏幕背光亮度就被设置为了 15%。 当然，你也可以用 C 语言、Python 或者任何你喜欢的语言，通过读写 sysfs 下的文件控制一些硬件。这都取决于你的想法和创意了！ 注：如果你使用的是其他显卡、或者外接显示器，能否有效果就取决于具体的硬件了。 结论 本文粗略介绍了 Linux 系统的 sysfs 模块的概念和用法，并提供了一个简单的脚本来设置显示屏的背光。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"sysfs","slug":"Linux/sysfs","permalink":"https://blog.inoki.cc/categories/Linux/sysfs/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Linux Driver","slug":"Linux-Driver","permalink":"https://blog.inoki.cc/tags/Linux-Driver/"},{"name":"sysfs","slug":"sysfs","permalink":"https://blog.inoki.cc/tags/sysfs/"}]},{"title":"Android bootloader analysis -- ABL(1)","slug":"android-bootloader-analysis-abl-1-en","date":"2021-10-18T19:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/10/18/android-bootloader-analysis-abl-1-en/","link":"","permalink":"https://blog.inoki.cc/2021/10/18/android-bootloader-analysis-abl-1-en/","excerpt":"","text":"In my previous article “Android Bootloader Analysis – Aboot”, I analyzed the overall boot flow and corresponding code of the previous generation of Aboot for Qualcomm platforms. After 2016, the PBL of the MSM8996 (Snapdragon 820) platform loads the new XBL, followed by a chain load of ABL or Aboot (only for the MSM8996 platform where the XBL is not yet mature), which is a boot loader built on EDK II to replace Aboot, which can choose to stay in It can choose to stay in fastboot, boot to Android using the system kernel and ramdisk in the system directory, or boot to Recovery using the recovery ramdisk, depending on key combinations. This article describes the code organization and general boot process of ABL. Due to space limitation, the code analysis for booting Linux and fastboot will be published in separate articles. Code Organization The Qualcomm ABL source code can be found at Code Aurora Forum. The ABL is built on EDK II and the overall project structure is the standard EDK II source tree. This article uses the uefi.lnx.3.0.r1 branch as written for analysis, committed as c4da6fcb959fa67cb2aa89007beebfab66226268. In the Makefile of the project, the two most important build targets are 12ABL_FV_IMG := $(BUILD_ROOT)/FV/abl.fvABL_FV_ELF := $(BOOTLOADER_OUT)/... /... /unsigned_abl.elf Of these, ABL_FV_IMG is the most important build target, which is the firmware (fv, firmware) built from QcomModulePkg. 12345ABL_FV_IMG: EDK_TOOLS_BIN @. . /edksetup.sh BaseTools &amp;&amp; \\ build -p $(WORKSPACE)/QcomModulePkg/QcomModulePkg.dsc cp $(BUILD_ROOT)/FV/FVMAIN_COMPACT.Fv $(ABL_FV_IMG) Whereas ABL_FV_ELF just calls QcomModulePkg/Tools/image_header.py to convert abl.fv to an ELF file that can be flushed to the abl partition in the device’s EMMC or flash memory. In QcomModulePkg, the firmware entry is FV.FVMAIN_COMPACT, which contains FV.FVMAIN, a module that encapsulates the base ARM stack, MMU, and other components provided by EDK II, and contains QcomModulePkg/Application/ LinuxLoader/LinuxLoader.inf, a Linux loader, is used to boot the firmware and load the Android Linux kernel on the ARM platform. This LinuxLoader is a UEFI application and its program entry point is defined as follows. 1ENTRY_POINT = LinuxLoaderEntry It contains some modules from EDK II. 1234567[Packages] ArmPkg/ArmPkg.dec MdePkg/MdePkg.dec EmbeddedPkg/EmbeddedPkg.dec ArmPlatformPkg/ArmPlatformPkg.dec MdeModulePkg/MdeModulePkg.dec QcomModulePkg/QcomModulePkg.dec In the Library of QcomModulePkg, there are FastbootLib, BootLib, zlib, etc. The implementation of Fastboot is in FastbootLib, while BootLib contains the specific implementation for booting the Linux kernel, and zlib because Linux kernels are sometimes compressed. Boot process In the LinuxLoaderEntry entry point function, the program first calls some basic platform code to set up the environment, then gets the boot verification status and device status with DeviceInfoInit (), then uses EnumeratePartitions () and UpdatePartitionEntries () to get and update the partition information. If there is more than one boot slot (in this case, Android devices with A/B partitions, where A and B are generally two slots), find the activated slot and record it. Next, it gets the keystroke status and sets the boot to fastboot flag when SCAN_DOWN is pressed, SCAN_UP for boot to recovery, and SCAN_ESC for reboot to Emergency Download (EDL) mode. The program then gets the reason for the reboot and sets the appropriate flag. When not booting to fastboot, the boot image is loaded and verified, and if it is loaded and verified successfully, BootLinux (&amp;Info) is called to boot the Linux kernel. Otherwise, call FastbootInitialize () to initialize and run fastboot. Summary This article has analyzed the project structure and overall boot process of ABL. In the next article, we will discuss the code flow for booting Linux normally (also including recovery booting).","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"Android 启动加载器分析 —— ABL(1)","slug":"android-bootloader-analysis-abl-1","date":"2021-10-18T19:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/10/18/android-bootloader-analysis-abl-1/","link":"","permalink":"https://blog.inoki.cc/2021/10/18/android-bootloader-analysis-abl-1/","excerpt":"","text":"我的前一篇文章《Android 启动加载器分析 —— Aboot》中分析了高通平台前代的 Aboot 的整体启动流程和相应的代码。 在 2016 年之后，MSM8996（Snapdragon 820）平台的 PBL 加载全新的 XBL，紧接着链式加载 ABL 或 Aboot（仅对于 XBL 还未成熟的 MSM8996 平台），这个程序是基于 EDK II 构建的用来替换 Aboot 的启动加载器，它可以根据按键组合选择留在 fastboot、使用系统 kernel 和在系统目录的 ramdisk 启动到 Android 系统、或是使用 recovery 的 ramdisk 启动到 Recovery。 本文介绍 ABL 的代码组织和大致启动流程，由于篇幅限制，对于启动 Linux 和 fastboot 的代码解析将会单独发各自的文章。 代码组织 高通平台的 ABL 源码可以在 Code Aurora Forum 处找到。 ABL 是基于 EDK II 构建的，整体的项目结构是标准的 EDK II 源码树。本文使用成文时的 uefi.lnx.3.0.r1 分支来分析，提交为 c4da6fcb959fa67cb2aa89007beebfab66226268。 在项目的 Makefile 中，最重要的两个构建目标是： 12ABL_FV_IMG := $(BUILD_ROOT)/FV/abl.fvABL_FV_ELF := $(BOOTLOADER_OUT)/../../unsigned_abl.elf 其中，ABL_FV_IMG 是最重要的构建目标，它是从 QcomModulePkg 构建的 firmware（fv，固件）： 12345ABL_FV_IMG: EDK_TOOLS_BIN @. ./edksetup.sh BaseTools &amp;&amp; \\ build -p $(WORKSPACE)/QcomModulePkg/QcomModulePkg.dsc cp $(BUILD_ROOT)/FV/FVMAIN_COMPACT.Fv $(ABL_FV_IMG) 而 ABL_FV_ELF 则只是调用 QcomModulePkg/Tools/image_header.py 来把 abl.fv 转换为一个 ELF 文件，可以刷写到设备的 EMMC 或闪存中的 abl 分区。 在 QcomModulePkg 中，固件的入口是 FV.FVMAIN_COMPACT，它包含了 FV.FVMAIN，在这个模块里，囊括了 EDK II 提供的基础 ARM 栈、MMU 等组件，并包含了 QcomModulePkg/Application/LinuxLoader/LinuxLoader.inf 这个 Linux 的加载器，用来在 ARM 平台上将这个固件启动并加载 Android 的 Linux 内核。 这个 LinuxLoader 是一个 UEFI 应用程序，它的程序入口点定义如下： 1ENTRY_POINT = LinuxLoaderEntry 它包含了 EDK II 中的一些模块： 1234567[Packages] ArmPkg/ArmPkg.dec MdePkg/MdePkg.dec EmbeddedPkg/EmbeddedPkg.dec ArmPlatformPkg/ArmPlatformPkg.dec MdeModulePkg/MdeModulePkg.dec QcomModulePkg/QcomModulePkg.dec 其中，在 QcomModulePkg 的 Library 中，有 FastbootLib、BootLib、zlib 等库，Fastboot 的实现就在 FastbootLib 中，而 BootLib 中包含了启动 Linux 内核的具体实现，至于 zlib 则是因为 Linux 内核有时是被压缩了的。 启动流程 在 LinuxLoaderEntry 入口点的函数中，程序首先调用一些基础的平台代码设置环境，然后通过 DeviceInfoInit () 获取启动验证状态和设备状态，再使用 EnumeratePartitions () 和 UpdatePartitionEntries () 获取并更新分区信息。 如果存在多个启动 slot 的话（这里指有 A/B 分区的 Android 设备，其中 A 和 B 一般即为两个 slot），就寻找已激活的 slot 并记录。 紧接着获取按键状态，在 SCAN_DOWN 按下时设置启动至 fastboot 的标识，SCAN_UP 为启动至 recovery 的表示，而 SCAN_ESC 按下时则重启设备至 Emergency Download（EDL）模式。然后程序获取重启的原因并设置相应标识。 在不启动至 fastboot 时，加载并验证启动镜像，若加载并验证成功，则调用 BootLinux (&amp;Info) 启动 Linux 内核。否则调用 FastbootInitialize () 初始化并运行 fastboot。 构建 构建 EDK II 的基础工具需要主机指令集的 GCC 工具集，而 QcomModulePkg 需要 LLVM 和 CLANG，因此需要安装这两个工具。之后使用以下命令编译： 1CLANG_PREFIX=aarch64-linux-gnu- PYTHON_COMMAND=python2 make 这里由于我的系统 python 指向的是 python3，而 EDK II 基础工具集需要 python2，因此我指定了使用 python2 为默认的解释器。 总结 本文分析了 ABL 的项目结构和整体启动流程。下篇文章中会讨论正常启动 Linux（也包含 recovery 的启动）的代码流程。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"}]},{"title":"Android bootloader analysis -- Aboot","slug":"android-bootloader-analysis-aboot-en","date":"2021-10-17T10:48:00.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/10/17/android-bootloader-analysis-aboot-en/","link":"","permalink":"https://blog.inoki.cc/2021/10/17/android-bootloader-analysis-aboot-en/","excerpt":"","text":"There are already many articles that explain the boot process of Android on Qualcomm platform. From my translation of [Translation] Qualcomm Android device boot chain of trust, it can be summarized as follows. Aboot: Before MSM8994 (Snapdragon 810), the device first loads Qualcomm’s bootrom (PBL) and SBL to initialise some hardware, and immediately hands over to Aboot, an application built on top of the LittleKernel system, which contains fastboot and enables When using the adb reboot bootloader, this is where it boots and stays in in fastboot. XBL/ABL: After the MSM8996 (Snapdragon 820), PBL loads the new XBL, followed by a chain load of ABL, which is a bootloader built on EDK II to replace Aboot (in fact, on the MSM8996 platform, Aboot is still used because XBL and ABL are not mature enough, with XBL It can choose to boot into Android using fastboot, the system kernel and ramdisk in the system directory, or the recovery ramdisk, depending on the keystroke combination. For both boot modes, the source code for Aboot and ABL can be found on Google or at the Code Aurora Forum(CAF): CAF Aboot: https://source.codeaurora.org/quic/la/kernel/lk/ CAF ABL: https://source.codeaurora.org/quic/la/abl/tianocore/edk2/ Note that the Qualcomm maintained projects have been hosted on https://git.codelinaro.org/ since 2022 As you can see, the source tree of Aboot is named lk, short for LittleKernel, which is a small symmetric multiprocessing (SMP) operating system kernel, and Aboot is a device-related application built on top of this operating system. This article will briefly analyze the source code of Aboot as an application (excluding encryption and image verification), and cover some of the device-related code. Code Organization The CAF Aboot commit d37db810993015ea77cc5231a95250b250f4eb07 (the master branch commit at the time of writing) is used here for reference. As an application, the source code of Aboot is in app/aboot/, and the core files are aboot.c and fastboot.c, in addition to some auxiliary code that shows hardware-related information. Depending on the SoC, hardware-related code and definitions are located in platform/ and target/, and most of the device drivers are located in dev/. And arch is the architecture related code and kernel is the actual lk kernel code. Overview During the boot process, lk is loaded, and after the architecture and platform-related initialization, the Aboot application is started. In the aboot.c code, the following code registers Aboot as an application and uses aboot_init as the entry point. 123APP_START(aboot) .init = aboot_init,APP_END In this function, the device’s storage device type is detected as EMMC or flash, and two global variables page_size and page_mask are set according to the corresponding page size, which are later used to determine the size of the kernel, ramdisk, and other components loaded from the storage device. The device base information and oem unlock information is then read and stored in the following structs. 1234567891011struct device_info&#123; unsigned char magic[DEVICE_MAGIC_SIZE]; bool is_unlocked; bool is_tampered; bool is_verified; bool charger_screen_enabled; char display_panel[MAX_PANEL_ID_LEN]; char bootloader_version[MAX_VERSION_LEN]; char radio_version[MAX_VERSION_LEN];&#125;; Then initialize the screen (if any), read the device serial number according to the device definition. Immediately afterwards, the boot mode is determined. If it is force reset (usually a long press of the power button to reboot), it goes directly to normal system boot, otherwise it goes to detect the key. If the volume up and down keys are pressed simultaneously (i.e. keys_get_state(KEY_VOLUMEUP) &amp;&amp; keys_get_state(KEY_VOLUMEDOWN)), the device is rebooted and enters Qualcomm’s dload mode. If the Volume Up key or Home key is pressed, mark it as entering recovery mode. If the Volume Down key or Back key is pressed, the device is marked as entering fastboot mode. If there is a pre-set reboot mode (e.g., set by adb reboot), boot into the appropriate mode. Finally, check if any fastboot boot mode flag is set, if not, set the partition where the image used for booting is located according to the recovery flag and boot to Linux from EMMC or flash memory (call function boot_linux_from_xxxx()), otherwise leave it in Aboot, register the commands available for fastboot and initialize fastboot. Boot Linux normally (including Recovery) In both normal boot and boot-to-Recovery modes, Aboot loads the kernel and ramdisk from the partition used for booting (typically the boot partition for normal boot and the recovery partition for Recovery mode). A normal boot image consists of a header that stores meta information, and the rest of the image is used to store the kernel, ramdisk, and other components. When the image is flushed, the start of the partition should be read into the following structure. 123456789101112131415161718192021222324struct boot_img_hdr&#123; unsigned char magic[BOOT_MAGIC_SIZE]; unsigned kernel_size; /* size in bytes */ unsigned kernel_addr; /* physical load addr */ unsigned ramdisk_size; /* size in bytes */ unsigned ramdisk_addr; /* physical load addr */ unsigned second_size; /* size in bytes */ unsigned second_addr; /* physical load addr */ unsigned tags_addr; /* physical addr for kernel tags */ unsigned page_size; /* flash page size we assume */ unsigned dt_size; /* device_tree in bytes */ unsigned unused; /* future expansion: should be 0 */ unsigned char name[BOOT_NAME_SIZE]; /* asciiz product name */ unsigned char cmdline[BOOT_ARGS_SIZE]; unsigned id[8]; /* timestamp / checksum / sha1 / etc */&#125;; where kernel_size and ramdisk_size are the size of the kernel and ramdisk to be loaded, and the corresponding xxx_addr is the physical address of the memory to be loaded into (depending on the configuration and device). Before going through the loading of the kernel, ramdisk (and possibly device tree and secondary bootloader, which are ignored here for now), if the device is not unlocked, the kernel needs to be verified and loaded if it passes the verification, for devices that are already unlocked, Aboot will load them directly. Then call the boot_linux function with the read and prepared arguments to prepare the kernel for booting. 123boot_linux((void *)hdr-&gt;kernel_addr, (void *)hdr-&gt;tags_addr, (const char *)hdr-&gt;cmdline, board_machtype(), (void *)hdr-&gt;ramdisk_addr, hdr-&gt;ramdisk_size); In this function, Aboot first updates the kernel’s command line parameters based on the device, such as the type of device to add to the baseband, the type of storage device, and so on. Then the device tree (if it exists) is updated according to the parameters. The hardware needs to be managed by the kernel, so lk will first turn off some hardware: `target_display Shutting down the display with target_display_shutdown(). call target_uninit() to cancel the hardware initialization performed in lk. call enter_critical_section() to disable device interrupts. initialize Watchdog to monitor for early kernel crashes msm_wdog_init(). call platform_uninit() to clean up platform initialization performed by previous lk. Explicitly invalidate the cache arch_disable_cache(UCACHE) and turn off the memory management unit (MMU) arch_disable_mmu(). Finally, check if the Magic Number of the kernel is 64-bit, so that you can enter the kernel via scm_elexec_call, otherwise you can enter the 32-bit kernel directly in 32-bit mode. Entering fastboot mode If you boot into fastboot, you will first call aboot_fastboot_register_commands() to register the available fastboot commands, and then use fastboot_init to initialize and enter fastboot mode. Note that we will still be in Aboot here, and fastboot is part of Aboot, so to speak. Entering fastboot mode If you boot into fastboot, you will first call aboot_fastboot_register_commands() to register the available fastboot commands, and then use fastboot_init to initialize and enter fastboot mode. Note that we will still be in Aboot here, and fastboot is part of Aboot, so to speak. Registering the fastboot command When registering commands, fastboot_register is a very important function that accepts commands and callback functions as arguments. In this version, the available commands are. 123456789101112131415&#123;\"flash:\", cmd_flash&#125;,&#123;\"erase:\", cmd_erase&#125;,&#123;\"boot\", cmd_boot&#125;,&#123;\"continue\", cmd_continue&#125;,&#123;\"reboot\", cmd_reboot&#125;,&#123;\"reboot-bootloader\", cmd_reboot_bootloader&#125;,&#123;\"oem unlock\", cmd_oem_unlock&#125;,&#123;\"oem unlock-go\", cmd_oem_unlock_go&#125;,&#123;\"oem lock\", cmd_oem_lock&#125;,&#123;\"oem verified\", cmd_oem_verified&#125;,&#123;\"oem device-info\", cmd_oem_devinfo&#125;,&#123;\"preflash\", cmd_preflash&#125;,&#123;\"oem enable-charger-screen\", cmd_oem_enable_charger_screen&#125;, &#123;\"oem enable-charger-screen\", cmd_oem_enable_charger_screen&#125;,&#123;\"oem disable-charger-screen\", cmd_oem_disable_charger_screen&#125;, &#123;\"oem disable-charger-screen\", cmd_oem_disable_charger_screen&#125;,&#123;\"oem select-display-panel\", cmd_oem_select_display_panel&#125;, In addition, fastboot_publish can add some variables that can be considered as fastboot’s environment variables. Initialize and enter fastboot The fastboot_init function that is called is defined in fastboot.c. 1int fastboot_init(void *base, unsigned size); It first calls target_fastboot_init() to initialize the hardware of a particular device, more importantly the USB interface. This is a device-specific function, for example for the MSM8974 device, it is implemented as follows. 12345678910void target_fastboot_init(void)&#123; /* Set the BOOT_DONE flag in PM8921 */ pm8x41_set_boot_done();#ifdef SSD_ENABLE clock_ce_enable(SSD_CE_INSTANCE_1); ssd_load_keystore_from_emmc();#endif&#125; Located in target/msm8974/init.c. After this, the USB hardware should be set up, and Aboot then configures and initializes a USB UDC device on the USB interface to receive and send fastboot-related USB packets. Finally, create a lk thread to handle fastboot-related events and initialize the USB interface to receive fastboot commands. Conclusion This article briefly describes and analyzes the implementation of the Aboot boot loader for Android based on the lk kernel prior to 2016, but does not go too far into how lk is built and set up for a particular platform or architecture. We hope you find this helpful. Additions Note that both ARM32 and AArch64 devices run lk and its application Aboot in 32-bit mode, and it is only when the kernel is loaded that the kernel is determined to be 32-bit or 64-bit, and then the kernel is booted in the appropriate boot mode. At load time, Aboot uses the VA() macro to map the physical address to the virtual address read by lk and loads the kernel to that address, as the MMU may exist.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"},{"name":"Aboot","slug":"Aboot","permalink":"https://blog.inoki.cc/tags/Aboot/"}]},{"title":"Android 启动加载器分析 —— Aboot","slug":"android-bootloader-analysis-aboot","date":"2021-10-17T10:48:00.000Z","updated":"2025-03-08T09:40:48.608Z","comments":true,"path":"2021/10/17/android-bootloader-analysis-aboot/","link":"","permalink":"https://blog.inoki.cc/2021/10/17/android-bootloader-analysis-aboot/","excerpt":"","text":"已经有很多文章解析过 Android 在高通平台的启动流程了。从我翻译的【译】高通 Android 设备的启动信任链中，可以总结为下： Aboot：在 MSM8994（Snapdragon 810）之前，设备首先加载高通的 bootrom（PBL）和 SBL 来初始化一些硬件，紧接着交给 Aboot，这个程序是在 LittleKernel 系统的基础上构建的一个应用程序，它包含了 fastboot，可以实现正常启动 boot 分区的镜像（包含 Linux Kernel 和 ramdisk）、或是根据特定按键组合启动 recovery 中的镜像（一般为 recovery）或留在 Aboot 中的 Fastboot。当使用 adb reboot bootloader 时，就是启动到这里并停留在 fastboot 中； XBL/ABL：在 MSM8996（Snapdragon 820）之后，PBL 加载全新的 XBL，紧接着链式加载 ABL，这个程序是基于 EDK II 构建的用来替换 Aboot 的启动加载器（实际上在 MSM8996 平台，由于 XBL 和 ABL 不够成熟，仍使用 Aboot，由 XBL 来对其进行加载），它可以根据按键组合选择留在 fastboot、使用系统 kernel 和在系统目录的 ramdisk 启动到 Android 系统、或是使用 recovery 的 ramdisk 启动到 Recovery。 这两种启动模式中，Aboot 和 ABL 的源码都可以在 Google 或是 Code Aurora Forum 处找到： CAF Aboot：https://source.codeaurora.org/quic/la/kernel/lk/ CAF ABL：https://source.codeaurora.org/quic/la/abl/tianocore/edk2/ 可以看到，Aboot 的源码树名为 lk，即 LittleKernel 的简称，它是一个对称多处理（SMP）的小型操作系统内核，而 Aboot 是在这个操作系统的基础上构建的一个设备相关的应用程序。本文将对 Aboot 作为应用程序部分的源码进行简要分析（不包括加密与镜像验证），并涉及一部分设备相关代码。 代码组织 这里使用 CAF Aboot 中 commit d37db810993015ea77cc5231a95250b250f4eb07（在成文时的 master 分支提交）为参考。 作为一个应用程序，Aboot 的源码在 app/aboot/ 中，核心文件为 aboot.c 和 fastboot.c，除此之外其中还有一些显示硬件相关的辅助代码。根据 SoC 不同，硬件相关的代码和定义分布在 platform/ 和 target/ 中，大部分设备驱动都位于 dev/ 中。而 arch 为架构相关代码，kernel 为实际的 lk 内核代码。 整体流程 启动过程中，lk 被加载，完成架构和平台相关的初始化之后，启动 Aboot 这个应用程序。在 aboot.c 代码中，以下代码注册 Aboot 为一个应用程序，并将 aboot_init 作为入口： 123APP_START(aboot) .init = aboot_init,APP_END 在这个函数中，会检测设备的储存设备类型为 EMMC 还是闪存，并根据相应的 page 大小设置 page_size 和 page_mask 两个全局变量，这两个变量在之后用于确定从储存设备中加载的内核、ramdisk 等组件的大小。 然后读取设备的基础信息和 oem 解锁信息，储存到以下结构体中： 1234567891011struct device_info&#123; unsigned char magic[DEVICE_MAGIC_SIZE]; bool is_unlocked; bool is_tampered; bool is_verified; bool charger_screen_enabled; char display_panel[MAX_PANEL_ID_LEN]; char bootloader_version[MAX_VERSION_LEN]; char radio_version[MAX_VERSION_LEN];&#125;; 然后根据设备定义初始化屏幕（如果有的话）、读取设备序列号。 紧接着就进入启动模式的确定： 如果是 force reset（一般为长按电源键重启），则直接进入正常系统启动，否则会去检测按键； 如果是音量上下键同时按下（即 keys_get_state(KEY_VOLUMEUP) &amp;&amp; keys_get_state(KEY_VOLUMEDOWN)），则重启设备并进入高通的 dload 模式； 如果音量上键或者 Home 键被按下，标记为进入 recovery 模式； 如果音量下键或者 Back 键被按下，标记为进入 fastboot 模式； 如果有预先设置的 reboot 模式（比如 adb reboot 设置的），则启动到相应的模式； 最后，检测是否有 fastboot 启动模式的标记被设置了，如果没有，则根据 recovery 的标记设置启动所用的镜像所在分区，并从 EMMC 或闪存启动到 Linux（调用函数 boot_linux_from_xxxx()），否则就留在 Aboot 中，注册 fastboot 可用的命令并初始化 fastboot。 正常启动 Linux（包括 Recovery） 在正常启动和启动至 Recovery 两种模式下，Aboot 都会从启动所用分区（对正常启动来说一般为 boot 分区，而 Recovery 模式为 recovery 分区）加载内核和 ramdisk。 一个正常的启动镜像由 header 储存元信息，剩下的部分用来存放内核、ramdisk 等组件。当刷入镜像时，分区的开始应当可以被读取到以下结构中： 123456789101112131415161718192021222324struct boot_img_hdr&#123; unsigned char magic[BOOT_MAGIC_SIZE]; unsigned kernel_size; /* size in bytes */ unsigned kernel_addr; /* physical load addr */ unsigned ramdisk_size; /* size in bytes */ unsigned ramdisk_addr; /* physical load addr */ unsigned second_size; /* size in bytes */ unsigned second_addr; /* physical load addr */ unsigned tags_addr; /* physical addr for kernel tags */ unsigned page_size; /* flash page size we assume */ unsigned dt_size; /* device_tree in bytes */ unsigned unused; /* future expansion: should be 0 */ unsigned char name[BOOT_NAME_SIZE]; /* asciiz product name */ unsigned char cmdline[BOOT_ARGS_SIZE]; unsigned id[8]; /* timestamp / checksum / sha1 / etc */&#125;; 其中 kernel_size 和 ramdisk_size 是要加载的内核和 ramdisk 的大小，对应的 xxx_addr 是需要加载到的内存的物理地址（取决于配置和设备）。 在经过内核、ramdisk（也可能有 device tree 和 secondary bootloader，这里暂时忽略）的加载前，若设备未解锁，则需要验证内核并在验证通过的情况加载，对于已经解锁的设备，Aboot 会直接加载。 然后使用读取的和准备好的参数调用 boot_linux 函数准备启动内核。 123boot_linux((void *)hdr-&gt;kernel_addr, (void *)hdr-&gt;tags_addr, (const char *)hdr-&gt;cmdline, board_machtype(), (void *)hdr-&gt;ramdisk_addr, hdr-&gt;ramdisk_size); 在这个函数中，Aboot 会先根据设备更新内核的命令行参数，比如加入基带的设备类型、储存设备类型等。然后根据参数更新 device tree（如果存在）。 之后就要准备启动内核了，硬件需要由内核管理，因此 lk 会先将一些硬件关闭： 使用 target_display_shutdown() 关闭显示； 调用 target_uninit() 取消 lk 中进行的硬件初始化； 调用 enter_critical_section() 禁用设备中断； 初始化 Watchdog 来监控早期的内核崩溃 msm_wdog_init()； 调用 platform_uninit() 清理之前 lk 进行的的平台初始化； 显式让缓存失效 arch_disable_cache(UCACHE) 并关闭内存管理单元（MMU）arch_disable_mmu()。 最后，检测内核的 Magic Number 是否为 64 位，从而通过 scm_elexec_call 进入内核，否则直接以 32 位模式进入 32 位内核。 进入 fastboot 模式 如果启动至 fastboot，会先调用 aboot_fastboot_register_commands() 注册可用的 fastboot 命令，然后使用 fastboot_init 初始化并进入 fastboot 模式。注意，这里我们仍会在 Aboot 中，可以说 fastboot 是 Aboot 的一部分。 注册 fastboot 命令 在注册命令时，fastboot_register 是一个很重要的函数，它接受命令和回调函数作为参数。在这个版本中，可用的命令有： 123456789101112131415&#123;\"flash:\", cmd_flash&#125;,&#123;\"erase:\", cmd_erase&#125;,&#123;\"boot\", cmd_boot&#125;,&#123;\"continue\", cmd_continue&#125;,&#123;\"reboot\", cmd_reboot&#125;,&#123;\"reboot-bootloader\", cmd_reboot_bootloader&#125;,&#123;\"oem unlock\", cmd_oem_unlock&#125;,&#123;\"oem unlock-go\", cmd_oem_unlock_go&#125;,&#123;\"oem lock\", cmd_oem_lock&#125;,&#123;\"oem verified\", cmd_oem_verified&#125;,&#123;\"oem device-info\", cmd_oem_devinfo&#125;,&#123;\"preflash\", cmd_preflash&#125;,&#123;\"oem enable-charger-screen\", cmd_oem_enable_charger_screen&#125;,&#123;\"oem disable-charger-screen\", cmd_oem_disable_charger_screen&#125;,&#123;\"oem select-display-panel\", cmd_oem_select_display_panel&#125;, 除此之外，fastboot_publish 可以添加一些变量，可以说是 fastboot 的环境变量。 初始化并进入 fastboot 调用的 fastboot_init 函数定义在 fastboot.c 中： 1int fastboot_init(void *base, unsigned size); 其首先调用 target_fastboot_init() 初始化特定设备的硬件，比较重要的是 USB 接口。这是一个设备特定的函数，比如对于 MSM8974 设备，它的实现如下： 12345678910void target_fastboot_init(void)&#123; /* Set the BOOT_DONE flag in PM8921 */ pm8x41_set_boot_done();#ifdef SSD_ENABLE clock_ce_enable(SSD_CE_INSTANCE_1); ssd_load_keystore_from_emmc();#endif&#125; 位于 target/msm8974/init.c 中。 在这之后，USB 硬件应当已经设置好了，Aboot 就在 USB 接口上配置并初始化一个 USB UDC 设备，用来接收和发送 fastboot 相关的 USB 包。 最后，创建一个 lk 的线程来处理 fastboot 相关事件，并初始化 USB 的接口来接收 fastboot 命令。 结论 这篇文章简要描述和分析了 2016 年之前、基于 lk 内核的 Android 使用的 Aboot 启动加载器的实现，但并没有太过深入 lk 针对某一平台或者某一架构进行构建和设置的内容。希望对您有所帮助。 补充 请注意，无论 ARM32 还是 AArch64 的设备，都会在 32 位模式下运行 lk 和其中的应用程序 Aboot，在加载内核时才会确定使用的内核为 32 位或是 64 位，进而通过相应的启动模式启动内核。 在加载的时候，由于 MMU 可能存在，Aboot 通过 VA() 宏将物理地址映射到 lk 读取到的虚拟地址上，并把内核加载到该地址。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"},{"name":"Aboot","slug":"Aboot","permalink":"https://blog.inoki.cc/tags/Aboot/"}]},{"title":"【译】高通 Android 设备的启动信任链","slug":"android-qcom-chain-of-trust","date":"2021-10-17T09:40:00.000Z","updated":"2025-03-08T09:40:48.608Z","comments":true,"path":"2021/10/17/android-qcom-chain-of-trust/","link":"","permalink":"https://blog.inoki.cc/2021/10/17/android-qcom-chain-of-trust/","excerpt":"","text":"原文链接：https://lineageos.org/engineering/Qualcomm-Firmware/ 高通公司的信任链是一个复杂的，但又简单易懂的程序集。你们中的许多人可能听说过“启动引导程序”这个术语，但不知道它实际上是什么，或做什么。在今天的文章中，我们将介绍与高通公司芯片组有关的上述内容。 术语 引导器：引导链中的一个环节的总称，它有一个特定的工作，在每次冷启动时运行。 冷启动：从断电状态重新启动。 QFUSE：集成在 SoC 中的微观硬件保险丝 - 一旦物理上被熔断，就无法重置或更换。 SoC：片上系统（你的手机的“主板”的一种）。 EFUSE: 基于软件的保险丝，其数据存储在 QFPROM 中。 QFPROM：高通公司的熔断器区域。 TrustZone：高通公司 ARM 芯片组的“安全域”实现。 QSEECOM：一个 Linux 内核驱动，让我们与 TrustZone 进行通信，并向 TrustZone 发出一个 SCM 调用，以完成保险丝熔断等操作。它只允许经过签名的小程序和经过批准的调用。 SCM：安全通道管理器（注：与 Linux 的 SMC 调用无关）。 DTB：设备树 Blob 二进制。其目的是为 Linux 提供“一种描述不可发现的硬件的方法”，阅读更多内容。 安卓验证启动（AVB）：在 aboot/ABL 层面实施的一套严格的检查，以验证操作系统各部分的完整性，请点击这里阅读更多内容。 DM-Verity:安卓验证启动的一个组件，它检查分区，看它们之前是否被安装过读/写，请点击这里阅读更多信息。 system_as_root: 一个新的安卓挂载设置逻辑，将系统分区挂载为&quot;/&quot;，而不是&quot;/system&quot;。这意味着系统文件现在位于&quot;/system/system&quot;。这是高通公司检查&quot;/&quot;是否曾在验证启动下被重新挂载读写的一种方式。它还引入了新的标准，即安卓 ramdisk 要存储在系统分区上，而不是存储在启动镜像中。 什么是高通公司的信任链/启动序列？ 高通公司设备的信任链、引导程序序列和安全世界。 详细信息 根据定义，引导程序是一个加载操作系统的程序，或在设备开启时链式加载另一个引导程序。 高通公司的设备都使用基于熔断器的逻辑来决定永久功能配置/加密密钥集。如上所述，其物理版本被称为 QFUSE，并以行为单位存储在 SoC 上称为 QFPROM 的区域中。 如果标记为高通安全启动的 QFUSE 保险丝熔断（在非中国/OnePlus 的设备上就是这样），PBL（高通的主要启动程序）被验证并从 BootROM 加载到内存中，这是 SoC 上一个不可写的存储空间。 然后，PBL 被执行，并启动一系列硬件，然后验证链中下一个引导装载程序的签名，加载并执行它。 链中的下一个引导程序是 SBL*/XBL（高通公司的二级/可扩展引导程序）。这些早期的引导程序启动了核心硬件，如 CPU 内核、MMU 等。它们还负责启动与安卓系统同时进行的核心进程，如被称为 TrustZone 的高通 ARM 芯片组的安全世界。SBL*/XBL 的最后一个目的是验证签名、加载和执行 Aboot/ABL。 Aboot 就是你们大多数人所说的 “bootloader 模式”，因为它是诸如 fastboot 或 OEM 固件刷写工具等服务的所在地。Aboot 将大部分剩余的核心硬件唤醒，然后依次验证启动镜像的签名，通过 dm-verity 将验证状态报告给 Android 验证启动，然后等待前两个步骤的成功，将内核/ramdisk/DTB 加载到内存。在许多设备上，Aboot/ABL 可以被配置为跳过密码学签名检查，允许启动任何内核/启动镜像。在 Aboot 将所有东西加载到内存中后，内核（在我们的例子中是 Linux）然后从启动镜像中解压，或者在 system_as_root 配置中，系统分区被验证并挂载到&quot;/&quot;，然后从那里提取出 ramdisk。在这之后不久，init 被执行，它带来了我们所知的 Android。 在 aboot/ABL 中禁用加密检查的配置选项通常被称为“Bootloader Lock Status”。当一个设备被锁定时，这意味着 aboot 目前正在通过 aboot/ABL 对该设备的启动镜像执行数字签名完整性检查，在较新的设备上，执行“绿色”的 Android 验证启动状态。这些被“锁定”的设备不允许用户刷写分区，也不能启动自定义的无签名内核。如果被锁定的设备被认为是安全的，安卓验证启动通常会报告“绿色”，并允许设备继续启动，如果它被认为是不安全的，它将报告“红色”状态，并阻止设备启动。在“解锁”的设备上，aboot/ABL 允许设备刷写，一些 OEM 厂商允许从内存中启动未签名的启动镜像（fastboot 启动），在这种情况下，验证启动会报告“橙色”或“红色”，这取决于镜像是否有签名，但无论如何都允许设备继续启动。 信任链的成熟 在过去十年中，高通公司的信任链在安全性方面有了巨大的增长。 以下是描述信任链成熟过程的图示： 至 2013 时代 在 MSM8960（Snapdragon S4 plus）及之前： 2013-2016 时代 在 MSM8974（Snapdragon 800）到 MSM8994（Snapdragon 810）之间： 现代化 (2016-2018) 时代 在 MSM8996（Snapdragon 820）之后： 正如你所看到的，引导链已经有了很大的发展。2015 年，可能的攻击区域被缩小了，二级引导程序（SBL）链被合并成一个统一的 SBL。随着进一步发展，我们看到 SBL 完全被高通公司的新的专有解决方案–可扩展引导程序（XBL）所取代，它缓解了 SBL 带来的许多安全问题。 Aboot 也已经从 LittleKernel（一个开源的引导程序）发展到了完全独立的解决方案，现在被称为专有的 Android 引导程序（ABL）。这个新的引导程序允许使用 UEFI，以及其他许多针对开发者/OEM 的安全和生活质量的改进。 而 system_as_root 配置也大大改善了安全性，以及总体架构。它将 Android ramdisk 从存储在启动镜像中转移到了系统分区中，正如其名称所暗示的，系统分区被挂载为&quot;/&quot;。这样做的部分原因是为了让它能够被 dm-verity/Android 验证启动所验证。 注意：新的无缝更新系统被称为“A/B”，它与 system_as_root 是独立概念的，尽管它们通常是并列的。OEM 可以选择实现一个而不是另一个。 OEM 附加功能 许多 OEM 在他们的 bootloader 设置中实施了额外的加密检查，以试图进一步提高安全性，或是为了一种功能（如允许终端用户解锁 bootloader）。 几个普遍的例子： 三星使用 eMMC CID/a 对应的哈希 CID 的 aboot 镜像来决定开发者（解锁）状态。 三星的“KNOX QFUSE”在任何入侵时都会被吹响，如果被触发，可以被配置为擦除设备。 摩托罗拉使用单一的 QFUSE，必须熔断才能解锁设备，从而使保修期永久失效。 索尼使用了一个加密 blob 和他们的“TA”分区上的一个位来允许解锁。 原始设备制造商也经常实施他们自己的专有模式，这有多种用途。一些例子包括： 三星的专有下载模式，用于固件刷写。 LG专有的 LAF（下载）模式用于固件刷写。 谷歌的 OSS Fastboot 模式用于固件刷写。 与一般的解决方案相比，OEM 的特定功能/模式往往有很大的优势，比如摩托罗拉是第一批扩展 fastboot 协议以允许刷写稀疏分块的系统镜像的 OEM 之一。然而，这些解决方案也很有可能存在不可预见的安全漏洞，比如 LG 经常出现的 LAF 模式漏洞，或者利用三星的 CID 方法解锁其他不可解锁设备的 SamDunk 漏洞。 同样重要的是要注意，虽然 OEM 厂商可以定制aboot/ABL，以及有价格的 SBL*/XBL，但 PBL 是由高通公司自己在 SoC 上构建和发布。PBL 很少出现公开的漏洞，因为大多数漏洞通过高通公司的 Bug Bounty Program 获得了大量的赏金，尽管 PBL 以前也出现过一些公开的漏洞，例如 Aleph Security 的 EDL（高通下载模式）漏洞，你可以在这里阅读相关信息。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Android","slug":"Linux/Android","permalink":"https://blog.inoki.cc/categories/Linux/Android/"},{"name":"Bootloader","slug":"Linux/Android/Bootloader","permalink":"https://blog.inoki.cc/categories/Linux/Android/Bootloader/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Android","slug":"Android","permalink":"https://blog.inoki.cc/tags/Android/"},{"name":"ABL","slug":"ABL","permalink":"https://blog.inoki.cc/tags/ABL/"},{"name":"Bootloader","slug":"Bootloader","permalink":"https://blog.inoki.cc/tags/Bootloader/"},{"name":"Aboot","slug":"Aboot","permalink":"https://blog.inoki.cc/tags/Aboot/"},{"name":"XBL","slug":"XBL","permalink":"https://blog.inoki.cc/tags/XBL/"}]},{"title":"【译】从零开始的 Wayland 合成器 —— 3. 渲染一个窗口","slug":"Writing-a-wayland-compositor-3","date":"2021-09-06T20:48:40.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/09/06/Writing-a-wayland-compositor-3/","link":"","permalink":"https://blog.inoki.cc/2021/09/06/Writing-a-wayland-compositor-3/","excerpt":"","text":"原文链接：Writing a Wayland Compositor, Part 3: Rendering a window 译者注：这个系列文章中使用的为早期 wlroots 版本，大约在 0.3 到 0.4.1 之间，请注意安装的版本 这是关于使用 wlroots 从头开始编写 Wayland 合成器的系列文章中的第三篇。如果你还没有看过第一篇文章的话，可以看看。我们从一个 Wayland 服务器开始，它接受客户端的连接，并暴露了一些全局的东西，但还没有做任何特别有趣的事情。我们今天的目标是做一些有趣的事情–渲染一个窗口！。 本文所剖析的提交是 342b7b6。 为了渲染窗口，我们要做的第一件事就是建立合成器。客户端使用 wl_compositor 全局来分配 wl_surfaces，并将 wl_buffers 附加到这些 surface。这些 surface 只是一个通用的机制，用于与合成器共享像素缓冲区，并不带有隐含的角色，如 &quot;应用窗口&quot;或 “面板”。 wlroots 提供了一个 wl_compositor 的实现。让我们为它预留一个引用： 12345678struct mcw_server &#123; struct wl_display *wl_display; struct wl_event_loop *wl_event_loop; struct wlr_backend *backend;+ struct wlr_compositor *compositor; struct wl_listener new_output; 然后将其组装起来： 12345678 wlr_primary_selection_device_manager_create(server.wl_display); wlr_idle_create(server.wl_display); + server.compositor = wlr_compositor_create(server.wl_display,+ wlr_backend_get_renderer(server.backend));+ wl_display_run(server.wl_display); wl_display_destroy(server.wl_display); 如果我们现在运行 mcwayface，用 weston-info 查看全局变量，我们会看到一个 wl_compositor 和 wl_subcompositor 已经出现： 12interface: &apos;wl_compositor&apos;, version: 4, name: 8interface: &apos;wl_subcompositor&apos;, version: 1, name: 9 你可以通过 wlroots 的 wl_compositor 获得一个 wl_subcompositor。我们将在以后的文章中讨论子合成器。说到我们将在另一篇文章中讨论的东西，也要加上这个： 1234567891011 wlr_primary_selection_device_manager_create(server.wl_display); wlr_idle_create(server.wl_display); server.compositor = wlr_compositor_create(server.wl_display, wlr_backend_get_renderer(server.backend)); + wlr_xdg_shell_v6_create(server.wl_display);+ wl_display_run(server.wl_display); wl_display_destroy(server.wl_display); return 0; 还记得我之前说过，surface 只是一些没有作用的像素团吗？ xdg_shell 是一个可以让 surface 具有作用的东西。我们将在下一篇文章中更多地讨论这个问题。添加了这个之后，很多客户端就可以连接到你的合成器并生成一个窗口。然而，如果不添加其他东西，这些窗口永远不会在屏幕上显示。你必须要渲染它们! wlroots 与 wlc 和 libweston 等库的不同之处在于，wlroots 不为你做任何渲染。这给了你很大的灵活性，你可以用任何你喜欢的方式渲染表面。客户端只是给了你一堆像素，你如何处理它们由你自己决定–也许你要做一个桌面合成器，也许你想把它们画在 Android 风格的应用切换器上，也许你的合成器在 VR 中排列窗口–所有这些都可以通过 wlroots 实现。 事情即将变得复杂，所以让我们从简单的部分开始：在 output_frame 处理程序中，我们必须获得我们想要渲染的每个 wlr_surface 的引用。所以让我们遍历我们的 wlr_compositor 所记录的每一个 surface： 123456789101112 wlr_renderer_begin(renderer, wlr_output);+ struct wl_resource *_surface;+ wl_resource_for_each(_surface, &amp;server-&gt;compositor-&gt;surfaces) &#123;+ struct wlr_surface *surface = wlr_surface_from_resource(_surface);+ if (!wlr_surface_has_buffer(surface)) &#123;+ continue;+ &#125;+ // TODO: Render this surface+ &#125; wlr_output_swap_buffers(wlr_output, NULL, NULL); wlr_compositor 结构有一个名为 surface 的成员，它是一个 wl_resource 的列表。我们提供了一个辅助方法来从其对应的 wl_resource 中产生一个 wlr_surface。调用 wlr_surface_has_buffer 只是为了确保客户端确实给了我们像素来显示在这个表面。 wlroots 可能会让你自己做渲染，但是我们提供了一些工具来帮助你编写具有简单渲染要求的合成器：wlr_renderer。我们已经稍微接触了一下，但现在我们要真正使用它了。这里需要有一点 OpenGL 的知识。如果你是一个完全不懂 OpenGL 的新手，我可以推荐这个教程来帮助你。由于你很匆忙，我们将对利用 wlr_renderer 所需的概念做一个快速的速成课程。如果你迷路了，就跳到下一个diff，把它当作使你的窗口出现的魔法咒语。 我们有一堆像素，我们想把它放在屏幕上。我们可以用着色器来做这个。如果你使用的是 wlr_renderer（mcwayface也会使用），着色器是为你提供的。为了使用我们的着色器，我们给它们提供一个纹理（一堆像素）和一个矩阵。如果我们把表面上的每个像素坐标当作一个矢量，从（0，0）；左上角，到（1，1）；右下角，我们的目标是产生一个矩阵，我们可以把矢量乘以这个矩阵来找到屏幕上要绘制的像素的最终坐标。我们必须将像素坐标从这个0-1系统投射到屏幕上我们想要的矩形的坐标。 然而，这里有一个问题：屏幕上的坐标也是从0到1，而不是，例如，0-1920和0-1080。为了把 &quot;把我的640x480窗口放在坐标100,100处 &quot;这样的坐标投射到屏幕坐标上，我们使用正投影矩阵。我知道这听起来很吓人，但不用担心-- wlroots 为你做了所有的工作。你的 wlr_output 已经有一个合适的矩阵，叫做 transform_matrix，它把你的屏幕的当前分辨率、比例系数和旋转都纳入其中。 好了，希望你还在听我说。这听起来有点复杂，但所有这些废话的表现是相当直接的。wlroots 提供了一些工具，使之对你来说很容易。首先，我们要准备一个 wlr_box，它代表（在输出坐标中）我们希望 surface 显示的地方。 12345678910111213 struct wl_resource *_surface; wl_resource_for_each(_surface, &amp;server-&gt;compositor-&gt;surfaces) &#123; struct wlr_surface *surface = wlr_surface_from_resource(_surface); if (!wlr_surface_has_buffer(surface)) &#123; continue; &#125;- // TODO: Render this surface+ struct wlr_box render_box = &#123;+ .x = 20, .y = 20,+ .width = surface-&gt;current-&gt;width,+ .height = surface-&gt;current-&gt;height+ &#125;; &#125; 现在，最精彩的部分来了：我刚才说的那些花哨的数学运算都可以通过 wlroots 提供的一个辅助函数来完成：wlr_matrix_project_box。 12345678910111213141516 struct wl_resource *_surface; wl_resource_for_each(_surface, &amp;server-&gt;compositor-&gt;surfaces) &#123; struct wlr_surface *surface = wlr_surface_from_resource(_surface); if (!wlr_surface_has_buffer(surface)) &#123; continue; &#125; struct wlr_box render_box = &#123; .x = 20, .y = 20, .width = surface-&gt;current-&gt;width, .height = surface-&gt;current-&gt;height &#125;;+ float matrix[16];+ wlr_matrix_project_box(&amp;matrix, &amp;render_box,+ surface-&gt;current-&gt;transform,+ 0, &amp;wlr_output-&gt;transform_matrix); &#125; 这需要一个 float[16] 的引用来存储输出矩阵，一个你想投影的盒子，一些其他的东西，现在并不重要，以及你想使用的投影–在这个例子中，我们只是使用 wlr_output 提供的投影。 我们之所以让你理解并执行这些步骤，是因为你完全有可能在将来想用不同的方式来做这些事情。这只是最简单的情况，但请记住，wlroots 是为各种情况设计的。现在我们已经得到了这个矩阵，我们终于可以渲染这个 surface 了。 123456789101112131415161718 struct wl_resource *_surface; wl_resource_for_each(_surface, &amp;server-&gt;compositor-&gt;surfaces) &#123; struct wlr_surface *surface = wlr_surface_from_resource(_surface); if (!wlr_surface_has_buffer(surface)) &#123; continue; &#125; struct wlr_box render_box = &#123; .x = 20, .y = 20, .width = surface-&gt;current-&gt;width, .height = surface-&gt;current-&gt;height &#125;; float matrix[16]; wlr_matrix_project_box(&amp;matrix, &amp;render_box, surface-&gt;current-&gt;transform, 0, &amp;wlr_output-&gt;transform_matrix);+ wlr_render_with_matrix(renderer, surface-&gt;texture, &amp;matrix, 1.0f);+ wlr_surface_send_frame_done(surface, &amp;now); &#125; 我们还抛出了一个 wlr_surface_send_frame_done，这让客户端知道我们已经完成了，所以他们可以发送另一帧。我们完成了! 现在运行 mcwayface，然后执行以下命令： 12$ WAYLAND_DISPLAY=wayland-1 weston-simple-shm &amp;$ WAYLAND_DISPLAY=wayland-1 gnome-terminal -- htop 看看这美妙的图片： 运行任何你喜欢的其他客户端–它们中的许多都可以工作。 我们今天使用了一点黑客技术，简单地渲染了 wl_compositor 所知道的所有表面。在实践中，我们需要扩展我们的 xdg_shell 支持（也可以添加一些其他的 shell）来正确地完成这个任务。我们将在下一篇文章中讨论这个问题。 在你走之前，请注意：在这次提交之后，我重新组织了一些东西–我们很快就会淘汰这种单文件的方法。请看这里的提交。 下回见! 本文及原文使用 CC-BY-SA 协议开放。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Wayland","slug":"Linux/Wayland","permalink":"https://blog.inoki.cc/categories/Linux/Wayland/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"}]},{"title":"【译】从零开始的 Wayland 合成器 —— 2. 装配服务器","slug":"Writing-a-wayland-compositor-2","date":"2021-09-06T20:47:40.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/09/06/Writing-a-wayland-compositor-2/","link":"","permalink":"https://blog.inoki.cc/2021/09/06/Writing-a-wayland-compositor-2/","excerpt":"","text":"原文链接：Writing a Wayland Compositor, Part 2: Rigging up the server 译者注：这个系列文章中使用的为早期 wlroots 版本，大约在 0.3 到 0.4.1 之间，请注意安装的版本 这是关于使用 wlroots 从头开始编写 Wayland 合成器的系列文章中的第二篇。如果你还没有看过第一篇文章，可以看看。上一次，我们最终得到了一个应用程序，它启动了 wlroots 后端，枚举了输出设备，并在屏幕上绘制了一些漂亮的颜色。今天，我们将开始接受 Wayland 客户端的连接，尽管我们还不打算对它们做什么。 本文剖析的提交是b45c651。 关于这些博客文章的性质，我想说的是：我们将需要大量的文章来充实我们的合成器。我将会比平时更频繁地发布这些文章，大概每周1-2篇，并继续以通常的速度发布我的文章。好吗？很好。 所以我们已经启动了后端，并且正在渲染一些有趣的东西，但是我们仍然没有运行Wayland服务器–Wayland客户端没有连接到我们的应用程序。添加这个其实很容易： 12345678910111213141516171819@@ -113,12 +113,18 @@ int main(int argc, char **argv) &#123; server.new_output.notify = new_output_notify; wl_signal_add(&amp;server.backend-&gt;events.new_output, &amp;server.new_output); + const char *socket = wl_display_add_socket_auto(server.wl_display);+ assert(socket);+ if (!wlr_backend_start(server.backend)) &#123; fprintf(stderr, \"Failed to start backend\\n\"); wl_display_destroy(server.wl_display); return 1; &#125; + printf(\"Running compositor on wayland display '%s'\\n\", socket);+ setenv(\"WAYLAND_DISPLAY\", socket, true);+ wl_display_run(server.wl_display); wl_display_destroy(server.wl_display); return 0; 这就是了! 如果你再次运行 McWayface，它将打印出这样的东西： 1Running compositor on wayland display &apos;wayland-1&apos; Weston 是 Wayland 的参考合成器，包括一些简单的参考客户端。我们可以使用 weston-info 连接到我们的服务器并列出全局变量： 12$ WAYLAND_DISPLAY=wayland-1 weston-infointerface: &apos;wl_drm&apos;, version: 2, name: 1 如果你还记得我的《Wayland 简介》，Wayland 服务器通过 Wayland 注册表向客户端输出了一个全局变量列表。这些全局变量提供了客户端可以用来与服务器互动的接口。我们通过 wlroots 获得了 wl_drm，但我们实际上还没有连接上任何有用的东西。wlroots提供了许多 “类型”，其中大部分是像这样的 Wayland 全局接口的实现。 一些 wlroots 的实现需要你进行一些操纵，但其中有几个是自动搞定的。装配这些东西很容易： 1234567891011 printf(\"Running compositor on wayland display '%s'\\n\", socket); setenv(\"WAYLAND_DISPLAY\", socket, true);++ wl_display_init_shm(server.wl_display);+ wlr_gamma_control_manager_create(server.wl_display);+ wlr_screenshooter_create(server.wl_display);+ wlr_primary_selection_device_manager_create(server.wl_display);+ wlr_idle_create(server.wl_display); wl_display_run(server.wl_display); wl_display_destroy(server.wl_display); 请注意，这些接口中的一些并不一定是你通常想要暴露给所有 Wayland 客户端的接口–例如，screenshooter 是应该被保护起来的东西。我们将在后面的文章中讨论安全问题。现在，如果我们再次运行 weston-info，我们会看到更多的全局变量已经出现： 12345678$ WAYLAND_DISPLAY=wayland-1 weston-infointerface: &apos;wl_shm&apos;, version: 1, name: 3 formats: XRGB8888 ARGB8888interface: &apos;wl_drm&apos;, version: 2, name: 1interface: &apos;gamma_control_manager&apos;, version: 1, name: 2interface: &apos;orbital_screenshooter&apos;, version: 1, name: 3interface: &apos;gtk_primary_selection_device_manager&apos;, version: 1, name: 4interface: &apos;org_kde_kwin_idle&apos;, version: 1, name: 5 你会发现 wlroots 实现了各种不同来源的协议–在这里我们看到 Orbital、GTK 和 KDE的 协议。wlroots 包括一个 Orbital 屏幕截图的客户端实例–我们现在可以用它来给我们的合成器截个图： 12$ WAYLAND_DISPLAY=wayland-1 ./examples/screenshotcannot set buffer size 啊，这是个问题–你可能已经注意到，我们没有任何 wl_output 的全局变量，屏幕截图客户端依靠它来计算屏幕截图缓冲区的分辨率。我们也可以添加这些： 1234567@@ -95,6 +99,8 @@ static void new_output_notify(struct wl_listener *listener, void *data) &#123; wl_signal_add(&amp;wlr_output-&gt;events.destroy, &amp;output-&gt;destroy); output-&gt;frame.notify = output_frame_notify; wl_signal_add(&amp;wlr_output-&gt;events.frame, &amp;output-&gt;frame);++ wlr_output_create_global(wlr_output); &#125; 再次运行 weston-info 会给我们提供一些关于我们现在的 output 的信息： 12345678910111213141516$ WAYLAND_DISPLAY=wayland-1 weston-infointerface: &apos;wl_drm&apos;, version: 2, name: 1interface: &apos;wl_output&apos;, version: 3, name: 2 x: 0, y: 0, scale: 1, physical_width: 0 mm, physical_height: 0 mm, make: &apos;wayland&apos;, model: &apos;wayland&apos;, subpixel_orientation: unknown, output_transform: normal, mode: width: 952 px, height: 521 px, refresh: 0.000 Hz, flags: currentinterface: &apos;wl_shm&apos;, version: 1, name: 3 formats: XRGB8888 ARGB8888interface: &apos;gamma_control_manager&apos;, version: 1, name: 4interface: &apos;orbital_screenshooter&apos;, version: 1, name: 5interface: &apos;gtk_primary_selection_device_manager&apos;, version: 1, name: 6interface: &apos;org_kde_kwin_idle&apos;, version: 1, name: 7 现在我们可以拍下那张截图了! 给它一个机会（wwwwww）! 我们现在已经接近完成了。下一篇文章将介绍 Surface 的概念，我们将用它们来渲染我们的第一个窗口。如果你在这篇文章中遇到任何问题，请联系我，sir@cmpwn.com，或者联系 wlroots 团队，#sway-devel。 本文及原文使用 CC-BY-SA 协议开放。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Wayland","slug":"Linux/Wayland","permalink":"https://blog.inoki.cc/categories/Linux/Wayland/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"}]},{"title":"【译】从零开始的 Wayland 合成器 —— 1. Hello wlroots","slug":"Writing-a-wayland-compositor-1","date":"2021-09-05T20:47:40.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/09/05/Writing-a-wayland-compositor-1/","link":"","permalink":"https://blog.inoki.cc/2021/09/05/Writing-a-wayland-compositor-1/","excerpt":"","text":"原文链接：Writing a Wayland Compositor, Part 1: Hello wlroots 译者注：这个系列文章中使用的为早期 wlroots 版本，大约在 0.3 到 0.4.1 之间，请注意安装的版本 这是一系列文章中的第一篇。 我正在写一篇关于从头开始构建一个 Wayland 合成器的文章。你可能知道，我（原作者）是 Sway 的主要维护者，这是一个相当受欢迎的 Wayland 合成器。在过去的几个月里，我们和许多其他优秀的开发者一起，一直在开发 wlroots。这是一个用于创建新的 Wayland 合成器的强大工具，但它非常复杂难以理解。不要感到绝望！这篇文章的目的是让大家了解 Wayland 合成器。这些文章的目的是让你理解并自如地使用它。 在我们深入讨论之前，请注意：wlroots 团队今天开始了一项众筹活动，以资助我们每个核心贡献者的旅行，让他们亲自会面并在黑客马拉松上工作两周。请考虑为该活动做出贡献! 在试图理解这一系列博文之前，你必须阅读并理解我之前的文章《Wayland 介绍》，因为我将依靠那里介绍的概念和术语来加快事情的进展。一些 OpenGL 的背景是有帮助的，但不是必须的。对 C 语言的良好理解是必须的。如果你对这个系列的任何文章有任何问题，请通过 sir@cmpwn.com 直接联系我，或者联系 irc.freenode.net 上的 #sway-devel 的 wlroots 团队。 在这一系列的文章中，我们正在构建的合成器将托管在 GitHub 上——Wayland McWayface。本系列文章中的每篇文章都会对从零到功能齐全的 Wayland 合成器之间的一次提交进行分解，这篇文章的提交是 f89092e。我只解释重要的部分–我建议你单独查看整个提交。 让我们开始吧。 第一步 首先，我将定义一个结构来保存我们的合成器的状态： 1234struct mcw_server &#123; struct wl_display *wl_display; struct wl_event_loop *wl_event_loop;&#125;; 注意：mcw 是 McWayface 的简称。我们将在整个系列文章中使用这个缩写。我们将把其中一个放在一边，并为它初始化一个 Wayland 的 display（注意：我们完全可以利用 wlroots 后端来制作非 Wayland 合成器的应用程序。然而，我们还是需要一个 Wayland 的 display，因为事件循环对于很多 wlroots 的内部程序来说是必要的）： 123456789int main(int argc, char **argv) &#123; struct mcw_server server; server.wl_display = wl_display_create(); assert(server.wl_display); server.wl_event_loop = wl_display_get_event_loop(server.wl_display); assert(server.wl_event_loop); return 0;&#125; Wayland 的 display 给了我们很多东西，但现在我们关心的是事件循环。这个事件循环被深深地整合到了 wlroots 中，它被用来在整个应用程序中分配信号，当各种文件描述符上的数据可用时被通知，等等。 创建后端 接下来，我们需要创建后端： 123456struct mcw_server &#123; struct wl_display *wl_display; struct wl_event_loop *wl_event_loop; struct wlr_backend *backend;&#125;; 后端是我们第一个 wlroots 概念，它负责从你那里抽象出低层次的输入和输出实现。每个后端可以生成零个或多个输入设备（如鼠标、键盘等）和零个或多个输出设备（如你桌上的显示器）。后端与 Wayland 无关–它们的目的是帮助你使用你作为 Wayland 合成器所需的其他 API。有各种不同目的的后端： drm 后端利用 Linux 的 DRM 子系统直接渲染到你的物理显示器 libinput 后端利用 libinput 来枚举和控制物理输入设备 Wayland 后端在另一个运行 Wayland 合成器的窗口上创建 “输出”，允许你对合成器进行嵌套。这对调试很有用 X11 后端与 Wayland 后端类似，但在 X11 服务器上打开一个 X11 窗口，而不是在 Wayland 服务器上打开一个 Wayland 窗口 另一个重要的后端是多后端，它允许你同时初始化几个后端并聚合它们的输入和输出设备。例如，这对于同时利用 drm 和 libinput 是必要的。 我们的库 wlroots 提供了一个辅助函数，用于根据用户的环境自动选择最合适的后端： 1234567 server.wl_event_loop = wl_display_get_event_loop(server.wl_display); assert(server.wl_event_loop); server.backend = wlr_backend_autocreate(server.wl_display); assert(server.backend); return 0;&#125; 我一般建议在开发过程中使用 Wayland 或 X11 后端，特别是在我们有办法退出合成器之前。如果你在运行中的 Wayland 或 X11 会话中调用 wlr_backend_autocreate，相应的后端会被自动选择。 我们现在可以启动后端并进入 Wayland 事件循环： 12345678if (!wlr_backend_start(server.backend)) &#123; fprintf(stderr, \"Failed to start backend\\n\"); return 1;&#125;wl_display_run(server.wl_display);wl_display_destroy(server.wl_display);return 0; 如果你在这时运行你的合成器，你应该看到后端启动，然后…什么都不做。如果你从运行中的 Wayland 或 X11 服务器上运行，它会打开一个窗口。如果你在 DRM 上运行它，它可能会做得很少，你甚至不能切换到另一个 TTY 来杀死它。 添加事件监听函数 为了渲染东西，我们需要知道我们可以在哪些输出上渲染。后台提供了一个 wl_signal，当它得到一个新的输出时通知我们。这将发生在启动时，以及任何输出在运行时被热插拔时。 让我们把它添加到我们的服务器结构体中： 12345678struct mcw_server &#123; struct wl_display *wl_display; struct wl_event_loop *wl_event_loop; struct wlr_backend *backend; struct wl_listener new_output; struct wl_list outputs; // mcw_output::link&#125;; 这增加了一个 wl_listeners，当新的输出被添加时，它就会被通知。我们还添加了一个 wl_list（这只是一个由 libwayland-server 提供的链接列表），我们以后会在其中存储一些状态。为了得到通知，我们必须使用 wl_signal_add： 1234567assert(server.backend);wl_list_init(&amp;server.outputs);server.new_output.notify = new_output_notify;wl_signal_add(&amp;server.backend-&gt;events.new_output, &amp;server.new_output); if (!wlr_backend_start(server.backend)) &#123; 我们在这里指定被通知的函数 new_output_notify： 1234567891011121314151617static void new_output_notify(struct wl_listener *listener, void *data) &#123; struct mcw_server *server = wl_container_of( listener, server, new_output); struct wlr_output *wlr_output = data; if (!wl_list_empty(&amp;wlr_output-&gt;modes)) &#123; struct wlr_output_mode *mode = wl_container_of(wlr_output-&gt;modes.prev, mode, link); wlr_output_set_mode(wlr_output, mode); &#125; struct mcw_output *output = calloc(1, sizeof(struct mcw_output)); clock_gettime(CLOCK_MONOTONIC, &amp;output-&gt;last_frame); output-&gt;server = server; output-&gt;wlr_output = wlr_output; wl_list_insert(&amp;server-&gt;outputs, &amp;output-&gt;link);&#125; 这有点复杂! 这个函数在处理传入的 wlr_output 时有几个作用。wl_container_of 使用一些基于 offsetof 的魔法，从监听器的指针中得到 mcw_server 的引用，然后我们将数据投到实际的类型，即 wlr_output。 设置输出 我们要做的下一件事是设置输出模式。一些后端（特别是 X11 和 Wayland）不支持设置模式，但它们对于 DRM 是必要的。输出模式指定了输出所支持的尺寸和刷新率，例如 1920x1080@60Hz。这个 if 语句的主体只是选择了最后一个（通常是最高的分辨率和刷新率），并通过 wlr_output_set_mode 将其应用于输出。我们必须设置输出模式，以便对其进行渲染。 然后，我们设置了一些状态，让我们在合成器中跟踪这些输出。我在文件的顶部添加了这个结构定义： 1234567struct mcw_output &#123; struct wlr_output *wlr_output; struct mcw_server *server; struct timespec last_frame; struct wl_list link;&#125;; 这将是我们用来存储我们对这个输出的任何状态的结构，这些状态是特定于我们的合成器需求的。我们包括一个对 wlr_output 的引用，一个对拥有这个输出的 mcw_server 的引用，以及最后一帧的时间，这在后面会有用。我们还预留了一个 wl_list，它被 libwayland 用于链接列表。 最后，我们将这个输出添加到服务器的输出列表中。 我们现在可以使用了，但它会泄露内存。我们还需要处理输出的移除，用一个由 wlr_output 提供的信号。我们将监听器添加到 mcw_output 结构中： 123456789struct mcw_output &#123; struct wlr_output *wlr_output; struct mcw_server *server; struct timespec last_frame; struct wl_listener destroy; struct wl_list link;&#125;; 然后我们在增加输出的时候把它加进来： 12345 wl_list_insert(&amp;server-&gt;outputs, &amp;output-&gt;link); output-&gt;destroy.notify = output_destroy_notify; wl_signal_add(&amp;wlr_output-&gt;events.destroy, &amp;output-&gt;destroy);&#125; 这将调用我们的 output_destroy_notify 函数来处理当输出被拔掉或以其他方式从 wlroots 移除时的清理工作。我们的处理程序看起来像这样： 1234567static void output_destroy_notify(struct wl_listener *listener, void *data) &#123; struct mcw_output *output = wl_container_of(listener, output, destroy); wl_list_remove(&amp;output-&gt;link); wl_list_remove(&amp;output-&gt;destroy.link); wl_list_remove(&amp;output-&gt;frame.link); free(output);&#125; 这些代码应该能够自解释的。我们现在有一个对输出的引用。然而，我们仍然没有渲染任何东西–如果你再次运行合成器，你会发现同样的行为。 监听帧的更新信号 为了渲染东西，我们必须监听帧的信号。根据选择的模式，输出只能以一定的速率接收新的帧。我们在 wlroots 中为你跟踪这一点，并在绘制新帧的时候发出帧信号。 让我们为此目的在 mcw_output 结构中添加一个监听器。 123456789struct mcw_output &#123; struct wlr_output *wlr_output; struct mcw_server *server; struct wl_listener destroy; struct wl_listener frame; struct wl_list link;&#125;; 然后，我们可以扩展 new_output_notify 来注册帧信号的监听器。 12345 output-&gt;destroy.notify = output_destroy_notify; wl_signal_add(&amp;wlr_output-&gt;events.destroy, &amp;output-&gt;destroy); output-&gt;frame.notify = output_frame_notify; wl_signal_add(&amp;wlr_output-&gt;events.frame, &amp;output-&gt;frame);&#125; 现在，每当输出准备好了一个新的帧，output_frame_notify 就会被调用。不过，我们仍然需要编写这个函数。让我们从最基本的开始。 1234static void output_frame_notify(struct wl_listener *listener, void *data) &#123; struct mcw_output *output = wl_container_of(listener, output, frame); struct wlr_output *wlr_output = data;&#125; 渲染一些内容 为了在这里渲染任何东西，我们需要首先获得一个 wlr_renderer2。我们可以从后端获得一个。 12345static void output_frame_notify(struct wl_listener *listener, void *data) &#123; struct mcw_output *output = wl_container_of(listener, output, frame); struct wlr_output *wlr_output = data; struct wlr_renderer *renderer = wlr_backend_get_renderer(wlr_output-&gt;backend);&#125; 现在我们可以利用这个渲染器，在输出端画一些东西： 1234567891011121314static void output_frame_notify(struct wl_listener *listener, void *data) &#123; struct mcw_output *output = wl_container_of(listener, output, frame); struct wlr_output *wlr_output = data; struct wlr_renderer *renderer = wlr_backend_get_renderer(wlr_output-&gt;backend); wlr_output_make_current(wlr_output, NULL); wlr_renderer_begin(renderer, wlr_output); float color[4] = &#123;1.0, 0, 0, 1.0&#125;; wlr_renderer_clear(renderer, color); wlr_output_swap_buffers(wlr_output, NULL, NULL); wlr_renderer_end(renderer);&#125; 调用 wlr_output_make_current 使输出的 OpenGL 上下文成为 “当前”，从这里你可以使用 OpenGL 调用来渲染到输出的缓冲区。我们调用 wlr_renderer_begin 来为我们配置一些合理的OpenGL默认值。 在这一点上，我们可以开始渲染了。我们将在后面详细介绍你能用 wlr_renderer 做什么，但现在我们将满足于把输出清除为纯红色。 当我们完成渲染后，我们调用 wlr_output_swap_buffers 来交换输出的前后缓冲区，将我们所渲染的内容提交到实际的屏幕上。我们调用 wlr_renderer_end 来清理 OpenGL 上下文，我们就完成了。现在运行我们的合成器应该可以看到一个纯红色的屏幕 总结 今天的文章到此结束。如果你看一下本文所描述的提交，你会发现我用一些代码更进一步，每一帧都把显示器清除成不同颜色。请随意尝试类似的变化吧 在接下来的两篇文章中，我们将完成 Wayland 服务器的连接，并在屏幕上呈现一个 Wayland 客户端。请期待吧! 本文及原文使用 CC-BY-SA 协议开放。","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"Wayland","slug":"Linux/Wayland","permalink":"https://blog.inoki.cc/categories/Linux/Wayland/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"}]},{"title":"The right way to store and retrieve SecIdentity/Identity on iOS","slug":"SecIdentity-iOS-storage","date":"2021-09-05T09:42:00.000Z","updated":"2025-03-08T09:40:48.594Z","comments":true,"path":"2021/09/05/SecIdentity-iOS-storage/","link":"","permalink":"https://blog.inoki.cc/2021/09/05/SecIdentity-iOS-storage/","excerpt":"","text":"Apple does have a documentation describing how to store an identity in the keychain. In this doc, it is described as a process much like the storage of certificate in the keychain. The only difference is: Use SecIdentityRef objects instead of SecCertificateRef objects. Use kSecClassIdentity instead of kSecClassCertificate for the kSecClass attribute. So, the code of storing an Identity becomes: 123456789NSDictionary* addquery = @&#123; (id)kSecValueRef: (__bridge id)identity, (id)kSecClass: (id)kSecClassIdentity, (id)kSecAttrLabel: @&quot;Identity&quot;, &#125;;OSStatus status = SecItemAdd((__bridge CFDictionaryRef)addquery, NULL);if (status != errSecSuccess) &#123; // Handle the error&#125; and retrieving as follows: 123456789101112NSDictionary *getquery = @&#123; (id)kSecClass: (id)kSecClassIdentity, (id)kSecAttrLabel: @&quot;Identity&quot;, (id)kSecReturnRef: @YES, &#125;;SecIdentityRef identity = NULL;OSStatus status = SecItemCopyMatching((__bridge CFDictionaryRef)getquery, (CFTypeRef *)&amp;identity);if (status != errSecSuccess) &#123; &lt;# Handle error #&gt; &#125;else &#123; &lt;# Use identity #&gt; &#125;if (identity) &#123; CFRelease(identity); &#125; // After you are done with it Problem However, on the iOS 14.5 emulator, although SecItemAdd returns 0 with no error, there is no identity stored: 1234Identity Test[2377:102582] Internet Password: (null)Identity Test[2377:102582] Cert: (null)Identity Test[2377:102582] Key: (null)Identity Test[2377:102582] Identity: (null) It is very weird… Solution I searched on Internet. This thread helps me a little: I can’t get SecIdentity from Keychain: 1Using labels on an identity is tricky because identities are not stored in the keychain as an atomic item but are store as a separate private key and certificate, and those items use labels in different ways. It inspired me to remove the kSecClass when storing. The code becomes: 12345678NSDictionary* addquery = @&#123; (id)kSecValueRef: (__bridge id)identity, (id)kSecAttrLabel: @&quot;Identity&quot;, &#125;;OSStatus status = SecItemAdd((__bridge CFDictionaryRef)addquery, NULL);if (status != errSecSuccess) &#123; // Handle the error&#125; With these lines of code, when querying, KeyChains gives me: 12345678910111213141516171819202122Identity Test[2555:109912] Internet Password: (null)Identity Test[2555:109912] Cert: ( &#123; ... labl = Identity; ... &#125;)Identity Test[2555:109912] Key: ( &#123; ... labl = Identity; ... &#125;)Identity Test[2555:109912] Identity: ( &#123; ... labl = Identity; ... &#125;) There are a private key, a certificate and an identity with my label. It works now 😃 When retrieving, we can still keep the kSecClass in the query to filter the identity only. Regarding that these are not mentioned by Apple at all, I hope this workaround can help someone. Unique Identity issue Then, I tried to store a second identity(labelled by Identity1) with the workaround. But it fails with the same observation above. So, I add some code to remove the previous identity before adding new: 12NSDictionary *spec = @&#123;(__bridge id)kSecClass: (id)kSecClassIdentity&#125;;SecItemDelete((__bridge CFDictionaryRef)spec); This will remove the corresponding private key, certificate and the identity itself. And the new identity can be added successfully. Thus, I wonder if the removal of the private key or the certificate will affect the identity? Here are the answers: kSecClass Certificate removed Private key removed Identity removed Identity can be added kSecClassCertificate YES NO YES YES kSecClassKey NO YES YES NO kSecClassIdentity YES YES YES YES We can see that, removing both certificate or identity should work. In my case, I need to store some more certificates other than the one from the identity. So, I should not remove all the certificates. I choose to remove the identity to keep atmost one at the same time. You could also do your own choice. Conclusion This post explores the Identity storage on iOS. Here are my discovery: do not store the identity with kSecClass, the KeyChain service will do this for you; only one identity is OK for an app. Any other questions? Post them in the comments.","categories":[{"name":"iOS","slug":"iOS","permalink":"https://blog.inoki.cc/categories/iOS/"}],"tags":[{"name":"iOS","slug":"iOS","permalink":"https://blog.inoki.cc/tags/iOS/"}]},{"title":"【译】 Vulkan 光线追踪","slug":"Vulkan-Ray-Tracing-Specification","date":"2021-08-02T23:08:10.000Z","updated":"2025-03-08T09:40:48.594Z","comments":true,"path":"2021/08/02/Vulkan-Ray-Tracing-Specification/","link":"","permalink":"https://blog.inoki.cc/2021/08/02/Vulkan-Ray-Tracing-Specification/","excerpt":"","text":"原文链接：Vulkan Ray Tracing Final Specification Release 总览 今天，Khronos® 发布了一套 Vulkan®、GLSL 和 SPIR-V 扩展规范的最终版本，将光线追踪无缝集成到现有的Vulkan框架中。这是一个重要的里程碑，因为它是业界第一个开放的、跨厂商的、跨平台的光线追踪加速标准–可以使用现有的GPU计算或专门的光线追踪核心来部署。凡是使用过 DirectX 12 中的 DirectX 光线追踪（DXR）的人都会对 Vulkan 光线追踪感到熟悉，但它也引入了一些高级功能，比如将光线追踪设置操作负载平衡到主机 CPU 上的能力。尽管光线追踪将首先部署在桌面系统上，但这些 Vulkan 扩展的设计是为了使光线追踪也能部署在移动设备上，并激励光线追踪的使用。 这些扩展最初是在 2020 年 3 月作为临时版本发布的。从那时起（见图 1），我们收到并采纳了硬件供应商和软件开发商的反馈，包括 Khronos 内部和更广泛的行业，但 API 的整体状态和提供的功能基本上没有变化。感谢所有审阅和使用临时扩展的人，特别是那些提供反馈意见的人! 今天发布的扩展规范只是 Vulkan 光线追踪技术推广的开始。在未来几天和几周内，其他生态系统组件，如着色器工具链和验证层将被更新，以支持光线追踪功能，确保开发人员能够在他们的应用程序中轻松使用这些扩展。这些生态系统的更新进展可以在 GitHub 上跟踪。这将在12月中旬发布支持 Khronos Vulkan 光线追踪的 Vulkan SDK（1.2.162.0 或更高版本）时达到最高活跃度。 这篇文章将强调 Vulkan Ray Tracing 扩展的临时版本和最终版本之间最重要的区别，并解释这些变化背后的一些原因。 秀出我们的规范！ 这套 Vulkan 光线追踪扩展所提供的整体功能自其临时版本以来没有变化。今天发布的最终扩展集是： 12345678910111213Vulkan extension specifications VK_KHR_acceleration_structure VK_KHR_ray_tracing_pipeline VK_KHR_ray_query VK_KHR_pipeline_library VK_KHR_deferred_host_operationsSPIR-V extensions specifications SPV_KHR_ray_tracing SPV_KHR_ray_queryGLSL extensions specifications GLSL_EXT_ray_tracing GLSL_EXT_ray_query GLSL_EXT_ray_flags_primitive_culling 拓展的结构 最明显的变化是，临时的 VK_KHR_ray_tracing 扩展已经被分成了 3 个扩展： VK_KHR_acceleration_structure - 用于加速结构的构建和管理 VK_KHR_ray_tracing_pipeline - 用于光线追踪着色器的阶段和流水线 VK_KHR_ray_query - 为所有着色器阶段提供光线查询的基本 我们收到的反馈是，一些市场希望能够支持光线追踪查询而不支持光线追踪流水线，为了避免重复和人为的依赖，我们对原来的扩展进行了细分。实现可以选择支持 VK_KHR_ray_tracing_pipeline、VK_KHR_ray_query 或两者之一，取决于市场需要。这两个扩展都依赖于VK_KHR_acceleration_structure 扩展，为加速结构管理提供一个共同的基础。主要的桌面厂商仍然致力于支持光线流水线和光线查询。关于对可选功能的支持和对其他市场的支持的具体细节，请与各个供应商商谈。 Vulkan 光线追踪扩展不再被标记为临时性的，因此五个扩展的扩展接口现在被定义在主 vulkan_core.h 头中，而不是临时的 vulkan_beta.h，用户不再需要 #define VK_ENABLE_BETA_EXTENSIONS 来启用 Vulkan 光线追踪功能。 扩展的依赖性也有变化。现在需要 Vulkan 1.1 和 SPIR-V 1.4。VK_KHR_acceleration_structure 需要Vulkan 1.1、VK_EXT_descriptor_indexing、VK_KHR_buffer_device_address，以及VK_KHR_deferred_host_operations。我们意识到，一个冗长的扩展依赖列表是令人讨厌的，理想情况下，我们希望简单地要求 Vulkan 1.2，但目前并非所有平台都支持 Vulkan 1.2，我们不想为采用光线追踪功能添加任何人为障碍。如果所有的目标市场都支持 Vulkan 1.2，那么应用程序就可以直接以 Vulkan 1.2 为目标，以达到简化的目的。我们也考虑过不把 VK_KHR_deferred_host_operations 作为一个明确的依赖关系，但是用延迟操作创建流水线的变化要求我们保留它。我们把 VK_KHR_pipeline_library 作为 VK_KHR_ray_tracing_pipeline 的软要求，而不是严格要求，因此应用程序只需要在实际使用时启用它。除了 VK_KHR_acceleration_structure，VK_KHR_ray_tracing_pipeline 和 VK_KHR_ray_query 都至少需要 SPIR-V 1.4，因为该版本中增加了入口点要求的变化。SPIR-V 1.5 也可以用于 Vulkan 1.2 的实现。 从功能上讲，所有的实现都必须具备以下功能： VK_KHR_deferred_host_operations accelerationStructure descriptorBindingAccelerationStructureUpdateAfterBind descriptorIndexing 功能（如果支持 Vulkan 1.2）或 VK_EXT_descriptor_indexing 扩展所需的所有功能 Vulkan 1.2 中的 bufferDeviceAddress 或 VK_KHR_buffer_device_address 支持 VK_KHR_ray_tracing_pipeline 的实现需要： VK_KHR_acceleration_structure rayTracingPipeline rayTracingPipelineTraceRaysIndirect rayTraversalPrimitiveCulling 若 VK_KHR_ray_query 也被支持 VK_KHR_pipeline_library 支持 VK_KHR_ray_query 的实现需要 require: VK_KHR_acceleration_structure rayQuery. 此外，还有一些可选择的能力与扩展定义。 对于 VK_KHR_acceleration_structure，有： accelerationStructureCaptureReplay accelerationStructureIndirectBuild accelerationStructureHostCommands 对于 VK_KHR_ray_tracing_pipeline，有： rayTracingPipelineShaderGroupHandleCaptureReplay rayTracingPipelineShaderGroupHandleCaptureReplayMixed rayTraversalPrimitiveCulling，若 VK_KHR_ray_query 未支持 加速结构 在最终的 Vulkan 光线追踪功能中，对应用程序影响最大的变化是加速结构的创建和布局。 我们从 API 翻译层（如 vkd3d-proton）的作者那里得到反馈，在临时 API Vulkan 光线追踪加速结构的基础上分层 DXR 是不现实的。这导致了对加速结构创建大小的改变，并使用 VkBuffer 上的加速结构存储分配，而不是专门的加速结构对象存储。这些变化的一个影响是，VkAccelerationStructureKHR 和 VkAccelerationStructureNV 不再是别名，不能互换使用。同样地，任何以它们为参数的结构或函数也不再是别名了。 我们还为分层添加了一个新的加速结构类型 VK_ACCELERATION_STRUCTURE_TYPE_GENERIC_KHR。 在实际的加速结构类型（顶部或底部）还不清楚的情况下，可以在加速结构创建时使用。实际的加速结构类型必须指定为 VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR 或 VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_KHR，当执行构建时不能改变。直接为 Vulkan 编写的应用程序不应该使用 VK_ACCELERATION_STRUCTURE_TYPE_GENERIC_KHR，因为这可能会影响未来的能力或性能。 我们还收到了分层 Vulkan 实现（如 MoltenVK）的作者的反馈，指出一些光线追踪的要求（如设备地址）会使 Vulkan 无法在其他一些 API 上以分层方式实现。不幸的是，我们不可能在解决这个问题的同时还支持其他目标，比如与 DXR 的功能对等。我们希望其他 API 的未来版本也能添加必要的功能来实现这种分层。 我们听说开发者真的很喜欢统一的创建和构建参数，就像在 VK_NV_ray_tracing 和 DXR 中。我们将加速结构的创建改为基于大小，大小可以从用于构建的同一结构中计算（vkGetAccelerationStructureBuildSizesKHR），或者从精简查询中计算（vkCmdWriteAccelerationStructuresPropertiesKHR）。我们还了解到，一些实现在创建时需要额外的信息，这导致 vkGetAccelerationStructureBuildSizesKHR 中增加了 pMaxPrimitiveCounts。 以前的几何体描述的某些方面很混乱，与自动生成的代码不能很好地配合（如验证层），因此我们解决了 ppGeometries 二元性造成的模糊，并增加了一个额外的 pGeometries 字段，但要求每次只使用其中一个字段。 其他新增内容包括：加速器结构的创建时间捕获和重放标志（用于调试工具），加速器结构的 nullDescriptor 支持，作为与 VK_EXT_robustness2 的交互，以及加速器结构的 VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT 支持。 最后但并非最不重要的是，我们做了修改，以便在所有扩展中一致地使用设备地址。我们还提出了许多命名建议，其中一些被采纳了，并且出于一致性和可扩展性的考虑，我们做了各种命名和风格上的改变。关于这些和其他变化的更多细节，请参见问题 3 和 4 以及 VK_KHR_acceleration_structure 中的变化日志。 延迟的主机操作 我们修改了 vkBuildAccelerationStructuresKHR 和 vkCreateRayTracingPipelinesKHR 命令中延迟主机操作的使用方式。现在，延迟操作请求不再被链入每个单独的构建或创建操作的 pNext 中，而是作为命令的顶级参数传入，整个命令要么延迟，要么不延迟。当命令被推迟时，应用程序不得访问返回参数，直到推迟的操作完成。之前的命令语义中，一些子操作可以被延迟，而另一些则不能，这使得对命令返回值的行为预期不明确，很难理解什么时候访问它们是安全的。我们认为，新的语义更清晰，应该能够提供更多的并行机会，但如上所述，这是以要求 VK_KHR_deferred_host_operations 扩展在任何时候都被启用为代价。 光线追踪流水线 对光线追踪流水线机制的改变没有那么剧烈，其中一些只影响 SPIR-V 和着色器编译器工具链。 除了上面提到的针对延迟操作的 vkCreateRayTracingPipelinesKHR 的变化之外，还有一些变化，使 VkPipelineLibraryCreateInfoKHR 和 VkRayTracingPipelineInterfaceCreateInfoKHR 成为可选项，这样如果不使用 VK_KHR_pipeline_library，就不需要启用它们。 对于光线追踪流水线来说，最大的 API 变化是增加了明确的堆栈大小管理。光线追踪流水线有一个潜在的大型着色器集，在光线追踪过程中可能会以各种调用链组合的方式被调用。在给定的着色器执行过程中，实现可以使用堆栈在内存中存储参数，这个堆栈的大小需要足够大，以处理实现可以执行的任何调用链中所有着色器所需的堆栈大小。默认的堆栈大小有可能相当大，所以我们增加了一种方法，让应用程序在流水线编译后指定一个更理想的堆栈大小。这是在应用程序可以根据对着色器和调用链属性的特定应用知识计算出更严格的堆栈大小约束的情况下使用的。为光线追踪流水线添加了一个新的动态状态（VK_DYNAMIC_STATE_RAY_TRACING_PIPELINE_STACK_SIZE_KHR），以及查询着色器组的堆栈大小（vkGetRayTracingShaderGroupStackSizeKHR）和为流水线设置动态堆栈大小（vkCmdSetRayTracingPipelineStackSizeKHR）的命令。 另一个新增功能是基于 DXR 分层工作的反馈，即通过加速结构地址追踪光线的能力。有了这个功能，从 vkGetAccelerationStructureDeviceAddressKHR 获取的加速结构的设备地址可以存储在一个缓冲区或其他着色器资源中。在着色器中，可以使用SPIR-V OpConvertUToAccelerationStructureKHR指令（在 GLSL 中表现为 accelerationStructureEXT 类型构造器）将其转换为不透明的 OpTypeAccelerationStructureKHR 描述器类型。然后，产生的变量可以用来指定加速结构，以便在 OpTraceRayKHR 指令（traceRayEXT()）中进行追踪。这种转换是单向的，在不透明的加速结构描述符上不支持其他操作。 SPIR-V 工作组也提供了关于 SPIR-V 扩展的反馈，这导致了对 OpTraceRayKHR 的有效载荷参数和 OpExecuteCallableKHR 的可调用数据参数的修改。以前，这些参数与 GLSL 中声明的有效载荷或可调用数据结构的位置布局限定符匹配。然而，这些位置在 SPIR-V 中是没有意义的，因此被替换为直接指向适当的存储类的指针，而不是使用整数位置。这对 GLSL 扩展没有影响，因为 glslang 自动处理了转换，然而，这确实需要 OpTraceRayKHR 和 OpExecuteCallableKHR 的新操作码，它们不能再与 SPV_NV_ray_tracing 的相应操作相联系。 另一个由内部反馈驱动的 SPIR-V 变化是将 OpIgnoreIntersectionKHR 和 OpTerminateRayKHR 变成终止指令，因为它们终止了执行它们的调用。这些指令也必须是一个块中的最后一条指令。同样，这也导致了新的操作码被分配给这些指令。这一变化确实影响了 GLSL–这些指令不再是内置函数，而是跳转语句，因此在着色器中使用时，不再显示为 ignoreIntersectionEXT()；而是简单地显示为 ignoreIntersectionEXT；。 在总结 SPIR-V 对光线追踪流水线的修改时，有一个新的能力和枚举（RayTracingKHR），使实现和工具链能够区分为现在已经过时的临时扩展而编写的 SPIR-V 和最终语义。我们还对 ShaderRecordBufferKHR 所需的明确布局做了一些澄清，并将其与StorageBuffer存储类的处理方式相同。我们还规定了 OpReportIntersectionKHR 的返回值和超出范围的T值的行为，并澄清了只有一个子集的比特用于各种光线追踪参数。 与 VK_KHR_acceleration_structure 扩展一样，我们做了修改，以完全使用缓冲设备地址，因此着色器绑定表现在被作为缓冲设备地址通过 VkStridedDeviceAddressRegionKHR 结构提供给追踪光线命令。同样地，vkCmdTraceRaysIndirectKHR 的间接参数也通过缓冲设备地址传递。 我们还更新了与 Vulkan 1.2 和 VK_KHR_vulkan_memory_model 扩展的交互，并要求某些内置变量（主要是与子组相关的）在支持着色器调用的着色器中被标记为 Volatile。 其他变化包括为着色器组句柄添加创建时间捕获和重放标志，添加以前遗漏的各种属性和限制，以及一些重命名以提高清晰度。关于这些和其他变化的更多细节，请参见 VK_KHR_ray_tracing_pipeline 中的问题 3 和 4，SPV_KHR_ray_tracing 中的问题 2，以及扩展变化日志。 光线查询 鉴于 Vulkan 的 API 中很少有光线查询，大部分与光线查询有关的变化都在 SPIR-V 的扩展和交互中。 SPV_KHR_ray_query 还包括支持通过加速结构地址发出光线查询，并增加了OpConvertUToAccelerationStructureKHR，同样可以用来将加速结构设备地址转换成不透明的OpTypeAccelerationStructureKHR 描述符。然后，这些描述符可以用来为 OpRayQueryInitializeKHR 指定要追踪的加速结构。 与光线流水线一样，存在一个新的能力和枚举（RayQueryKHR），使实现和工具链能够区分为现在已经过时的临时扩展而编写的 SPIR-V 和最终语义。我们还澄清了只有一个子集的位用于剔除掩码，并且不允许从 AABB 基元中查询候选 T 值。 最后，我们还规定了光线参数的数值限制，要求 HitT 在 OpRayQueryGenerateIntersectionKHR 的光线区间内，并将追踪限制在顶层加速结构上。 关于这些和其他变化的更多细节，请参见 VK_KHR_ray_query 的第1期，SPV_KHR_ray_query 的第1期，以及扩展的变化日志。 路在脚下 This section gives an overview of the new flow for acceleration structure creation and includes a quick primer on resource creation flags and ray tracing synchronization. 加速结构的创建 为了创建一个加速结构，应用程序必须首先确定加速结构所需的尺寸。对于构建来说，加速结构的大小以及构建和更新的缓冲区大小是通过 vkGetAccelerationStructureBuildSizesInfoKHR 结构中的 vkGetAccelerationStructureBuildSizesKHR 命令获得。要创建的加速结构的形状和类型在 VkAccelerationStructureBuildGeometryInfoKHR 结构中描述。这和以后用于实际构建的结构是一样的，但是加速结构参数和几何体数据指针不需要在这时完全填充（尽管它们可以填充），只是加速结构类型，以及几何体类型、计数和最大尺寸。这些尺寸对任何足够相似的加速结构都是有效的。对于将成为压缩拷贝目标的加速结构，所需的尺寸可以通过 vkCmdWriteAccelerationStructuresPropertiesKHR 命令获得。一旦确定了所需的大小，应用程序就会为加速结构创建一个 VkBuffer（accelerationStructureSize），并根据需要为构建（buildScratchSize）和更新（updateScratchSize）缓冲区创建 VkBuffer。 接下来，可以使用 vkCreateAccelerationStructureKHR 命令创建 VkAccelerationStructureKHR 对象，该命令创建一个指定类型和大小的加速结构，并将其放置在 VkAccelerationStructureCreateInfoKHR 中提供的缓冲区的偏移处。与 Vulkan 中的大多数其他资源不同，缓冲区的指定部分完全为加速结构提供了内存；不需要查询额外的内存需求或将内存绑定到加速结构对象上。如果需要，可以在同一个 VkBuffer 中放置多个加速结构，只要加速结构不重叠。 最后，可以使用 vkCmdBuildAccelerationStructuresKHR 命令来构建加速结构。构建时使用与确定加速结构大小相同的 VkAccelerationStructureBuildGeometryInfoKHR 结构，但这次必须指定目标加速结构以及所有几何数据指针（用于顶点、索引、变换、aabbs和实例）和抓取数据指针。一旦构建完成，加速结构是完全独立的，构建输入和从头开始的缓冲区可以被应用程序重新利用，除非它计划将它们用于未来的更新构建。 资源使用与同步 本节提供了关于何时应使用各种缓冲区使用标志的高层次概述，以及对各种光线追踪操作应使用何种类型的同步的简要描述。 将用于加速结构备份的缓冲区是用 VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR 用法创建的，将用于构建从头空间的缓冲区需要指定 VK_BUFFER_USAGE_STORAGE_BUFFER_BIT 用法。和加速结构的构建输入，如顶点、索引、变换、aabb和实例数据，需要指定 VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR 用法。用于着色器绑定表的缓冲区以 VK_BUFFER_USAGE_SHADER_BINDING_TABLE_BIT_KHR 用法创建，用于间接构建和跟踪参数的缓冲区以 VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT 用法创建。 为了与加速结构构建命令（vkCmdBuildAccelerationStructuresKHR vkCmdBuildAccelerationStructuresIndirectKHR）同步依赖，使用 VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_KHRpipeline 阶段。对源加速结构或目标加速结构的访问，以及对取回缓冲区的访问，使用 VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_KHR 或 VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_KHR 的访问类型。对构建的输入缓冲区（顶点、索引、变换、aabb或实例数据）的访问使用 VK_ACCESS_SHADER_READ_BIT 的访问类型，对间接参数的访问使用 VK_ACCESS_INDIRECT_COMMAND_READ_BIT 的访问类型。 当与加速结构复制命令（vkCmdWriteAccelerationStructuresPropertiesKHR、vkCmdCopyAccelerationStructureKHR、vkCmdCopyAccelerationStructureToMemoryKHR 和 vkCmdCopyMemoryToAccelerationStructureKHR）同步依赖时，也使用 VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_KHR 流水线阶段。读取或写入加速结构的访问分别使用 VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_KHR 或者 VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_KHR。通过设备地址访问缓冲区进行读取或写入，分别使用 VK_ACCESS_TRANSFER_READ_BIT 或 VK_ACCESS_TRANSFER_WRITE_BIT 的访问类型。 为了与光线追踪命令（vkCmdTraceRaysKHR 和 vkCmdTraceRaysIndirectKHR）同步依赖， VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR 流水线阶段被用于访问着色器绑定表缓冲区，访问类型为 VK_ACCESS_SHADER_READ_BIT。对于间接参数的访问，使用 VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT 流水线阶段，访问类型为 VK_ACCESS_INDIRECT_COMMAND_READ_BIT。 为了与任何图形、计算或光线追踪流水线阶段中用于光线查询指令的加速结构同步依赖关系，适当的流水线阶段与 VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_KHR 访问类型应当一起使用。 结论与资源 现在，最终的 Vulkan 光线追踪扩展已经发布，目前支持临时规范的生态系统工件将尽快更新，工具和其他组件的推出将在 GitHub 上进行跟踪。我们鼓励所有开发者过渡到使用最终的 Khronos Vulkan 光线追踪扩展。 包括用于 NVIDIA GPU 的最终 Vulkan 光线追踪扩展的驱动程序可以在 developer.nvidia.com/vulkan-driver 上找到，同时还有关于哪些GPU受到支持的信息。支持这些扩展的 AMD GPU 的初始驱动程序可以在https://www.amd.com/en/support/kb/release-notes/rn-rad-win-20-11-2-vrt-beta。英特尔 Xe-HPG GPU 将支持光线追踪扩展，于2021年推出，并通过常规驱动更新程序提供驱动支持。 关于如何将 Vulkan 光线追踪用于混合渲染的见解，其中光栅化和光线追踪被串联使用，以实现引人注目的视觉保真度和互动性，请查看 Vulkan 光线追踪混合渲染的最佳实践博客，其中讨论了光线追踪反射在《重返德军总部：新血缘》中使用最终扩展描述的光线追踪反射的实现。。 今天还发布了最新的 NVIDIA Vulkan 光线追踪教程，以及支持 Vulkan 光线追踪扩展的 NVIDIA Nsight 图形开发工具的 2020.6 版本。敬请关注更多即将发布的关于生产驱动、工具和示例的公告。 Vulkan 工作组很高兴能够让开发者和内容创作社区使用 Vulkan 光线追踪，我们欢迎任何反馈或问题。这些问题可以通过 Khronos 开发者 Slack 和 Vulkan GitHub 问题追踪器进行分享。 欢迎来到便携式、跨厂商、跨平台的光线追踪加速时代！","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://blog.inoki.cc/categories/Computer-Graphics/"},{"name":"Vulkan","slug":"Computer-Graphics/Vulkan","permalink":"https://blog.inoki.cc/categories/Computer-Graphics/Vulkan/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://blog.inoki.cc/tags/Computer-Graphics/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://blog.inoki.cc/tags/Vulkan/"},{"name":"Ray Tracing","slug":"Ray-Tracing","permalink":"https://blog.inoki.cc/tags/Ray-Tracing/"}]},{"title":"Write your own IME on macOS - 1. Create project","slug":"Write-your-own-IME-on-macOS-1","date":"2021-06-19T19:15:00.000Z","updated":"2025-03-08T09:40:48.603Z","comments":true,"path":"2021/06/19/Write-your-own-IME-on-macOS-1/","link":"","permalink":"https://blog.inoki.cc/2021/06/19/Write-your-own-IME-on-macOS-1/","excerpt":"","text":"On macOS, it is not so difficult to write an Input Method Engine (IME). Unlike Linux or the other Unix-like OS, macOS provides an official framework, InputMethodKit, to help you write an Input Method Engine. An IME project is in fact a normal Cocoa app located in a special directory, with a special bundle identifier, some special declarations in plist manifest file, and some special classes/objects in the project. This post may help you initiate your own IME project. Let’s go! Create the project First, open XCode, create a new App project: Then, type your IME name. Here I choose the typical name “HelloWorld”. Notice that there must be an inputmethod identifier in the bundle identifier. I choose to append a suffix to my organization identifier. However, you should also be able to do it in another way. Add some magic In this section, I’ll add some magic to to turn the app into an IME. Plist magic In the manifest file Info.plist, there are magic to declare some information of your IME: Key Type InputMethodConnectionName String InputMethodServerControllerClass String tsInputMethodCharacterRepertoireKey Array The InputMethodConnectionName will be the name of your IME, recognized by macOS. The InputMethodServerControllerClass is the name of the Input Method controller class in your IME, which is in charge of communicating with macOS, exchanging the input events and submitting the candidate selected by the user. The tsInputMethodCharacterRepertoireKey can help you declare the category of your IME. It will depend where your IME will show up in the Input Source panel of the macOS system preference. As an array, there can be multiple items. Thus, an IME for several languages is possible. For example, Squirrel has a zh-Hans string in the array, so it shows up in the Chinese, Simplified language as follow: If all is set, we can have an Info.plist like this: I choose InokiHelloWorldIME as the connection name. There will be an Input Method controller class named InokiHelloWorldController in my project, in charge of events. And I added zh-Hans, zh-Hant and Latn for the category. Class magic We need to create our Input Method controller class, inheriting IMKInputController class from Input Method Kit. Add these codes to the implementation(.m) file, so that we can observe what happens when we are “using”(not actually) the IME: 123456789- (void)activateServer:(id)sender&#123; NSLog(@\"Server activated for %@\", [sender bundleIdentifier]);&#125;- (void)deactivateServer:(id)sender&#123; NSLog(@\"Server deactivated for %@\", [sender bundleIdentifier]);&#125; This method is using one of the controller API to receive input event from macOS: 12345- (BOOL)inputText:(NSString*)string client:(id)sender&#123; NSLog(@\"Controller received: %@\", string); return NO;&#125; There are in fact 3 different APIs to handle the input event, such as: 123- (BOOL)inputText:(NSString*)string key:(NSInteger)keyCode modifiers:(NSUInteger)flags client:(id)sender;- (BOOL)inputText:(NSString*)string client:(id)sender;- (BOOL)handleEvent:(NSEvent*)event client:(id)sender; For more details, you can take a look at the declaration of IMKInputController in InputMethodKit/IMKInputController.h. With all these done, macOS should be able to find your Input Controller, thanks to the runtime information in Objective-C. Main Code magic Finally, we need a minimum main function like this. 123456789101112131415#import &lt;Cocoa/Cocoa.h&gt;#import &lt;InputMethodKit/InputMethodKit.h&gt;NSString* connectionName = @\"InokiHelloWorldIME\";IMKServer* server;int main(int argc, char * argv[]) &#123; @autoreleasepool&#123; server = [[IMKServer alloc] initWithName:(NSString*)connectionName bundleIdentifier:[[NSBundle mainBundle] bundleIdentifier]]; [[NSApplication sharedApplication] run]; &#125; return 0;&#125; In which we create an instance of IMKServer and make it alive during all the life cycle of our app. The server is also registered to macOS, so that the OS knows which process it should communicate. Run it Finally, we can build it and copy it into /Library/Input Methods. For debug or running, this post (in Chinese) is a good example. Here, I concentrate more on the potential and undocumented bug (ok, it might be a feature) as follows. Oups, you may be isolated in a sandbox You may suffer an error like: 1[IMKServer _createConnection]: *Failed* to register NSConnection name=xxxxx Same to me. I took several hours to dive into macOS and debug such error. I found that the reason: IMKServer needs an NSConnection to communicate with macOS. However, by default, the app is sandboxized (by the &lt;project-name.entitlements&gt;) since a version of XCode. So, the solutions are various: Remove the entitlements file; Allow NSConnection from sandbox; Disable the App sandbox in the entitlements file. Then, your IME should be good to go. Conclusion In this post, there is a brief description for creating an IME project. I show an issue that may generally exist related to the sandbox stuff. Hope this can help you. In the next post, I’ll try to show up the event handle in an IME on macOS.","categories":[{"name":"IME","slug":"IME","permalink":"https://blog.inoki.cc/categories/IME/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"https://blog.inoki.cc/tags/macOS/"},{"name":"IME","slug":"IME","permalink":"https://blog.inoki.cc/tags/IME/"}]},{"title":"KDE Connect iOS Develop Dairy(3) Certificate","slug":"KDEConnect-iOS-dev-dairy-3","date":"2021-02-07T14:34:50.000Z","updated":"2025-03-08T09:40:48.578Z","comments":true,"path":"2021/02/07/KDEConnect-iOS-dev-dairy-3/","link":"","permalink":"https://blog.inoki.cc/2021/02/07/KDEConnect-iOS-dev-dairy-3/","excerpt":"","text":"As mentioned at the end of my previous post KDE Connect iOS Develop Dairy(2) Identity Protocol, the new version KDE Connect protocol needs a TLS/SSL connection to make a completed identification. Indeed, devices use the TLS/SSL connection to communicate with each other, under secure consideration. In such a connection with asymmetric cryptography, the most important thing is the private key, the public key exchange, and the certificate signed with each device’s private key. This post describes how I added a related library (OpenSSL) and used it to generate these elements. Investigation OpenSSL is a widely used library for my purpose. However, there are too many options for each entity. For the private-public key pair, there are several algorithms such as the Elliptic-Curve Digital Signature Algorithm (ECDSA), RSA, etc. What we need to use is precisely the one used by the original KDE Connect. So, I did an investigation on the original version on KDE Invent. Implementation in KDE Connect codebase KDE Connect uses QCA-Qt5 (Qt Cryptographic Architecture), a Qt library providing a straightforward API. To generate a private key (and its paired public key) with 2048 bits from the RSA algorithm, KDE Connect profits this single line: 123456void KdeConnectConfig::generatePrivateKey(const QString&amp; keyPath)&#123; // ... d-&gt;m_privateKey = QCA::KeyGenerator().createRSA(2048); // ...&#125; Then, the generated private key is stored in m_privateKey field. To generate a certificate, KDE Connect uses this method: 1234567891011121314151617181920212223242526void KdeConnectConfig::generateCertificate(const QString&amp; certPath)&#123; // ... QString uuid = QUuid::createUuid().toString(); DBusHelper::filterNonExportableCharacters(uuid); qCDebug(KDECONNECT_CORE) &lt;&lt; \"My id:\" &lt;&lt; uuid; // FIXME: We only use QCA here to generate the cert and key, would be nice to get rid of it completely. // The same thing we are doing with QCA could be done invoking openssl (although it's potentially less portable): // openssl req -new -x509 -sha256 -newkey rsa:2048 -nodes -keyout privateKey.pem -days 3650 -out certificate.pem -subj \"/O=KDE/OU=KDE Connect/CN=_e6e29ad4_2b31_4b6d_8f7a_9872dbaa9095_\" QCA::CertificateOptions certificateOptions = QCA::CertificateOptions(); QDateTime startTime = QDateTime::currentDateTime().addYears(-1); QDateTime endTime = startTime.addYears(10); QCA::CertificateInfo certificateInfo; certificateInfo.insert(QCA::CommonName, uuid); certificateInfo.insert(QCA::Organization,QStringLiteral(\"KDE\")); certificateInfo.insert(QCA::OrganizationalUnit,QStringLiteral(\"Kde connect\")); certificateOptions.setInfo(certificateInfo); certificateOptions.setFormat(QCA::PKCS10); certificateOptions.setSerialNumber(QCA::BigInteger(10)); certificateOptions.setValidityPeriod(startTime, endTime); d-&gt;m_certificate = QSslCertificate(QCA::Certificate(certificateOptions, d-&gt;m_privateKey).toPEM().toLatin1()); // ...&#125; TL;DR, KDE Connect gets a UUID of the current device, use it as Common Name(CN) to generate a certificate with PKCS10; the certificate is valid from one year before to ten years later; there are 2 other fields: Orgnization(O) set to KDE and Organization Unit(OU) set to `Kde connect. Finally, KDE Connect uses the private key to sign the certificate (we can call it self-sign, because there is no authority). We can see that the QCA::Certificate constructor is in charge of all of them. Unfortunately, on iOS, it is not so easy to find an all-in-one solution. I needed to find out how it is done in detail. 123456789Certificate::Certificate(const CertificateOptions &amp;opts, const PrivateKey &amp;key, const QString &amp;provider):d(new Private)&#123; CertContext *c = static_cast&lt;CertContext *&gt;(getContext(QStringLiteral(\"cert\"), provider)); if(c-&gt;createSelfSigned(opts, *(static_cast&lt;const PKeyContext *&gt;(key.context())))) change(c); else delete c;&#125; In the constructor, we can see that a cert context is got, and used to create a self-signed certificate. The method is declared here: 1234567891011121314151617181920212223class QCA_EXPORT CertContext : public CertBase&#123; Q_OBJECTpublic: /** Standard constructor \\param p the provider associated with this context */ CertContext(Provider *p) : CertBase(p, QStringLiteral(\"cert\")) &#123;&#125; /** Create a self-signed certificate based on the given options and private key. Returns true if successful, otherwise false. If successful, this object becomes the self-signed certificate. If unsuccessful, this object is considered to be in an uninitialized state. \\param opts the options to set on the certificate \\param priv the key to be used to sign the certificate */ virtual bool createSelfSigned(const CertificateOptions &amp;opts, const PKeyContext &amp;priv) = 0; and implemented here: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111class MyCertContext : public CertContext&#123; Q_OBJECTpublic: bool createSelfSigned(const CertificateOptions &amp;opts, const PKeyContext &amp;priv) override &#123; _props = CertContextProps(); item.reset(); CertificateInfo info = opts.info(); // Note: removing default constraints, let the app choose these if it wants Constraints constraints = opts.constraints(); // constraints - logic from Botan /*Constraints constraints; if(opts.isCA()) &#123; constraints += KeyCertificateSign; constraints += CRLSign; &#125; else constraints = find_constraints(priv, opts.constraints());*/ EVP_PKEY *pk = static_cast&lt;const MyPKeyContext *&gt;(&amp;priv)-&gt;get_pkey(); X509_EXTENSION *ex; const EVP_MD *md; if(priv.key()-&gt;type() == PKey::RSA) md = EVP_sha1(); else if(priv.key()-&gt;type() == PKey::DSA) md = EVP_sha1(); else return false; // create X509 *x = X509_new(); X509_set_version(x, 2); // serial BIGNUM *bn = bi2bn(opts.serialNumber()); BN_to_ASN1_INTEGER(bn, X509_get_serialNumber(x)); BN_free(bn); // validity period ASN1_TIME_set(X509_get_notBefore(x), opts.notValidBefore().toTime_t()); ASN1_TIME_set(X509_get_notAfter(x), opts.notValidAfter().toTime_t()); // public key X509_set_pubkey(x, pk); // subject X509_NAME *name = new_cert_name(info); X509_set_subject_name(x, name); // issuer == subject X509_set_issuer_name(x, name); // subject key id ex = new_subject_key_id(x); &#123; X509_add_ext(x, ex, -1); X509_EXTENSION_free(ex); &#125; // CA mode ex = new_basic_constraints(opts.isCA(), opts.pathLimit()); if(ex) &#123; X509_add_ext(x, ex, -1); X509_EXTENSION_free(ex); &#125; // subject alt name ex = new_cert_subject_alt_name(info); if(ex) &#123; X509_add_ext(x, ex, -1); X509_EXTENSION_free(ex); &#125; // key usage ex = new_cert_key_usage(constraints); if(ex) &#123; X509_add_ext(x, ex, -1); X509_EXTENSION_free(ex); &#125; // extended key usage ex = new_cert_ext_key_usage(constraints); if(ex) &#123; X509_add_ext(x, ex, -1); X509_EXTENSION_free(ex); &#125; // policies ex = new_cert_policies(opts.policies()); if(ex) &#123; X509_add_ext(x, ex, -1); X509_EXTENSION_free(ex); &#125; // finished X509_sign(x, pk, md); item.cert = x; make_props(); return true; &#125; I could use this as a reference to implement the generation of the private key and the certificate. Implementation on iOS The next step is to generate a certificate and load it on iOS, to test. Generate and store self-signed certificate on iOS I tried several times and several ways, because there were many difficulties. They are noted here. Hope these can help. First generation with OpenSSL cli To make an easy start, I tried to generate a private key and a certificate using OpenSSL. The equivalent command is listed in the comment: 1openssl req -new -x509 -sha256 -newkey rsa:2048 -nodes -keyout privateKey.pem -days 3650 -out certificate.pem -subj &quot;/O=KDE/OU=KDE Connect/CN=_e6e29ad4_2b31_4b6d_8f7a_9872dbaa9095_&quot; After this, I have a privateKey.pem and a certificate.pem. Load self-signed certificate on iOS I tried to separetly load the key and the certificate on iOS, but I did not find a proper API to do so. In a secure connection on iOS, the type needed is SecIdentityRef. However, there is an API to do so: 1OSStatus SecItemImport(CFDataRef importedData, CFStringRef fileNameOrExtension, SecExternalFormat *inputFormat, SecExternalItemType *itemType, SecItemImportExportFlags flags, const SecItemImportExportKeyParameters *keyParams, SecKeychainRef importKeychain, CFArrayRef _Nullable *outItems); only for macOS 10.7+, but not for iOS. There is another one: 1OSStatus SecPKCS12Import(CFDataRef pkcs12_data, CFDictionaryRef options, CFArrayRef _Nullable *items); to import both the private key and the certificate at the same time. But it only accepts the data from a p12 file. So, finally, I sumed the private key and the certificate into a p12 file. And the loading method is like: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152- (void) loadSecIdentity&#123; BOOL needGenerateCertificate = NO; NSString *resourcePath = NULL; NSArray *documentDirectories = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES); for (NSString *directory in documentDirectories) &#123; NSLog(@&quot;Find %@&quot;, directory); resourcePath = [directory stringByAppendingString:@&quot;/rsaPrivate.p12&quot;]; &#125; NSFileManager *fileManager = [NSFileManager defaultManager]; if (resourcePath != NULL &amp;&amp; [fileManager fileExistsAtPath:resourcePath]) &#123; NSData *p12Data = [NSData dataWithContentsOfFile:resourcePath]; NSMutableDictionary * options = [[NSMutableDictionary alloc] init]; [options setObject:@&quot;&quot; forKey:(id)kSecImportExportPassphrase]; // No password CFArrayRef items = CFArrayCreate(NULL, 0, 0, NULL); OSStatus securityError = SecPKCS12Import((CFDataRef) p12Data, (CFDictionaryRef)options, &amp;items); SecIdentityRef identityApp; if (securityError == noErr &amp;&amp; CFArrayGetCount(items) &gt; 0) &#123; SecKeyRef privateKeyRef = NULL; CFDictionaryRef identityDict = CFArrayGetValueAtIndex(items, 0); identityApp = (SecIdentityRef)CFDictionaryGetValue(identityDict, kSecImportItemIdentity); securityError = SecIdentityCopyPrivateKey(identityApp, &amp;privateKeyRef); if (securityError != noErr) &#123; // Fail to retrieve private key from the .p12 file needGenerateCertificate = YES; &#125; else &#123; _identity = identityApp; NSLog(@&quot;Certificate loaded successfully from %@&quot;, resourcePath); &#125; &#125; else &#123; // Not valid component in the .p12 file needGenerateCertificate = YES; &#125; &#125; else &#123; // No .p12 file needGenerateCertificate = YES; &#125; if (needGenerateCertificate) &#123; // generate certificate NSLog(@&quot;Need generate certificate&quot;); [self generateAndLoadSecIdentity]; &#125;&#125; The p12 file is still available in the project, and should be removed soon. Attemption on generation with OpenSSL-Universal I tried to use OpenSSL-Universal by adding: 1pod 'OpenSSL-Universal' But it does not work, in both meanings: the generated certificate cannot be correctly loaded; there is an error indicating the missing bitcode on Xcode 11.3.1 and on a real iPhone. Success generation After searching, I choose to use: 1pod 'openssl-ios-bitcode' The final generation method is as follow: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081- (void) generateSecIdentity&#123; // generate private key EVP_PKEY * pkey; pkey = EVP_PKEY_new(); RSA * rsa; rsa = RSA_generate_key( 2048, /* number of bits for the key - 2048 is a sensible value */ RSA_F4, /* exponent - RSA_F4 is defined as 0x10001L */ NULL, /* callback - can be NULL if we aren&apos;t displaying progress */ NULL /* callback argument - not needed in this case */ ); EVP_PKEY_assign_RSA(pkey, rsa); // generate cert X509 *x509; x509 = X509_new(); ASN1_INTEGER_set(X509_get_serialNumber(x509), 10); X509_gmtime_adj(X509_get_notBefore(x509), 0); X509_gmtime_adj(X509_get_notAfter(x509), 31536000L); X509_set_pubkey(x509, pkey); X509_NAME *name; name = X509_get_subject_name(x509); X509_NAME_add_entry_by_txt(name, &quot;OU&quot;, MBSTRING_ASC, // OU = organisational unit (unsigned char *)&quot;Kde connect&quot;, -1, -1, 0); X509_NAME_add_entry_by_txt(name, &quot;O&quot;, MBSTRING_ASC, // O = organization (unsigned char *)&quot;KDE&quot;, -1, -1, 0); X509_NAME_add_entry_by_txt(name, &quot;CN&quot;, MBSTRING_ASC, // CN = common name, TODO: uuid (unsigned char *)[[NetworkPackage getUUID] UTF8String], -1, -1, 0); X509_set_issuer_name(x509, name); if (!X509_sign(x509, pkey, EVP_md5())) &#123; @throw [[NSException alloc] initWithName:@&quot;Fail sign cert&quot; reason:@&quot;Error&quot; userInfo:nil]; &#125; if (!X509_check_private_key(x509, pkey)) &#123; @throw [[NSException alloc] initWithName:@&quot;Fail validate cert&quot; reason:@&quot;Error&quot; userInfo:nil]; &#125; // load algo and encryption components SSLeay_add_all_algorithms(); ERR_load_crypto_strings(); // create p12 format data PKCS12 *p12 = NULL; p12 = PKCS12_create(/* password */ &quot;&quot;, /* name */ &quot;KDE Connect&quot;, pkey, x509, /* ca */ NULL, /* nid_key */ 0, /* nid_cert */ 0, /* iter */ 0, /* mac_iter */ PKCS12_DEFAULT_ITER, /* keytype */ 0); if(!p12) &#123; @throw [[NSException alloc] initWithName:@&quot;Fail getP12File&quot; reason:@&quot;Error creating PKCS#12 structure&quot; userInfo:nil]; &#125; // write into `Documents/rsaPrivate.p12` NSArray *documentDirectories = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES); NSString *p12FilePath = NULL; for (NSString *directory in documentDirectories) &#123; NSLog(@&quot;Find %@&quot;, directory); p12FilePath = [directory stringByAppendingString:@&quot;/rsaPrivate.p12&quot;]; &#125; if (![[NSFileManager defaultManager] createFileAtPath:p12FilePath contents:nil attributes:nil]) &#123; NSLog(@&quot;Error creating file for P12&quot;); @throw [[NSException alloc] initWithName:@&quot;Fail getP12File&quot; reason:@&quot;Fail Error creating file for P12&quot; userInfo:nil]; &#125; // get a FILE struct for the P12 file NSFileHandle *outputFileHandle = [NSFileHandle fileHandleForWritingAtPath:p12FilePath]; FILE *p12File = fdopen([outputFileHandle fileDescriptor], &quot;w&quot;); i2d_PKCS12_fp(p12File, p12); PKCS12_free(p12); fclose(p12File); [outputFileHandle closeFile];&#125; Conclusion In this post, I described, in general, how I generate and load the private key and certificate in KDE Connect iOS. This aims at preparing a TLS/SSL connection between an iOS device and a device using the current version of KDE Connect. In the next post, I will tell the TLS/SSL transport in KDE Connect iOS. Thanks for reading!","categories":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"【译】Xen 的奇妙冒险 —— RPi4 篇","slug":"Xen-on-Raspberry-Pi-4-Adeventures","date":"2021-01-27T15:47:40.000Z","updated":"2025-03-08T09:40:48.607Z","comments":true,"path":"2021/01/27/Xen-on-Raspberry-Pi-4-Adeventures/","link":"","permalink":"https://blog.inoki.cc/2021/01/27/Xen-on-Raspberry-Pi-4-Adeventures/","excerpt":"","text":"原文链接：Xen on Raspberry Pi 4 adventures 作者：Stefano Stabellini 和 Roman Shaposhnik 树莓派（RPi）由于价格低廉而应用广泛，多年来一直是 ARM 社区的关键设备。根据 RPi 基金会的数据，已经售出了超过 3500 万台，其中 44% 销往工业领域。我们一直渴望在其上运行 Xen 管理程序，但 RPi 与其他 ARM 平台之间的技术差异使其在很长一段时间内都不能成为现实。具体来说，就是因为其使用了一个没有虚拟化支持的非标准中断控制器。 然后，带有一个标准 GIC-400 中断控制器的 Raspberry Pi 4 出现了。这个中断控制器本来就被 Xen 平台支持。终于，我们可以在 RPi 设备上运行 Xen 了。很快，Project EVE 的 Roman Shaposhnik 和其他一些社区成员开始在 xen-devel 邮件列表中询问这个问题。&quot;这应该很容易，&quot;我们回答道。&quot;它甚至可能不用任何额外工作就能工作，&quot;我们在回复中写道。但我们完全没有意识到，我们即将在 Xen 内存分配器和 Linux 地址转换层的之间里展开一场宏大的冒险。 第一个障碍是低内存地址的可用性。RPi4 的设备只能访问前 1GB 的内存。对 Dom0 来说 1GB 以下的内存是不够的。Julien Grall 通过一个简单的单行修复解决了这个问题，增加了在 RPi4 上 Dom0 的 1GB 以下内存分配。该补丁现在已经出现在 Xen 4.14 中。 &quot;这种低于1GB的限制虽然不常见的，但现在它被修复了，它应当可以工作了。&quot;但我们又错了，Linux中的 Xen 子系统使用 virt_to_phys 将虚拟地址转换为物理地址，这对大多数虚拟地址都有效，但不是所有的虚拟地址。原来，RPi4 Linux 内核有时会使用无法通过 virt_to_phys 转化为物理地址的虚拟地址，这样做会导致严重错误。修正的方法是在适当的时候使用不同的地址翻译函数。现在该补丁已经存在于 Linux 的主分支中。 我们感到信心十足，终于到了终点。&quot;内存分配–检查。内存翻译–检查。成了！&quot;不，还没有。事实证明，最重要的问题还没有被发现。Linux 内核一直有物理地址和 DMA 地址的概念，其中 DMA 地址是用来给设备编程的，它可能和物理地址不同。但实际上，在 Xen 可以运行的 x86、ARM 和 ARM64 平台，DMA 地址与物理地址相同。Linux 中的 Xen 子系统就是利用 DMA 与物理地址的二元性来进行自己的地址转换。它利用它将客户机看到的物理地址转换为 Xen 看到的物理地址。 让我们感到惊讶和惊喜的是，Raspberry Pi 4 是第一个物理地址与 DMA 地址不同的平台，导致 Linux 中的 Xen 子系统崩溃。要缩小问题的范围并不容易。一旦我们了解了这个问题，通过十几个补丁，我们完全支持了在 Linux 中处理 DMA 与物理地址的转换。Linux 补丁已经在主分支中，将在 Linux 5.9 中提供。 解决了地址翻译问题，我们有趣的 Hack 冒险就结束了。应用 Xen 和 Linux 补丁后，Xen 和 Dom0 可以完美地工作。一旦 Linux 5.9 出来，我们就可以让 Xen 在 RPi4 上开箱即用。 我们将向您展示如何在 RPi4 上运行 Xen，真正的 Xen Hack 方式，并作为下游分发的一部分，以获得更简单的最终用户体验。 在树莓派 4 上玩转 Xen 如果你打算在 ARM 上对 Xen 进行 Hack，并希望使用 RPi4 来完成，这里是你需要做的，以使 Xen 使用 UBoot 和 TFTP 启动和运行。我喜欢使用 TFTP，因为它可以在开发过程中极快地更新任何二进制文件。请参阅本教程，了解如何设置和配置 TFTP 服务器。你还需要一个 UART 连接来获得 Xen 和 Linux 的早期输出，请参考这篇文章。 使用 rpi-imager 格式化 SD 卡与常规默认的 Raspberry Pi 操作系统。挂载第一个SD卡分区并编辑 config.txt。确保添加以下内容： 12345kernel=u-boot.binenable_uart=1arm_64bit=1 从任何发行版中下载一个适合 RPi4 的 U Boot 二进制文件(u-boot.bin)，例如 OpenSUSE。下载 JeOS 镜像，然后打开它并保存 u-boot.bin。 1234567xz -d openSUSE-Tumbleweed-ARM-JeOS-raspberrypi4.aarch64.raw.xzkpartx -a ./openSUSE-Tumbleweed-ARM-JeOS-raspberrypi4.aarch64.rawmount /dev/mapper/loop0p1 /mntcp /mnt/u-boot.bin /tmp 将 u-boot.bin 和 config.txt 一起放入第一个SD卡分区。下次系统启动时，你会得到一个 UBoot 提示，允许你从网络上的 TFTP 服务器加载 Xen、Dom0 的 Linux 内核、Dom0 rootfs 和设备树。我通过在 SD 卡上放置 UBoot boot.scr 脚本来自动完成加载步骤： 1234567setenv serverip 192.168.0.1setenv ipaddr 192.168.0.2tftpb 0xC00000 boot2.scrsource 0xC00000 其中： 12- serverip 是你的 TFTP 服务器的 IP- ipaddr 是你的 RPi4 的 IP 使用 mkimage 生成 boot.scr，并将其放在 config.txt 和 u-boot.bin 一起： 1mkimage -T script -A arm64 -C none -a 0x2400000 -e 0x2400000 -d boot.source boot.scr 其中： 12- boot.source 是输入- boot.scr 是输出 UBoot 會自动执行所提供的 boot.scr，它会设定网络，并从 TFTP 服务器取得第二个脚本 (boot2.scr)。boot2.scr 应当包含了所有载入 Xen 和其他所需二进制文件的指令。您可以使用 ImageBuilder 生成 boot2.scr。 确保使用 Xen 4.14 或更高版本。Linux 内核应该是主分支（或等到 5.9 出来后，5.4-rc4 也可以），Linux ARM64 默认配置可以作为内核配置。任何 64 位的 rootfs 都应该可以用于 Dom0。使用上游 Linux 自带的 RPi4 的设备树（arch/arm64/boot/dts/broadcom/bcm2711-rpi-4-b.dtb）。注意 RPi4 有两个 UART，默认是地址为 0x7e215040 的 bcm2835-aux-uart。它在设备树中被指定为 serial1，而不是 serial0。您可以通过在 Xen 命令行中指定让 Xen 使用 serial1： 1console=dtuart dtuart=serial1 sync_console Xen 命令行由 ImageBuilder 生成的 boot2.scr 脚本提供，名为 “xen,xen-bootargs”。编辑 boot2.source 后，你可以用 mkimage 重新生成 boot2.scr： 1mkimage -A arm64 -T script -C none -a 0xC00000 -e 0xC00000 -d boot2.source boot2.scr 树莓派 4 上的 Xen：一个简单的操作 通过在 RPi 4 上从头开始构建和启动 Xen 这样的脏活，不仅可以让你深感满足，而且可以让你深入了解 ARM 上的一切是如何结合在一起的。然而，有时您只是想快速体验一下在这块板子上使用 Xen 的感觉。对于 Xen 来说，这通常不是问题，因为几乎每个 Linux 发行版都提供 Xen 包，只需调用 “apt” 或 “zypper” 就可以在系统上运行一个功能齐全的 Xen。然而，鉴于 Raspberry Pi 4 的支持只有几个月的时间，整合工作还没有完成。唯一一个在 Raspberry Pi 4 上完全集成和测试支持 Xen 的操作系统是 LF Edge 的 Project EVE。 Project EVE 是一个设计上安全的操作系统，支持在现场部署的计算设备上运行边缘容器。这些设备可以是物联网网关、工业 PC 或通用计算机。所有在 EVE 上运行的应用都被表示为边缘容器，并受制于由 k3s 驱动的容器协调策略。边缘容器本身可以封装虚拟机、容器或 Unikernels。 你可以在该项目网站 http://projecteve.dev 和其 GitHub repo 找到更多关于 EVE 的信息。为 Raspberry Pi 4 创建可启动媒体的最新说明也可在以下网站获得。 https://github.com/lf-edge/eve/blob/master/docs/README.md 因为 EVE 发布的是完全编译完成的可下载的二进制文件，使用它在 Raspberry Pi 4 上尝试 Xen 就很简单了： 123$ docker pull lfedge/eve:5.9.0-rpi-xen-arm64 # you can pick a different 5.x.y release if you like$ docker run lfedge/eve:5.9.0-rpi-xen-arm64 live &gt; live.raw 随后使用你喜欢的工具将生成的 live.raw 二进制文件刷写到 SD 卡上。 一旦这些步骤完成，你就可以将卡插入到你的 Raspberry Pi 4 中，连接键盘和显示器，享受一个极简主义的 Linux 发行版（基于 Alpine Linux 和 Linuxkit），这就是在 Xen 下运行的 Dom0 项目 EVE。 就 Linux 发行版而言，EVE 呈现出了一种有些新颖的操作系统设计，但同时，它也深受 Qubes OS、ChromeOS、Core OS 和 Smart OS 的启发。如果你想让它超越简单的控制台任务，探索如何在上面运行用户域，我们建议前往 EVE 的姊妹项目 Eden，按照那边的简短教程进行操作。 如果有任何问题，您可以在 LF Edge 的 Slack 频道中找到一个活跃的 EVE 和 Eden 用户社区，从 http://lfedge.slack.com/ 的 #eve 开始–我们很乐意听到您的反馈。 Hack 愉快！","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Raspberry Pi","slug":"Embedded-System/Raspberry-Pi","permalink":"https://blog.inoki.cc/categories/Embedded-System/Raspberry-Pi/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"}]},{"title":"SDDM tips (1)","slug":"AX88179_178a_USB_Ethernet_adapter_Linux_Driver/SDDM-tips-1","date":"2021-01-25T09:30:40.000Z","updated":"2025-03-08T09:40:48.545Z","comments":true,"path":"2021/01/25/AX88179_178a_USB_Ethernet_adapter_Linux_Driver/SDDM-tips-1/","link":"","permalink":"https://blog.inoki.cc/2021/01/25/AX88179_178a_USB_Ethernet_adapter_Linux_Driver/SDDM-tips-1/","excerpt":"","text":"SDDM is the abbreviation of Simple Desktop Display Manager, which is a default display manager for LXQt and KDE Plasma. It officially supports Linux and FreeBSD, but should also work well with other Unix-like system. User HOME SDDM works under a special user in an UNIX-like system: sddm. Its HOME directory is set to /var/lib/sddm. If we want to install it ourselves, an sddm user needs to be created, with its home set to /var/lib/sddm by default. In this directory, a state.conf will be created. The content of it on my PC is: 123456789[Last]# Name of the last logged-in user.# This user will be preselected when the login screen appearsUser=inoki# Name of the session for the last logged-in user.# This session will be preselected when the login screen appears.Session=/usr/share/xsessions/plasma.desktop which notes the latest login user and the correspond session. This will accelerate the next login. The file is declared in src/common/configuration.h and will be loaded later. Configurations Like the other programs, SDDM also reads configuration from /etc. The file is /etc/sddm.conf, which contains several sections: General Theme Users Wayland X11 Icons User icons are stored in $(DATADIR)/faces/ or ~/.face.icon (for each user). Themes Themes are stored in $(DATADIR)/themes/. SDDM loads Main.qml file in it to create an user interface. Scripts Scripts to launch a specific session under an environment are stored in $(DATADIR)/scripts/. These scripts will start the desktop environment. For example, for X11, the configuration items are: 12345678910111213[X11]DisplayCommand=/usr/share/sddm/scripts/XsetupDisplayStopCommand=/usr/share/sddm/scripts/XstopEnableHiDPI=falseMinimumVT=1ServerArguments=-nolisten tcpServerPath=/usr/bin/XSessionCommand=/usr/share/sddm/scripts/XsessionSessionDir=/usr/share/xsessionsSessionLogFile=.local/share/sddm/xorg-session.logUserAuthFile=.XauthorityXauthPath=/usr/bin/xauthXephyrPath=/usr/bin/Xephyr The script is Xsetup, Xsession, Xstop, etc. The desktop entries for desktop environments are placed in /usr/share/xsessions. In my case, the plasma.desktop indicates the executable: 1234567[Desktop Entry]Type=XSessionExec=/usr/bin/startplasma-x11TryExec=/usr/bin/startplasma-x11DesktopNames=KDEName=Plasma... Conclusion Unfinished. TBC…","categories":[{"name":"KDE","slug":"KDE","permalink":"https://blog.inoki.cc/categories/KDE/"}],"tags":[{"name":"KDE","slug":"KDE","permalink":"https://blog.inoki.cc/tags/KDE/"},{"name":"SDDM","slug":"SDDM","permalink":"https://blog.inoki.cc/tags/SDDM/"}]},{"title":"滑稽、混乱、局促与 2020","slug":"My-2020","date":"2020-12-30T09:41:40.000Z","updated":"2025-03-08T09:40:48.586Z","comments":true,"path":"2020/12/30/My-2020/","link":"","permalink":"https://blog.inoki.cc/2020/12/30/My-2020/","excerpt":"","text":"从去年 11 月陆续收到 offer 并选择了自己最感兴趣的一个那一刻起，我想象中的 2020 本应未来可期：二月末实习结束，和一年没回家的女朋友回成都吃好吃的，三月末再一起出国、在一个全新的地方安家，我办入学手续，她找到工作。然后就可以过上没羞没臊无忧无虑的小生活。 但我没想到，在二十一世纪的 10 年份的最后又看到了引发肺炎的病毒传播的消息，更没有想到、它对我的一年、乃至之后能产生多大的影响。 开端 这一年是从圣诞和元旦组成的假期开始的，这个假期在西班牙玩得挺开心，但也隐隐担心病毒的情况，回到住所便给在国内的家里人打电话，希望他们小心。 假期结束，回到实习的公司，那时 WHO 已经发布了当时的病毒情况，但还没有提到人传人，但凭借小时候的经验、 加上我虽然有限但还存在的生物知识，我觉得它和 03 年那次应当差不多。 和同事们一起吃午饭的时候聊到了病毒。由于前司在国内也有大量业务，有个同事经常会去武汉参与中国国标 GB 的规范讨论，我便提醒他要小心、最近要避免去武汉，这波疫情可能会挺严重的。但决策也不是他定的，他也只能谢谢我的提醒，若是上级发下来话，该去还是要去的。后来由于封城，后续的会议计划也就取消了。 到了一月末，国内已经大规模封城，城际旅行都要进行多日的隔离。在家人的劝说下，女朋友和我一商量，把回国的机票退了，这样没那么多麻烦和折腾。没想到更多的事情还在等着我们。 滑稽 既然不打算回国了，起码三月份是空出来了，我们就打算先去意大利玩一段时间。行程还没确定下来，到了二月初，忽然意大利变成了疫区，北方很多城市确诊飙增，很多区域考虑封城。于是这一行程就搁置了下来。 转念一想三月到瑞士去坐坐火车、滑滑雪也可以，于是准备订三月的票。忽然爆出了瑞士确诊开始上升、还被周边国家抢了各种防疫物资。 退而求其次，我们去波尔多和里昂总可以了吧，结果第二天波尔多就发现一例从武汉而来的确诊、里昂由于临近意大利也进入了增长期。 各种旅行方案被病毒否决的情况下，时间来到了二月末，我要回到学校所在地帮女朋友搬家。出行前一天，新闻爆出学校所在地有数例确诊、溯源不明、恐成为法国第一个爆发点。 再加上圣诞期间去的巴塞罗那和马德里的爆发，我觉得自己对疫情的爆发真的是指哪打哪。啊，原来小丑竟是我自己。 混乱 时间来到三月中旬，在法国封城的前一天，只带了一点点行李就离开了住所，飞到新学校所在城市那边租到的房子（这点足够幸运XD）。但新学校的行政部门暂时远程（直接等于不工作），导致入学手续没法办理，预计到五月底才能重开。 既然入学延后了，就打算先找点事情做。于是三月又开了些开源项目、还有在和合作者的项目里写写代码；四月份重新捡起了 B 站帐号，做一些 KDE 社区的宣传工作、水了好一些视频；五月转世了某境外社交账号，制造一些暴论；六月份又开始拿着狗家的资助打工。 幸运的是女朋友临时签也下来了，可以和我一起呆一年，不至于太过孤单。但由于不是当地学校毕业的学生，她也需要找到工作或者结婚才能把签证续下去。可惜似乎当地招人也不是很多，找朋友内推亚麻的机会也因为经验和方向的原因草草收场。后来总结发现，复杂系统真的不能算是一个好找工作的专业。 六月初，终于完成一大堆 paperwork 顺利入学，然后事情突然就多了起来：合作者的项目；自己的科研工作；赚狗家资助的暑期打工；给女朋友讲计算机工程、算法、前端 ReactJS、后端 Java；还有之前在各个平台挖了的坑。 和合作者的上一个项目投了个他们领域的顶刊，有很多修改意见，程序也跟着意见改，只能感慨顶刊的 reviewer 就是认真负责且专业；自己的工作也逐渐入门，但每天开始 push 自己赶快出成果；暑期打工也要保证一定的工作时间和工作量；而女朋友那边因为研究生主要是建模、分析，太久没有接触计算机工程相关的东西，很多知识已经忘记了，于是需要一点一点从头开始梳理；至于平台挖的坑，无非就是做一些翻译工作、学 Rust、学 k8s 等。在远程工作期间，生活与工作的界限变得模糊，大量的工作积压就非常容易顾此失彼，异常的混乱就由此开始，每天泡在电脑前十多个小时，缺乏社交，脾气也渐渐变差。 压力也慢慢积攒了起来，但总有爆发的时候，于是在八月底到九月底的周末，开始没日没夜的打游戏：先是《GTA: V》和《马里奥：奥德赛》。接着《Nier: Automata》成了数年没有玩过大作的自己宣泄的出口，先是三周目通关，然后是支线，支线有任务依赖于怪物图鉴收集和武器搜集，于是刷了好几个 100% 出来。因为缺乏睡眠，渐渐分不清游戏和现实，内心产生了 “这一切都毫无意义” 的想法。再加上当时全世界的混乱，让我觉得人类最终还是会因为自己灭亡的，自己做什么都是没有意义的。 九月底的时候，开始详细研究如何写更好的 paper。疯狂的自我否定和对这个世界的否定使我消极地面对。十月底的时候，准备发文的一个点子确定了下来，于是推迟了其他事情，专心做这一件事。 混乱逐渐消失，大脑也开始放松，开始考虑自己的工作以外、却同样重要的事情。 局促 远距离搬家留下了很多东西，包括之前在巴黎的房子的合约。法国又时不时封城、限制旅行距离、限制出入境，导致我本人没法再飞回去拿行李和退房，于是就拜托朋友帮我完成退房。匆匆忙忙之下，丢掉了很多东西，比如积攒多年的算法笔记、比如宜家小鲨鱼。最后抽了一周，趁着法国没封城，飞了一个往返，从朋友那里拿走了行李。行李很多，在巴黎上地铁的时候不太方便，差点被黑哥哥抢了。最后托运完行李，在最后时刻赶上了飞机。 而准备发文的那个 idea 确定了下来之后，需要在一个月的时间内完成整个文章相关的实验、文章的书写和修改，从零开始构建这一切。必须做的事情都是压着 deadline 完成，这让我怀疑自己是否接了太多了工作，亦或是能力开始退化。 十二月初赶完最后一个，猛然发现离女朋友临时签证过期已经没有多久了，去掉圣诞节前后的假期，她及时找到工作的可能性已经降到了一个极低的水平。考虑结婚又正遇到市政厅延缓接待，预估了一下时间，应该是赶不上了；再者说，这种情况下婚礼也不好办，草草了事总觉得对不起她。为了不发生黑户的情况导致黑名单，等疫情结束之后好再回来，最后决定让两年都没回成家的女朋友先回家玩一段时间。 各种局促的事件和事件背景下局限的选择，构成了这一年。 尾声 总的看下来，这一年我的主基调和世界的总体基调保持了一致：混乱。而且如同无头苍蝇，不知何处去。 原本和女朋友多去几个国家、地区玩的计划完全落空，在这一年，每天就是呆在家里，写代码、玩游戏、做饭。 在一年的最后，和女朋友到海边玩一玩，完全丢下工作放空几天，似乎又找回了多年前的自己。 但世界再乱，生活再难，总有一些小确幸，也完成了一些事情、学到了一些东西，也算有了成长。 代码 写了 iOS 版本的 KDE Connect，给全平台填好了坑。 给 embox 嵌入式 OS、fcitx 输入框架、libpinyin 及其 ibus 绑定、homebrew 项目贡献了代码。 学了 Rust、Haskell（未完待续），开了一个简单解释器项目和一个 emulator 项目练练手；学了 Julia、k8s 却不知道可以用在哪；研究了 macOS 的跨进程通信 XPC、跨平台绘图标准 EGL 并写了些 Hello World。 人际 在网上认识了很多人，虽然觉得有一部分人可能和自己的三观不是很合，但我还是觉得人的多样性才是这个社会最精彩的地方，正如生物的多样性才是地球的奇迹。于是心理上把自己定位成人类观察者，看待一切就完全平和了下来。最后这个月，甚至把本就个位数的 Block 和 Mute 列表全部清空。 通过潜水看群友讨论来领悟 programming language、迫害群友成了每天必做的快乐的事，这也很大程度上帮助我。虽然依然总不知道怎么保持好尺度，希望有觉得自己被冒犯到的推/群友直接 pm 我呀。 最后，就当得到的失去的都是命。 人嘛，一年一年过得很快的，快乐就好了。","categories":[{"name":"Dairy","slug":"Dairy","permalink":"https://blog.inoki.cc/categories/Dairy/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"private","slug":"private","permalink":"https://blog.inoki.cc/tags/private/"}]},{"title":"【译】GBDK 手柄","slug":"GBDK-Joypad-Tutorial","date":"2020-09-19T22:41:23.000Z","updated":"2025-03-08T09:40:48.564Z","comments":true,"path":"2020/09/19/GBDK-Joypad-Tutorial/","link":"","permalink":"https://blog.inoki.cc/2020/09/19/GBDK-Joypad-Tutorial/","excerpt":"","text":"原文链接：https://gbdev.gg8.se/wiki/articles/GBDK_Joypad_Tutorial 介绍 本教程旨在详细介绍将手柄与 GBDK 配合使用的方法。 工具 您将需要：GBDK，文本编辑器，Game Boy Tile Designer 和仿真器（建议使用 BGB，它有许多调试功能）以及任何水平的 C 知识。 如果需要，请替换您喜欢的工具，但是本教程假定您具有上面列出的工具。 joypad() 函数 GBDK 的 gb.h 具有 Joypad() 函数，该函数返回手柄的状态。 joypad() 函数可以返回以下输入的状态： 12345678J_STARTJ_SELECTJ_BJ_AJ_DOWNJ_UPJ_LEFTJ_RIGHT Program 1: 返回 joypad() 状态 让我们编写一个简单的程序来在按下按钮时返回 joypad() 的状态： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;stdio.h&gt; // include this file for the printf() function#include &lt;gb/gb.h&gt; // include this file for Game Boy functionsvoid main(void)&#123; while(1) &#123; switch(joypad()) &#123; case J_RIGHT : // If joypad() is equal to RIGHT printf(\"Right!\\n\"); delay(100); break; case J_LEFT : // If joypad() is equal to LEFT printf(\"Left!\\n\"); delay(100); break; case J_UP : // If joypad() is equal to UP printf(\"Up!\\n\"); delay(100); break; case J_DOWN : // If joypad() is equal to DOWN printf(\"Down!\\n\"); delay(100); break; case J_START : // If joypad() is equal to START printf(\"Start!\\n\"); delay(100); break; case J_SELECT : // If joypad() is equal to SELECT printf(\"Select!\\n\"); delay(100); break; case J_A : // If joypad() is equal to A printf(\"A!\\n\"); delay(100); break; case J_B : // If joypad() is equal to B printf(\"B!\\n\"); delay(100); break; default : break; &#125; &#125; &#125; Program 2: 使用 waitpad() 和 waitpadup() 您还可以使用另外两个游戏手柄的函数： 12waitpad() // This function waits for a button to be pressed.waitpadup() // This function waits for all buttons to be released. 让我们在一个简单的程序中同时使用 waitpad() 函数和 waitpadup() 函数： 1234567891011121314151617181920#include &lt;stdio.h&gt; // include this file for the printf() function#include &lt;gb/gb.h&gt; // include this file for Game Boy functionsvoid main(void)&#123; while(1) &#123; printf(\"Please press A\\n\"); waitpad(J_A); // waitpad() is waiting for the A button to be pressed. printf(\"You pressed A! Cool!\\n\\n\"); printf(\"Hold down the LEFT button\\n\"); waitpad(J_LEFT); // waitpad() is waiting for the LEFT button to be pressed. printf(\"You're holding down LEFT!\\n\"); waitpadup(); // waitpadup() is waiting for all buttons to be depressed but you have to hold down LEFT to get here so it is // waiting on LEFT to be depressed. printf(\"You've released LEFT\\n\\n\\n\"); &#125; &#125; Program 3: 在屏幕上移动精灵 现在，让我们使用 joypad() 函数在屏幕上移动精灵。如果您对 GBDK Sprite 不熟悉，则需要查看 GBDK Sprite 教程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;gb/gb.h&gt; // include this file for Game Boy functions//Created with GBTD, exported to .c with options from: 0, to: 0, label: smileunsigned char smile[] =&#123; 0x3C,0x3C,0x42,0x42,0x81,0x81,0xA5,0xA5, 0x81,0x81,0x81,0xA5,0x42,0x5A,0x3C,0x3C&#125;;void main()&#123; int x = 55; // Our beginning x coord int y = 75; // Our beginning y coord SPRITES_8x8; set_sprite_data(0, 0, smile); set_sprite_tile(0, 0); move_sprite(0, x, y); // Move sprite to our predefined x and y coords SHOW_SPRITES; while(1)&#123; if(joypad()==J_RIGHT) // If RIGHT is pressed &#123; x++; move_sprite(0,x,y); // move sprite 0 to x and y coords delay(10); &#125; if(joypad()==J_LEFT) // If LEFT is pressed &#123; x--; move_sprite(0,x,y); // move sprite 0 to x and y coords delay(10); &#125; if(joypad()==J_UP) // If UP is pressed &#123; y--; move_sprite(0,x,y); // move sprite 0 to x and y coords delay(10); &#125; if(joypad()==J_DOWN) // If DOWN is pressed &#123; y++; move_sprite(0,x,y); // move sprite 0 to x and y coords delay(10); &#125; &#125;","categories":[{"name":"GBDK","slug":"GBDK","permalink":"https://blog.inoki.cc/categories/GBDK/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"GBDK","slug":"GBDK","permalink":"https://blog.inoki.cc/tags/GBDK/"}]},{"title":"【译】GBDK Sprite 精灵","slug":"GBDK-Sprite-Tutorial","date":"2020-09-19T21:41:23.000Z","updated":"2025-03-08T09:40:48.565Z","comments":true,"path":"2020/09/19/GBDK-Sprite-Tutorial/","link":"","permalink":"https://blog.inoki.cc/2020/09/19/GBDK-Sprite-Tutorial/","excerpt":"","text":"原文链接：https://gbdev.gg8.se/wiki/articles/GBDK_Sprite_Tutorial 介绍 本教程旨在介绍一种工作流程，能够显示多个精灵和设置动画。为了使它尽可能地易于访问，我假设您不了解 C 语言。如果您不想在开始之前的几个小时内浏览参考文件，这就是为您准备的。 工具 您将需要：GBDK，文本编辑器，Game Boy Tile Designer 和仿真器（建议使用 BGB，它有许多调试功能）以及任何水平的 C 知识。 如果需要，请替换您喜欢的工具，但是本教程假定您具有上面列出的工具。 第一步：创建瓦块 运行 GBTD。单击视图，图块大小，16x16。 绘制图像，将其复制并粘贴到第二个瓦块插槽中，然后进行更改以制作两帧动画。 我们将在这些之间来回切换。 单击文件，导出到，将 Type 更改为 GBDK C 文件（* .c），并将 To 更改为1。我还将文件名和标签更改为“ smile”。 点击确定。 这将创建一个 .c 和 .h 文件。.c 文件应如下所示： 123456789101112131415161718192021//lots of commentsunsigned char smile[] =&#123; 0x0F,0x0F,0x30,0x30,0x40,0x40,0x40,0x40, 0x84,0x84,0x84,0x84,0x84,0x84,0x84,0x84, 0x84,0x84,0x84,0x84,0x80,0x80,0x80,0x80, 0x44,0x44,0x43,0x43,0x30,0x30,0x0F,0x0F, 0xF0,0xF0,0x0C,0x0C,0x02,0x02,0x02,0x02, 0x21,0x21,0x21,0x21,0x21,0x21,0x21,0x21, 0x21,0x21,0x21,0x21,0x01,0x01,0x01,0x01, 0x22,0x22,0xC2,0xC2,0x0C,0x0C,0xF0,0xF0, 0x0F,0x0F,0x30,0x30,0x40,0x40,0x40,0x40, 0x84,0x84,0x84,0x84,0x84,0x84,0x84,0x84, 0x84,0x84,0x84,0x84,0x80,0x80,0x80,0x80, 0x44,0x44,0x43,0x43,0x30,0x30,0x0F,0x0F, 0xF0,0xF0,0x0C,0x0C,0x02,0x02,0x02,0x02, 0x01,0x01,0x01,0x01,0x01,0x01,0xF9,0xF9, 0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01, 0x22,0x22,0xC2,0xC2,0x0C,0x0C,0xF0,0xF0&#125;;//more comments 可见，GBTE 只是将像素转换为以标签命名的数组。我们将在要编写的代码中包含 .c 文件。 第二步：set_sprite_data 在屏幕上绘制精灵 GBDK 通过 gb.h 中提供的一些函数来处理精灵。 启动您的文本编辑器，并包含必要的文件： 12#include &lt;gb/gb.h&gt; //Angle brackets check the compiler's include folders#include \"smile.c\" //double quotes check the folder of the code that's being compiled 每个 C 脚本都需要一个主函数，因此请在其中添加以下函数之一： 123void main()&#123;&#125; 这是我们将编写所有代码的地方。 进入 main 函数，输入： 12345SPRITES_8x16;set_sprite_data(0, 8, smile);set_sprite_tile(0, 0);move_sprite(0, 75, 75);SHOW_SPRITES; 逐行显示： 告诉 GBDK 一次加载两个 8x8 精灵，制作一个 8x16 瓦片 从零开始，将 8 个 8x8 瓦片从 smile 数组推入运行中的精灵数据 将图块 0 设置为精灵数据中编号为 0 的精灵 将精灵 0 移动到该坐标 这是到目前为止的完整代码： 12345678910#include &lt;gb/gb.h&gt;#include \"smile.c\"void main()&#123; SPRITES_8x16; set_sprite_data(0, 8, smile); set_sprite_tile(0, 0); move_sprite(0, 75, 75); SHOW_SPRITES;&#125; 将该文件保存为 filename.c，使用 lcc 编译：/path/to/GBDK/bin/lcc -o gamename.gb filename.c。 运行 BGB 并加载 gamename.gb。 Emmmmmm，这里只有半张脸。好吧，由于 Gameboy 只能处理最大 8x16 的瓦块，我们需要通过把两个 8x16 的瓦块画在一起来构造一个 16x16 的。 首先，让我们看看精灵和图块如何存储在 Gameboy 上。 在 BGB 中，您已编写的 rom 已加载并运行，右键单击，将鼠标悬停在 “其他” 上，单击 “VRAM查看器”。 在这里，您可以看到我们使用 set_sprite_data 设置为 8x8 瓦片的精灵。最左侧的两个数字 0 和 1 亮起，表示它们正在使用中。我们想要的是设置第二个图块，将其用脸的右半部分填充，然后将其与左半部分对齐。 将此添加到代码中： 12set_sprite_tile(1, 2);move_sprite(1, 75 + 8, 75); 在 VRAM 查看器中进行计数时，该面的左上象限是精灵 0，左下角是 1，右上角从 2 开始，并且 SPRITES_8x16 行将使我们设置的图块包含精灵 3，即 所有四个象限。现在，我们在屏幕上激活了两个精灵，分别是 0 号和 1 号 ，而精灵 1 比精灵 0 靠右 8 个像素，这意味着它可以完美排列以显示一个 16x16 的面。 请记住，每次移动此精灵时，都需要将两个部分一起移动。 编译并运行它，然后在 VRAM 查看器中查看。 第三步：动画 我们将定时使用 set_sprite_tile 替换图块。 在 SHOW_SPRITES 之后在主函数中编写一个 while 循环。我们使用 while(1)，这样它会永远循环。 123while(1)&#123;&#125; 在该循环内，将图块编号 1（脸的右侧）更改为精灵 6（我使用 VRAM 查看器进行计数）。 1set_sprite_tile(1, 6); 将其交换回去并延迟几个时间，以便可以看到更改，我们会得到以下代码： 123456while(1)&#123; set_sprite_tile(1, 6); delay(500); set_sprite_tile(1,2); delay(500);&#125; 这是所有可以用于复制和粘贴的代码： 12345678910111213141516171819#include &lt;gb/gb.h&gt;#include \"smile.c\"void main()&#123; SPRITES_8x16; set_sprite_data(0, 8, smile); set_sprite_tile(0, 0); move_sprite(0, 75, 75); set_sprite_tile(1, 2); move_sprite(1, 75 + 8, 75); SHOW_SPRITES; while(1)&#123; set_sprite_tile(1, 6); delay(500); set_sprite_tile(1,2); delay(500); &#125;&#125; 编译并运行它。成功运行！ 在 VRAM 查看器中实时观看图块切换。 一个有趣的注释：由于仅精灵的右侧发生了变化，因此左侧的重复是多余的。将来的迭代可能会删除它以保存数据。此外，只有右上角的四分之一会发生变化，因此，如果我们绘制四个8x8瓦片而不是两个8x16瓦片，我们可以通过仅包含并交换该象限来节省更多空间。 现在，让这个更加复杂一点：加载多个精灵集。 第四步：多个精灵集合 本节在这里展示了跟踪“哪些精灵存储在何处”的重要性。 我为动画制作了第二张脸，并将其导出到 frown.c（带有皱眉标签），并使用上述方法将其包含在代码中。 这是数组： 12345678910111213141516171819unsigned char frown[] =&#123; 0x0F,0x0F,0x30,0x30,0x40,0x40,0x40,0x40, 0x84,0x84,0x84,0x84,0x84,0x84,0x84,0x84, 0x84,0x84,0x84,0x84,0x80,0x80,0x87,0x87, 0x58,0x58,0x40,0x40,0x30,0x30,0x0F,0x0F, 0xF0,0xF0,0x0C,0x0C,0x02,0x02,0x02,0x02, 0x21,0x21,0x21,0x21,0x21,0x21,0x21,0x21, 0x21,0x21,0x21,0x21,0x01,0x01,0xE1,0xE1, 0x1A,0x1A,0x02,0x02,0x0C,0x0C,0xF0,0xF0, 0x0F,0x0F,0x30,0x30,0x40,0x40,0x40,0x40, 0x90,0x90,0x8E,0x8E,0x80,0x80,0x84,0x84, 0x84,0x84,0x84,0x84,0x80,0x80,0x87,0x87, 0x58,0x58,0x40,0x40,0x30,0x30,0x0F,0x0F, 0xF0,0xF0,0x0C,0x0C,0x02,0x02,0x02,0x02, 0x09,0x09,0x71,0x71,0x01,0x01,0x21,0x21, 0x21,0x21,0x21,0x21,0x01,0x01,0xE1,0xE1, 0x1A,0x1A,0x02,0x02,0x0C,0x0C,0xF0,0xF0&#125;; 让我们在主函数中（在循环上方）将其设置为我们的Sprite数据： 1set_sprite_data(8, 8, frown); 这就是本演示的重点：当图块以数字方式进展时（图块 0，图块 1，图块 2 …），set_sprite_data 只是将 8x8 子图插入到数据集中。第一个参数必须指向内存中的第一个自由精灵，并且要记住，我们已经用微笑艺术的 8 个精灵填充了 0-7 。如果我们将第一个参数设置为小于 8 的任何值，它将覆盖部分微笑，对于更大的覆盖范围，并且两张脸之间会有间隙。第二个参数再次是我们在此处插入的 8x8 磁贴的数量，并且我们的心理计数最高跳到 16，这意味着 0-15 被占用。 这样做的复杂之处在于，即使我们有并行的动画周期，我们也必须记住每个图块在内存中的位置。 好处是任何图块都可以从子画面堆栈中的任何位置拉出。 让我们复制微笑代码以便与新的皱眉脸一起使用，同时交换精灵： 12345678910111213141516171819202122232425262728293031#include &lt;gb/gb.h&gt;#include \"smile.c\"#include \"frown.c\"void main()&#123; SPRITES_8x16; set_sprite_data(0, 8, smile); set_sprite_tile(0, 0); move_sprite(0, 55, 75); set_sprite_tile(1, 2); move_sprite(1, 55 + 8, 75); set_sprite_data(8, 8, frown); set_sprite_tile(2, 8); move_sprite(2, 95, 75); set_sprite_tile(3, 10); move_sprite(3, 95 + 8, 75); SHOW_SPRITES; while(1)&#123; set_sprite_tile(1, 6); set_sprite_tile(2, 12); set_sprite_tile(3, 14); delay(500); set_sprite_tile(1,2); set_sprite_tile(2, 8); set_sprite_tile(3, 10); delay(500); &#125;&#125; 我们用第二张脸的左半部分和右半部分填充编号为 2 和 3 的精灵。 当笑脸在精灵数据 2（和 3）和 6（和 7）之间切换时，皱眉在左侧的 8（和 9）和 12（和 13）之间以及在 10（和 11）和 14（和 15）之间循环。 ）在右侧，两边同时出现。 编译并在 VRAM 查看器中查看！ 结论 希望这可以教您如何使用 GBDK 加载和显示精灵，或者至少以人类可读形式呈现了一个真实示例。","categories":[{"name":"GBDK","slug":"GBDK","permalink":"https://blog.inoki.cc/categories/GBDK/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"GBDK","slug":"GBDK","permalink":"https://blog.inoki.cc/tags/GBDK/"}]},{"title":"KDE Frameworks - KDNSSD","slug":"KDE-Frameworks-KDNSSD","date":"2020-09-06T08:22:00.000Z","updated":"2025-03-08T09:40:48.573Z","comments":true,"path":"2020/09/06/KDE-Frameworks-KDNSSD/","link":"","permalink":"https://blog.inoki.cc/2020/09/06/KDE-Frameworks-KDNSSD/","excerpt":"","text":"Important: this post assumes that you have knowledge on Qt and CMake/QMake, and that you have at least some concept on library linking. Introduction The KDE Frameworks[1] provides a set of frameworks based on Qt framework. It can largely reduce duplicated work on implementing lots of common-use components in many Desktop Applications. The KDE Frameworks not only support Linux/Unix Desktop, most of its frameworks can also work on Windows, macOS, even Android and iOS. DNS Service Discovery(DNS-SD)[2] is a way of using standard DNS programming interfaces, servers, and packet formats to browse the network for services. The protocol is widely used in the modern applications to provide inter-discovery functionality between devices, for example, printer discovery, Local Area Network multiplayer game, etc. This post shows up how to use KDNSSD[3] framework in KDE Frameworks. KDNSSD Set Up The KDNSSD framework is located at the Layer 1 in the KDE Frameworks, which means that KDNSSD doesn’t rely on any other framework in the KDE Frameworks. It does require Qt, but it’s not a big barricade. If you don’t have Qt development kit, you can easily install one and then continue. In most Linux distribution, in particular, the Linux distribution which has KDE desktop support, there should be software packets of KDNSSD. Installation On Debian/Ubuntu, 1sudo apt install libkf5dnssd libkf5dnssd-dev On RedHat family (CentOS, Fedora) : 1sudo yum install kf5-kdnssd kf5-kdnssd-devel On Arch Linux: 1sudo pacman -S kdnssd The development files (eg. header files) and the runtime libraries should be installed and configured correctly. Linking According to the documentation[4], you can use either CMake or QMake: 12find_package(KF5DNSSD)target_link_libraries(yourapp KF5::DNSSD) 1QT += KDNSSD Even, you could use pkg-config if you’d like. Here I choose to use CMake, the one mostly used in KDE Community. KDNSSD Hello World The first lesson in Computer Engineer is usually a Hello World, which contains the most basic functionality. In KDNSSD, or DNS-SD, the most basic one is to expose a service and to discover a service. So, the Hello World here is to expose a service on the local machine, and discover it Exposing a serivce Firstly, I create a ServicePublisher class in service_publish.cpp, as the service exposer program. Its constructor creates a KDNSSD::PublicService object, which pretends there is a My files service based on HTTP and thus TCP protocol, listening on 8080 port. Then, we set up a connection between signal and slot. And finally publish the DNS-SD information asynchronously. 123456ServicePubisher() // Typo&#123; m_service = new KDNSSD::PublicService(\"My files\", \"_http._tcp\", 8080); connect(m_service, &amp;KDNSSD::PublicService::published, this, &amp;ServicePubisher::isPublished); m_service-&gt;publishAsync();&#125; The published signal is connected to isPublished method in the class. It will output the publish state once the state is notified: 12345678void isPublished(bool state)&#123; if (state) &#123; qDebug() &lt;&lt; \"Service published\"; &#125; else &#123; qDebug() &lt;&lt; \"Service not published\"; &#125;&#125; Exposing a service Then, I created another class ServiceExplorer to try discovering services which are declared to be based on HTTP and TCP protocol. 123456789101112131415ServiceExplorer()&#123; m_browser = new KDNSSD::ServiceBrowser(QStringLiteral(\"_http._tcp\")); connect(m_browser, &amp;KDNSSD::ServiceBrowser::serviceAdded, this, [](KDNSSD::RemoteService::Ptr service) &#123; qDebug() &lt;&lt; \"Service found on\" &lt;&lt; service-&gt;hostName() &lt;&lt; service-&gt;serviceName(); &#125;); connect(m_browser, &amp;KDNSSD::ServiceBrowser::serviceRemoved, this, [](KDNSSD::RemoteService::Ptr service) &#123; qDebug() &lt;&lt; \"Service unregistered on\" &lt;&lt; service-&gt;hostName(); &#125;); m_browser-&gt;startBrowse();&#125; The serviceAdded and serviceRemoved signals are connected with anonymous functions, which only do some output. CMake file At the end, add the 2 programs as executable and link them to the KDNSSD: 1234567add_executable(kdnssd-discover-helloworld service_discover.cpp)add_executable(kdnssd-publish-helloworld service_publish.cpp)find_package(KF5DNSSD)target_link_libraries(kdnssd-discover-helloworld KF5::DNSSD)target_link_libraries(kdnssd-publish-helloworld KF5::DNSSD) Build and run them 😃 You should be able to discover the fake My Files service published by the ServicePublisher. You can find the source code on my kde-frameworks-tutorial GitHub repo. Give me and my project a star if you like it 😃 You can also watch it to get notified when there is an update. Conclusion Here I only show a basic use of KDNSSD. To know more details about it, reading documentation is the best way. Good luck! For further reading, you could find the links in Reference chapter. Reference [1] KDE Frameworks, https://kde.org/products/frameworks/ [2] DNS-SD, http://www.dns-sd.org/ [3] RFC 6763 DNS-Based Service Discovery, https://www.ietf.org/rfc/rfc6763.txt [4] KDNSSD Dcoumentation, https://api.kde.org/frameworks/kdnssd/html/index.html","categories":[{"name":"KDE Frameworks","slug":"KDE-Frameworks","permalink":"https://blog.inoki.cc/categories/KDE-Frameworks/"}],"tags":[{"name":"KDE Frameworks","slug":"KDE-Frameworks","permalink":"https://blog.inoki.cc/tags/KDE-Frameworks/"}]},{"title":"【译】软件定义无线电的基础 —— 3.接收机","slug":"Basic-of-Software-Defined-Radio-3","date":"2020-08-07T20:27:00.000Z","updated":"2025-03-08T09:40:48.548Z","comments":true,"path":"2020/08/07/Basic-of-Software-Defined-Radio-3/","link":"","permalink":"https://blog.inoki.cc/2020/08/07/Basic-of-Software-Defined-Radio-3/","excerpt":"","text":"原文链接：https://www.eetimes.com/sdr-basics-part-3-transmitters/ 软件定义无线电（SDR）的发送功能也基于某种形式的超外差或直接转换。图 18.8 和 18.9 说明了这两个选项。多载波选项最适合单载波和多载波应用，而直接转换为单载波应用提供了一种出色的低成本解决方案。 随着集成技术的改进，多载波直接转换可能成为可能。但是，这样的发射配置需要比寄生需求好约 15 dB 的边带抑制，以防止中心频率一侧的图像超过另一侧的潜在弱载波。 在任何一种应用中，数字信号处理器（DSP）或基带 ASIC 均用于生成调制后的基带数据。此数据直接送入一对基带数字/模拟转换器（DAC）（I 和 Q）以进行直接 RF 调制，或送入负责将其数字转换为合适的数字中频（IF）的数字处理器。 取决于应用，可以单独使用 DSP 或与数字处理器结合使用，对基带数据进行数字预失真，从而消除信号链中稍后产生的失真产物。如果要使用 IF 级，则必须使用 FPGA 或 ASIC 或使用传统的混频器或调制器将 DSP 产生的基带数据数字化上变频至所需的 IF。 这种传统技术已被数字方式所取代，这是由于数字逻辑提供了更多的灵活性、而且良好的具有性价比的数模转换器已经可用。与相关的接收功能一样，该设备的目的是对所需通道的带宽进行整形，然后通过数字方式将其上变频至所需 IF 频率。 如果需要多个通道，则可以在一个芯片上合成它们。转换后，可以将每个通道加在一起并插值到所需的数据速率，然后发送到 DAC。如果需要，可以将数字预失真与 DSP 一起添加，以校正信号链中的失真。 混频器或调制器可以用来将频率转换为最终 RF 频率。如果采用直接射频调制，则使用射频调制器。如果使用中频（直接来自 DAC 或传统中频上变频），则将使用混频器转换为最终 RF 频率。与接收混频器/解调器一样，可能需要更改数据的偏置电平或驱动电平或 LO 电平以优化失真。 18.8 使用单个上变频超外差的多通道传输 18.9: 单载波直接转换传输 与接收 LO 一样，发送 LO 的频率也可变，并且可以通过使用 PLL 或 DDS 技术的软件控制轻松编程。在此，也可能需要更改 LO 驱动电平，以优化各种信号条件下的杂散性能。与接收器的单频段操作一样，也可能存在需要固定 LO 的情况。 这样的例子将用于在单个频带内的操作，其中调谐在 ASIC 或 FPGA 内完成。与接收路径一样，数据转换器或 DAC 通常是瓶颈。但是，由于发射信号路径的动态范围要求比接收路径的动态范围要求低得多（通常为 25 至 45 dB），因此组件选择并不那么困难。有许多可用的 DAC 可以简化大范围的调整，包括增益和失调校正，从而可以最大程度地减小发射信号链中的 I/Q 不平衡。 其他所需的功能包括数据速率插值和 I/Q 相位校正。 最后，通过前置放大器和功率放大器（PA）实现功率增益。除了这些设备必须在很宽的频率范围内工作之外，还需要调整RF输出功率。这可能存在调整的问题，要求某些频率以比其他频率更低的功率进行传输。虽然 PA 增益通常是固定的，但前置放大器可以采用 VGA 的形式。 结论 随着全球范围内新的和更复杂的通信标准的发展，对新收发器架构的需求也将增长。但是，越来越多的可用资金，无论是资金还是人力，都限制了可以解决的设计。幸运的是，软件无线电技术可用于这些架构中不断壮大的一组，这些架构允许单个平台利用到许多不同的设计中。如此文所示，这具有许多明显的优势，并且不仅限于互操作性，投资保持和极大的灵活性。 与任何软件项目一样，SDR 的潜力通常仅受设计人员的想象力限制。与任何软件项目一样，最大的好处是，如果存在设计错误，则可以动动键盘就简单地解决问题。 幸运的是，最近十年来，半导体技术取得了重大进步，不仅在性能上，而且在成本上也取得了令人瞩目的成就[17]。SDR 是从这些多样化的技术中受益匪浅的领域，并且随着 SDR 含义的发展，它将继续这样的趋势，就像编程语言历史上的情况一样。 尽管 SDR 并非解决所有通信问题的方法，但它将在未来几年内为挑战性设计问题提供可靠的解决方案。包括相控阵技术，定位服务，互操作性以及尚未定义的复杂概念。但是，仍然存在一些挑战，使得无法完全接受该技术。两个主要问题分别是成本和功耗。有趣的是，这两者具有一阶正相关关系：解决一个问题、另一个只会变得更好。没有低功耗，用户设备将无法充分利用 SDR 技术。显然，电源问题来自对高性能组件的需求，高性能意味着超线性设备，高线性度器件意味着通过高电流会降低效率。 因此，如果解决了如何设计低功耗高线性度设备的问题，并且这是可以解决的，那么成本也将下降，这为许多其他应用打开了大门。因此，继续进行 SDR 开发和演进的关键是继续沿摩尔定律曲线改进设备，并继续对灵活的无线电架构产生兴趣。尽管存在这些挑战，但当前的性能状态已足以使工程师和制造商认真研究 SDR 的可能性。 参考 J. H. Reed, Software Radio: A Modern Approach to Radio Engineering, Prentice Hall, Upper Saddle River, NJ, 2002. J. Mitola, III, “Software Radio”Cognitive Radio,” http://ourworld. compuserve.com/homepages/jmitola/. B. Brannon, D. Efstathiou, and T. Gratzek, “A Look at Software Radios: Are They Fact or Fiction?” Electronic Design, (December 1998): pp. 117″122. B. Clarke and K. Kreitzer, “Software Radio Concepts,” unpublished paper. B. Brannon, “Digital-Radio-Receiver Design Requires Reevaluation of Parameters,” EDN, 43 (November 1998): pp. 163″170. B. Brannon, “New A/D Converter Benefi ts Digital IFs,” RF Design, 18 (May 1995):pp. 50″65. W. H. Hayward, “Introduction to Radio Frequency Design,” The American Radio Relay League, 1994″1996. J. J. Carr, Secrets of RF Circuit Design, McGraw-Hill, New York, 2001. B. Brannon, “Fast and Hot: Data Converters for Tomorrow’s Software-Defi ned Radios,” RF Design, 25 (July 2002): pp. 60″66. B. Brannon and C. Cloninger, “Redefining the Role of ADCs in Wireless,” Applied Microwave and Wireless, 13 (March 2001): pp. 94″105. B. Brannon, “DNL and Some of Its Effects on Converter Performance,” Wireless Design and Development, 9 (June 2001): p. 10. w.newnespress.com B. Brannon, “Overcoming Converter Nonlinearies with Dither,” Analog Devices Applications Note AN-410, www.analog.com. W. Kester, “High-Speed Sampling and High-Speed ADCs,” Section 4, High-Speed Design Techniques, www.analog.com. W. Kester, “High-Speed DACs and DDS Systems,” Section 6, High-Speed Design Techniques, www.analog.com. About CDMA and CDMA University. Available at http:// www.qualcomm.com. Specifications. Available at http://www.3gpp2.org. R. H. Walden, “Analog-to-Digital Converter Survey and Analysis,” IEEE Communications Magazine, 17 (April 1999): pp. 539″550. H. Nyquist, “Certain Topics in Telegraph Transmission Theory,” AIEE Transactions, 47 (April 1928): pp. 617″644. AD6645 Datasheet. Available at http://www.analog.com.","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/categories/SDR/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/tags/SDR/"}]},{"title":"云输入在 ibus-libpinyin 中的实现 - 配置项","slug":"IBus-libpinyin-cloud-input-configurations","date":"2020-07-16T20:20:00.000Z","updated":"2025-03-08T09:40:48.566Z","comments":true,"path":"2020/07/16/IBus-libpinyin-cloud-input-configurations/","link":"","permalink":"https://blog.inoki.cc/2020/07/16/IBus-libpinyin-cloud-input-configurations/","excerpt":"","text":"前几篇文章描述了云输入请求的全过程。其中，和云输入有关的参数（比如：需要请求几个云输入结果，延时发送请求需要延时多久等）是由 GLib 中的 GSettings 模块负责储存与读取的。 大多数情况下，这个模块都可以通过读取项目中的配置描述文件，生成对应的配置项（实际上，也可以通过命令行创建、读取、修改配置项，这里不做累述）。 配置描述文件 GSettings 通过读取一个以 .gschema.xml 结尾、XML 格式的配置描述文件生成对应配置项。一个典型的配置描述文件如下： 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;schemalist&gt; &lt;schema path=\"/org/example/myapp/\" id=\"org.example.myapp\"&gt; &lt;key name='automatic-updates' type='b'&gt; &lt;default&gt;true&lt;/default&gt; &lt;summary&gt;Automatically install updates&lt;/summary&gt; &lt;description&gt; If enabled, updates will automatically be downloaded and installed. If disabled, updates will still be downloaded, but the user will be asked to install them manually. &lt;/description&gt; &lt;/key&gt; &lt;/schema&gt;&lt;/schemalist&gt; 每个 &lt;schema&gt; 标签对应一个应用程序；每个 &lt;key&gt; 对应一个配置项，name 属性指定了配置项的名称，type 属性指定了值的类型，示例中的 automatic-updates 属性为一个布尔值，默认值为 true。 创建好一个配置项描述文件了之后，在 Makefile.am 中将文件名传给 gsettings_SCHEMAS，GLib 中 automake 相关的操作会进行之后的操作。比如，在 ibus-libpinyin 中的 data/Makefile.am 这一行就声明了项目中的配置描述文件： 1gsettings_SCHEMAS = com.github.libpinyin.ibus-libpinyin.gschema.xml 在这个文件中，声明了两个“应用程序”的配置项，因为实际上 ibus-libpinyin 包含了一个拼音输入法 libpinyin 和一个注音输入法 libbopomofo。 123&lt;schema path=\"/com/github/libpinyin/ibus-libpinyin/libpinyin/\" id=\"com.github.libpinyin.ibus-libpinyin.libpinyin\"&gt;&lt;/schema&gt;&lt;schema path=\"/com/github/libpinyin/ibus-libpinyin/libbopomofo/\" id=\"com.github.libpinyin.ibus-libpinyin.libbopomofo\"&gt;&lt;/schema&gt; 云输入相关配置项 在这两组配置项中，与云输入有关的配置项如下： 12345678910111213141516&lt;key name=\"enable-cloud-input\" type=\"b\"&gt; &lt;default&gt;false&lt;/default&gt; &lt;summary&gt;Enable Cloud Input&lt;/summary&gt;&lt;/key&gt;&lt;key name=\"cloud-input-source\" type=\"i\"&gt; &lt;default&gt;0&lt;/default&gt; &lt;summary&gt;Cloud Input Source&lt;/summary&gt;&lt;/key&gt;&lt;key name=\"cloud-candidates-number\" type=\"i\"&gt; &lt;default&gt;1&lt;/default&gt; &lt;summary&gt;Cloud Candidates Number&lt;/summary&gt;&lt;/key&gt;&lt;key name=\"cloud-request-delay-time\" type=\"i\"&gt; &lt;default&gt;600&lt;/default&gt; &lt;summary&gt;Sending Cloud request with delay&lt;/summary&gt;&lt;/key&gt; 其中，enable-cloud-input 为是否启用云输入，cloud-input-source 为云输入源的选择，cloud-candidates-number 是期望返回的云输入候选个数，cloud-request-delay-time 是延时发送云输入请求的时间，单位为毫秒。 现在版本中的配置项是从 18 版精简之后的，精简之前的配置项更加繁琐，如图所示： 配置界面 现在出现在配置页面中的配置项只有两个了，于是将之前 18 版中单独的配置页面移除，配置项放入 pinyin 配置页中： 在这个配置页面中，仅有云输入的启用和云输入源的选择可用。 延时发送云输入请求的时间一般情况下不会有人修改，目前的值先设为 600ms，上线后收集用户的反馈，根据情况进行修改。另外，用户也可以通过 GSettings 的命令行接口对这个值进行修改。而期望返回的云输入候选个数，由于前文所说的“百度云输入源无论何时都只返回一个候选”，目前默认定为1。 配置的 GUI 界面是 setup/ibus-libpinyin-preferences.ui 文件描述的，在 setup/main2.py 代码中由 Gtk 的 Python 绑定负责实例化和事件处理。 关于配置部分的整体架构如图： 配置界面 GUI 和 Python 程序可以读取或修改 GSettings 中的配置值。 ibus-libpinyin 中的 libpinyin 或 libbopomofo 的各个模块可以读取到配置值。 通过 GSettings 命令行工具也可以直接修改对应的值。 ibus-libpinyin 主程序中的云输入配置项 PYConfig 文件中声明了 Config 类，以及与配置相关的一系列值。比如与云输入相关的 CloudInputSource 云输入源： 1234enum CloudInputSource&#123; BAIDU = 0, GOOGLE&#125;; 在 Config 类中储存了与云输入配置项有关的保护变量及其读取函数： 123456789gboolean enableCloudInput (void) const &#123; return m_enable_cloud_input; &#125;guint cloudInputSource (void) const &#123; return m_cloud_input_source; &#125;guint cloudCandidatesNumber (void) const &#123; return m_cloud_candidates_number; &#125;guint cloudRequestDelayTime (void) const &#123; return m_cloud_request_delay_time; &#125;gboolean m_enable_cloud_input;guint m_cloud_input_source;guint m_cloud_candidates_number;guint m_cloud_request_delay_time; 正如之前配置读取架构描述的那样，这里的数据流应当是单向的，因此不应当有从此处更改配置值的操作。 读取配置时需要用到配置项名字，对应的是 .gschema.xml 中的 key 标签的 name 属性值，在 ibus-libpinyin 中声明成一系列常量： 1234const gchar * const CONFIG_INIT_ENABLE_CLOUD_INPUT = \"enable-cloud-input\";const gchar * const CONFIG_CLOUD_INPUT_SOURCE = \"cloud-input-source\";const gchar * const CONFIG_CLOUD_CANDIDATES_NUMBER = \"cloud-candidates-number\";const gchar * const CONFIG_CLOUD_REQUEST_DELAY_TIME = \"cloud-request-delay-time\"; 在这个类中，可以通过下面的方法读取一个属性值： 1m_enable_cloud_input = read (CONFIG_INIT_ENABLE_CLOUD_INPUT, false); 读取过后，还有对值的合法性的一系列检查，如果超过了限制，会置为默认值，并显示一个警告。 12345678910111213141516m_cloud_candidates_number = read (CONFIG_CLOUD_CANDIDATES_NUMBER, 1);if (m_cloud_candidates_number &gt; 10 || m_cloud_candidates_number &lt; 1) &#123; m_cloud_candidates_number = 1; g_warn_if_reached ();&#125;m_cloud_input_source = read (CONFIG_CLOUD_INPUT_SOURCE, 0);if (m_cloud_input_source != BAIDU &amp;&amp; m_cloud_input_source != GOOGLE) &#123; m_cloud_input_source = BAIDU; g_warn_if_reached ();&#125;m_cloud_request_delay_time = read (CONFIG_CLOUD_REQUEST_DELAY_TIME, 600);if (m_cloud_request_delay_time &gt; 2000 || m_cloud_request_delay_time &lt; 200) &#123; m_cloud_request_delay_time = 600; g_warn_if_reached ();&#125; 在构造函数中，初始化过默认值之后，会将 valueChangedCallback 函数注册为 changed 信号的回调。 12345initDefaultValues ();g_signal_connect (m_settings, \"changed\", G_CALLBACK (valueChangedCallback), this); 如果值发生了变化，这个函数会被调用，然后对应的配置值会被更新。 云输入中获取配置的实现 目前，云输入的配置仅仅在 CloudCandidates 构造函数中读取： 123m_cloud_source = m_editor-&gt;m_config.cloudInputSource ();m_delayed_time = m_editor-&gt;m_config.cloudRequestDelayTime ();m_cloud_candidates_number = m_editor-&gt;m_config.cloudCandidatesNumber (); 之后的过程都直接使用 CloudCandidates 内暂存的配置值。 这样造成的问题是，用户在更改了配置之后，值更改的事件会被触发，Config 和它的子类中的值会更新为新值；但 CloudCandidates 中仍为旧值，只有在切换到其他输入法，再切换回来，CloudCandidates 的构造函数才会再次被调用，新的配置值才会更新到这个新的 CloudCandidates 实例。 优化的其中一项方法是将暂存的值取消，每次使用时直接从 Config 的实例读取，这样能保证一直是最新的值。 总结 这篇文章粗略介绍了使用 GLib 的 GSettings 实现应用程序配置的过程，以及具体的在 ibus-libpinyin 中的实现。","categories":[{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/categories/ibus-libpinyin/"}],"tags":[{"name":"IBus","slug":"IBus","permalink":"https://blog.inoki.cc/tags/IBus/"},{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/tags/ibus-libpinyin/"},{"name":"Cloud Input","slug":"Cloud-Input","permalink":"https://blog.inoki.cc/tags/Cloud-Input/"}]},{"title":"KDE Connect 安装 Q&A","slug":"KDEConnect-Install-QA","date":"2020-07-07T23:33:33.000Z","updated":"2025-03-08T09:40:48.574Z","comments":true,"path":"2020/07/07/KDEConnect-Install-QA/","link":"","permalink":"https://blog.inoki.cc/2020/07/07/KDEConnect-Install-QA/","excerpt":"","text":"这篇文章记录了 QQ 群中回答的一些安装配置方面的问题。 群号码：668331167 或点击链接加入群聊【KDE Connect 中文交流群】 Windows 安装后无法运行问题 https://bugs.kde.org/show_bug.cgi?id=412665 文件：bin/data/dbus-1/services/org.kde.kdeconnect.service 把这个文件里面的Exec原本的 C:/CraftRoot/bin/kdeconnectd 改成 &lt;你的安装路径&gt;/bin/kdeconnectd 或 kdeconnectd。 32 位系统 暂时无解，请等待 KDE 的打包系统更新。 同步 Win 的通知 现在桌面版读取通知仅限 KDE plasma 下可用。 传多个文件 它实际上是去开了 kdeconnect-handler，把文件路径当参数传进去，但是估计实现不好，把多个文件路径当作一个了，就出 bug。 可以在状态栏图标那右键选 send files，然后再多选。 Linux Ubuntu/Debian “演讲指针”插件崩溃 前几天有朋友反馈，在 kubuntu 下的使用“演讲指针”插件存在崩溃的问题，是因为缺一个运行时依赖，可以这样解决： 1sudo apt-get install qml-module-qtquick-particles2 Ubuntu 和 Kubuntu 应该是相似的 apt 源，可能也存在类似的问题 Deepin 系统自带版本 西班牙人维护的软件源里面有 1.0 版本的 indicator-kdeconnect 和 kdeconnect 本体。 需要的话在安装软件源之后可以安装： 123sudo apt updatesudo apt install kdeconnectsudo apt install indicator-kdeconnect Flatpak 先安上flatpak，debian/ubuntu/deepin 可以直接 1sudo apt install flatpak 添加官方 flathub 源（需挂梯子）： 1flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo 添加 KDE 官方依赖的 flatpak 源 1flatpak remote-add kdeapps http://distribute.kde.org/kdeapps.flatpakrepo 在安装之后执行这个命令，允许 KDE Connect 访问下载文件夹： 1sudo flatpak override --filesystem=xdg-download org.kde.kdeconnect 电脑发送文件还有问题【待修复】—— xdg-portal-desktop 版本太老，读写文件的 bug 确认至少在 0.11 版就已经被修复了。可以尝试安装新版 xdg-portal-desktop 修复。 卸载 1flatpak uninstall org.kde.kdeconnect GSConnect https://extensions.gnome.org/extension/1319/gsconnect/ Android Android 10 剪贴板 Android 10 不让后台应用访问剪贴板了，新版本可以从通知栏主动发送剪贴板内容。 Android 无法接收到文件 如果是 Android 10 的话需要预先配置好访问权限： 插件设置-》 FileSystem Expose 加上传输目录就行。 MIUI 有人反映过有些文件传输问题。。。 macOS 翻译问题 在中文系统下界面目前没有翻译。 macOS 主动查找设备问题 发现一个 macOS 版本的 bug，mac 无线网络不支持 1500 以上的 MTU，所以发不出 UDP 广播识别包。 解决方法:从手机端刷新，找到 Mac 并连接配对😂 配置页面不在最前 配置了不让 KDE Connect 的图标在 Dock 栏显示的副作用。 如果有需要的话，可以把 kdeconnect-indicator.app/Contents/Info.plist 里的 12&lt;key&gt;LSUIElement&lt;/key&gt;&lt;string&gt;1&lt;/string&gt; 删掉，就可以在最上层打开窗口了，但是相应的 KDE Connect 的图标会在 Dock 中显示。 Chrome OS Android 子系统自带 NAT 我才发现 chrome OS 也能用（Android 版的），但是因为有层 NAT，需要添加IP+从 Chrome OS 里发起配对请求😂 系统无关 梯子相关 Chien：你梯子的规则可能没设置好，绕过局域网和大陆地址比较好。国情国情，国内网络环境太复杂了 解决方案： 先检查是否挂了梯子 请在梯子的例外列表添加 KDE Connect 或在白名单添加路由器内网 微信通知无法同步 TIM 可以，QQ 可能可以，微信通知不完全走系统通知，目前还有问题。","categories":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"},{"name":"中文","slug":"KDE-Connect/中文","permalink":"https://blog.inoki.cc/categories/KDE-Connect/中文/"}],"tags":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"【译】为 Rust 生成 Qt 绑定","slug":"Rust-Qt-Binding-Generator","date":"2020-07-04T16:51:00.000Z","updated":"2025-03-08T09:40:48.593Z","comments":true,"path":"2020/07/04/Rust-Qt-Binding-Generator/","link":"","permalink":"https://blog.inoki.cc/2020/07/04/Rust-Qt-Binding-Generator/","excerpt":"","text":"原文链接：https://www.vandenoever.info/blog/2017/09/04/rust_qt_binding_generator.html 这篇博客文章是 Rust Qt Binding Generator 的发布。该项目正在审核中，之后会加入到 KDE 当中。您可以在此处获取源代码。 该代码生成器可帮助在 Qt 和 QML 中快速开始使用 Rust 代码。换句话说，它有助于在 Rust 代码之上创建基于 Qt 的 GUI。 Qt是成熟的跨平台图形用户界面库。而 Rust 是一种新的编程语言，具有强大的编译时检查和现代语法。 入门 有两个模板项目可帮助您快速入门。一个用于 Qt Widgets，另一个用于 Qt Quick。只需复制这些文件夹、作为新项目开始编码。 文件关系 Qt Widgets (main.cpp) / Qt Quick (main.qml) ⟵ 写出的 UI 代码 src/Binding.h, src/Binding.cpp, rust/src/interface.rs ⟵ 从 binding.json 中生成 rust/src/implementation.rs ⟵ 写出的 Rust 代码 为了结合 Qt 和 Rust，需要在一个 JSON 文件中编写一个接口。生成器会从这个文件创建 Qt 代码和 Rust 代码。Qt 代码可以直接使用。而 Rust 代码有两个文件：接口和实现。接口可以直接使用。 12345678910111213141516171819&#123; \"cppFile\": \"src/Binding.cpp\", \"rust\": &#123; \"dir\": \"rust\", \"interfaceModule\": \"interface\", \"implementationModule\": \"implementation\" &#125;, \"objects\": &#123; \"Greeting\": &#123; \"type\": \"Object\", \"properties\": &#123; \"message\": &#123; \"type\": \"QString\", \"write\": true &#125; &#125; &#125; &#125;&#125; 这个文件描述了 Greeting 这个对象的绑定。它有一个可写属性 message。 运行这个命令，Rust 的 Qt 绑定生成器会从描述中创建绑定源代码： 1rust_qt_binding_generator binding.json 这个过程会生成下面四个文件： src/Binding.h src/Binding.cpp rust/src/interface.rs rust/src/implementation.rs 只需要更改 Implementation.rs 即可，其余文件是绑定文件。Implementation.rs 是使用一个简单实现创建出的，带有一些注释，文件内容如下： 12345678910111213141516171819202122232425262728293031323334use interface::*;/// A Greetingpub struct Greeting &#123; /// Emit signals to the Qt code. emit: GreetingEmitter, /// The message of the greeting. message: String,&#125;/// Implementation of the binding/// GreetingTrait is defined in interface.rsimpl GreetingTrait for Greeting &#123; /// Create a new greeting with default data. fn new(emit: GreetingEmitter) -&gt; Greeting &#123; Greeting &#123; emit: emit, message: \"Hello World!\".into(), &#125; &#125; /// The emitter can emit signals to the Qt code. fn emit(&amp;self) -&gt; &amp;GreetingEmitter &#123; &amp;self.emit &#125; /// Get the message of the Greeting fn message(&amp;self) -&gt; &amp;str &#123; &amp;self.message &#125; /// Set the message of the Greeting fn set_message(&amp;mut self, value: String) &#123; self.message = value; self.emit.message_changed(); &#125;&#125; Qt 和 QML 项目的构建关键是 QObject 和 Model View 类。 rust_qt_binding_generator 读取一个 json 文件以生成 QObject 或 QAbstractItemModel 类，这些类会调用生成的 Rust 文件。对于 JSON 文件中的每种类型，都会生成应实现的 Rust Trait。 这样，Rust 代码就可以从 Qt 和 QML 项目中调用了。 Qt Widgets 与 Rust 这里的 C++ 代码使用了上面编写的 Rust 代码。 1234567#include \"Binding.h\"#include &lt;QDebug&gt;int main() &#123; Greeting greeting; qDebug() &lt;&lt; greeting.message(); return 0;&#125; Qt Quick 与 Rust 这里的 Qt Quick（QML） 代码使用了上面编写的 Rust 代码。 12345678Rectangle &#123; Greeting &#123; id: rust &#125; Text &#123; text: rust.message &#125;&#125; 示例程序 该项目带有一个演示应用程序，该应用程序显示了基于 Rust 的 Qt 用户界面。 它使用了对象，列表和树的所有功能。阅读这些演示代码是入门的好方法。 Dcoekr 开发环境 为了快速上手，该项目附带了一个Dockerfile。执行下面的命令可以启动具有所需依赖项的 Docker 会话： 1./docker/docker-bash-session.sh 更多信息 Rust Qt Binding Generator Qt Qt 示例与教程 The QML Book","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Qt","slug":"Qt","permalink":"https://blog.inoki.cc/categories/Qt/"},{"name":"Rust","slug":"Rust","permalink":"https://blog.inoki.cc/categories/Rust/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Qt","slug":"Qt","permalink":"https://blog.inoki.cc/tags/Qt/"},{"name":"Rust","slug":"Rust","permalink":"https://blog.inoki.cc/tags/Rust/"}]},{"title":"【译】软件定义无线电的基础 —— 2.接收机","slug":"Basic-of-Software-Defined-Radio-2","date":"2020-07-03T20:08:00.000Z","updated":"2025-03-08T09:40:48.547Z","comments":true,"path":"2020/07/03/Basic-of-Software-Defined-Radio-2/","link":"","permalink":"https://blog.inoki.cc/2020/07/03/Basic-of-Software-Defined-Radio-2/","excerpt":"","text":"原文链接：https://www.eetimes.com/sdr-basics-part-2-receivers/ 架构 理想情况下，SDR 的设计人员希望将数据转换器直接放在天线上。但是，这不是实际情况中的解决方案。实际上，一些模拟前端必须在接收路径中的 ADC 之前和发送路径中的数模转换器之后才能使用，来执行适当的频率转换。这些体系结构中最常见的是超外差（super-heterodyne）架构。尽管这种架构已经有数十年的历史了，但全新的半导体技术和更高的集成度使该体系结构仍然充满活力，并在发送和接收信号路径中都得到了广泛使用[5，6]。 其他体系结构（例如用于发送和接收的直接转换）在要求不高的应用程序中受到欢迎。当前，直接转换（Tx和Rx）在用户终端中被发现用于蜂窝通信、以及在基站侧的 Tx，随着未来的发展，也存在于接收端实现直接转换的可能性。在此之前，超外差架构将继续以一种或另一种形式使用。 接收器 高性能 SDR 接收器通常由超外差架构的某些变体构造而成。超外差接收器可在很大的频率范围内提供稳定的性能，同时保持良好的灵敏度和选择性[7，8]。尽管设计并非易事，但结合使用宽带模拟技术和多个前端的可能性将允许在不同的 RF 频段上进行操作。对于多载波应用，必要时也可以同时进行。 多载波 取决于应用程序，我们可能需要一个或多个接收通道。传统应用可能只需要一个 RF 通道。但是，需要高容量或互操作性的应用程序可能需要多载波设计。由于 SDR 采用具有足够可用带宽的高度过采样 ADC ，因此非常适合多载波应用。 过采样 ADC 是一种采样率超出了满足奈奎斯特抽样准则[18]要求的采样率的 ADC ，该准则规定转换器的采样率必须是信息带宽的两倍。由于 SDR 可能不清楚将用于接收信号的带宽，因此采样率必须足够高才能对所有预期的带宽进行采样。 当前的 ADC 技术允许将高达 100 MHz 的高动态范围带宽数字化。有了这么多的带宽，也就可以处理多个通道。图 18.5 给出了一个典型的多载波接收机示例，图 18.6 给出了其频谱显示。 18.5. 多载波 CDMA 示例 18.6. 使用 IS-95 的多模式频谱和窄带载波 在此示例中， ADC 的采样率设置为 61.44 兆采样/秒（MSPS），这提供了 30.72 MHz 的奈奎斯特带宽。如果每个RF通道的宽度为 1.25 MHz，则奈奎斯特表示潜在频道的数量约为 24.5。实际上，通过在抗混叠滤波器上允许合理的过渡带，典型的可用带宽是采样率的三分之一，而不是奈奎斯特的一半。因此，这个示例的可用带宽为 20.48 MHz，在 1.25 MHz 带宽时仅允许 16 个频道。 由于可以改变信道特性，因此很容易将 CDMA 示例更改为 GSM 示例。在这种情况下，通过将数字通道滤波器从 GSM 更改为 CDMA 并将新的处理代码加载到 DSP 中，分别重新配置了数字预处理和通用 DSP。由于 GSM 信道的宽度为 200 kHz，因此可以轻松地将该示例重新配置为 102 信道的 GSM 接收器。 虽然这两个示例都提供了很多实用性，但也许更有趣的示例是：配置接收器，以使部分信道可以是 CDMA，而其他信道可以配置为 GSM！ 此外，如果其中一种配置已满负荷使用，而另一种配置未得到充分利用，则可以将 CDMA 信道转换为多个 GSM 信道，反之亦然，从而可以根据需要灵活地动态重新分配系统资源（软件定义无线电的主要目标）。 单载波 并非所有 SDR 应用程序都需要一个以上的信道。低容量系统可能只需要一个载波。在这些应用中，仍然需要一个高的过采样率。如果这个信道是可重新编程的，则可能会窄到几个 kHz 或 5-10 MHz。为了适应此带宽范围，采样率应适合最高的潜在带宽，在这种情况下为 10 MHz。从多载波示例中，我们通常将采样至少三倍的带宽。在此示例中，30.72 MSPS 或更高的采样率将允许处理从几 kHz 到最高 10 MHz 的信号带宽。除了只处理一个信道之外，单载波接收机也具有多载波接收机的全部容量，也可以根据需要重新配置。 SDR 接收器的元素 参考图 18.7 中的单载波框图，同时要记住这也适用于多载波示例，一个完全开发的 SDR 将具有所有可编程的信号元素。 18.7. 单载波接收示例 天线也不例外，也是可编程的。但不幸的是，它是 SDR 中最弱的元素之一[1]。由于大多数天线结构的带宽仅为其中心频率的一小部分，因此多频带操作会变得困难。在使用单个工作频带的许多应用中，这不是个问题。但是，对于必须在多个几个频率上运行的系统，必须通过某种方式调整天线以跟踪工作频率、保持工作效率。 的确，几乎所有天线都可以与有源电子设备进行阻抗匹配，但是通常会牺牲链路增益，从而可能导致天线损耗，而大多数天线设计实际上应该提供适度的信号增益。因此，需要通过简单地改变天线的匹配来调整天线的电长度。TODO:尝试解释。 信号链中的下一个是频带选择滤波器这一电子器件。提供该元件是为了限制呈现给高增益阶段的输入频率的范围，以最大程度地减小互调失真的影响。即使在互调不成问题的情况下，高强度的频带外信号也有可能在随后的阶段中限制潜在的增益量，从而导致灵敏度受限，尤其是对于在发射功率电平可能超过 100 kW 的电视和音频广播服务附近调谐的接收器。 对于必须处理许多数量级信号幅度的多载波接收机而言，这尤其成问题。如果所有信号都令人感兴趣，那么将不可能对较强的信号进行滤波，而且得到的接收器必须具有相对较大的信号动态范围[8]。 大多数接收器需要一个低噪声放大器（LNA）。一个 SDR 理想情况下应包含能够在所需频率范围内工作的 LNA。除了典型的 LNA 和 High IP3 之外，可能还需要具有调整增益的能力，并在可能的情况下按比例减小功率（通常是 NF 和 IP3 跟踪偏置电流），这将允许各种信号条件在整个操作的频带范围内都存在。// TODO: 优化翻译 混频器用于将 RF 频谱转换为合适的 IF 频率。尽管在图 18.7 中仅显示了一个混频器，但是许多接收器可以使用两个或三个混频器级，每个级依次产生一个较低的频率。（请注意：接收器 IF 并不总是低于 RF 信号。在高频接收器中可以找到一个常见的例子，在该接收器中，所需的RF信号可能只有几个 MHz。在这些情况下，它们经常混频到 10.7 MHz，21.4 MHz，45 MHz 或更高的 IF 频率，因为所需组件的可用性或性能）每个连续级还利用了分布在整个链中的滤波功能，以消除不需要的像/，以及其他在混合过程中留存下来的不需要的信号。滤波也应适合该应用程序。传统的单载波接收器通常会通过混频器级应用信道滤波，以帮助控制每级的 IP3 要求。而在多载波接收机的情况下，无法预先知道信道带宽，从而无法进行模拟信道滤波。 因此，混合过程必须保留整个感兴趣的频谱。同样，我们的单载波 SDR 应用程序也必须保留最大可能的频谱，以防 SDR 需要全频谱。在这种情况下，即使仅关注一个载波，我们的单载波示例也可能正在处理许多载波。与 LNA 一样，我们希望 SDR 中的混频器具有可调的偏置。与 LNA 一样，该偏置可用于正确设置设备的转换增益和 IP3 以对应于所需的信号条件。 除混合器之外或代替混合器，某些接收机体系结构还使用正交解调器。解调器的目的是分离 I 和 Q 分量。 分开后，I 和 Q 路径必须保持单独的信号调理。在数字域，这不是问题。但是，在模拟域中，信号路径必须完美匹配，否则将引入 I/Q 不平衡，从而可能限制系统的适用性。 如单载波示例所示，许多 SDR 接收器通过利用实采样（而不是复采样）来避免此问题，并在数字预处理器中使用可提供完美正交的数字正交解调器。 当与输入的 RF 信号混合时，本地振荡器用于生成适当的 IF。通常，本地振荡器（LO）的频率可变，并且可以使用 PLL 或 DDS 技术通过软件控制轻松编程。在某些情况下，LO 可能不需要跳频。一个例子是用于接收固定频带内的多个载波。在这种情况下，LO 是固定的，并且整个频带被按块转换为所需的中频。通常可能需要更改 LO 的驱动电平，以优化各种信号条件下的寄生/伪性能。// TODO: 优化翻译 中频放大器通常是 AGC 形式的。AGC 的目标是在不过度驱动信号链其余部分的情况下，使用可能的最大增益。有时，AGC 由模拟控制回路控制。但是，数字控制回路也可以用于实现使用模拟反馈无法实现的困难控制回路。在多载波应用中，使用 AGC 最好的情况下也很难。如果接收器中的动态范围不足（主要由 ADC 决定），则强信号的增益降低可能会导致较弱的信号在接收器的本底噪声中丢失。在这样的应用中，理想的增益数字控制环路。只要没有信号丢失的危险，就可以正常使用控制回路。 然而，如果在存在非常强的信号的情况下检测到弱信号，可以做出决定允许有限量的削除，而不是减少弱信号的增益，而因此产生弱信号丢失的风险。通过数字控制环路比通过模拟环路更容易控制此类条件情况，从而可以更好地控制接收器的总转换增益。 ADC 用于将一个或多个 IF 信号转换为数字格式以进行处理。ADC 通常是瓶颈，而 ADC 的选择通常是决定 SDR 架构的驱动因素[1、9、10]。通常，设计人员被迫选择最佳的可用 ADC，因为意识到在许多情况下 ADC 可能会被过度指定。 还有一些时候，空中接口标准可能不针对多载波接收器，并且比在现场部署时所要求的 ADC 要好得多，这仅仅是因为该标准规定了测试方法。对于 ADC，可能需要更改采样率，输入范围以及潜在的活动带宽。数字预处理器可以采用多种形式。对于很高的采样率和数据速率，通常将其实现为 FPGA 或 ASIC。这些电路本质上在功能和参数范围上都非常灵活。当然，可以针对所需的任何功能对 FPGA 进行编程。通常，将对 FPGA 进行编程以执行正交解调和调谐，通道滤波以及数据速率降低。// TODO: 优化翻译 其他功能，例如 RF 功率测量和信道线性化也是可能的。所有这些元素都可以使用多种数字技术轻松生成，并且可以通过将各种系数加载到 FPGA 来轻松进行编程。通过这样做，可以使用单芯片配置来生成数字预处理器，这样的数字预处理器能够调整 ADC 的奈奎斯特频带的整个范围，还可以过滤从数 kHz 到数 MHz 带宽的信号。当需要多个频道时，可以重复设计以填充 FPGA。如果需要低成本的选择，则可以使用执行这些功能的各种 ASIC，它们通常被称为通道器，RSP 或 DDC。 SDR 中的最后一个元素是 DSP。由于这是一个通用 DSP，因此可以针对任何所需的处理任务进行编程。典型的任务包括均衡，检测，实现 rake 接收器的功能，甚至是实现网络接口，仅举几例。 由于它们是完全可编程的，因此它们几乎可以用于任何信号处理任务，并控制框图其他元素中的所有功能。随着 DSP 处理能力的提高，它也可能会接管数字预处理器中的许多功能。 总结 第三部分将会讲解 SDR 的发送端。 参考 J. H. Reed, Software Radio: A Modern Approach to Radio Engineering, Prentice Hall, Upper Saddle River, NJ, 2002. J. Mitola, III, “Software Radio”Cognitive Radio,” http://ourworld. compuserve.com/homepages/jmitola/. B. Brannon, D. Efstathiou, and T. Gratzek, “A Look at Software Radios: Are They Fact or Fiction?” Electronic Design, (December 1998): pp. 117″122. B. Clarke and K. Kreitzer, “Software Radio Concepts,” unpublished paper. B. Brannon, “Digital-Radio-Receiver Design Requires Reevaluation of Parameters,” EDN, 43 (November 1998): pp. 163″170. B. Brannon, “New A/D Converter Benefi ts Digital IFs,” RF Design, 18 (May 1995): pp. 50″65. W. H. Hayward, “Introduction to Radio Frequency Design,” The American Radio Relay League, 1994″1996. J. J. Carr, Secrets of RF Circuit Design, McGraw-Hill, New York, 2001. B. Brannon, “Fast and Hot: Data Converters for Tomorrow’s Software-Defi ned Radios,” RF Design, 25 (July 2002): pp. 60″66. B. Brannon and C. Cloninger, “Redefi ning the Role of ADCs in Wireless,” Applied Microwave and Wireless, 13 (March 2001): pp. 94″105. B. Brannon, “DNL and Some of Its Effects on Converter Performance,” Wireless Design and Development, 9 (June 2001): p. 10. w.newnespress.com B. Brannon, “Overcoming Converter Nonlinearies with Dither,” Analog Devices Applications Note AN-410, www.analog.com. W. Kester, “High-Speed Sampling and High-Speed ADCs,” Section 4, High-Speed Design Techniques, www.analog.com. W. Kester, “High-Speed DACs and DDS Systems,” Section 6, High-Speed Design Techniques, www.analog.com. About CDMA and CDMA University. Available at http:// www.qualcomm.com. Specifi cations. Available at http://www.3gpp2.org. R. H. Walden, “Analog-to-Digital Converter Survey and Analysis,” IEEE Communications Magazine, 17 (April 1999): pp. 539″550. H. Nyquist, “Certain Topics in Telegraph Transmission Theory,” AIEE Transactions, 47 (April 1928): pp. 617″644. AD6645 Datasheet. Available at http://www.analog.com.","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/categories/SDR/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/tags/SDR/"}]},{"title":"KDE Frameworks - Introduction","slug":"KDE-Frameworks-Introduction","date":"2020-07-02T23:22:00.000Z","updated":"2025-03-08T09:40:48.573Z","comments":true,"path":"2020/07/02/KDE-Frameworks-Introduction/","link":"","permalink":"https://blog.inoki.cc/2020/07/02/KDE-Frameworks-Introduction/","excerpt":"","text":"Note: this is an extraction of KDE Frameworks API with some comments Italics means the project might be interesting to some developers. Bold means the project can be very useful for some applications. The KDE Frameworks build on the Qt framework, providing everything from simple utility classes (such as those in KCoreAddons) to integrated solutions for common requirements of desktop applications (such as KNewStuff, for fetching downloadable add-on content in an application, or the powerful KIO multi-protocol file access framework). The KDE Frameworks can be used in CMake-based and QMake-based projects, and most of them are portable to at least Windows, Mac and Linux. The documentation of each framework has code snippets that show how to include the framework in a QMake or CMake project. The frameworks are divided into four tiers, based on the kind of dependencies that they have. For instance, Tier 1 frameworks depend on Qt and possibly some third-party libraries, but not on other frameworks. This makes them easy to integrate into existing applications. Tier 1 Tier 1 frameworks depend only on Qt (and possibly a small number of other third-party libraries), so can easily be used by any Qt-based project. Framework Type Description Note Attica functional Open Collaboration Services API, version 1.6, REST BluezQt integration Qt wrapper for BlueZ 5 (Bluetooth) DBus API Linux Only BreezeIcons functional Breeze icon theme Beautiful icons ECM functional Extra CMake modules KApiDox functional Scripts and data for building API documentation (dox) in a standard format and style KArchive functional File compression KCalendarCore functional The KDE calendar access library KCGroups functional control cgroup resources through systemd dbus interface Linux only KCodecs functional provide a collection of methods to manipulate strings using various encodings KConfig functional Configuration system gconfig-like KCoreAddons functional Addons to QtCore KDBusAddons functional Addons to QtDBus KDNSSD integration a library for handling the DNS-based Service Discovery Protocol (DNS-SD) KGuiAddons functional Addons to QtGui KHolidays functional Holiday calculation library KI18n functional Advanced internationalization framework KIdleTime functional Monitoring user activity Kirigami2 functional QtQuick plugins to build user interfaces based on the KDE human interface guidelines KItemModels functional Models for Qt Model/View system KItemViews functional Widget addons for Qt Model/View KPlotting functional Lightweight plotting framework KQuickCharts functional A QtQuick module providing high-performance charts I don’t know why, but it only supports Linux and FreeBSD KSyntaxHighlighting functional Syntax Highlighting Kate uses it, helpful for Text Editor KUserFeedback solution User feedback framework KWayland integration Qt-style API to interact with the wayland-client and wayland-server API KWidgetsAddons functional Addons to QtWidgets KWindowSystem integration Access to the windowing system ModemManagerQt integration Qt wrapper for ModemManager API Linux Only NetworkManagerQt integration Qt wrapper for NetworkManager API Linux Only Oxygen-icons functional Oxygen icon theme Prison solution Barcode abstraction layer providing uniform access to generation of barcodes QQC2-Desktop-Style functional QtQuickControls 2 style that integrates with the desktop Solid integration Hardware integration and detection Hardware Discovery, Power Management, Network Management Sonnet solution Support for spellchecking plugin-based spell checking library ThreadWeaver functional High-level multithreading framework job-based interface to queue tasks Tier 2 Tier 2 frameworks additionally depend on tier 1 frameworks, but still have easily manageable dependencies. Framework Type Description Note KActivities solution Runtime and library to organize the user work in separate activities KAuth integration Abstraction to system policy and authentication features run high-privileged tasks (Linux, macOS, etc) KCompletion functional Text completion helpers and widgets completion for user input KContacts functional Support for vCard contacts read/write data in vCard standard (RFC 2425 / RFC 2426) KCrash integration Support for application crash analysis and bug report from apps crash report KDocTools functional Documentation generation from docbook KFileMetaData integration A file metadata and text extraction library extracting the text and metadata from different files KImageFormats functional Image format plugins for Qt additional image format plugins for QtGui (runtime plugin) KJobWidgets functional Widgets for tracking KJob instances widgets for showing progress of asynchronous jobs KNotifications solution Abstraction for system notifications cross-platform notification! KPackage functional Library to load and install packages of non binary files as they were a plugin KPeople functional Provides access to all contacts and the people who hold them gather all types of contacts KPty integration Pty abstraction interfacing with pseudo terminal devices KQuickImageEditor functional QtQuick plugins for image editing UI QtQuick components for image editing, Linux only KUnitConversion functional Support for unit conversion Unit Conversion Syndication functional An RSS/Atom parser library parse RSS (0.9/1.0, 0.91…2.0) and Atom (0.3 and 1.0) feeds Tier 3 Tier 3 frameworks are generally more powerful, comprehensive packages, and consequently have more complex dependencies. Framework Type Description Note Baloo solution Baloo is a file indexing and searching framework for KDE Plasma, Linux/FreeBSD only KActivitiesStats solution A library for accessing the usage data collected by the activities system KBookmarks functional Support for bookmarks and the XBEL format access and manipulate bookmarks KCMUtils integration Utilities for working with KCModules KConfigWidgets integration Widgets for configuration dialogs can be integrated into KDE Plasma system setting KDAV functional The KDav library interact with WebDAV calendars and todos with KJobs KDeclarative functional Provides integration of QML and KDE Frameworks bridge between QML and KDE Frameworks KDED solution Extensible deamon for providing system level services Linux/FreeBSD only KDESu integration Integration with su for elevated privileges su GUI for console mode programs, Linux/FreeBSD only KEmoticons functional Support for emoticons and emoticons themes from text to images in HTML KGlobalAccel integration Add support for global workspace shortcuts Linux/FreeBSD only KIconThemes integration Support for icon themes KInit solution Process launcher to speed up launching KDE applications KIO solution Resource and network access abstraction SFTP, Samba, etc KNewStuff solution Support for downloading application assets from the network collaborative data sharing for applications KNotifyConfig integration Configuration system for KNotify KParts solution Document centric plugin system KRunner solution Parallelized query system KService solution Advanced plugin and service introspection handling desktop services KTextEditor solution Advanced embeddable text editor with rich text support KTextWidgets functional Advanced text editing widgets KWallet solution Secure and unified container for user passwords KXmlGui integration User configurable main windows managing menu and toolbar actions in an abstract way Plasma solution Plugin based UI runtime used to write primary user interfaces KDE Plasma! Purpose integration Offers available actions for a specific purpose allow other apps use this one Tier 4 Tier 4 frameworks can be mostly ignored by application programmers; this tier consists of plugins acting behind the scenes to provide additional functionality or platform integration to existing frameworks (including Qt). Framework Type Description Note FrameworkIntegration integration Workspace and cross-framework integration plugins Porting Aids Porting Aids frameworks provide code and utilities to ease the transition from kdelibs 4 to KDE Frameworks 5. Code should aim to port away from this framework, new projects should avoid using these libraries. Framework Type Description Note KDELibs4Support solution Porting aid from KDELibs4 KDesignerPlugin functional Tool to generate custom widget plugins for Qt Designer/Creator KDEWebKit integration KDE Integration for QtWebKit KHtml solution KHTML APIs KJS functional Support for JS scripting in applications KJsEmbed functional Embedded JS KMediaPlayer integration Plugin interface for media player features Kross solution Multi-language application scripting KXmlRpcClient functional Interaction with XMLRPC services","categories":[{"name":"KDE Frameworks","slug":"KDE-Frameworks","permalink":"https://blog.inoki.cc/categories/KDE-Frameworks/"}],"tags":[{"name":"KDE Frameworks","slug":"KDE-Frameworks","permalink":"https://blog.inoki.cc/tags/KDE-Frameworks/"}]},{"title":"【译】软件定义无线电的基础 —— 1.概述","slug":"Basic-of-Software-Defined-Radio-1","date":"2020-07-02T20:08:00.000Z","updated":"2025-03-08T09:40:48.547Z","comments":true,"path":"2020/07/02/Basic-of-Software-Defined-Radio-1/","link":"","permalink":"https://blog.inoki.cc/2020/07/02/Basic-of-Software-Defined-Radio-1/","excerpt":"","text":"原文链接：https://www.eetimes.com/basics-of-software-defined-radio-part-1/ 在过去十年里，半导体科技在性能和价格方面都大有改善，许多新型的无线电技术从军用和研发实验室中流出，并成为了主流。其中一项技术就是软件定义无线电。 尽管近些年已经讨论了很多，软件无线电仍没有能够被很好的定义。很大程度上，这是由于软件无线电提供的灵活性，允许它们在实践中的许多形式上进行变通，来适应不同的需求。然而，软件定义无线电，简称 SDR，在与其他类型的无线电进行比较的时候，的确具有许多唯一的特征。恰如其名，SDR 具有通过软件或可重定义逻辑改变自身功能的能力。这些事情是由数字信号处理器（DSP）或者可编程逻辑阵列（FPGA）来完成的，我们会在之后的章节中对它们进行讨论。 为了使用数字处理，必须将传统的模拟信号与数字域进行相互转换。这项操作是使用模数（ADC）和数模（DAC）转换器完成的。为了充分利用数字处理的优势，SDR 在信号链中、将信号尽可能多的保持在的数字域中，并在尽可能靠近天线的位置进行数字化和信号重构，从而使数字技术能够执行传统上由模拟组件完成的功能，以及其他在模拟领域无法实现的功能。但是，这是有一定局限的。尽管将 ADC 或 DAC 直接连接到天线是一个理想的最终目标，仍存在模拟前端能够改进的选择性和灵敏度问题。 在天线处数字化的替代方法，就是使用完全灵活的模拟前端（AFE），该前端能够将各种频率和频带转换为数据转换器本身可以适当处理的频率和频带[1]。SDR 在用于多载波、单载波、单频带、多频带和多模式收发器时效果非常理想。其中一些问题将在以后介绍。关键在于，SDR 具有超越简单的单通道、单模式收发器技术的能力，并且可以任意更改模式，频道带宽、速率和调制都可以通过软件灵活确定。这些特性可以通过直接输入、软盘、无线下载或通过使用细致的信号分析，通过称为 无线电认知 的过程来更改，这一过程是指确定信息是如何编码[2]。 无论采用何种方式重新配置无线电，完全实现的 SDR 都将能够使用可编程的信道带宽和调制特性来找到一个宽阔的频率范围。下表列出了 SDR 的一些可能的动态特性： 频道带宽 数据速率 调制类型 转换增益 除 RF 调谐外，收发器还必须具备利用这些特性中的一个以上特性的能力，才能被视为 SDR。 软件无线电的各个方面 正如前面的列表所示，SDR 具有许多特征。尽管不要求 SDR 具有所有这些特征，但是需要拥有一个以上这些特征。此外，前面的类别可以进一步细分，下面各节会对其进行描述。应该记住的是，软件定义意味着高度的灵活性和可变性，因此该讨论并没有囊括所有内容，并且会随着时间的推移而变化。但是，它可以作为了解 SDR 可能存在的方方面面的起点。 多频段 大多数传统的无线电架构在单个频段上或一个频率范围上操作。在许多应用中，需要进行多种频率操作。举几个例子：蜂窝通信，政府和非政府机构以及智能收集。在这些情况下，通常的做法是使用多个无线电，每个无线电都设计为在一个指定的频段内工作。多频段无线电具有按顺序或同时在两个或多个频段上运行的能力，例如在基站可能链接来自不同频段的手机的情况下。 多载波 多载波或多通道无线电具有一次同时在一个以上频率上运行的能力，可以在同一频带内，或者也可以在多频带无线电的情况下，同时在两个不同频带内。通常，多载波适用于可能同时服务多个用户的基站，但是它也适用于可能正在不同 RF 载波上处理语音和数据的用户终端。 多模式 多模式意味着能够处理几种不同类型的标准。 标准包括 AM， FM， GMSK 和 CDMA，但不限于这些。SDR 能够与许多不同的标准一起工作并不断进行重新编程。因此，比多模式更好的术语是多变的模式，其暗示离散数量的模式，是一种可变的模式，也意味着连续可变的操作模式。与其他特征一样，在多载波无线电的情况下，这些模式可以是连续的或同时的。 多速率 多速率与多模式密切相关。多速率无线电可以在不同的采样率中处理信号链的不同部分（例如在多速率滤波器中），或是具有处理需要不同数据速率的不同模式的能力。多速率无线电的一个示例是可以处理 270.833 kSPS 的 GSM 或 1.2288 MCPS 的CDMA的无线电。与其他特征一样，这可以在不同的载波上连续执行或同时执行。 可变带宽 可变带宽是多模式的另一个方面。 传统无线电使用固定的模拟滤波器（例如 SAW 或陶瓷滤波器）来确定信道带宽。 但是，SDR 使用可以更改的数字滤波器来确定通道带宽。尽管可以使用一系列开关模拟滤波器来更改传统接收器中的信道带宽，但其中只有少数几个实用。另外，数字滤波器具有实现模拟域中不可能的滤波器的潜力。 最后，数字滤波器也是可以定制的，以适应干扰源并补偿传输路径失真，这是模拟滤波器难以实现的两个功能。 总结 第二部分会着眼于接收器，描述 SDR 的架构。 参考 J. H. Reed, Software Radio: A Modern Approach to Radio Engineering, Prentice Hall, Upper Saddle River, NJ, 2002. J. Mitola, III, “Software Radio”Cognitive Radio,” http://ourworld.compuserve.com/homepages/jmitola/.","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/categories/SDR/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"SDR","slug":"SDR","permalink":"https://blog.inoki.cc/tags/SDR/"}]},{"title":"云输入在 ibus-libpinyin 中的实现 - 状态与错误处理","slug":"IBus-libpinyin-cloud-input-state-and-error-handle","date":"2020-06-15T16:33:00.000Z","updated":"2025-03-08T09:40:48.568Z","comments":true,"path":"2020/06/15/IBus-libpinyin-cloud-input-state-and-error-handle/","link":"","permalink":"https://blog.inoki.cc/2020/06/15/IBus-libpinyin-cloud-input-state-and-error-handle/","excerpt":"","text":"上一篇文章描述了云输入部分发出请求，接收到回复之后对回复的验证、处理，以及对返回的候选词的提取。在取得候选之后，会将其加入到 parser 中的 m_candidates 列表中，并返回一个状态；若没有取得候选或者在验证过程中发现了问题，也会返回一个指出问题的错误状态。 这篇文章接着这个流程，叙述在代码中是如何对这些状态或错误进行一系列处理的。除此之外，在发送请求前和发送请求时也有相应的状态，这篇文章的最后也会对这个过程进行描述。 由于之前的版本并没有状态与错误处理的流程，因此在这篇文章中不再对 18 和 20 版进行区分，只描述最新版本中的做法。 状态指示字符串 在处理过程中，会使用一系列字符串被更新到候选列表中，用来替代最初的占位符，告诉用户云输入候选处理当前的状态： 已过期: 1234567static const std::string CANDIDATE_CLOUD_PREFIX = \"☁\";static const std::string CANDIDATE_PENDING_TEXT = CANDIDATE_CLOUD_PREFIX;static const std::string CANDIDATE_LOADING_TEXT = CANDIDATE_CLOUD_PREFIX + \"...\";static const std::string CANDIDATE_NO_CANDIDATE_TEXT = CANDIDATE_CLOUD_PREFIX + \"[No Candidate]\";static const std::string CANDIDATE_INVALID_DATA_TEXT = CANDIDATE_CLOUD_PREFIX + \"[Invalid Data]\";static const std::string CANDIDATE_BAD_FORMAT_TEXT = CANDIDATE_CLOUD_PREFIX + \"[Bad Format]\"; 更新： 1234567891011static const std::string CANDIDATE_PENDING_TEXT_WITHOUT_PREFIX = \"[⏱️]\";static const std::string CANDIDATE_LOADING_TEXT_WITHOUT_PREFIX = \"...\";static const std::string CANDIDATE_NO_CANDIDATE_TEXT_WITHOUT_PREFIX = \"[🚫]\";static const std::string CANDIDATE_INVALID_DATA_TEXT_WITHOUT_PREFIX = \"[❌]\";static const std::string CANDIDATE_BAD_FORMAT_TEXT_WITHOUT_PREFIX = \"[❓]\";static const std::string CANDIDATE_PENDING_TEXT = CANDIDATE_CLOUD_PREFIX + CANDIDATE_PENDING_TEXT_WITHOUT_PREFIX;static const std::string CANDIDATE_LOADING_TEXT = CANDIDATE_CLOUD_PREFIX + CANDIDATE_LOADING_TEXT_WITHOUT_PREFIX;static const std::string CANDIDATE_NO_CANDIDATE_TEXT = CANDIDATE_CLOUD_PREFIX + CANDIDATE_NO_CANDIDATE_TEXT_WITHOUT_PREFIX;static const std::string CANDIDATE_INVALID_DATA_TEXT = CANDIDATE_CLOUD_PREFIX + CANDIDATE_INVALID_DATA_TEXT_WITHOUT_PREFIX ;static const std::string CANDIDATE_BAD_FORMAT_TEXT = CANDIDATE_CLOUD_PREFIX + CANDIDATE_BAD_FORMAT_TEXT_WITHOUT_PREFIX; 其中，带有 WITHOUT_PREFIX 后缀的在状态改变时，会被储存在缓存的候选列表 m_candidates 中，更新候选时添加到候选列表中。 这些字符串带有一个 “☁” 的前缀，后面则是对应的状态字符串。 CANDIDATE_PENDING_TEXT 用来指示请求还未发送； CANDIDATE_LOADING_TEXT 在请求已发送，但未收到有效回复时显示。 其他三个则是用来显示处理请求的回复时的错误状态。 处理回复时可能的错误/状态 在 CloudCandidates.cpp 中，定义了一系列可能的错误或状态： 12345678enum CandidateResponseParserError &#123; PARSER_NOERR, PARSER_INVALID_DATA, PARSER_BAD_FORMAT, PARSER_NO_CANDIDATE, PARSER_NETWORK_ERROR, PARSER_UNKNOWN&#125;; 其中 PARSER_NOERR 是没有发现处理过程中存在问题。 PARSER_INVALID_DATA 和 PARSER_BAD_FORMAT 是指在验证过程中发现返回的结构不同、或者返回的结果无效。 如果到最后，发现云输入源没有返回任何候选，那么就用 PARSER_NO_CANDIDATE 通知上层。 以上几个错误或状态都在上篇文章《云输入在 ibus-libpinyin 中的实现 - 候选词解析》中出现过。 而 PARSER_NETWORK_ERROR 比较特殊，它仅仅用在取得的回复的输入流/缓冲区无效时，它仅仅在 CloudCandidatesResponseJsonParser 被返回： 1234567guint CloudCandidatesResponseJsonParser::parse (GInputStream *stream)&#123; /* ... */ if (!stream) return PARSER_NETWORK_ERROR; /* ... */&#125; 如果输入流或者缓冲区的读取没有问题，就交给具体实现的 parseJsonResponse 去解析，并返回它传回的错误（无错误则返回 PARSER_NOERR）。 最后一个 PARSER_UNKNOWN 仅作保留，没有使用。 错误/状态的处理 处理收到的回复时，是由 CloudCandidates 中的 processCloudResponse 方法来调用具体的 Parser 实现的 parse 方法的，返回的错误也就储存在 processCloudResponse 方法的 ret_code 变量中： 1ret_code = parser-&gt;parse (stream); 接下来会先对处理过程中一个重要的流程——如何替换候选列表中的云输入占位符，进行描述。然后是对各个错误类型的处理。 替换占位符、更新候选的方法 在处理时，很重要的一个操作是找到之前插入的云输入占位符的位置，以便更新占位符处的文本。 使用迭代器记录 上个 20 版的版本中，在插入占位符时，m_cloud_candidates_first_pos 和 m_candidates_end_pos 记录下来的了云输入占位符的开始位置和结束位置。这里的 m_cloud_candidates_first_pos 指向整句候选之后的第一个位置，而 m_candidates_end_pos 指向它之后第 N 个位置，其中 N 为配置的云输入候选词个数。 在进行更新占位符时，使用下面的循环即可，之后的章节中不再累述： 123for (std::vector&lt;EnhancedCandidate&gt;::iterator pos = m_cloud_candidates_first_pos; pos != m_candidates_end_pos; ++pos) &#123; /* ... */&#125; 这种方法的确能提高更新速度，因为它减少了每次从头查找的多余操作。但有一个问题是，如果云输入插入占位符并记录下来之后，其他候选处理过程又添加了新的候选，这时这两个迭代器的指向可能就不对了。 比如，在云输入进行 processCandidates 之后， Lua 脚本候选又在相同位置（整句候选之后的第一个位置）进行了添加和处理，这时 m_cloud_candidates_first_pos 的指向实际上是 Lua 脚本候选词，于是在更新过程中，它（们）就会被云输入的候选覆盖掉。 我采用的解决方案是，将云输入的候选处理放到最后。 不记录云占位符的位置 为了解决使用迭代器记录产生的问题，再加上每次云输入请求都会记录请求的拼音、并保存已解析的候选，最近的 20 版云输入已经可以通过 editor 的 updateCandidates 调用 CloudCandidates 的 processCandidates 正常更新候选。 使用下标记录 而之前的版本是使用一个固定开始下标和固定的占位符个数来记录，这种记录方法可能会导致程序在特定情况下崩溃。比如，固定的开始下标为2时，假如只有一个匹配的候选，使用2这个下标访问候选词列表，就会发生越界的问题。 处理 PARSER_NETWORK_ERROR 首先进行处理的是最特殊的错误状态，即网络出错时。 1pos-&gt;m_display_string = CANDIDATE_INVALID_DATA_TEXT; 在输入或者缓冲区不可用时，会把所有的占位符都修改为显示最开始提到的一系列状态指示字符串中的 CANDIDATE_INVALID_DATA_TEXT。 处理 PARSER_NETWORK_ERROR 之后 如果没有发生网络错误，说明至少回复是被处理了的。考虑到异步请求无法保证先后顺序，在进行接下来的其他判断时，我们希望确定在处理的的确是最近一次请求的。也就是说，只有在这个判断确认是最近一次的请求时，才进一步判断之后的小节里描述的其他状态。 我的方法是判断 parser 中获取到的拼音是否与当前编辑器中的一致： 1234else if (!g_strcmp0 (annotation, text) || !g_strcmp0 (annotation, double_pinyin_text))&#123; /* ... */&#125; 在上一篇中的章节 两个源返回结果上的差异 中，有提到从百度源解析出的拼音是进行了自动补全的，这种情况下就会导致这里的判断结果为假，从而导致结果被丢弃。 目前采用的方案是，对百度源不进行这一判断。因此，在新版本中这个条件添加了当前使用的是否是百度源的判断。 处理 PARSER_NOERR 这是无错误的情况。 1234if (ret_code == PARSER_NOERR)&#123; /* update to the candidates list */ std::vector&lt;std::string&gt; &amp;updated_candidates = parser-&gt;getStringCandidates (); 首先，将获取到的储存在 parser 中的候选取出。 12std::vector&lt;EnhancedCandidate&gt;::iterator pos = m_cloud_candidates_first_pos;std::vector&lt;EnhancedCandidate&gt;::iterator cached_candidate_pos = m_candidates.begin(); 找到候选词列表中占位符的初始位置，获取在 CloudCandidates 缓存的占位符的迭代器。 1234567891011121314 for (guint i = 0; cached_candidate_pos != m_candidates.end() &amp;&amp; pos != m_candidates_end_pos &amp;&amp; i &lt; updated_candidates.size (); ++i, ++pos, ++cached_candidate_pos) &#123; /* display candidate with prefix in lookup table */ EnhancedCandidate &amp; enhanced = *pos; enhanced.m_candidate_id = i; enhanced.m_display_string = CANDIDATE_CLOUD_PREFIX + updated_candidates[i]; /* cache candidate without prefix in m_candidates */ EnhancedCandidate &amp; cached = *cached_candidate_pos; cached.m_display_string = updated_candidates[i]; cached.m_candidate_id = enhanced.m_candidate_id; &#125;&#125; 紧接着对每个候选词列表中的占位符进行更新，将其修改为 &quot;☁&quot; + 候选词，同时将缓存的占位符修改为不带 &quot;☁&quot; 的候选词，并同步对应的候选在候选词列表中的 id。这样，当用户选择一个候选时，只需要遍历缓存在 CloudCandidates 中的候选，将传入的候选（为用户选中的）修改为缓存的对应的不带有 &quot;☁&quot; 的项并返回。 在之前的版本中，缓存的占位符没有被很好的使用，当用户选择时，会去遍历传入的选中的候选的字符内容，如果找到 &quot;☁&quot; 标记，则将其移除并返回。 新的实现更好一些，能够物尽其用，将缓存的候选最大程度利用上。 详细的用户选择后的操作在《云输入在 ibus-libpinyin 中的实现 - 概述》 处理用户选择的候选 一章。 处理 PARSER_NO_CANDIDATE 这种情况是指结构正确、解析过程中没有出现问题，但没有解析出候选。 1pos-&gt;m_display_string = CANDIDATE_NO_CANDIDATE_TEXT; 我认为这应当是一个出现了错误的状态，而不是说是单纯的没有候选。因此，这里把所有的占位符都修改为状态指示字符串中的 CANDIDATE_NO_CANDIDATE_TEXT。 处理 PARSER_INVALID_DATA 这种情况告诉用户，请求时返回的数据无效。 1pos-&gt;m_display_string = CANDIDATE_INVALID_DATA_TEXT; 类似的，把所有的占位符都修改为状态指示字符串中的 CANDIDATE_INVALID_DATA_TEXT。 处理 PARSER_BAD_FORMAT 在处理时发现数据的格式有问题，就会返回这种错误状态，这种情况可能在输入流或缓冲区不完整时出现。比如这里的读取流并进行 Json 解析时： 123456/* parse Json from input steam */if (!json_parser_load_from_stream (m_parser, stream, NULL, error) || error != NULL)&#123; g_input_stream_close (stream, NULL, error); /* Close stream to release libsoup connexion */ return PARSER_BAD_FORMAT;&#125; 同样，这里把所有的占位符都修改为状态指示字符串中的 CANDIDATE_BAD_FORMAT_TEXT。 1pos-&gt;m_display_string = CANDIDATE_BAD_FORMAT_TEXT; 不同阶段下的状态 除了上述的对收到的回复的解析时的错误或状态的处理，在此之前，还有对延时请求和等待回复两个状态。这两个状态可以简化在出现错误时对错误的定位。 延迟请求状态 在候选词列表插入占位符时，占位符的初始显示为 CANDIDATE_PENDING_TEXT。插入占位符之后，即进入延期等待状态。 等待回复状态 在延时等待结束之后，cloudAsyncRequest 方法会被调用用来发送请求。 12345678910111213141516171819voidCloudCandidates::cloudAsyncRequest (const gchar* requestStr)&#123; /* ... */ SoupMessage *msg = soup_message_new (\"GET\", queryRequest); soup_session_send_async (m_session, msg, NULL, cloudResponseCallBack, static_cast&lt;gpointer&gt; (this)); m_message = msg; /* update loading text to replace pending text */ for (std::vector&lt;EnhancedCandidate&gt;::iterator pos = m_cloud_candidates_first_pos; pos != m_candidates_end_pos; ++pos) &#123; if (CANDIDATE_CLOUD_INPUT == pos-&gt;m_candidate_type) &#123; if (CANDIDATE_PENDING_TEXT == pos-&gt;m_display_string) &#123; pos-&gt;m_display_string = CANDIDATE_LOADING_TEXT; &#125; &#125; else break; &#125; /* ... */&#125; 在这个方法中，请求发送完成之后，会将占位符更新为 CANDIDATE_LOADING_TEXT。 总结 这篇文章讲述了云输入的不同阶段下对状态的处理，以及解析请求的回复之后、对解析成功与否的状态和错误的处理。 它们都将特定的字符串更新到了候选词列表中，但这个列表是存在在 ibus-libpinyin 中的，真正显示在用户眼前，则是通过 ibus-libpinyin 通知 ibus 有新的候选列表完成的。这一过程在《云输入在 ibus-libpinyin 中的实现 - 概述》20-版异步请求中有相关解释。 下一篇文章会重点讨论一下与云输入有关的配置项。到这里，云输入的整体流程应当已经比较清楚了，我还会继续跟着开发过程更新这几篇文章中相关的内容。 不出意外，在云输入合并之后，下一步就是实现双拼形码相关的功能了。","categories":[{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/categories/ibus-libpinyin/"}],"tags":[{"name":"IBus","slug":"IBus","permalink":"https://blog.inoki.cc/tags/IBus/"},{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/tags/ibus-libpinyin/"},{"name":"Cloud Input","slug":"Cloud-Input","permalink":"https://blog.inoki.cc/tags/Cloud-Input/"}]},{"title":"云输入在 ibus-libpinyin 中的实现 - 候选词解析","slug":"IBus-libpinyin-cloud-input-candidate-parser","date":"2020-06-05T23:55:00.000Z","updated":"2025-03-08T09:40:48.566Z","comments":true,"path":"2020/06/05/IBus-libpinyin-cloud-input-candidate-parser/","link":"","permalink":"https://blog.inoki.cc/2020/06/05/IBus-libpinyin-cloud-input-candidate-parser/","excerpt":"","text":"上一篇文章粗略地介绍了目前在 ibus-libpinyin 的云输入实现的整个流程，其中对请求返回结果的解析没有提及。这篇文章会重点阐述返回结果的解析是如何实现的，之后的过程，包括在候选列表中更新占位符、错误处理，会在下一篇中详细讲解。 注：同上一篇文章一样，之前的版本称为 18 版云输入，现在的一系列版本称为 20 版。 返回结果的示例 目前，云输入功能可选的有 Google 和百度两个源，可能是为了让墙内外的用户都能使用吧。 其中，一个典型的 Google 源返回结果如下： 1[\"SUCCESS\",[[\"ceshi\",[\"测试\"],[],&#123;\"annotation\":[\"ce shi\"],\"candidate_type\":[0],\"lc\":[\"16 16\"]&#125;]]] 关键的请求参数为： 参数名 参数值 text ceshi num 1 其中 text 是请求的拼音，num 是期望返回的候选个数。 百度源的返回结果及其对应的请求参数是： 1&#123;\"errmsg\":\"\",\"errno\":\"0\",\"result\":[[[\"百度\",5,&#123;\"pinyin\":\"bai'du\",\"type\":\"IMEDICT\"&#125;]],\"bai'du\"],\"status\":\"T\"&#125; 参数名 参数值 input baidu ed 1 这里，input 是请求的拼音，而 ed 是请求的候选词个数。 可以看出，两个源返回的都是 json 字符串，并且格式还算是清晰。接下来就是把候选（比如 Google 源的示例中的“测试”和百度源的示例中的“百度”）解析提取出来的过程。 18 版解析实现 18 版的云输入使用了一个非常简易的解析方式：将回复存入字符串，通过截取子串的方式处理字符串来提取候选。在此之前，首先要将回复放入一个字符串中。 将回复放入字符串 在 18 版中，无论是同步模式还是异步模式，结果最终都被储存在叫做 res 的字符串中。 同步 同步模式下，在请求完全结束后，把消息取出并置入 buffer 缓冲区，最后放入 res 中。 1234567891011SoupMessageBody *msgBody =soup_message_body_new ();soup_message_body_truncate (msgBody);msgBody = msg-&gt;response_body;/* clear useless characters */soup_message_body_flatten(msgBody);SoupBuffer *bufferBody= soup_message_body_get_chunk(msgBody, 0);const gchar *buffer= bufferBody-&gt;data;String res;res.clear ();res.append (buffer); 异步 异步模式下，在请求完成后可以获取到回复的输入流。 12GError **error = NULL;GInputStream *stream = soup_session_send_finish (SOUP_SESSION(source_object), result, error); 然后从输入流中读取字符到 buffer 变量中，最后将其放入 res 字符串中。 12345678gchar buffer[BUFFERLENGTH];error = NULL;g_input_stream_read (stream, buffer, BUFFERLENGTH, NULL, error);CloudCandidates *cloudCandidates = static_cast&lt;CloudCandidates *&gt; (user_data);String res;res.clear ();res.append (buffer); 异步模式下，返回的输入流并不一定包含完整的字符串，大部分延迟较高的情况下，当执行到上面代码中的 g_input_stream_read 时，流中的内容都不是完整的，从而导致 res 中只储存了前几个字符，这会导致下面字符串处理时程序崩溃。 通过字符串处理解析候选 对百度源的回复的解析是一个简易的字符串判断与提取： 12345678910111213141516/*BAIDU */if (res[11]=='T')&#123; if (res[49] !=']') &#123; /*respond true , with results*/ gchar **resultsArr = g_strsplit(res.data()+49, \"],\", 0); guint resultsArrLength = g_strv_length(resultsArr); for(int i = 0; i != resultsArrLength-1; ++i) &#123; int end =strcspn(resultsArr[i], \",\"); std::string tmp = g_strndup(resultsArr[i]+2,end-3); cloudCandidates-&gt;m_candidates[i].m_display_string = tmp; &#125; &#125;&#125; 代码中多处出现了硬编码 res 数组下标的情况。虽然这里的代码在网关正常返回结果的时候的确可以运行，但网关返回错误信息时、或者异步模式下 res 中储存的不是完整的流中的字符串时，就会产生数组越界、非法访问，从而导致输入法崩溃。 对 Google 源的解析也一样是字符串的判断和提取： 12345678910111213/*GOOGLE */const gchar *tmp_res = res;const gchar *prefix = \"[\\\"SUCCESS\\\"\";if (g_str_has_prefix (tmp_res, prefix))&#123; gchar **prefix_arr = g_strsplit (tmp_res, \"\\\",[\\\"\", -1); gchar *prefix_str = prefix_arr[1]; gchar **suffix_arr = g_strsplit (prefix_str, \"\\\"],\", -1); std::string tmp = suffix_arr[0]; cloudCandidates-&gt;m_candidates[0].m_display_string = tmp; g_strfreev (prefix_arr); g_strfreev (suffix_arr);&#125; 这里的代码没有硬编码的下标，但如果 res 中没能取到回复输入流中的所有字符，会导致没有候选的情况出现。 20 版解析实现 在 20 版中，为了验证数据，也为了解析这一过程的健壮性，我选择移除 18 版中的字符串判断与提取这一方法，转而使用完整的 json 解析。 其中，考虑到 ibus-libpinyin 整体依赖于 glib，直接使用 JSON-GLib 会更加方便，于是添加了它作为一个依赖。 类关系 为了可拓展性，参考了导师的意见，我创建了 CloudCandidatesResponseParser 类作为所有解析类的基类。 1234567891011121314151617class CloudCandidatesResponseParser&#123;public: CloudCandidatesResponseParser () : m_annotation (NULL) &#123;&#125; virtual ~CloudCandidatesResponseParser () &#123;&#125; virtual guint parse (GInputStream *stream) = 0; virtual guint parse (const gchar *data) = 0; virtual std::vector&lt;std::string&gt; &amp;getStringCandidates () &#123; return m_candidates; &#125; virtual std::vector&lt;EnhancedCandidate&gt; getCandidates (); virtual const gchar *getAnnotation () &#123; return m_annotation; &#125;protected: std::vector&lt;std::string&gt; m_candidates; const gchar *m_annotation;&#125;; 它包含了两个私有（保护）属性和它们的 getter： m_candidates 是解析出的候选列表，每个元素是一个字符串； m_annotation 是解析出的结果中返回的拼音的值。 12virtual guint parse (GInputStream *stream) = 0;virtual guint parse (const gchar *data) = 0; 这是两个未实现的方法，需要在具体的类中实现，用来负责解析流中或者缓冲区中的数据。 1234567891011121314class CloudCandidatesResponseJsonParser : public CloudCandidatesResponseParser&#123;public: CloudCandidatesResponseJsonParser (); virtual ~CloudCandidatesResponseJsonParser (); guint parse (GInputStream *stream); guint parse (const gchar *data);protected: JsonParser *m_parser; virtual guint parseJsonResponse (JsonNode *root) = 0;&#125;; 接下来，CloudCandidatesResponseJsonParser 类继承了 CloudCandidatesResponseParser 类，并实现了上述的两个方法。 12345678910111213141516171819202122232425262728293031guint CloudCandidatesResponseJsonParser::parse (GInputStream *stream)&#123; GError **error = NULL; if (!stream) return PARSER_NETWORK_ERROR; /* parse Json from input steam */ if (!json_parser_load_from_stream (m_parser, stream, NULL, error) || error != NULL) &#123; g_input_stream_close (stream, NULL, error); // Close stream to release libsoup connexion return PARSER_BAD_FORMAT; &#125; g_input_stream_close (stream, NULL, error); // Close stream to release libsoup connexion return parseJsonResponse (json_parser_get_root (m_parser));&#125;guint CloudCandidatesResponseJsonParser::parse (const gchar *data)&#123; GError **error = NULL; if (!data) return PARSER_NETWORK_ERROR; /* parse Json from data */ if (!json_parser_load_from_data (m_parser, data, strlen (data), error) || error != NULL) return PARSER_BAD_FORMAT; return parseJsonResponse (json_parser_get_root (m_parser));&#125; 它们都是用一个 JSON-GLib 中的 JsonParser 示例去解析，并把解析的对象传给 CloudCandidatesResponseJsonParser 中定义的 parseJsonResponse 来进行具体的处理。 这个方法在当前类中也是未实现的状态，具体的处理行为是和云输入的源有关的，因此，交给下面在 GoogleCloudCandidatesResponseJsonParser 和 BaiduCloudCandidatesResponseJsonParser 中实现的 parseJsonResponse 分别进行 Google 源和百度源返回结果的处理。 123456789101112131415161718class GoogleCloudCandidatesResponseJsonParser : public CloudCandidatesResponseJsonParser&#123;protected: guint parseJsonResponse (JsonNode *root);public: GoogleCloudCandidatesResponseJsonParser () : CloudCandidatesResponseJsonParser () &#123;&#125;&#125;;class BaiduCloudCandidatesResponseJsonParser : public CloudCandidatesResponseJsonParser&#123;private: guint parseJsonResponse (JsonNode *root);public: BaiduCloudCandidatesResponseJsonParser () : CloudCandidatesResponseJsonParser () &#123;&#125; ~BaiduCloudCandidatesResponseJsonParser () &#123; if (m_annotation) g_free ((gpointer)m_annotation); &#125;&#125;; 下面的小节就来描述一下在这两个类中 parseJsonResponse 做了什么。 候选词提取处理 这一步的目的，是将候选词和拼音解析出来，分别放入 m_candidates 列表和 m_annotation 中。为了方便理解，下面结合之前提到的两个具体例子来辅助理解。 Google 源的返回结果处理 1[\"SUCCESS\",[[\"ceshi\",[\"测试\"],[],&#123;\"annotation\":[\"ce shi\"],\"candidate_type\":[0],\"lc\":[\"16 16\"]&#125;]]] 我们使用最初的那个 Google 源的回复举例，Google 源的处理实现如下，其中的参数 JsonNode *root 为 JSON-GLib 解析出的一个实例： 1234guint GoogleCloudCandidatesResponseJsonParser::parseJsonResponse (JsonNode *root)&#123; if (!JSON_NODE_HOLDS_ARRAY (root)) return PARSER_BAD_FORMAT; 首先先检查格式，最外层应当是一个数组，若格式有问题，就返回一个 PARSER_BAD_FORMAT 的状态。 123456789101112/* validate Google source and the structure of response */JsonArray *google_root_array = json_node_get_array (root);const gchar *google_response_status;JsonArray *google_response_array;JsonArray *google_result_array;const gchar *google_candidate_annotation;JsonArray *google_candidate_array;guint result_counter;if (json_array_get_length (google_root_array) &lt;= 1) return PARSER_INVALID_DATA; 紧接着获取到这个数组实例，并准备一些变量方便之后对元素的描述。 然后检测数组的大小是否至少为2，以免之后获取元素时出现越界。若元素数量符合期待，紧接着就可以做进一步的元素取出。否则返回一个 PARSER_INVALID_DATA 状态。 1234567891011google_response_status = json_array_get_string_element (google_root_array, 0);if (g_strcmp0 (google_response_status, \"SUCCESS\")) return PARSER_INVALID_DATA;google_response_array = json_array_get_array_element (google_root_array, 1);if (json_array_get_length (google_response_array) &lt; 1) return PARSER_INVALID_DATA;google_result_array = json_array_get_array_element (google_response_array, 0); 紧接着，取出数组中的元素： 第一个元素（下标为0），应当是一个字符串，描述这次请求是否是成功的，若不成功，则返回一个 PARSER_INVALID_DATA 状态。 第二个元素是接下来要处理的 google_response_array 这个数组结构，长度至少为1，对应的 json 部分为： 1[[\"ceshi\",[\"测试\"],[],&#123;\"annotation\":[\"ce shi\"],\"candidate_type\":[0],\"lc\":[\"16 16\"]&#125;]] 然后进一步的取到它的内层数组 google_result_array，从这里开始，就有了真正需要的数据。 1234567google_candidate_annotation = json_array_get_string_element (google_result_array, 0);if (!google_candidate_annotation) return PARSER_INVALID_DATA;/* update annotation with the returned annotation */m_annotation = google_candidate_annotation; 第一个取出的是 google_result_array 的第一个元素，这个元素应当是一个字符串，表示的是用户的输入，在上述例子中为 &quot;ceshi&quot; 这个元素。并把它存到当前实例的 m_annotation 属性中。 123456789101112131415 google_candidate_array = json_array_get_array_element (google_result_array, 1); result_counter = json_array_get_length (google_candidate_array); if (result_counter &lt; 1) return PARSER_NO_CANDIDATE; for (guint i = 0; i &lt; result_counter; ++i) &#123; std::string candidate = json_array_get_string_element (google_candidate_array, i); m_candidates.push_back (candidate); &#125; return PARSER_NOERR;&#125; 第二个取出的是 google_result_array 的第二个元素，是一个包含了候选词的数组，取名为 google_candidate_array。 先判断它的长度，若不包含任何元素，则返回 PARSER_NO_CANDIDATE 状态。 有元素的话就把所有元素取出，添加到 m_candidates 这个属性对应的候选词列表中。然后返回 PARSER_NOERR 状态。 百度源的返回结果处理 1&#123;\"errmsg\":\"\",\"errno\":\"0\",\"result\":[[[\"百度\",5,&#123;\"pinyin\":\"bai'du\",\"type\":\"IMEDICT\"&#125;]],\"bai'du\"],\"status\":\"T\"&#125; 同样的，对于百度，我们也使用最初的例子，其中的参数 JsonNode *root 也是 JSON-GLib 解析出的一个实例： 1234guint BaiduCloudCandidatesResponseJsonParser::parseJsonResponse (JsonNode *root)&#123; if (!JSON_NODE_HOLDS_OBJECT (root)) return PARSER_BAD_FORMAT; 先检查格式，最外层应当是一个对应，在格式不匹配的情况下就返回一个 PARSER_BAD_FORMAT 的状态。 1234567/* validate Baidu source and the structure of response */JsonObject *baidu_root_object = json_node_get_object (root);const gchar *baidu_response_status;JsonArray *baidu_result_array;JsonArray *baidu_candidate_array;const gchar *baidu_candidate_annotation;guint result_counter; 类似但却不同的，这里是获取到这个 json 对象的实例，并创建一系列变量用来接收之后的元素。 1234567if (!json_object_has_member (baidu_root_object, \"status\")) return PARSER_INVALID_DATA;baidu_response_status = json_object_get_string_member (baidu_root_object, \"status\");if (g_strcmp0 (baidu_response_status, \"T\")) return PARSER_INVALID_DATA; 首先先看 status 元素存在且是否为 T，如果不存在或者为其他值，这次请求的应当已经是失败的了，就不需要进行下一步的操作，直接返回 PARSER_INVALID_DATA 状态。 123456if (!json_object_has_member (baidu_root_object, \"result\")) return PARSER_INVALID_DATA;baidu_result_array = json_object_get_array_member (baidu_root_object, \"result\");baidu_candidate_array = json_array_get_array_element (baidu_result_array, 0); 然后则是对 result 元素存在性的检测，这个元素是存放有结果的一个数组。这个数组的第一个元素是存放有候选词信息的数组，将其取出，用 baidu_candidate_array 指向它。这是之后取候选词时主要要操作的对象。 12345678910baidu_candidate_annotation = json_array_get_string_element (baidu_result_array, 1);if (!baidu_candidate_annotation) return PARSER_INVALID_DATA;/* update annotation with the returned annotation */m_annotation = NULL;gchar **words = g_strsplit (baidu_candidate_annotation, \"'\", -1);m_annotation = g_strjoinv (\"\", words);g_strfreev (words); 第二个元素则是返回回来的匹配到的拼音，它是一个字符串，这个表示拼音的字符串使用了单引号 ' 作为分割，而我们所希望的是一个没有分隔符的连续的拼音串（方便与当前编辑器中的用户输入），因此需要对其进行分割与合并的处理。 进行处理后，存放在 m_annotation 中。由于是通过 g_strjoinv 创建出来的，这个字符串是需要手动释放的。于是，在上面展示的 BaiduCloudCandidatesResponseJsonParser 类的析构函数中完成了这一释放过程： 1~BaiduCloudCandidatesResponseJsonParser () &#123; if (m_annotation) g_free ((gpointer)m_annotation); &#125; 处理完了拼音，接下来就可以拿起之前取出的 baidu_candidate_array 候选词数组了。整体流程和 Google 源的十分相似，唯一不同的是更内层的处理。 1234result_counter = json_array_get_length (baidu_candidate_array);if (result_counter &lt; 1) return PARSER_NO_CANDIDATE; 首先是看候选数组的长度，判断有无可用的候选词。 而数组内的每一个候选词，都有以下结构： 1[\"百度\",5,&#123;\"pinyin\":\"bai'du\",\"type\":\"IMEDICT\"&#125;] 第一个元素是候选词的字符串，紧跟着的应当是候选在 UTF-8 编码情况下的长度，之后是这个候选对应，包含拼音和类型的一个 json 对象。 123456789101112131415 for (guint i = 0; i &lt; result_counter; ++i) &#123; std::string candidate; JsonArray *baidu_candidate = json_array_get_array_element (baidu_candidate_array, i); if (json_array_get_length (baidu_candidate) &lt; 1) candidate = CANDIDATE_INVALID_DATA_TEXT; else candidate = json_array_get_string_element (baidu_candidate, 0); m_candidates.push_back (candidate); &#125; return PARSER_NOERR;&#125; 这里我们只取候选数组里的第一个元素，也就是候选词的字符串，并将其加入到 m_candidates 候选数组中。如果没有这个元素，就添加一个 CANDIDATE_INVALID_DATA_TEXT 作为提示。 最后，返回 PARSER_NOERR。 两个源返回结果上的差异 两个源上返回的内容有不一致的地方，因此个别细节需要单独考虑。 其中比较重要的，也是引发一些其他问题的一个点就是，对用户输入的 echo。 在 20 版异步模式下，可能会有多个请求的回复陆续到达，而它们的顺序是无法保证的。为了解决这个问题，对返回结果对应的用户输入和当前的用户输入进行了比较，如果一致，说明是当前用户输入进行的请求，否则就丢弃这个结果对应的候选。 Google 源在返回候选词结果时，不仅对候选词进行了拼音标注，还将请求时的用户输入返回； 百度源则没有返回请求时发送的原始的用户输入，有对候选词的拼音标注，和自动补全拼音后的用户输入。 因此，对百度源返回的结果，目前无法找回原始的用户输入，也就无法和当前编辑器中的用户输入进行成功匹配。在输入拼音不完全的时候会有候选词被丢弃的情况出现。 对此，有以下几种方案： 导师提出了在有不完整拼音（模糊拼音）的情况下不给百度源发送请求； 写一个字符串相似程度的算法，为百度源的返回结果设定一个相似度阈值，达到阈值之后就允许显示； 无论是否匹配，在百度源的情况下都允许显示。 具体采用哪一种比较好，还需要进一步的讨论。目前采用的是第三种方案。 总结 这篇文章讲述了对从请求的回复中提取候选的过程，提取出候选后，会根据状态处理提取出来的候选，这部分会在下篇文章叙述。最后交由在 云输入在 ibus-libpinyin 中的实现 - 概述 一文中描述的过程，更新替换候选词的占位符，完成整个云输入的过程。","categories":[{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/categories/ibus-libpinyin/"}],"tags":[{"name":"IBus","slug":"IBus","permalink":"https://blog.inoki.cc/tags/IBus/"},{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/tags/ibus-libpinyin/"},{"name":"Cloud Input","slug":"Cloud-Input","permalink":"https://blog.inoki.cc/tags/Cloud-Input/"}]},{"title":"云输入在 ibus-libpinyin 中的实现 - 概述","slug":"IBus-libpinyin-cloud-input-global-view","date":"2020-05-31T23:55:00.000Z","updated":"2025-03-08T09:40:48.567Z","comments":true,"path":"2020/05/31/IBus-libpinyin-cloud-input-global-view/","link":"","permalink":"https://blog.inoki.cc/2020/05/31/IBus-libpinyin-cloud-input-global-view/","excerpt":"","text":"在 2018 年的 Google Summer of Code (GSoC)中，ibus-libpinyin 的云输入功能由 Linyu Xu 首次引入。该版本并没有被合并入主分支中，本文将其称为 18 版云输入。 18 版采用了同步请求候选词的模式，也就是说，发送请求、解析请求的过程会阻塞 ibus-libpinyin 的行为，在网络情况不好时，就会让人感觉到十分卡顿，出现未响应的现象。同时，由于返回结果解析采用了比较简易的字符串提取，导致取出候选的实现健壮性不高。一系列原因导致 18 版云输入并不能作为一个生产环境可用的功能。 今年（2020）我的 GSoC 项目目标之一就是优化该功能，并将其合并入 ibus-libpinyin 的主分支中。 目前正在迭代的一系列版本在改文中被统称为 20 版云输入，本文将对云输入按照时间顺序进行一个简要介绍，让读者对云输入功能有一个概览。 当用户按下键盘 在 ibus-libpinyin 中，用户进行输入之后，编辑器的实例 PhoneticEditor 会调用 updateCandidates 方法。在该方法中，每一种候选词实例的 processCandidates 方法都会被调用，修改候选词列表。 云输入部分的候选词处理由 PYPCloudCandidates 中的 CloudCandidates 完成。但这时，我们还没有云输入候选的结果，因此需要先插入占位符，方便之后进行替换，从而将云输入返回的结果加入候选词列表中。 添加候选词占位符 首先，CloudCandidates 会找到指定的位置，从该位置开始插入预先设定个数的候选词占位符。目前使用了一个云的符号☁（在 18 版中为省略号），用来提示用户该位置是一个云输入的候选词，将会被云输入请求返回的候选词取代。 这个位置在 18 版云输入是由 m_first_cloud_candidate_position 属性指定的，作为一个整数表示的下标，它给定了一个固定位置来插入、修改占位符。这样可能会在候选词较少时导致用数组下标访问越界的问题。 20 版云输入中，则将其放在 1-3 个整句候选词的后面。并把该位置用一个迭代器记录下来，方便取到候选词之后对占位符进行快速的修改。 在这两个版本的云输入中，m_cloud_candidates_number 都用来指定候选词的个数。 一切处理结束后，若拼音长度大于 m_min_cloud_trigger_length，即最小的触发云输入请求的拼音长度（18 版中可配置，20 版中由 CLOUD_MINIMUM_TRIGGER_LENGTH 宏定义），CloudCandidates 会去调用对应的方法来请求云输入的候选，以便之后对占位符进行替换。 在异步模式下，如果使用迭代器记录占位符的插入位置，另一边使用这个位置进行读取的话，是线程不安全的，可能会产生数据竞争。而在候选列表更新后，如果另一个线程仍使用之前的迭代器，存在非法访问的可能性。 最新的版本中，不再对占位符插入位置进行记录。而是在每次被调用时，判断记录的最近一次请求拼音是否与本次一致： 如果一致，则将 m_candidates 更新到候选列表中 如果不一致，则添加占位符到候选列表中 占位符个数的处理 18 版云输入中，虽然在配置页面有调整占位符个数的配置项，在 gsetting 中也有对应的数据项，但在 CloudCandidates 中，仍使用了 1m_cloud_candidates_number = 1; 将其配制成了一个常值。 在 20 版云输入的改进过程当中，我首先将这个常值改为从配置中读取。在后来的测试中，我发现在百度的云输入源中，无论传入的希望返回候选词的个数是多少（查询字符串中的 ed 字段），它都只返回一个候选词；而 Google 源可以返回预期个数的候选词。 为了保持行为的一致性，目前已将其从配置界面中移出，并固定这一配置项的值为1。用户依然可通过 gsetting 对其进行修改。 发送请求 在文章开头提到过，18 版云输入使用了同步的机制来请求候选词，这样会阻塞进程；当时的异步请求模式并没有完成。 在 20 版云输入中，异步请求模式有了一个可用的实现，后来，在优化用户体验、减少无用的请求的目标下，我又实现了延时的异步请求，也就是在认为用户完成输入后才发起网络请求获取云输入候选词。 同步请求 同步请求模式下，cloudSyncRequest 方法会在插入占位符完成后被调用。 该方法使用 libsoup 的 API 发送请求，并把结果储存在一个缓冲区中进行解析。结果处理部分在之后的文章中详细解释。 取到候选词之后，它把占位符替换为对应的候选词并返回。 这之后，ibus-libpinyin 才可以响应接下来的其他事件。发送请求是一个耗时操作，也就是这个过程导致同步请求模式下卡顿。异步模式就是为了解决这种无响应状态而生。 异步请求 异步请求在 18 版云输入中其实已经有了一个雏形，即 cloudAsyncRequest 方法。 这个方法调用 soup_session_send_async 来发送请求，cloudResponseCallBack 被作为回调函数参数传入，完成时会被调用来处理结果。 从这里开始，18 版和 20 版开始有实现上的差别。 18 版的实现尝试 异步模式下，最后取到的结果是一个输入流，该版本里把这个输入流中的字符全部读出，放到一个缓冲区中： 1g_input_stream_read (stream, buffer, BUFFERLENGTH, NULL, error); 但对于流来说，在该时刻返回的字符并不一定是完整的结果，用这个函数读出来大部分情况下是不完整的字符串，从而导致候选词不能被正常找到并取出。 在 20 版中，由于加入了 JSON 解析的过程，读取流中字符并解析的操作交给了 json-glib 库，它会一直尝试读取流中的字符，直到完成 JSON 字符串的解析，这样取出的结果通常情况下都是完整的，极大的增强了其健壮性。 这里，我们假定返回结果被完整取出了，之后使用相同的结果处理过程，将返回的候选词更新到候选词列表中。 最后，这个方法尝试调用 cloudCandidates-&gt;m_editor-&gt;update () 来将更新后的候选词刷新到输入法面板上。 1234567891011voidPhoneticEditor::update (void)&#123; guint lookup_cursor = getLookupCursor (); pinyin_guess_candidates (m_instance, lookup_cursor, m_config.sortOption ()); updateLookupTable (); updatePreeditText (); updateAuxiliaryText ();&#125; 这个方法会重新调用 updateLookupTable 方法： 12345678910111213voidPhoneticEditor::updateLookupTable (void)&#123; m_lookup_table.clear (); updateCandidates (); fillLookupTable (); if (m_lookup_table.size()) &#123; Editor::updateLookupTable (m_lookup_table, TRUE); &#125; else &#123; hideLookupTable (); &#125;&#125; 进而调用 updateCandidates 方法： 12345678910111213141516171819gbooleanPhoneticEditor::updateCandidates (void)&#123; m_candidates.clear (); m_libpinyin_candidates.processCandidates (m_candidates); if (m_config.emojiCandidate ()) m_emoji_candidates.processCandidates (m_candidates); #ifdef ENABLE_CLOUD_INPUT_MODE if(m_cloud_candidates.m_cloud_state) m_cloud_candidates.processCandidates (m_candidates);#endif /* ... */ return TRUE;&#125; 可以看到在这里，所有候选词被清除又重新生成了，也就是说，这一操作并不能正常完成，将云输入的候选词更新到输入法面板的操作。 20 版异步请求 在 cloudResponseCallBack 获取到返回的结果的输入流之后，processCloudResponse 被调用来处理和解析结果，结果会被更新到候选词列表中，替换原来的占位符。这个过程在之后的文章会详细描述。 已过期： 之后就是将候选更新到输入法面板了，为了避免和 18 版一样的问题，这里我没有再直接调用 update 方法，而是选择性的调用一些操作： 1234/* regenerate lookup table */cloudCandidates-&gt;m_editor-&gt;m_lookup_table.clear ();cloudCandidates-&gt;m_editor-&gt;fillLookupTable ();cloudCandidates-&gt;m_editor-&gt;updateLookupTableFast (); 清除查询表； 用新的候选词列表重新填充查询表； 快速更新查询表。 这里的过程是否可以简化，还需要进一步的研究和讨论。 更新： 在最新的版本中，加入了最近一次请求的拼音字符串和对应的结果的缓存，所有对占位符进行的修改、以及云输入候选的更新都被放在了 CloudCandidates::processCandidates 中处理。 因此，在需要更新的时候，只需要将需要的候选置入结果缓存 m_candidates 中，然后调用下面的更新方法即可： 12345678910111213141516171819voidCloudCandidates::updateLookupTable ()&#123; /* retrieve cursor position in lookup table */ guint cursor = m_editor-&gt;m_lookup_table.cursorPos (); /* update cached cloud input candidates */ m_editor-&gt;updateCandidates (); /* regenerate lookup table */ m_editor-&gt;m_lookup_table.clear (); m_editor-&gt;fillLookupTable (); /* recover cursor position in lookup table */ m_editor-&gt;m_lookup_table.setCursorPos (cursor); /* notify ibus */ m_editor-&gt;updateLookupTableFast ();&#125; 这个更新的实现还考虑了保存光标位置，并在更新之后恢复，防止由于云输入候选的更新导致用户选择候选的光标重置的问题。 延时异步 异步请求会在每一次 processCloudResponse 时发出一个新的异步请求，在进行长句的输入时，之前发送的请求返回的结果会被丢弃，这造成了大量请求的浪费。为了解决这个问题，进一步的改进加入了延时请求行为。 延时请求使用了 glib 中的 g_timeout_add_full 函数，该函数的原型为： 123456guintg_timeout_add_full (gint priority, guint interval, GSourceFunc function, gpointer data, GDestroyNotify notify); 它的简化版函数原型是： 1234guintg_timeout_add (guint interval, GSourceFunc function, gpointer data); 该函数会在 glib 的事件循环中添加一个被周期调用的函数，每隔给定的毫秒数之后，这个函数都会被调用一次，直到这个函数返回 FALSE。 间隔的毫秒数由 interval 给定，调用的函数是传入的 function 参数，而 data 变量可以携带任何开发者想传入到 function 函数中的用户数据。此外，完整版的函数还允许指定调用的优先级，以便事件循环合理安排调用顺序；并且允许传入一个销毁前的通知，方便开发者进行一些清理工作。 在 20 版的实现中，为了传入足够的数据，我创建了一个结构体来储存一些必要信息： 123456typedef struct&#123; guint event_id; const gchar request_str[MAX_PINYIN_LEN + 1]; CloudCandidates *cloud_candidates;&#125; DelayedCloudAsyncRequestCallbackUserData; 其中，thread_id event_id 是当前的用户数据对应的事件 id，request_str 是当前延时希望发出请求所用的拼音，而cloud_candidates 则是对云输入候选进行处理的实例的引用，也就是延时的发送者。 在创建延时之前，会首先分配、创建一个 DelayedCloudAsyncRequestCallbackUserData 的实例，并把对应的数据填入。 然后，创建延时事件并在当前 CloudCandidates 实例中记录其 id： 1event_id = m_source_event_id = g_timeout_add_full(G_PRIORITY_DEFAULT, m_delayed_time, delayedCloudAsyncRequestCallBack, user_data, delayedCloudAsyncRequestDestroyCallBack); 函数 delayedCloudAsyncRequestCallBack 会在延时结束后被调用，delayedCloudAsyncRequestDestroyCallBack 则会在 delayedCloudAsyncRequestCallBack 返回 FALSE，事件循环决定结束延时事件后被调用。 第二个函数 delayedCloudAsyncRequestDestroyCallBack 比较简单，这里先行介绍： 1234567voidCloudCandidates::delayedCloudAsyncRequestDestroyCallBack (gpointer user_data)&#123; /* clean up */ if (user_data) g_free (user_data);&#125; 即将之前创建的用户数据所占用的内存释放，避免内存泄漏。 而在 delayedCloudAsyncRequestCallBack 中，除了一开始对数据进行检查外，最重要的是这段代码： 123456/* only send with a latest timer */if (data-&gt;event_id == cloudCandidates-&gt;m_source_event_id)&#123; cloudCandidates-&gt;m_source_event_id = 0; cloudCandidates-&gt;cloudAsyncRequest(data-&gt;request_str);&#125; 首先，对当前用户数据中的事件 id 和 CloudCandidates 实例中记录的 id 进行比较，如果一致，说明我们当前事件的确是最近一次发出的延时事件，则调用对应的函数，开始发送异步请求。 最后，无论在哪种情况下，都会返回 FALSE，以便让事件循环开始清理，而非继续循环执行该事件。 目前的延时时长为 600ms，也可以在 gsetting 中配置。 处理用户选择的候选 除去中间的处理云输入请求返回结果的过程（在《候选词解析》这篇文章中详述），和用户交互的最后一步就是用户对候选进行选择的过程。 在这一过程中，CloudCandidates 实例中的 selectCandidate 会被调用，被选中的候选会作为参数传入。 首先对其进行一个判断，确定这个候选词已经是否仍是占位符，若是占位符，则暂时不做出反应。若不是占位符，就进行进一步的处理。 在最新的版本中，传入的候选是带有云输入前缀 ☁ 的，而在 CloudCandidates 实例的 m_candidates 中缓存了不带有前缀的候选，因此，我们尝试找到对应 id 的候选，将传入的候选修改为无前缀的云输入候选词并返回。这时候选词就会上屏。 12345678/* take the cached candidate with the same candidate id */for (std::vector&lt;EnhancedCandidate&gt;::iterator pos = m_candidates.begin(); pos != m_candidates.end(); ++pos) &#123; if (pos-&gt;m_candidate_id == enhanced.m_candidate_id) &#123; enhanced.m_display_string = pos-&gt;m_display_string; /* modify in-place and commit */ return SELECT_CANDIDATE_COMMIT | SELECT_CANDIDATE_MODIFY_IN_PLACE; &#125;&#125; 在上一版中，CloudCandidates 实例的 m_candidates 没有被很好的利用。去除云输入前缀 ☁ 的处理是通过迭代器修改传入的候选来完成的。不过也能达到相同的目的。 总结 本文按照事件发生的时间顺序粗略描述了云输入功能背后发生了什么，其中中间的一些部分会放在其他的相关文章中详细描述。 而随着版本的迭代，整体流程可能还是会发生一些微小的变化，这篇文章也会跟着更新。","categories":[{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/categories/ibus-libpinyin/"}],"tags":[{"name":"IBus","slug":"IBus","permalink":"https://blog.inoki.cc/tags/IBus/"},{"name":"ibus-libpinyin","slug":"ibus-libpinyin","permalink":"https://blog.inoki.cc/tags/ibus-libpinyin/"},{"name":"Cloud Input","slug":"Cloud-Input","permalink":"https://blog.inoki.cc/tags/Cloud-Input/"}]},{"title":"【译】LoRaWAN 入门","slug":"LoRa-Primer","date":"2020-05-26T10:28:00.000Z","updated":"2025-03-08T09:40:48.583Z","comments":true,"path":"2020/05/26/LoRa-Primer/","link":"","permalink":"https://blog.inoki.cc/2020/05/26/LoRa-Primer/","excerpt":"","text":"LoRaWAN（或简称 LoRa）是 LPWAN（“低功耗广域网”）技术。所使用的无线电技术很漂亮，可确保您以很小的发射功率就可以在相当长的距离内发送数据。 LoRa 在称为的 ISM （也称为“工业科学医学”）频段中运行，该频段是未经许可的无线电频谱的一部分。这并不意味着您可以以任何期望的方式使用它，一次可以使用多少功率以及可以传输多长时间是有限制的。这就是所谓的“占空比”。LoRa 的占空比在1％到0.1％之间，具体取决于您要发送的比特率。 LoRaWAN 的鸟瞰图 LoRaWAN网络由网关，网络，应用程序和设备组成。设备将无线电数据包发送到网络的网关。网络由再次由零个或多个设备组成的应用程序组成。网络和应用程序通常是后端服务中的抽象。 设备通过无线电与一个或多个网关通信。每个数据包都很短，通常不超过几十个字节。数据包被一个或多个网关拾取，设备进入睡眠状态，通常等待一秒钟，然后设备开始侦听来自网关的响应。如果网关具有为设备安排的数据，它将把数据发送到设备。完成此操作后，设备将再次进入睡眠状态，直到有更多数据并允许其根据占空比发送为止。 网关将无线电数据包解码为一个小缓冲区，然后将缓冲区转发到 LoRa 后端。LoRa 后端跟踪所有网关和网络，并确定数据包所属的网络，如果网络知道设备，则将数据传递到该设备所属的应用程序。如果为该设备安排了数据，它将通过网关返回到该设备。 带宽 由于设备发送的数据包很小，并且设备每五分钟仅发送一个数据包，因此您不会在设备之间收到大量数据，因此典型的用例场景是设备不经常发送，且发送少量数据，通常每小时或每天只有几次。 范围 设备的覆盖范围令人印象深刻。一个简单的有线天线足以到达几公里外的网关。在金属笼子里将无法获得良好的覆盖，无线电波不会穿过墙壁或金属，但是该协议本身可以实现微弱的传输。现场实验表明，LoRa 设备在城市环境中可以达到几公里的范围，并且视线范围甚至可以达到 20 公里甚至更高。无线电波很奇怪，因此你可能可以在看似不可能的地方获得良好的覆盖，而在其他地方几乎没有。 获取网关 如果您无法在自己的住所或城镇中得到覆盖，请不要担心。LoRa 网关相对便宜（200欧元及以上），几乎不需要维护。不过，网关必须连接到一项后端服务，并且有很多可供选择。最著名的服务是 The Things Network 和 loriot.io，它们都允许您连接自己的网关。如果您住在挪威，则可以从 Telenor 连接到 Cloud Connect。我们已经覆盖了几个城市，并且这项服务是免费的，可用于开发工作。 安全 LoRaWAN 网络中的设备和应用程序之间传输的所有数据均使用 AES-128 加密，使用两个加密密钥，一个网络会话密钥和一个应用程序会话密钥。这两个密钥对于设备而言都是唯一的，分别用于网络消息和应用程序有效负载。如果您使用一些聪明的密钥管理策略，则可以使应用程序与设备的负载有效加密，仅由应用程序和设备共享，而网络（或网关）操作员不知道有效负载是什么。 网路 LoRaWAN 中的网络的工作方式类似于手机网络。多个网络可以在同一区域中运行，并且多个网络可以在同一网关之外运行。最大的区别是 LoRaWAN 中的设备无法从一个网络跳到另一个网络，因为连接到应用程序的设备只能是单个网络的成员。 应用领域 LoRaWAN 中的应用程序只是在给定网络上运行的设备的集合。一台设备不能属于一个以上的应用程序，没有应用程序的话该设备也就不能存在。 相关链接 了解LoRaWAN的局限性（Adelantado，Vilajosana等人，IEEE杂志2017年1月）：https://arxiv.org/pdf/1607.08011.pdf","categories":[{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/categories/LoRa/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"LoRaWAN","slug":"LoRaWAN","permalink":"https://blog.inoki.cc/tags/LoRaWAN/"},{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/tags/LoRa/"},{"name":"IoT","slug":"IoT","permalink":"https://blog.inoki.cc/tags/IoT/"}]},{"title":"【译】LoRa 数据速率和扩频因子","slug":"LoRa-Data-rate-and-spreading-factor","date":"2020-05-25T11:20:00.000Z","updated":"2025-03-08T09:40:48.582Z","comments":true,"path":"2020/05/25/LoRa-Data-rate-and-spreading-factor/","link":"","permalink":"https://blog.inoki.cc/2020/05/25/LoRa-Data-rate-and-spreading-factor/","excerpt":"","text":"原文链接：https://docs.exploratory.engineering/lora/dr_sf/ 或早或晚你会遇到术语：数据速率（DR），扩频因子（SF）和带宽（BW）。这三个术语是相关的，但是它们之间的联系并不是很明显。 LoRa使用了所谓的“线性调频”协议，该协议是在第二次世界大战期间为声纳和雷达应用开发的，因此绝不是一项新技术。 线性调频协议使用固定幅度的频率调制。它可以通过产生扫过整个信道的信号来利用分配的整个频谱来传输信号,这种信号称为啁啾。啁啾有两种：“上啁啾”频率向上移动和（毫不意外）“下啁啾”频率向下移动，即当有啁啾时，它将沿分配的频率在一个方向上移动 。 带宽 LoRa使用三种带宽：125kHz，250kHz 和 500kHz，线性调频脉冲会占用整个带宽。如果您在类似 Gqrx 的 SDR 应用程序中查看 LoRa 数据包，则会看到清晰定义的啁啾正方形。 扩频因子 简而言之，扩频因子是rp的持续时间。 LoRa 的扩频因子为 7 到 12。SF7是空中时间最短的，SF12是空中时间最长的。扩展因子的每增加一，传输相同数量数据的时间就要增加一倍。在相同的带宽下，更长的空中时间显然会导致单位时间内传输的数据更少。 数据速率 LoRaWAN 使用不同的频率，扩频因子和带宽配置，具体取决于您在世界上的位置。对于 EU868，EU433，CN780 和 AS923 频段，数据速率如下： Data Rate Configuration bits/s Max payload DR0 SF12/125kHz 250 59 DR1 SF11/125kHz 440 59 DR2 SF10/125kHz 980 59 DR3 SF9/125kHz 1 760 123 DR4 SF8/125kHz 3 125 230 DR5 SF7/125kHz 5 470 230 DR6 SF7/250kHz 11 000 230 DR7 FSK: 50kpbs 50 000 230 请注意，取决于配置，AS923 频带可能不使用 DR0 和 DR1。 在 US902-928 和 AU915-928 频段中，数据速率如下： Data Rate Configuration bits/s Max payload DR0 SF10/125kHz 980 19 DR1 SF9/125kHz 1 760 61 DR2 SF8/125kHz 3 125 133 DR3 SF7/125kHz 5 470 250 DR4 SF8/500kHz 12 500 250 DR8 SF12/500kHz 980 41 DR9 SF11/500kHz 1 760 117 DR10 SF10/500kHz 3 900 230 DR11 SF9/500kHz 7 000 230 DR12 SF8/500kHz 12 500 230 DR13 SF7/500kHz 21 900 230 对于 CN470-510 和 KR920-923 频段，只有五个定义的数据速率： Data Rate Configuration bits/s Max payload DR0 SF12/125kHz 250 59 DR1 SF11/125kHz 440 59 DR2 SF10/125kHz 980 59 DR3 SF9/125kHz 1 760 123 DR4 SF8/125kHz 3 125 230 DR5 SF7/125kHz 5 470 230 如表所见，DR4 在两个不同的地区可能是两个不同的东西。幸运的是，您不必担心这一点，因为设备上的库和后端服务通常会设法选择要使用的最佳数据速率。 信息最大有效负载大小很重要！ 即使通常情况下可以忽略所选的数据速率，最大有效负载大小也意味着应将有效负载进行限制。如果荷载超过最大长度，则应将其分成多段。","categories":[{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/categories/LoRa/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"LoRaWAN","slug":"LoRaWAN","permalink":"https://blog.inoki.cc/tags/LoRaWAN/"},{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/tags/LoRa/"},{"name":"IoT","slug":"IoT","permalink":"https://blog.inoki.cc/tags/IoT/"}]},{"title":"【译】LoRa 中的关键概念","slug":"LoRa-Key_Concept","date":"2020-05-25T11:20:00.000Z","updated":"2025-03-08T09:40:48.583Z","comments":true,"path":"2020/05/25/LoRa-Key_Concept/","link":"","permalink":"https://blog.inoki.cc/2020/05/25/LoRa-Key_Concept/","excerpt":"","text":"原文链接：https://docs.exploratory.engineering/lora/lora_key_concepts/ LoRaWAN 关键概念 LoRaWAN 设备的配置可能会令人困惑。您需要跟踪两个关键点，EUI 和必须的各种各样奇怪的配置参数。 设备 EUI，网络 EUI，应用 EUI 和 DevAddr 在 LoRaWAN 中，网络，应用程序和设备由 EUI64 标识符标识。EUI64是全球唯一的标识符。您可以在此处了解更多信息：https://standards.ieee.org/develop/regauth/tut/eui64.pdf。EUI 用于在后端服务器内部标识 LoRaWAN 所有的（虚拟）部分。 DevAddr 值是特定网络中设备的唯一标识符。它由 NwkID 和 NetAddr 的两个不同部分组成，这是一个32位无符号整数，用于标识你的设备，是设备加入网络后用于标识设备的标识符。 网络和应用程序会话密钥 LoRaWAN 中的加密相对简单。如果您使用ABP（“个性化激活”设备；具有预配置密钥的设备），则可能需要担心两个密钥： 网络会话密钥是网络和设备已知的每个设备的唯一密钥，该密钥用于不携带任何有效负载的内部管理消息。该密钥用于向发送到设备的消息添加校验和。 应用程序会话密钥是应用程序和设备已知的每个设备的唯一密钥，用于加密来自设备的有效负载的密钥，使得任何人都很难窃听与后端服务器的通信。该密钥也用于计算校验和。 ABP 与 OTAA 设备 LoRaWAN 网络中有两种设备，即“ABP”设备和“ OTAA”设备： ABP（个性化激活）设备 这种设备带有三项信息：网络会话密钥，应用程序会话密钥和设备地址。 这些设备通电后可以立即开始发送，但是每个设备都需要一组唯一的密钥。如果有人闯入您的设备并拿到了密钥，你可以轻松地仅对受影响的一台设备进行布建，而无需更改其他的设备。 这种设备类型的最大缺点是，您必须跟踪加电之间往返于后端服务器的消息的帧计数器。通常，后端服务器会忽略帧计数器与预期的计数器不同的消息，但是您可以在测试设备时取消此检查。注意：关闭此检查会使设备容易受到重放攻击，因此通常保留用于测试。 OTAA（空中激活）设备 这是最常见的设备类型。在配置它们时，这些设备中的每一个都将获得三部分信息：应用程序密钥，应用程序EUI和设备EUI。打开设备电源后，它将启动加入网络过程，在此过程中它将根据现有的应用程序密钥协商一组新的密钥。协商完成后（通常在不到五秒钟的时间内），其行为将类似于 ABP 设备。 如果关闭设备电源，则启动时它必须再次加入网络。自然，对 OTAA 设备来说最重要的是应用程序密钥。如果有人设法从您的一台设备上抢走密钥，则攻击者可能会假冒您网络中的任何设备。另一方面，使用OTAA设备可以轻松管理大量设备，因为您无需管理很多密钥。 选择 您选择哪种设备类型取决于您计划如何配置新设备。开启时，无论您的设备是否在网关范围内，ABP 设备都可以立即开始发送。另一方面，如果您的设备大多位于网关的范围内，并且会在没有任何板载存储的情况下频繁上下电，则可以使用 OTAA 设备。开发新设备时，OTAA设备最为方便。 什么是“私人网络”？ 如果您看到配置文件中某处提到的“专用网络”，就像其他许多人一样——你可能想知道它的真正含义，因为它是您设置的参数，但是没有再次看到。 LoRaWAN 中的专用网络是一种设备（和网关）网络，它接受带有专用前导码（作为消息的第一位发送的标识符）而不是标准的前导码的消息。LoRaWAN 中只有两种类型的前导码：标准的 LoRaWAN 公共前导或私有前导。 如果发送了私有前导码，则数据格式完全取决于设备和后端服务器。如果要与其他网络兼容（并且兼容），需要保持私有网络标志为关闭状态。 ADR 自适应数据速率 ADR（自适应数据速率）是后端服务器可用来让设备以尽可能低的功率传输的技巧。如果设备靠近网关，则设备可以以较低的功率和较高的数据速率进行传输，使用尽可能少的功率。如果两个或三个网关可以接收到设备的消息，则可以调回传输功率并节省能源。 消息类型：确认的和不确认的消息 LoRaWAN 定义了两种消息-确认的和不确认的。确认的消息需要后端服务器的确认，如果没有收到确认，则消息将以不同的扩展因子和带宽重新发送。 同样，后端服务器将重新传输确认的消息，直到设备确认响应。 由于 LoRaWAN 仅使用了一个确认标志，因此无法确认旧消息。 上下游消息 迟早有人会提到“上游”和“下游”。如果您在设备上工作，则无法完全直观地了解是哪个方向，但是请记住上游方向朝着网关天线去的方向，下游方向是从网关天线出发的方向。但如果将设备放在气象气球中，则会这个规则不再适用。 我让我的设备发送消息时，它没有发送！ 如果您在设备上安排一条消息，有时您会感到该消息会在设备上保留很长一段时间，直到发送出去为止，其他情况下，消息会立即发送出去。 这是因为 LoRaWAN 设备必须始终遵守的 ISM 频段上的占空比限制（即发送和不发送所花费的时间的比率）。对于某些频率，最大占空比为1％，而对于其他频率，最大占空比仅为0.1％。如果您花费一秒钟发送一条消息，则必须等待99秒，然后才能在占空比为1％时发送另一条消息，而如果占空比为0.1％，则可能必须等待15分钟以上。","categories":[{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/categories/LoRa/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"LoRaWAN","slug":"LoRaWAN","permalink":"https://blog.inoki.cc/tags/LoRaWAN/"},{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/tags/LoRa/"},{"name":"IoT","slug":"IoT","permalink":"https://blog.inoki.cc/tags/IoT/"}]},{"title":"Enable UART to play with Raspberry Pi Bare Metal","slug":"Enable-UART-Raspberry-Pi-Bare-Metal","date":"2020-05-17T23:57:50.000Z","updated":"2025-03-08T09:40:48.562Z","comments":true,"path":"2020/05/17/Enable-UART-Raspberry-Pi-Bare-Metal/","link":"","permalink":"https://blog.inoki.cc/2020/05/17/Enable-UART-Raspberry-Pi-Bare-Metal/","excerpt":"","text":"If you want to write an OS for Raspberry Pi, you may need play with its Bare Metal mode. Thus, a UART debug serial is needed. Considering that the bootloader of Raspberry Pi is proprietary, and it’s provided as a binary file in the /boot partition, we cannot modify the boot sequence, and we cannot see the output of the binary executable. Through the UART serial, the only thing that we can see is the successful boot after the loading of Raspian kernel: But, as we are on Bare Metal mode, if anything goes wrong during booting your own “kernel”, it’s not easy to find out the reason. This post will help you enable the UART debug mode to see what’s happening behind the proprietary code before loading your own kernel. Bootloader file bootcode.bin Mount the /boot partition on the SD card, you can see lots of files. Some of them are device tree files; some of them are configuration files. The one we concentrate on, is bootcode.bin, the proprietary executable from Raspberry Pi. It’s a binary file, so it’s not readable for human-being. But there are some static strings in the binary file, which might be meaningful to us. For us, the most important string is BOOT_UART. To enable the debug output of the binary executable, just modify its value from 0 to 1: Save and boot Save that modification and insert the SD card into your Raspberry Pi. Then boot it, you will see the magic output: I hope this post can help you, and enjoy your Raspberry Pi Bare Metal development!","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Raspberry Pi","slug":"Embedded-System/Raspberry-Pi","permalink":"https://blog.inoki.cc/categories/Embedded-System/Raspberry-Pi/"}],"tags":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/tags/Embedded-System/"},{"name":"Bare Metal","slug":"Bare-Metal","permalink":"https://blog.inoki.cc/tags/Bare-Metal/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://blog.inoki.cc/tags/Raspberry-Pi/"},{"name":"Debug","slug":"Debug","permalink":"https://blog.inoki.cc/tags/Debug/"},{"name":"UART","slug":"UART","permalink":"https://blog.inoki.cc/tags/UART/"}]},{"title":"【译】扩频因子如何影响 LoRaWAN 设备的电池寿命","slug":"LoRaWAN-how-spreading-factor-affects-lorawan-device-battery-life","date":"2020-05-16T22:27:00.000Z","updated":"2025-03-08T09:40:48.583Z","comments":true,"path":"2020/05/16/LoRaWAN-how-spreading-factor-affects-lorawan-device-battery-life/","link":"","permalink":"https://blog.inoki.cc/2020/05/16/LoRaWAN-how-spreading-factor-affects-lorawan-device-battery-life/","excerpt":"","text":"原文链接：https://www.thethingsnetwork.org/article/how-spreading-factor-affects-lorawan-device-battery-life 在 LoRaWAN 中，扩频因子是一个关键指标，它既可以帮助你完成你的 IoT 解决方案，也可以毁掉它，所谓 “成也SF，败也SF”。找到正确的扩频因子对实现 LoRaWAN 设备长期性能至关重要。这篇文章会解释如何找到电池寿命和长距离通信之间的正确平衡。 扩频因子（SF）决定每秒发送多少个线性调频脉冲，即数据的载体。网络根据通信设备和网关之间的环境条件来决定扩展因子（等级在7-12之间）。我们假定设备已启用 “自适应数据速率（ADR）” 功能，除持续移动的设备外，这个功能应当应用于所有设备。 较低的 SF 意味着每秒发送更多的 Chirps；因此，您可以每秒编码更多数据。较高的 SF 意味着每秒更少的 Chirps；因此，每秒能编码的数据较少。由于数据速率低，发送具有较高 SF 的相同数量的数据需要更长的传输时间，即空中时间。更长的通话时间意味着调制解调器的启动和运行时间更长，并且消耗更多的能量。 高 SF 的好处在于，更长的通话时间使接收机有更多机会对信号功率进行采样，从而提高了灵敏度。更高的灵敏度意味着您可以在更远的地方接收信号，从而获得更好的覆盖范围。从理论上讲，SF中的每一步都将传输相同数量的数据的时间加倍，请参见下图。SF 的每一个步长都与大约 2.5dB 的额外链路预算相关。 理论都很美好，但实践中空中传输时间和电池寿命如何呢？ 为了对此获得一个估计，我们使用了两个工具： LoRaTools 中的空中传输时间计算器 用 Otii 测试 SF7 和 SF12 的能量消耗曲线 在此测试中，我们测量了 Bintel 的一个 LoRaWAN 设备，该设备使用 Semtech 的 SX1276 芯片组。我们的设置是室内室外场景：设备是在办公室，在开发人员的桌子上，并且网关位于附近一栋建筑物的外面。因此，这不是该设备的正常使用场景，他的正常使用场景是户外的垃圾箱。我们使用 19 字节的有效负载和 125kHz 的带宽测量了第一次传输和整个活动周期的能耗。 测量中，活动周期包含了对一个需要确认的消息的传输和一个对 ACK 的监听周期。 测量显示，与 SF7 相比，在 SF12 中传输大约需要25倍的时间和25倍的能量。空中时间计算器显示了相同的结果。 但是，数字 25 并非一成不变。它取决于有效负载大小和分配用于传输的报头。如果您使用不同大小的有效载荷，则可以看到不同的倍数。 请注意，以上计算仅仅对于发送时间，并不是整个活动周期。在此特定测量中，SF12中每个活动周期的能量消耗比是SF7能量的20倍（能量统计显示 55.1 uWh 对 2.78 uWh，见下图）。 值得一提的是，活动周期的能耗取决于设备的类别。如果是 A 类设备，则只有两个接收窗口，这意味着接收器的唤醒时间不会超过这两个窗口。另一种配置（C类）可以是设备保持连续收听，这会大大增加能耗。在这种情况下，SF 数无关紧要。 由于每种应用都是独特的，很难得出更多的结论。但是我们要强调的是，使能耗最低的最佳扩展因子不一定是最高或最低的，而是很可能介于两者之间：由于需要确认消息，如果重传次数过多，则短时传输的节能将因重传而迅速丢失。要记住的重要一点是，总能耗永远不会仅通过一个参数进行优化。 您可以下载下面的 .otii 文件来检查不同 SF 设置时的能耗测量： 需要用 Otii 应用程序 打开： https://github.com/qoitech/otii-example-projects/blob/master/LoRa-SF7-vs-SF12.otii 更多有关 LoRa, LoRaWAN 的信息可以在下列链接找到： LoRa CHIRP LoRa crash course Decoding the LoRa PHY","categories":[{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/categories/LoRa/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"LoRaWAN","slug":"LoRaWAN","permalink":"https://blog.inoki.cc/tags/LoRaWAN/"},{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/tags/LoRa/"},{"name":"IoT","slug":"IoT","permalink":"https://blog.inoki.cc/tags/IoT/"}]},{"title":"LoRaWAN specification 1.1 - Glossary","slug":"LoRaWAN-spec-read-gloassary","date":"2020-05-16T10:27:00.000Z","updated":"2025-03-08T09:40:48.585Z","comments":true,"path":"2020/05/16/LoRaWAN-spec-read-gloassary/","link":"","permalink":"https://blog.inoki.cc/2020/05/16/LoRaWAN-spec-read-gloassary/","excerpt":"","text":"Abbreviation Full text 中文 ADR Adaptive Data Rate 自适应数据速率 AES Advanced Encryption Standard 高级加密标准 AFA Adaptive Frequency Agility 自适应频率捷变 AR Acknowledgement Request 确认请求 CBC Cipher Block Chaining 密码块链接 CMAC Cipher-based Message Authentication Code 基于密码的消息认证代码 CR Coding Rate 编码率 CRC Cyclic Redundancy Check 循环冗余校验 DR Data Rate 数据速率 ECB Electronic Code Book 电子密码本 ETSI European Telecommunications Standards Institute 欧洲电信标准协会 EIRP Equivalent Isotropically Radiated Power 等效各向同性辐射功率 FSK Frequency Shift Keying modulation technique 频移键控调制技术 GPRS General Packet Radio Service 通用分组无线业务 HAL Hardware Abstraction Layer 硬件抽象层 IP Internet Protocol 互联网协议 LBT Listen Before Talk / Listen Before Transmit 先听后发 LoRaTM Long Range modulation technique 长程调制技术 LoRaWANTM Long Range Network protocol 长程网络协议 MAC Medium Access Control 介质访问控制 MIC Message Integrity Code 消息完整性码 RF Radio Frequency 无线电频率 RFU Reserved for Future Usage 保留以备将来使用 Rx Receiver 接受端 RSSI Received Signal Strength Indicator 接收信号强度指示器 SF Spreading Factor 扩频因子 SNR Signal Noise Ratio 信噪比 SPI Serial Peripheral Interface 串行外设接口 SSL Secure Socket Layer 安全套结层 Tx Transmitter 发送端 USB Universal Serial Bus 通用串行总线 Extra 补充内容 Block cipher mode of operation 分组密码工作模式 In cryptography, a block cipher mode of operation is an algorithm that uses a block cipher to provide information security such as confidentiality or authenticity. Mode Formulas Ciphertext Electronic codebook (ECB) Yi = F(PlainTexti, Key) Yi Cipher block chaining (CBC) Yi = PlainTexti XOR Ciphertexti−1 F(Y, Key); Propagating CBC (PCBC) Yi = PlainTexti XOR (Ciphertexti−1 XOR PlainTexti−1) F(Y, Key); Ciphertext0 = IV Cipher feedback (CFB) Yi = Ciphertexti−1 Plaintext XOR F(Y, Key); Ciphertext0 = IV Output feedback (OFB) Yi = F(Yi−1, Key); Y0 = IV Plaintext XOR Yi Counter (CTR) Yi = F(IV + g(i), Key); IV = token() Plaintext XOR Yi ECB The simplest of the encryption modes is the electronic codebook (ECB) mode (named after conventional physical codebooks). The message is divided into blocks, and each block is encrypted separately. 最简单的加密模式即为电子密码本（Electronic codebook，ECB）模式。需要加密的消息按照块密码的块大小被分为数个块，并对每个块进行独立加密。 CBC Ehrsam, Meyer, Smith and Tuchman invented the cipher block chaining (CBC) mode of operation in 1976. In CBC mode, each block of plaintext is XORed with the previous ciphertext block before being encrypted. This way, each ciphertext block depends on all plaintext blocks processed up to that point. To make each message unique, an initialization vector must be used in the first block. 1976年，IBM发明了密码分组链接（CBC，Cipher-block chaining）模式。在CBC模式中，每个明文块先与前一个密文块进行异或后，再进行加密。在这种方法中，每个密文块都依赖于它前面的所有明文块。同时，为了保证每条消息的唯一性，在第一个块中需要使用初始化向量。 Others 其他加密方式 Propagating cipher block chaining (PCBC) Cipher feedback (CFB) Output feedback (OFB) Counter (CTR) Listen Before Talk/Transmit 先听后发 Listen Before Talk (LBT) or sometimes called Listen Before Transmit is a technique used in radio-communications whereby a radio transmitters first sense its radio environment before it starts a transmission. LBT can be used by a radio device to find a network the device is allowed to operate on or to find a free radio channel to operate on. Difficulty in the latter situation is the signal threshold down to which the device has to listen. “先听后说”（LBT）或有时称为“先听后发”是无线电通信中使用的一种技术，通过该技术，无线电发射机在开始传输之前首先会感知其无线电环境。 无线电设备可以使用 LBT 完成： 查找允许该设备运行的网络 或者找到要运行的空闲无线电信道。 后一种情况的困难在于设备必须监听信号阈值。 LoRa Modulation Spreading Factor 扩频因子 LoRa 扩频调制技术采用多个信息码片来代表有效负载信息的每个位。扩频信息的发送速度称为符号速率(Rs)，而码片速率与标称符号速率之间的比值即为扩频因子，其表示每个信息位发送的符号数量。LoRaTM 调制解调器中扩频因子的取值范围见下表。扩频因子为6时，LoRa 的数据传输速率最快。 注意：因为不同的SF之间为正交关系，因此必须提前获知链路发送端和接收端的SF。另外，还必须获知接受机输入端的信噪比。。在负信噪比条件下信号也能正常接收，这改善了LoRa接受机的灵敏度，链路预算及覆盖范围。 扩频调制带宽(BW) 增加带宽，可以提高有效数据速率以缩短传输时间，但是会牺牲接收灵敏度。 LoRa符号速率Rs可以通过以下公式计算： Rs=BW2sRs= \\frac{BW}{2^s} Rs=2sBW​ 每Hz每秒发送一个码片。 LoRa 数据速率 DR 可以通过以下公式计算： DR=SF∗BW2s∗CRDR = SF* \\frac{BW}{2^s} * CR DR=SF∗2sBW​∗CR LoRa 扩频技术一经推出，就凭借它惊人的灵敏度(-148dbm)、强悍的抗干扰能力、出色的系统容量表现，赢得了广泛的关注。说通俗点，LoRa扩频技术改变了传输功耗和传输距离之间的平衡，彻底改变了嵌入式无线通信领域的局面。它给人们呈现了一个能实现远距离、长电池寿命、大系统容量、低硬件成本的全新通信技术，而这正是物联网(IoT)所需要的。 LoRa扩频原理 常规的数字数据通信原理是使用与数据速率相适应的尽可能小的带宽。这是因为带宽数是有限的，而且有很多的用户要分享。 扩频通信的原理是尽可能使用最大带宽数, 同样的能量在一个大的带宽上传播。这里扩频带宽的很小部分与常规无线信号相干扰， 但常规无线信号不影响扩频信号，这是因为两者相比常规信号带宽很窄。 为何使用扩频技术: 扩大带宽、减少干扰。当扩频因子为1时，数据1就用“1”来表示，扩频因子为4时，可能用“1011”来表示1，这样传输的时候可以降低误码率也就是信噪比，但是却减少了可以传输的实际数据，所以，扩频因子越大，传输的数据数率就越小。 根据对速率的不同要求分配不同数量的码道，提高利用率。扩频因子还有另一个用途，那就是正交码(OVSF: Orthogonal Variable Spreading Factor ，正交可变扩频因子)，通过OVSF可以获得正交的扩频码，扩频因子为4时有4个正交的扩频码，正交的扩频码可以让同时传输的无线信号互不干扰，也就是说，扩频因子为4时，可以同时传输4个人的信息。 One of references: Data Rate and Spreading Factor","categories":[{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/categories/LoRa/"}],"tags":[{"name":"LoRaWAN","slug":"LoRaWAN","permalink":"https://blog.inoki.cc/tags/LoRaWAN/"},{"name":"LoRa","slug":"LoRa","permalink":"https://blog.inoki.cc/tags/LoRa/"},{"name":"IoT","slug":"IoT","permalink":"https://blog.inoki.cc/tags/IoT/"}]},{"title":"KDE Connect iOS 开发日记(2) 识别协议","slug":"KDEConnect-iOS-dev-dairy-ZHCN-2","date":"2020-04-19T15:34:50.000Z","updated":"2025-03-08T09:40:48.582Z","comments":true,"path":"2020/04/19/KDEConnect-iOS-dev-dairy-ZHCN-2/","link":"","permalink":"https://blog.inoki.cc/2020/04/19/KDEConnect-iOS-dev-dairy-ZHCN-2/","excerpt":"","text":"在上一篇文章中，KDE Connect iOS 的构建已修复，可以将应用程序安装到设备或模拟器中。 要与其他设备连接，我们需要与它们配对。但是，在此之前，设备需要使用 KDE Connect 识别机制相互发现。 识别过程 初始身份验证过程非常简单，如下所示: 1.首先，设备 A 将发送一个 UDP 广播数据包，其中包含其身份数据包； 2.每个接收到 UDP 广播的设备 B 都会尝试提取数据包中的 TCP 端口信息，并尝试通过该端口与设备连接； 3.通过 TCP 连接，每个设备 B 都会向设备 A 发送自己的标识数据包； 4.然后，设备会将链接项添加到发现的设备列表中，并等待用户的操作。 升级识别网络包 第一次尝试，除了 iOS 设备，我所有的设备都可以找到彼此。 在调试模式下，我看到发现消息和相关的输出： 1&quot;Inoki&quot; uses an old protocol version, this won&apos;t work 因此，我使用 Wireshark 捕获数据包，以了解为什么 KDE Connect iOS 中的旧实现无法正常工作。 区别在于数据包内容和定制数据。 识别网络包内容 所有的网络包都是通过序列化 NetWorkPackage 类来实现的，这个类在 lib/NetworkPackage.h 和 lib/NetworkPackage.m 文件中被定义。 类中包含的属性有: 123456@property(nonatomic) NSString* _Id;@property(nonatomic) NSString *_Type;@property(nonatomic) NSMutableDictionary *_Body;@property(nonatomic) NSData *_Payload;@property(nonatomic) NSDictionary *_PayloadTransferInfo;@property(nonatomic)long _PayloadSize; 序列化之后，内容将是 JSON 格式的字符串。例如，来自 KDE Connect iOS 的数据包内容为： 12345678910111213&#123; \"id\":\"1587284674\", \"type\":\"kdeconnect.identity\", \"body\":&#123; \"deviceId\":\"test-kdeconnect-ios\", \"SupportedOutgoingInterfaces\":\"kdeconnect.ping,kdeconnect.mpris,kdeconnect.share,kdeconnect.clipboard,kdeconnect.mousepad,kdeconnect.battery,kdeconnect.calendar,kdeconnect.reminder,kdeconnect.contact\", \"protocolVersion\":5, \"tcpPort\":1714, \"deviceType\":\"Phone\", \"deviceName\":\"Inoki\", \"SupportedIncomingInterfaces\":\"kdeconnect.calendar,kdeconnect.clipboard,kdeconnect.ping,kdeconnect.reminder,kdeconnect.share,kdeconnect.contact\" &#125;&#125; 来自 KDE Connect 的其他平台的内容是： 1234567891011121314151617&#123; \"id\":1587284383, \"type\":\"kdeconnect.identity\", \"body\":&#123; \"deviceId\":\"9985DA4FDD3449C78ACC8597D2C5A782\", \"protocolVersion\":7, \"tcpPort\":1716, \"deviceType\":\"phone\", \"deviceName\":\"Inoki\", \"incomingCapabilities\":[ \"kdeconnect.calendar\",\"kdeconnect.clipboard\",\"kdeconnect.ping\",\"kdeconnect.reminder\",\"kdeconnect.share\",\"kdeconnect.contact\" ], \"outgoingCapabilities\":[ \"kdeconnect.ping\",\"kdeconnect.mpris\",\"kdeconnect.share\",\"kdeconnect.clipboard\",\"kdeconnect.mousepad\",\"kdeconnect.battery\",\"kdeconnect.calendar\",\"kdeconnect.reminder\",\"kdeconnect.contact\" ] &#125;&#125; 修复 id 字段的类型 我们可以看到第一个区别是关于 id 字段。在 KDE Connect iOS 数据包中，它是一个字符串。但是在较新版本的协议中，它是一个整数。 因此我将其类型从 NSString 改为 NSNumber: 123456@property(nonatomic) NSNumber *_Id;@property(nonatomic) NSString *_Type;@property(nonatomic) NSMutableDictionary *_Body;@property(nonatomic) NSData *_Payload;@property(nonatomic) NSDictionary *_PayloadTransferInfo;@property(nonatomic)long _PayloadSize; 更新支持的功能类型 另一个重大更改是功能描述的类型和名称： 它们之前分别是 SupportedOutgoingInterfaces 和 SupportedIncomingInterfaces，字符串类型； 在最新版本中，它们是 incomingCapabilities 和 outgoingCapabilities，数组类型。 在 KDE Connect iOS 中，它是由 lib/NetworkPackage.m 中的以下代码生成的： 12[np setObject:[[[PluginFactory sharedInstance] getSupportedIncomingInterfaces] componentsJoinedByString:@&quot;,&quot;] forKey:@&quot;SupportedIncomingInterfaces&quot;];[np setObject:[[[PluginFactory sharedInstance] getSupportedOutgoingInterfaces] componentsJoinedByString:@&quot;,&quot; ] forKey:@&quot;SupportedOutgoingInterfaces&quot;]; 显然，返回的值是数组，但是它们由逗号字符串连接形成一个字符串。因此，我只是更改了键名，并删除了 componentsJoinedByString 方法： 12[np setObject:[[PluginFactory sharedInstance] getSupportedIncomingInterfaces] forKey:@&quot;incomingCapabilities&quot;];[np setObject:[[PluginFactory sharedInstance] getSupportedOutgoingInterfaces] forKey:@&quot;outgoingCapabilities&quot;]; 更新协议版本 协议版本字段在头文件中定义： 1#define ProtocolVersion 5 我将其升级为 7 来匹配现版本。 身份数据包定制数据 在 Wireshark 数据包中 KDE Connect iOS 的身份数据包的定制数据为 \\x0D\\x0A。来自其他 KDE Connect 版本的是 \\x0A。 因此，我更改了 lib/NetworkPackage.m 中的代码： 12- #define LFDATA [NSData dataWithBytes:&quot;\\x0D\\x0A&quot; length:2]+ #define LFDATA [NSData dataWithBytes:&quot;\\x0A&quot; length:1] 结论 最终，KDE Connect iOS 可以找到其他设备并建立与它们的连接： 相反，其他人还找不到 KDE Connect iOS 客户端。这是因为新版本在 TCP 连接后需要 TLS / SSL。这将在下一篇文章中解决。 祝我好运！","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"KDE Connect iOS Develop Dairy(2) Identity Protocol","slug":"KDEConnect-iOS-dev-dairy-2","date":"2020-04-19T14:34:50.000Z","updated":"2025-03-08T09:40:48.577Z","comments":true,"path":"2020/04/19/KDEConnect-iOS-dev-dairy-2/","link":"","permalink":"https://blog.inoki.cc/2020/04/19/KDEConnect-iOS-dev-dairy-2/","excerpt":"","text":"In the previous post, KDE Connect iOS Develop Dairy(1) Build, the build of KDE Connect iOS has been fixed, we can install the application into a device or a simulator. To connect with the other devices, we need to pair with them. But, before that, the devices need to discover each other with the KDE Connect identity mechanism. Identity Process The initial identity process is straightforward, as shown below: First, device A will send a UDP broadcast packet, which carries its identity packet; Each device B, which receives the UDP broadcast, will try to extract the TCP port information in the packet and try to connect with the device via the port; With a TCP connection, each device B will send its identity packet to device A; Then, the devices will add a link item to the discovered device list and wait for users’ actions. Update Identity Packet With a first attempt, all my devices can find each other, except the iOS one. In the debug mode, I saw a discover message and an associated output: 1&quot;Inoki&quot; uses an old protocol version, this won&apos;t work So, I captured the packets using Wireshark, to see why the old implementation in KDE Connect iOS does not work. The differences are in the packet content and tailored data. Identity Packet content All network packets are generated by serializing NetWorkPackage class, which is defined in lib/NetworkPackage.h and lib/NetworkPackage.m. The properties of that class are: 123456@property(nonatomic) NSString* _Id;@property(nonatomic) NSString *_Type;@property(nonatomic) NSMutableDictionary *_Body;@property(nonatomic) NSData *_Payload;@property(nonatomic) NSDictionary *_PayloadTransferInfo;@property(nonatomic)long _PayloadSize; After the serialization, the content will be a JSON format string. For example, the packet content from KDE Connect iOS is: 12345678910111213&#123; \"id\":\"1587284674\", \"type\":\"kdeconnect.identity\", \"body\":&#123; \"deviceId\":\"test-kdeconnect-ios\", \"SupportedOutgoingInterfaces\":\"kdeconnect.ping,kdeconnect.mpris,kdeconnect.share,kdeconnect.clipboard,kdeconnect.mousepad,kdeconnect.battery,kdeconnect.calendar,kdeconnect.reminder,kdeconnect.contact\", \"protocolVersion\":5, \"tcpPort\":1714, \"deviceType\":\"Phone\", \"deviceName\":\"Inoki\", \"SupportedIncomingInterfaces\":\"kdeconnect.calendar,kdeconnect.clipboard,kdeconnect.ping,kdeconnect.reminder,kdeconnect.share,kdeconnect.contact\" &#125;&#125; And the one from KDE Connect on the other platforms is: 1234567891011121314151617&#123; \"id\":1587284383, \"type\":\"kdeconnect.identity\", \"body\":&#123; \"deviceId\":\"9985DA4FDD3449C78ACC8597D2C5A782\", \"protocolVersion\":7, \"tcpPort\":1716, \"deviceType\":\"phone\", \"deviceName\":\"Inoki\", \"incomingCapabilities\":[ \"kdeconnect.calendar\",\"kdeconnect.clipboard\",\"kdeconnect.ping\",\"kdeconnect.reminder\",\"kdeconnect.share\",\"kdeconnect.contact\" ], \"outgoingCapabilities\":[ \"kdeconnect.ping\",\"kdeconnect.mpris\",\"kdeconnect.share\",\"kdeconnect.clipboard\",\"kdeconnect.mousepad\",\"kdeconnect.battery\",\"kdeconnect.calendar\",\"kdeconnect.reminder\",\"kdeconnect.contact\" ] &#125;&#125; Fix id field type We can see the first difference is about the id field. In the KDE Connect iOS packet, it is a string. But in the newer version protocol, it is an integer. So, I changedß its property type from NSString to NSNumber: 123456@property(nonatomic) NSNumber *_Id;@property(nonatomic) NSString *_Type;@property(nonatomic) NSMutableDictionary *_Body;@property(nonatomic) NSData *_Payload;@property(nonatomic) NSDictionary *_PayloadTransferInfo;@property(nonatomic)long _PayloadSize; Update capabilities type Another significant change is the type and the name of description of capacibilities: They were SupportedOutgoingInterfaces and SupportedIncomingInterfaces, with string type; In the latest version, they are incomingCapabilities and outgoingCapabilities, with array type. In KDE Connect iOS, it is generated by the following lines in lib/NetworkPackage.m: 12[np setObject:[[[PluginFactory sharedInstance] getSupportedIncomingInterfaces] componentsJoinedByString:@&quot;,&quot;] forKey:@&quot;SupportedIncomingInterfaces&quot;];[np setObject:[[[PluginFactory sharedInstance] getSupportedOutgoingInterfaces] componentsJoinedByString:@&quot;,&quot; ] forKey:@&quot;SupportedOutgoingInterfaces&quot;]; The returned values are arrays, and a comma string joins them. So, I changed the key and removed the componentsJoinedByString method: 12[np setObject:[[PluginFactory sharedInstance] getSupportedIncomingInterfaces] forKey:@&quot;incomingCapabilities&quot;];[np setObject:[[PluginFactory sharedInstance] getSupportedOutgoingInterfaces] forKey:@&quot;outgoingCapabilities&quot;]; Update the protocol version The protocol version field is defined in the header file: 1#define ProtocolVersion 5 I update it to 7 to match the current version. Identity Packet tailor data The tailor data of identity packet from KDE Connect iOS in a Wireshark traffic is \\x0D\\x0A. And the one from other KDE Connect versions is \\x0A. So, I change the line in lib/NetworkPackage.m: 12- #define LFDATA [NSData dataWithBytes:&quot;\\x0D\\x0A&quot; length:2]+ #define LFDATA [NSData dataWithBytes:&quot;\\x0A&quot; length:1] Conclusion Finally, the KDE Connect iOS can find the other device and establish connections to them: On the contrary, the others cannot find KDE Connect iOS client out yet. That’s because the new version requires TLS/SSL after a TCP connection. This will get fixed in the next post. Good luck to myself!","categories":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"KDE Connect iOS 开发日记(1) 构建","slug":"KDEConnect-iOS-dev-dairy-ZHCN-1","date":"2020-04-18T22:20:30.000Z","updated":"2025-03-08T09:40:48.578Z","comments":true,"path":"2020/04/18/KDEConnect-iOS-dev-dairy-ZHCN-1/","link":"","permalink":"https://blog.inoki.cc/2020/04/18/KDEConnect-iOS-dev-dairy-ZHCN-1/","excerpt":"","text":"处理依赖 KDE Connect iOS 项目使用 CocoaPods 来管理依赖: COCOAPODS 是什么 CocoaPods 是 Swift 和 Objective-C Cocoa 项目的依赖项管理器。 它拥有超过 7.2 万个库，并在超过300万个应用程序中使用。 CocoaPods可以帮助您优雅地扩展项目。 与 CocoaPods 有关的文件是 Podfile，它指定了这个项目面向的 iOS 的版本 (7.0)，依赖的名称、版本和源： 1234567platform :ios, &apos;7.0&apos;pod &apos;CocoaAsyncSocket&apos;, &apos;~&gt; 7.3.5&apos;pod &apos;MRProgress&apos;pod &apos;InAppSettingsKit&apos;, &apos;~&gt; 2.1&apos;pod &apos;VTAcknowledgementsViewController&apos;pod &apos;XbICalendar&apos;, :podspec =&gt; &apos;https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec&apos;pod &apos;MYBlurIntroductionView&apos; 构建的第一步就是安装这些依赖。在安装了 CocoaPods 之后，我根据官方文档运行了 pod install，但是出现了问题： 12345678910111213141516171819202122232425262728$ pod installAnalyzing dependenciesFetching podspec for `XbICalendar` from `https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec`Downloading dependenciesInstalling CocoaAsyncSocket (7.3.5)Installing InAppSettingsKit (2.15)Installing MRProgress (0.8.3)Installing MYBlurIntroductionView (1.0.3)Installing VTAcknowledgementsViewController (1.5.2)Installing XbICalendar (0.3.3)Generating Pods projectIntegrating client projects[!] Could not automatically select an Xcode workspace. Specify one in your Podfile like so: workspace &apos;path/to/Workspace.xcworkspace&apos;[!] The abstract target Pods is not inherited by a concrete target, so the following dependencies won&apos;t make it into any targets in your project: - CocoaAsyncSocket (~&gt; 7.3.5) - InAppSettingsKit (~&gt; 2.1) - MRProgress - MYBlurIntroductionView - VTAcknowledgementsViewController - XbICalendar (from `https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec`)[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `InAppSettingsKit (2.15)` which has a minimum requirement of iOS 8.0.[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `VTAcknowledgementsViewController (1.5.2)` which has a minimum requirement of iOS 8.0 - tvOS 9.0. 看起来有一些 bug 要修了 😃 修复 Bug 123[!] Could not automatically select an Xcode workspace. Specify one in your Podfile like so: workspace &apos;path/to/Workspace.xcworkspace&apos; 在这个项目中，.xcworkspace 文件对应的是 kdeconnect-ios.xcworkspace。所以我在文件中添加了 workspace 'kdeconnect-ios' 一句。 123[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `InAppSettingsKit (2.15)` which has a minimum requirement of iOS 8.0.[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `VTAcknowledgementsViewController (1.5.2)` which has a minimum requirement of iOS 8.0 - tvOS 9.0. 很明显，这个输出指出，目标的系统版本需要升级。为了方便，我直接把它升级到了 platform :ios, '12.0'。 12[!] The abstract target Pods is not inherited by a concrete target, so the following dependencies won&apos;t make it into any targets in your project: ... 这个消息则说明 pods(对应依赖的概念) 没有指定目标项目。根据 CocoaPod 的文档，我应当添加 target &quot;kdeconnect-ios&quot; 并把所有的 pods 放在一个 do ... end 结构中。 最终版本 Podfile 最终，Podfile 文件变成了： 123456789101112workspace &apos;kdeconnect-ios&apos;target &quot;kdeconnect-ios&quot; doplatform :ios, &apos;12.0&apos;pod &apos;CocoaAsyncSocket&apos;, &apos;~&gt; 7.3.5&apos;pod &apos;MRProgress&apos;pod &apos;InAppSettingsKit&apos;, &apos;~&gt; 2.1&apos;pod &apos;VTAcknowledgementsViewController&apos;pod &apos;XbICalendar&apos;, :podspec =&gt; &apos;https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec&apos;pod &apos;MYBlurIntroductionView&apos;end 修复过后，输出正常了起来： 123456$ pod installAnalyzing dependenciesDownloading dependenciesGenerating Pods projectIntegrating client projectPod installation complete! There are 6 dependencies from the Podfile and 6 total pods installed. 使用 XCode 构建 既然安装依赖部分已经没有问题了，使用 XCode 编译构建它就变得顺理成章了（虽然 XCode 是世界最差 IDE 没有之一）。 应用程序标识符 第一个问题出现在我点击 Build 按钮的时候： 12Failed to register bundle identifier.The app identifier &quot;application-identifier&quot; cannot be registered to your development team. Change your bundle identifier to a unique string to try again. Apple 试图为我的 Apple 帐号和这个应用程序生成一个自签名证书。但它没法处理现在这个格式的标识符。 因此我把标识符改成了 org.kde.kdeconnect.ios，然后点击 Try again，这次，自签名证书生成成功。 Multiple commands produce 紧接着，我重新开始构建。另一个 bug 就出现了： 123Multiple commands produce &apos;/Users/inoki/Library/Developer/Xcode/DerivedData/kdeconnect-ios-hhcvmcgjatxxdugxbjbrwgotfgna/Build/Products/Debug-iphoneos/kdeconnect-ios.app/zh-Hans.lproj/Localizable.strings&apos;:1) Target &apos;kdeconnect-ios&apos; (project &apos;kdeconnect-ios&apos;) has copy command from &apos;/Users/inoki/Projects/kdeconnect-ios-test/kdeconnect-ios/zh-Hans.lproj/Localizable.strings&apos; to &apos;/Users/inoki/Library/Developer/Xcode/DerivedData/kdeconnect-ios-hhcvmcgjatxxdugxbjbrwgotfgna/Build/Products/Debug-iphoneos/kdeconnect-ios.app/zh-Hans.lproj/Localizable.strings&apos;2) Target &apos;kdeconnect-ios&apos; (project &apos;kdeconnect-ios&apos;) has copy command from &apos;/Users/inoki/Projects/kdeconnect-ios-test/kdeconnect-ios/zh-Hans.lproj/Localizable.strings&apos; to &apos;/Users/inoki/Library/Developer/Xcode/DerivedData/kdeconnect-ios-hhcvmcgjatxxdugxbjbrwgotfgna/Build/Products/Debug-iphoneos/kdeconnect-ios.app/zh-Hans.lproj/Localizable.strings&apos; 我参考了这个在 GitHub 上的 issue，把构建系统更改为 legacy： 缺失的头文件 接着，另一个错误出现了： 1kdeconnect-ios/AppSettingViewController.m:27:9: &apos;IASKPSTitleValueSpecifierViewCell.h&apos; file not found 这个问题可能是某个依赖版本升级导致的，直接移除这行： 1#import &quot;IASKPSTitleValueSpecifierViewCell.h&quot; 库链接错误，禁用 Bitcode 之后，我再次重新构建，又一个问题出现了： 1ld: &apos;/Users/inoki/Projects/kdeconnect-ios-test/Pods/XbICalendar/libical/lib/libical.a(icalcomponent.c.o)&apos; does not contain bitcode. You must rebuild it with bitcode enabled (Xcode setting ENABLE_BITCODE), obtain an updated library from the vendor, or disable bitcode for this target. for architecture arm64 Bitcode 可能是一个新的特性，但目前来说我想尽快将 KDE Connect iOS 构建起来。因此我在 Build Settings-&gt;Build Options 中禁用了它： 链接 WebKit 库 另一个问题是与 WebKit 有关的： 1Undefined symbols for architecture arm64: &quot;_OBJC_CLASS_$_WKWebView&quot; 看起来是因为 WebKit 框架没有被加入到项目中。所以，可以在 Build Phases-&gt;Link Binary with Libraries 将其加入： 文件未找到(Pods-acknowledgements.plist, Pods-resources.sh) 最终，当一切都完成构建，又一个问题出现： 1Pods/Pods-acknowledgements.plist:0: Reading data: The file “Pods-acknowledgements.plist” couldn’t be opened because there is no such file. 这可能是因为 CocoaPod 版本导致的不兼容问题。我把 Pods/Target Support Files/Pods-kdeconnect-ios 中对应的文件复制到 Pods/ 里来修复： 12cp Pods-kdeconnect-ios-acknowledgements.plist ../../Pods-acknowledgements.plistcp Pods-kdeconnect-ios-resources.sh ../../Pods-resources.sh 最终，程序终于构建成功并在设备上运行了 😃","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"KDE Connect iOS Develop Dairy(1) Build","slug":"KDEConnect-iOS-dev-dairy-1","date":"2020-04-18T21:43:50.000Z","updated":"2025-03-08T09:40:48.574Z","comments":true,"path":"2020/04/18/KDEConnect-iOS-dev-dairy-1/","link":"","permalink":"https://blog.inoki.cc/2020/04/18/KDEConnect-iOS-dev-dairy-1/","excerpt":"","text":"Handle Dependencies The project uses CocoaPods to manage its dependencies: WHAT IS COCOAPODS CocoaPods is a dependency manager for Swift and Objective-C Cocoa projects. It has over 72 thousand libraries and is used in over 3 million apps. CocoaPods can help you scale your projects elegantly. The CocoaPods file is Podfile, which describes the iOS version (7.0) to use, and the dependencies name, version, and source: 1234567platform :ios, &apos;7.0&apos;pod &apos;CocoaAsyncSocket&apos;, &apos;~&gt; 7.3.5&apos;pod &apos;MRProgress&apos;pod &apos;InAppSettingsKit&apos;, &apos;~&gt; 2.1&apos;pod &apos;VTAcknowledgementsViewController&apos;pod &apos;XbICalendar&apos;, :podspec =&gt; &apos;https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec&apos;pod &apos;MYBlurIntroductionView&apos; The first step to build it is installing the dependencies. After installing CocoaPods, I ran pod install and got some errors: 12345678910111213141516171819202122232425262728$ pod installAnalyzing dependenciesFetching podspec for `XbICalendar` from `https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec`Downloading dependenciesInstalling CocoaAsyncSocket (7.3.5)Installing InAppSettingsKit (2.15)Installing MRProgress (0.8.3)Installing MYBlurIntroductionView (1.0.3)Installing VTAcknowledgementsViewController (1.5.2)Installing XbICalendar (0.3.3)Generating Pods projectIntegrating client projects[!] Could not automatically select an Xcode workspace. Specify one in your Podfile like so: workspace &apos;path/to/Workspace.xcworkspace&apos;[!] The abstract target Pods is not inherited by a concrete target, so the following dependencies won&apos;t make it into any targets in your project: - CocoaAsyncSocket (~&gt; 7.3.5) - InAppSettingsKit (~&gt; 2.1) - MRProgress - MYBlurIntroductionView - VTAcknowledgementsViewController - XbICalendar (from `https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec`)[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `InAppSettingsKit (2.15)` which has a minimum requirement of iOS 8.0.[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `VTAcknowledgementsViewController (1.5.2)` which has a minimum requirement of iOS 8.0 - tvOS 9.0. There are some bugs to fix 😃 Bugfix 123[!] Could not automatically select an Xcode workspace. Specify one in your Podfile like so: workspace &apos;path/to/Workspace.xcworkspace&apos; In this project, the .xcworkspace file is kdeconnect-ios.xcworkspace. So, I add workspace 'kdeconnect-ios' into the file. 123[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `InAppSettingsKit (2.15)` which has a minimum requirement of iOS 8.0.[!] The platform of the target `Pods` (iOS 7.0) may not be compatible with `VTAcknowledgementsViewController (1.5.2)` which has a minimum requirement of iOS 8.0 - tvOS 9.0. The target OS version should be updated. I directly update it to platform :ios, '12.0'. 12[!] The abstract target Pods is not inherited by a concrete target, so the following dependencies won&apos;t make it into any targets in your project: ... This message indicates that the pods(dependencies) do not have a target; according to the CocoaPod doc, I should add target &quot;kdeconnect-ios&quot; and wrap all the pods with a do ... end body. Final Podfile As a result, the Podfile should be: 123456789101112workspace &apos;kdeconnect-ios&apos;target &quot;kdeconnect-ios&quot; doplatform :ios, &apos;12.0&apos;pod &apos;CocoaAsyncSocket&apos;, &apos;~&gt; 7.3.5&apos;pod &apos;MRProgress&apos;pod &apos;InAppSettingsKit&apos;, &apos;~&gt; 2.1&apos;pod &apos;VTAcknowledgementsViewController&apos;pod &apos;XbICalendar&apos;, :podspec =&gt; &apos;https://raw.githubusercontent.com/libical/XbICalendar/master/XbICalendar.podspec&apos;pod &apos;MYBlurIntroductionView&apos;end After fixing, the output seems normal: 123456$ pod installAnalyzing dependenciesDownloading dependenciesGenerating Pods projectIntegrating client projectPod installation complete! There are 6 dependencies from the Podfile and 6 total pods installed. Build with XCode Without error in installing dependencies, it is possible to open and build it with XCode (though it could be the worst IDE in the world). Identifier The first issue occurred while I click Build: 12Failed to register bundle identifier.The app identifier &quot;application-identifier&quot; cannot be registered to your development team. Change your bundle identifier to a unique string to try again. Apple wants to generate a self-signed certificate for my Apple account and the application. But it cannot handle the identifier. I change it to org.kde.kdeconnect.ios and click Try again. It works. Multiple commands produce Then, rebuild. And another one came out: 123Multiple commands produce &apos;/Users/inoki/Library/Developer/Xcode/DerivedData/kdeconnect-ios-hhcvmcgjatxxdugxbjbrwgotfgna/Build/Products/Debug-iphoneos/kdeconnect-ios.app/zh-Hans.lproj/Localizable.strings&apos;:1) Target &apos;kdeconnect-ios&apos; (project &apos;kdeconnect-ios&apos;) has copy command from &apos;/Users/inoki/Projects/kdeconnect-ios-test/kdeconnect-ios/zh-Hans.lproj/Localizable.strings&apos; to &apos;/Users/inoki/Library/Developer/Xcode/DerivedData/kdeconnect-ios-hhcvmcgjatxxdugxbjbrwgotfgna/Build/Products/Debug-iphoneos/kdeconnect-ios.app/zh-Hans.lproj/Localizable.strings&apos;2) Target &apos;kdeconnect-ios&apos; (project &apos;kdeconnect-ios&apos;) has copy command from &apos;/Users/inoki/Projects/kdeconnect-ios-test/kdeconnect-ios/zh-Hans.lproj/Localizable.strings&apos; to &apos;/Users/inoki/Library/Developer/Xcode/DerivedData/kdeconnect-ios-hhcvmcgjatxxdugxbjbrwgotfgna/Build/Products/Debug-iphoneos/kdeconnect-ios.app/zh-Hans.lproj/Localizable.strings&apos; To fix it, I refer this GitHub issue and change the build system to the legacy one: Missing header After that, another error occurs: 1kdeconnect-ios/AppSettingViewController.m:27:9: &apos;IASKPSTitleValueSpecifierViewCell.h&apos; file not found This may be an update of one dependency; remove this import line: 1#import &quot;IASKPSTitleValueSpecifierViewCell.h&quot; Link error, disable Bitcode I rebuilt it, but another one came… 1ld: &apos;/Users/inoki/Projects/kdeconnect-ios-test/Pods/XbICalendar/libical/lib/libical.a(icalcomponent.c.o)&apos; does not contain bitcode. You must rebuild it with bitcode enabled (Xcode setting ENABLE_BITCODE), obtain an updated library from the vendor, or disable bitcode for this target. for architecture arm64 Bitcode may be a feature, but I want to get it to build as soon as possible. So, I disable it in Build Settings-&gt;Build Options: Link with WebKit Another link error occurs. It is about the WebView stuff: 1Undefined symbols for architecture arm64: &quot;_OBJC_CLASS_$_WKWebView&quot; It seems that the WebKit framework is not included in the project. So, add it in Build Phases-&gt;Link Binary with Libraries: File(Pods-acknowledgements.plist, Pods-resources.sh) not found Finally, at the end of building phases, the error came out: 1Pods/Pods-acknowledgements.plist:0: Reading data: The file “Pods-acknowledgements.plist” couldn’t be opened because there is no such file. This could be an error caused by CocoaPod version. To fix it, copy the files in Pods/Target Support Files/Pods-kdeconnect-ios to Pods/: 12cp Pods-kdeconnect-ios-acknowledgements.plist ../../Pods-acknowledgements.plistcp Pods-kdeconnect-ios-resources.sh ../../Pods-resources.sh Finally, it works 😃","categories":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"KDE Connect iOS Develop Dairy(0) Index","slug":"KDEConnect-iOS-dev-dairy-0","date":"2020-04-18T10:34:50.000Z","updated":"2025-03-08T09:40:48.574Z","comments":true,"path":"2020/04/18/KDEConnect-iOS-dev-dairy-0/","link":"","permalink":"https://blog.inoki.cc/2020/04/18/KDEConnect-iOS-dev-dairy-0/","excerpt":"","text":"Preface Thanks to the previous work on KDE Connect for iOS, there is a not bad codebase on KDE git. This serie of blogs aims in bringing KDE Connect back to the iOS platform. You could check the progress here. Context KDE Connect iOS Develop Dairy(1) Build KDE Connect iOS Develop Dairy(2) Identity Protocol KDE Connect iOS Develop Dairy(3) Certificate …Under Construction Preview Here are some screenshots:","categories":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"KDE Connect iOS 开发日记(0) 索引","slug":"KDEConnect-iOS-dev-dairy-ZHCN-0","date":"2020-04-18T10:34:50.000Z","updated":"2025-03-08T09:40:48.578Z","comments":true,"path":"2020/04/18/KDEConnect-iOS-dev-dairy-ZHCN-0/","link":"","permalink":"https://blog.inoki.cc/2020/04/18/KDEConnect-iOS-dev-dairy-ZHCN-0/","excerpt":"","text":"前言 感谢先前社区内开发者的努力，KDE Connect iOS 版本已经有了一定量的代码，可以在 KDE git 上找到。这个系列博客致力于记录我如何将 KDE Connect 重新带回 iOS 平台。 目录 KDE Connect iOS 开发日记(1) 构建 KDE Connect iOS 开发日记(2) 识别协议 KDE Connect iOS 开发日记(3) 证书 …剩余部分仍在构建中 预览 在这里可以看到目前进度的截图:","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/categories/KDE-Connect/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"KDE Connect","slug":"KDE-Connect","permalink":"https://blog.inoki.cc/tags/KDE-Connect/"}]},{"title":"在 Ubuntu 18.04 构建 Intelligent Input Bus (IBus)","slug":"Build-iBus","date":"2020-02-29T10:40:00.000Z","updated":"2025-03-08T09:40:48.556Z","comments":true,"path":"2020/02/29/Build-iBus/","link":"","permalink":"https://blog.inoki.cc/2020/02/29/Build-iBus/","excerpt":"","text":"简介 Intelligent Input Bus，简称IBus，是 Unix-like 操作系统下的多语输入法平台。因为它采用了总线（Bus）式的架构，所以命名为Bus。 在东北亚开源软件（OSS）论坛第3工作小组提出的《输入法引擎服务提供者界面规格》（Specification of IM engine Service Provider Interface）草案里，能实现以 Bus 为核心的架构被建议采用。SCIM-1.4 的架构并不被看好，因为它是用 C++ 开发的，因此常常会有C++应用二进制接口不符合的情况发生。 从那时起，一些人开始着手开发下一代的输入法平台，像是苏哲领导的IM-Bus，以及胡正的SCIM-2，可惜的是它们的开发进度仍然停滞不前。因此，时任红帽（现任谷歌）的黄鹏开始用 Python 开发 IBus 以实现 IM-Bus 提出的构想。IBus 并不完全实现东北亚 OSS 论坛所建议的函数，而是采用D-Bus及Glib来实做。尽管如此，IBus 已经开始被 OSS 社群所接受，FreeBSD 以及各大 Linux 发行版 如 Fedora、Ubuntu 已经将 IBus 纳入其包库里。在 Fedora 11 里，IBus 已经成为默认的多语输入平台。 IBus 是用 C 及 Python 开发的，如此可以避免 C++ ABI transition 问题。IBus 主要透过下列三种服务(Service)来提供功能： 输入法引擎服务：为输入法本身。 配置服务：管理IBus以及输入法的设置选项。 控制面板服务：提供诸如语言条，候选字菜单等用户界面。 IBus 使用 D-Bus 作 ibus-daemon服务，以及 IM客户端（像是konsole, gedit, firefox)之间的沟通。 ibus-daemon 透过接受服务登录，以及发送 D-Bus 消息来管理服务及IM客户端。IBus支持 XIM 协议及 Gtk IM 模块以及 Qt IM 模块。 项目托管在 GitHub IBus 组织下 https://github.com/ibus/ibus。 构建 首先，获取最新的源代码，并进入其目录： 12git clone https://github.com/ibus/ibus.gitcd ibus 目前这里使用的是 master 分支上的代码，有时该分支可能并不稳定。可以使用一个 release 分支或标签的代码来构建，以避免一些奇怪的错误。这里我使用 1.5.y 分支的代码： 1git checkout -b 1.5.y origin/1.5.y 使用脚本调用 auto configure 工具链，来生成 Makefile 文件 1./autogen.sh --prefix=/usr --sysconfdir=/etc 这时，如果有错误，说明有些依赖并没有被安装在系统里，需要用户手动安装，请看依赖章节。 如果一切正常，我们就可以用 make 进行构建和安装了： 1make &amp;&amp; sudo make install 如果构建失败，请对照构建时依赖相关问题。 完成之后运行一下： 1ibus-setup 在 IBus 的代码里，有一个 simple engine 输入引擎服务，它不提供任何真实的输入功能，只是把桌面环境支持的各种键盘布局显示出来，我们可以用它检测 IBus 是否成功构建： 若没有这些键盘布局，可能 ibus-daemon 出了些问题，尝试运行： 1ibus-daemon 在运行时依赖相关问题中有一些我遇到的问题，可供参考。 之后就可以构建想用的输入服务了。据官方文档，目前的引擎有： ibus-anthy: 日文输入法。 ibus-array: 行列输入法 ibus-bopomofo: 使用注音符号的拼音输入法，基于ibus-pinyin引擎开发，但输入方式与一般标准智能形注音输入法（如新酷音输入法或微软新注音）不同。 ibus-chewing: 新酷音输入法，智能形注音输入法。 ibus-hangul: 韩文输入法。 ibus-kkc：日文假名汉字转换输入法。 ibus-m17n: 使用m17n-db的多语输入法。 ibus-pinyin: 拼音输入法，为IBus主要开发者所开发。 ibus-libpinyin: 是 Red Hat 工程师主导、基于 n-gram 语言模型的集成性泛拼音输入法引擎。 ibus-libzhuyin: 与 ibus-libpinyin 系出同源，支持注音符号输入，名为“新注音”(New Zhuyin) 输入法，是智能形的注音输入法。 ibus-table: 码表输入引擎。 ibus-googlepinyin: Google拼音输入法的ibus版本（这个并不是官方的Google输入法，而是由爱好者从Android项目上迁移过来） 依赖 最基础的依赖是 D-Bus 及其 Python 绑定，在 Ubuntu 里，这些以来应该是已经被预置在桌面版本的系统中了： 123python &gt;= 2.5dbus-glib &gt;= 0.74dbus-python &gt;= 0.83.0 官方文档还推荐安装qt &gt;= 4.4.0，这是为了让 IBus 能和 Qt 的 IM 协作，这个依赖对于使用 Qt 的应用程序（如使用的桌面环境是KDE）来说是至关重要的。但在 Ubuntu 18.04 中， Gnome 被作为默认的桌面环境，因此，可以根据自己的需要来配置。 构建时依赖相关问题 根据我的经历，以下这些是我在 Ubuntu 18.04 上配置期间遇到的问题： 配置期间，提示未找到 gnome-autogen.sh：安装 gnome-common 配置期间，提示未找到 gtk-doc：安装 gtk-doc 配置期间，提示未找到 gtk±2.0：安装 libgtk2.0-dev 配置期间，提示未找到 gtk±3.0：安装 libgtk-3-dev 配置期间，提示未找到 dconf：安装 libdconf-dev 配置期间，提示未找到 emoji-test.txt：安装 unicode-data 配置期间，提示未找到 annotations/en.xml：安装 unicode-cldr-core 配置期间，提示未找到 unicode/ucd/NamesList.txt：创建一个符号链接 unicode/NamesList.txt -&gt; unicode/ucd/NamesList.txt (unicode-data 包已安装) 配置期间，提示未找到 unicode/ucd/Blocks.txt：创建一个符号链接 unicode/Blocks.txt -&gt; unicode/ucd/Blocks.txt (unicode-data 包已安装) 编译期间，提示未找到 valac：安装 valac-0.40-vapi, valac-0.40-dev 编译期间，提示 Vala bindings require Gobject Introspection：安装 libgirepository1.0-dev 运行时依赖相关问题 ibus_serializable_serialize_object 符号未找到 我在运行 ibus-daemon 时遇到了 Not found symbol ibus_serializable_serialize_object 的报错。 根据分析，是 libibus-1.0.so 被安错了地方： ibus-daemon 链接到 /usr/lib/x86_64-linux-gnu/libibus-1.0.so.5，这个文件是个符号链接，指向真正的 so 文件。而在我的电脑它指向了上之前的包管理器安装的 so 版本，于是就出现 ABI 不兼容的问题，提示找不到 symbol。 根据 log，安装脚本里的确安装了新版本的 so 并且处理了指向，只是它被安在了 /usr/lib。于是我把 /usr/lib/x86_64-linux-gnu/libibus-1.0.so.5 指向改为了新安装的 so 文件，再次运行，一切正常。","categories":[{"name":"Build","slug":"Build","permalink":"https://blog.inoki.cc/categories/Build/"}],"tags":[{"name":"IBus","slug":"IBus","permalink":"https://blog.inoki.cc/tags/IBus/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.inoki.cc/tags/Ubuntu/"}]},{"title":"Visual Studio Code c/cpp configuration","slug":"VSCode-c-cpp-configuration","date":"2020-01-05T08:40:40.000Z","updated":"2025-03-08T09:40:48.594Z","comments":true,"path":"2020/01/05/VSCode-c-cpp-configuration/","link":"","permalink":"https://blog.inoki.cc/2020/01/05/VSCode-c-cpp-configuration/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121&#123; \"configurations\": [ &#123; \"name\": \"Craft-KDE\", \"includePath\": [ \"$&#123;workspaceFolder&#125;/**\", \"/usr/local/include\", \"/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include\", \"&lt;CraftRoot-Path&gt;/include\", \"&lt;CraftRoot-Path&gt;/include/KF5/KActivities\", \"&lt;CraftRoot-Path&gt;/include/KF5/KActivitiesStats\", \"&lt;CraftRoot-Path&gt;/include/KF5/KArchive\", \"&lt;CraftRoot-Path&gt;/include/KF5/KAuth\", \"&lt;CraftRoot-Path&gt;/include/KF5/KBookmarks\", \"&lt;CraftRoot-Path&gt;/include/KF5/KCMUtils\", \"&lt;CraftRoot-Path&gt;/include/KF5/KCodecs\", \"&lt;CraftRoot-Path&gt;/include/KF5/KCompletion\", \"&lt;CraftRoot-Path&gt;/include/KF5/KConfigCore\", \"&lt;CraftRoot-Path&gt;/include/KF5/KConfigGui\", \"&lt;CraftRoot-Path&gt;/include/KF5/KConfigWidgets\", \"&lt;CraftRoot-Path&gt;/include/KF5/KContacts\", \"&lt;CraftRoot-Path&gt;/include/KF5/KCoreAddons\", \"&lt;CraftRoot-Path&gt;/include/KF5/KCrash\", \"&lt;CraftRoot-Path&gt;/include/KF5/KDBusAddons\", \"&lt;CraftRoot-Path&gt;/include/KF5/KDELibs4Support\", \"&lt;CraftRoot-Path&gt;/include/KF5/KDEWebKit\", \"&lt;CraftRoot-Path&gt;/include/KF5/KDNSSD\", \"&lt;CraftRoot-Path&gt;/include/KF5/KDeclarative\", \"&lt;CraftRoot-Path&gt;/include/KF5/KDocTools\", \"&lt;CraftRoot-Path&gt;/include/KF5/KEmoticons\", \"&lt;CraftRoot-Path&gt;/include/KF5/KFileMetaData\", \"&lt;CraftRoot-Path&gt;/include/KF5/KGlobalAccel\", \"&lt;CraftRoot-Path&gt;/include/KF5/KGuiAddons\", \"&lt;CraftRoot-Path&gt;/include/KF5/KHolidays\", \"&lt;CraftRoot-Path&gt;/include/KF5/KHtml\", \"&lt;CraftRoot-Path&gt;/include/KF5/KI18n\", \"&lt;CraftRoot-Path&gt;/include/KF5/KIOCore\", \"&lt;CraftRoot-Path&gt;/include/KF5/KIOFileWidgets\", \"&lt;CraftRoot-Path&gt;/include/KF5/KIOGui\", \"&lt;CraftRoot-Path&gt;/include/KF5/KIOWidgets\", \"&lt;CraftRoot-Path&gt;/include/KF5/KIconThemes\", \"&lt;CraftRoot-Path&gt;/include/KF5/KIdleTime\", \"&lt;CraftRoot-Path&gt;/include/KF5/KItemModels\", \"&lt;CraftRoot-Path&gt;/include/KF5/KItemViews\", \"&lt;CraftRoot-Path&gt;/include/KF5/KJobWidgets\", \"&lt;CraftRoot-Path&gt;/include/KF5/KJsEmbed\", \"&lt;CraftRoot-Path&gt;/include/KF5/KMediaPlayer\", \"&lt;CraftRoot-Path&gt;/include/KF5/KNewStuff3\", \"&lt;CraftRoot-Path&gt;/include/KF5/KNotifications\", \"&lt;CraftRoot-Path&gt;/include/KF5/KNotifyConfig\", \"&lt;CraftRoot-Path&gt;/include/KF5/KPackage\", \"&lt;CraftRoot-Path&gt;/include/KF5/KParts\", \"&lt;CraftRoot-Path&gt;/include/KF5/KPeople\", \"&lt;CraftRoot-Path&gt;/include/KF5/KPlotting\", \"&lt;CraftRoot-Path&gt;/include/KF5/KPty\", \"&lt;CraftRoot-Path&gt;/include/KF5/KRunner\", \"&lt;CraftRoot-Path&gt;/include/KF5/KService\", \"&lt;CraftRoot-Path&gt;/include/KF5/KStyle\", \"&lt;CraftRoot-Path&gt;/include/KF5/KSyntaxHighlighting\", \"&lt;CraftRoot-Path&gt;/include/KF5/KTextEditor\", \"&lt;CraftRoot-Path&gt;/include/KF5/KTextWidgets\", \"&lt;CraftRoot-Path&gt;/include/KF5/KUnitConversion\", \"&lt;CraftRoot-Path&gt;/include/KF5/KWallet\", \"&lt;CraftRoot-Path&gt;/include/KF5/KWidgetsAddons\", \"&lt;CraftRoot-Path&gt;/include/KF5/KWindowSystem\", \"&lt;CraftRoot-Path&gt;/include/KF5/KXmlGui\", \"&lt;CraftRoot-Path&gt;/include/KF5/KXmlRpcClient\", \"&lt;CraftRoot-Path&gt;/include/KF5/Kirigami2\", \"&lt;CraftRoot-Path&gt;/include/KF5/KrossCore\", \"&lt;CraftRoot-Path&gt;/include/KF5/KrossUi\", \"&lt;CraftRoot-Path&gt;/lib/QtConcurrent.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtCore.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtDBus.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtDesigner.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtDesignerComponents.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtGui.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtHelp.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtLocation.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtMacExtras.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtMultimedia.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtMultimediaQuick.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtMultimediaWidgets.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtNetwork.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtOpenGL.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtPositioning.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtPositioningQuick.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtPrintSupport.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQml.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuick.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuickControls2.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuickParticles.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuickShapes.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuickTemplates2.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuickTest.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtQuickWidgets.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtScript.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtScriptTools.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtSensors.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtSql.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtSvg.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtTest.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtTextToSpeech.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtUiPlugin.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtWebChannel.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtWebKit.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtWebKitWidgets.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtWidgets.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtXml.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/QtXmlPatterns.framework/Headers\", \"&lt;CraftRoot-Path&gt;/lib/qca-qt5.framework/Headers\" ], \"defines\": [\"Q_OS_MAC\", \"Q_OS_MACOS\"], \"macFrameworkPath\": [\"/System/Library/Frameworks\", \"/Library/Frameworks\", \"&lt;CraftRoot-Path&gt;/lib/\"], \"compilerPath\": \"/usr/bin/clang\", \"cStandard\": \"c11\", \"cppStandard\": \"c++17\", \"intelliSenseMode\": \"$&#123;default&#125;\" &#125; ], \"version\": 4&#125;","categories":[{"name":"VSCode","slug":"VSCode","permalink":"https://blog.inoki.cc/categories/VSCode/"}],"tags":[{"name":"VSCode","slug":"VSCode","permalink":"https://blog.inoki.cc/tags/VSCode/"}]},{"title":"FFmpeg Decoding","slug":"FFmpeg-Decoding","date":"2019-12-16T18:42:00.000Z","updated":"2025-03-08T09:40:48.564Z","comments":true,"path":"2019/12/16/FFmpeg-Decoding/","link":"","permalink":"https://blog.inoki.cc/2019/12/16/FFmpeg-Decoding/","excerpt":"","text":"FFmpeg is a complete, cross-platform solution to record, convert and stream audio and video. But on the Internet, almost all tutorials only tell you how to use the FFmpeg with its executables. Although the origin tool ffmpeg executable is good enough, it’s still good to know how FFmpeg works behind. This serie of posts will explore and build encoders, decoders, filters and other utilities with FFmpeg libraries for you and for myself. In this post, we aim at building a video decoder from scratch. Target To make it simple, we’re going to build a program: which accepts an argument, as the path of video and the second argument, as the frame index of frames in the video So, we just need a simple main function: 123456789101112int main(int argc, char *argv[])&#123; // argc == 3 // argv[1] - file path // argv[2] - frame index if (argc &lt; 3) &#123; printf(\"Please provide file path and frame index\"); return -1; &#125; return 0;&#125; Read arguments For the file path, we should be able to directly use it to open the file. As a result, we do not need to handle with it. 1234567int frameIndex = 0;frameIndex = atoi(argv[2]);if (frameIndex &lt;= 0) &#123; printf(\"Please provide a positive frame index\"); return -1;&#125; Here we just read the second argument and transfer it to an integer. Read file We have already got the file path, so we can use the function avformat_open_input, defined in libavformat/avformat.h and implemented in libavformat/utils.c, to open and store it into a FFmpeg readable and operatable format. 1int avformat_open_input(AVFormatContext **ps, const char *url, ff_const59 AVInputFormat *fmt, AVDictionary **options); To call it, we need an AVFormatContext instance. For the last two parameters, we just let them NULL. 12345AVFormatContext *pFormatCtx = NULL;// Open video fileif (avformat_open_input(&amp;pFormatCtx, argv[1], NULL, NULL) != 0) return -1; // Couldn't open file Up to now, we have the handle(context) to the file. Find video stream There are several streams in one video file, for example, there is video stream, audio stream. Some has also subtitle stream. We firstly get the stream information, and it will be filled into pFormatCtx-&gt;nb_streams. 12345678910111213// Retrieve stream informationif (avformat_find_stream_info(pFormatCtx, NULL) &lt; 0) return -1; // Couldn't find stream information// Find the first video streamvideoStream = -1;printf(\"Stream counter: %d\\n\", pFormatCtx-&gt;nb_streams);for (i = 0; i &lt; pFormatCtx-&gt;nb_streams; i++) &#123; if (pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_VIDEO) &#123; videoStream = i; break; &#125;&#125; Then we try to find out which is the video stream. Codec context As not to destroy the information in the origin video, it’s better to make a copy to the video. 12345678910111213141516171819202122232425262728293031323334353637AVCodecContext *pCodecCtxOrig = NULL;AVCodecContext *pCodecCtx = NULL;AVCodec *pCodec = NULL;AVCodecParameters *par = NULL;// Allocate memory to store itpar = avcodec_parameters_alloc();// Get a pointer to the codec context for the video streampCodecCtxOrig = pFormatCtx-&gt;streams[videoStream]-&gt;codec;// Find the decoder for the video streampCodec = avcodec_find_decoder(pCodecCtxOrig-&gt;codec_id);if (pCodec == NULL) &#123; fprintf(stderr, \"Unsupported codec!\\n\"); return -1; // Codec not found&#125;else &#123; printf(\"Codec: %s!\\n\", pCodec-&gt;long_name);&#125;// Copy contextpCodecCtx = avcodec_alloc_context3(pCodec);if (avcodec_parameters_from_context(par, pCodecCtxOrig) &lt; 0) &#123; fprintf(stderr, \"Copy param from origin context failed!\\n\"); return -1; // Codec not found&#125;if (avcodec_parameters_to_context(pCodecCtx, par) &lt; 0) &#123; fprintf(stderr, \"Copy param to context failed!\\n\"); return -1; // Codec not found&#125;// Open codecif (avcodec_open2(pCodecCtx, pCodec, NULL) &lt; 0) return -1; // Could not open codec Read frame The core functionnality is here: 12345678910111213141516171819202122232425AVFrame *pFrame = NULL;AVPacket packet;// Allocate video framepFrame = av_frame_alloc();// Read frames and save first five frames to diski = 0;while (av_read_frame(pFormatCtx, &amp;packet) &gt;= 0) &#123; // Is this a packet from the video stream? if (packet.stream_index == videoStream) &#123; // Decode video frame // avcodec_decode_video2(pCodecCtx, pFrame, &amp;frameFinished, &amp;packet); avcodec_send_packet(pCodecCtx, &amp;packet); avcodec_receive_frame(pCodecCtx, pFrame); // Frame got if (++i == frameIndex) printf(\"Frame \\t%d: width - %d height - %d\\n\", i, pFrame-&gt;width, pFrame-&gt;height); &#125; // Free the packet that was allocated by av_read_frame // av_free_packet(&amp;packet); av_packet_unref(&amp;packet);&#125; In this code, we use av_read_frame to read a frame until there is no more frame. Then, avcodec_send_packet(pCodecCtx, &amp;packet); and avcodec_receive_frame(pCodecCtx, pFrame); are called to use the codec context to retrieve the frame in this packet. Then, we can get the frame information and the origin bytes stream in the AVFrame structure. Free memory Finally, do not forget to free all momeries which have been allocated. 1234567891011avcodec_parameters_free(&amp;par);// Free the YUV frameav_frame_free(&amp;pFrame);// Close the codecsavcodec_close(pCodecCtx);avcodec_close(pCodecCtxOrig);// Close the video fileavformat_close_input(&amp;pFormatCtx); Conclusion Up to here, we have been abled to retrieve all frames in a video, and may do some processing on it 😃 You should know how we can do a decoding of video using FFmpeg API. You can find the full code here: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#include &lt;stdio.h&gt;#include &lt;libavformat/avformat.h&gt;#include &lt;libavcodec/avcodec.h&gt;#include &lt;libavutil/avutil.h&gt;int main(int argc, char *argv[])&#123; // Initalizing these to NULL prevents segfaults! AVFormatContext *pFormatCtx = NULL; int i, videoStream; AVCodecContext *pCodecCtxOrig = NULL; AVCodecContext *pCodecCtx = NULL; AVCodec *pCodec = NULL; AVFrame *pFrame = NULL; AVPacket packet; AVCodecParameters *par = NULL; int frameIndex = 0; if (argc &lt; 3) &#123; printf(\"Please provide file path and frame index\"); return -1; &#125; frameIndex = atoi(argv[2]); if (frameIndex &lt;= 0) &#123; printf(\"Please provide a positive frame index\"); return -1; &#125; par = avcodec_parameters_alloc(); // Do not need // av_register_all(); // Open video file if (avformat_open_input(&amp;pFormatCtx, argv[1], NULL, NULL) != 0) return -1; // Couldn't open file // Retrieve stream information if (avformat_find_stream_info(pFormatCtx, NULL) &lt; 0) return -1; // Couldn't find stream information // Dump information about file onto standard error av_dump_format(pFormatCtx, 0, argv[1], 0); // Find the first video stream videoStream = -1; printf(\"Stream counter: %d\\n\", pFormatCtx-&gt;nb_streams); for (i = 0; i &lt; pFormatCtx-&gt;nb_streams; i++) &#123; if (pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_VIDEO) &#123; videoStream = i; break; &#125; &#125; if (videoStream == -1) return -1; // Didn't find a video stream printf(\"Stream %d is the video stream\\n\", videoStream); // Get a pointer to the codec context for the video stream pCodecCtxOrig = pFormatCtx-&gt;streams[videoStream]-&gt;codec; // Find the decoder for the video stream pCodec = avcodec_find_decoder(pCodecCtxOrig-&gt;codec_id); if (pCodec == NULL) &#123; fprintf(stderr, \"Unsupported codec!\\n\"); return -1; // Codec not found &#125; else &#123; printf(\"Codec: %s!\\n\", pCodec-&gt;long_name); &#125; // Copy context pCodecCtx = avcodec_alloc_context3(pCodec); if (avcodec_parameters_from_context(par, pCodecCtxOrig) &lt; 0) &#123; fprintf(stderr, \"Copy param from origin context failed!\\n\"); return -1; // Codec not found &#125; if (avcodec_parameters_to_context(pCodecCtx, par) &lt; 0) &#123; fprintf(stderr, \"Copy param to context failed!\\n\"); return -1; // Codec not found &#125; // Open codec if (avcodec_open2(pCodecCtx, pCodec, NULL) &lt; 0) return -1; // Could not open codec // Allocate video frame pFrame = av_frame_alloc(); // Read frames and save first five frames to disk i = 0; while (av_read_frame(pFormatCtx, &amp;packet) &gt;= 0) &#123; // Is this a packet from the video stream? if (packet.stream_index == videoStream) &#123; // Decode video frame // avcodec_decode_video2(pCodecCtx, pFrame, &amp;frameFinished, &amp;packet); avcodec_send_packet(pCodecCtx, &amp;packet); avcodec_receive_frame(pCodecCtx, pFrame); // Frame got if (++i == frameIndex) printf(\"Frame \\t%d: width - %d height - %d\\n\", i, pFrame-&gt;width, pFrame-&gt;height); &#125; // Free the packet that was allocated by av_read_frame // av_free_packet(&amp;packet); av_packet_unref(&amp;packet); &#125; avcodec_parameters_free(&amp;par); // Free the YUV frame av_frame_free(&amp;pFrame); // Close the codecs avcodec_close(pCodecCtx); avcodec_close(pCodecCtxOrig); // Close the video file avformat_close_input(&amp;pFormatCtx); return 0;&#125;","categories":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"https://blog.inoki.cc/categories/FFmpeg/"}],"tags":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"https://blog.inoki.cc/tags/FFmpeg/"}]},{"title":"Bug AX88179_178a USB-Ethernet adapter Linux Driver","slug":"Bug_AX88179_178a_USB_Ethernet_adapter_Linux_Driver","date":"2019-12-12T10:52:00.000Z","updated":"2025-03-08T09:40:48.548Z","comments":true,"path":"2019/12/12/Bug_AX88179_178a_USB_Ethernet_adapter_Linux_Driver/","link":"","permalink":"https://blog.inoki.cc/2019/12/12/Bug_AX88179_178a_USB_Ethernet_adapter_Linux_Driver/","excerpt":"","text":"In my previous post, AX88179_178a USB-Ethernet adapter Linux Driver, there is a simple analysis of the Linux Driver of AX88179_178a. And I mentioned that on the mainline, there is a bug while handling the USB packet that we received. Background The phenomenon is that the TLS connection cannot be established through a bridged network. Both in the two following cases: Bridged network on VirtualBox In VirtualBox, we setuped a bridged network via the device Edimax EU-4306, to connect the Virtual Machine with a raspberry. Bridged network on Raspberry Pi On device B, we made a network bridge to connect the PC and the device A. All the packets which don’t have a destination to device a will be resent to the other side. Diagnosis It was a mystery why in these two cases, the communication doesn’t work. So, I used Wireshark to do a monitoring on the interfaces. First one was running on the PC: We can see that, the first packet with 1514 length is the No.616. We should note that the packet No.617 is the one with length 336, and it acts as a TLS handshake packet. The second one is on the device B, monitoring the network interface which is created by Edimax EU-4306: The packet matches the No.616 is the packet No.1858 on this interface. And No.617 matches No.1859. Both of them has two bytes in addition at the end. The two bytes are translated as VSS-Monitoring ethernet trailer, Source Port: 26490 or something similar. The device B should resent all packets to the other network interface. Here is the traffic on the other network interface: We cannot find the index of packet, but we can well find the packet in order. The two we are following are the one with 1516 length and the one following it with 338 length. And finally, on the device A, our destination, we can see that all packets with 1516 length disappeared, which means that they are dropped. Problem Up to here, we can see that it’s the Edimax EU-4306 USB-Ethernet Adapter causing the bug. But, why? So, we need firstly introduce the concept of MTU, Maximum Transmission Unit. In Linux world and maybe the other system, it’s the maximum size, in byte, of a packet, which can be sent to a network interface. The sender will check the size of data it’s going to send, and do some segmentation to cut the data into packets if the size of data is larger than MTU. But the device which acts as a switch, that means which provides the bridged network, will not do the segmentation because it has no such permission. The device just receives a packet, and try to resend it to another physical network. Meanwhile, the network interface of this device will do a check of packet size. The packet will be dropped if it’s too large(larger than MTU). It’s kind of something abstract. So we just take the second case in the Background chapter as an example. This is the topology of the bridged network. All MTU in the picture are 1500, it’s also the one in the Ethernet protocol. To describe better the question, we just use a packet of size 1514(1500 + 6 bytes destionation MAC address + 6 bytes source MAC address + 2 bytes protocol type). The target is to send this packet to device A. The first step is using the USB network driver to wrap the network packet, with some necessary USB information. This will be done by Linux Kernel, and the output will be sent to the USB device. When the adapter receives the packet, it will handle with it, there may be some control message. The adapter squashes out the network packet, and send it to another side. Another side is also an adapter, it will wrap the network packet to a USB packet, as to send it to the USB Host. Here the USB Host is device B. Here, the adapter is well Edimax EU-4306 using AX88179_178a driver. The driver unwraps the USB packet, but unfortunately, adds two bytes at the end of network packet. So, the size of network packet becomes 1516, with two bytes in addition and by accident. Then, device B, as a switch, tries to resend the network packet to the other interface. But the other interface realizes the packet is larger than its MTU. Finally, it drops the network packet. Thus, device A will never receive the packet. Fixup Up to now, it’s clear that the error is caused by the reception function of AX88178_179a, while unwrapping a packet. Single packet To make it simpler, we come back to the tiny packet describe in my previous post: Obviously, the larger one is the USB packet. The analysis in detail of the packet can be found in that post. We’ll directly the data that is extracted from the packet. The packet length should be 0x3e -&gt; 62 bytes. So, if we count from 0040, the end should be at 007d. 123456789if (pkt_cnt == 0) &#123; /* Skip IP alignment psudo header */ skb_pull(skb, 2); skb-&gt;len = pkt_len; skb_set_tail_pointer(skb, pkt_len); skb-&gt;truesize = pkt_len + sizeof(struct sk_buff); ax88179_rx_checksum(skb, pkt_hdr); return 1;&#125; With the code on Linux mainline codebase: Remove the first two bytes because they are useless, and they just work as an auxiliary tool to align some bytes. Here, 0xee 0xee are removed , the length in the buffer structure is also reduced. So, the real packet size is 0x3c - 60 bytes. Then, set the length to the packet length: 0x3e. Finally, do something with the buffer. We don’t care this. If you are sensitive, you should have already realized that the problem occured in the second step. We begin at 0042 after the removing. But it always ends up with an offset of 62 bytes. So, we got a packet from 0xff 0xff to 0xf9 0xc2, where the last two bytes are not in the origin network packet, they are a part of USB packet. Here is my code to fix it up: 123456789if (pkt_cnt == 0) &#123; /* Skip IP alignment psudo header */ skb-&gt;len = pkt_len; skb_pull(skb, 2); skb_set_tail_pointer(skb, pkt_len); skb-&gt;truesize = skb-&gt;len + sizeof(struct sk_buff); ax88179_rx_checksum(skb, pkt_hdr); return 1;&#125; It’s really simple, I just change the order of the first step and the second step. It means that we’ll firstly change the size to the packet size that we extract, then we remove the first two bytes and reduce the size by 2. Thus, the packet is okay, with 60 bytes and from 0xff 0xff. Multiple packet For the case when we have plenty of network packets in a single USB packet, we do nearly the same thing: 123456789101112131415161718ax_skb = skb_clone(skb, GFP_ATOMIC);if (ax_skb) &#123; /* Code on mainline ax_skb-&gt;len = pkt_len; ax_skb-&gt;data = skb-&gt;data + 2; */ ax_skb-&gt;len = pkt_len; ax_skb-&gt;data = skb-&gt;data + 2; /* Skip IP alignment psudo header */ skb_pull(ax_skb, 2); skb_set_tail_pointer(ax_skb, pkt_len); ax_skb-&gt;truesize = ax_skb-&gt;len + sizeof(struct sk_buff); ax88179_rx_checksum(ax_skb, pkt_hdr); usbnet_skb_return(dev, ax_skb);&#125; else &#123; return 0;&#125; Okay, we test! Test We test it with the ARP packet mentioned in my last post: Here we can see the length is 60, no more 62. It means we fixed it! Conclusion This is a serious bug in common, but the use case is not in common: if the packet need not be resent, there is no panic because the protocol on top-level can well handle the packet length with its own length field. I hope one day the bug can be fixed on the mainline codebase of Linux. Maybe I can do that? As it’s a driver of a device for a manufacturer, I don’t know whether have the right to do that…","categories":[{"name":"Source Code","slug":"Source-Code","permalink":"https://blog.inoki.cc/categories/Source-Code/"},{"name":"Linux Driver","slug":"Source-Code/Linux-Driver","permalink":"https://blog.inoki.cc/categories/Source-Code/Linux-Driver/"},{"name":"Bug","slug":"Bug","permalink":"https://blog.inoki.cc/categories/Bug/"},{"name":"USB-Net","slug":"Source-Code/Linux-Driver/USB-Net","permalink":"https://blog.inoki.cc/categories/Source-Code/Linux-Driver/USB-Net/"},{"name":"Linux Driver","slug":"Linux-Driver","permalink":"https://blog.inoki.cc/categories/Linux-Driver/"},{"name":"Linux Driver","slug":"Bug/Linux-Driver","permalink":"https://blog.inoki.cc/categories/Bug/Linux-Driver/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Linux Driver","slug":"Linux-Driver","permalink":"https://blog.inoki.cc/tags/Linux-Driver/"},{"name":"ASIX","slug":"ASIX","permalink":"https://blog.inoki.cc/tags/ASIX/"},{"name":"Bug","slug":"Bug","permalink":"https://blog.inoki.cc/tags/Bug/"}]},{"title":"Write your first FFmpeg program on Windows","slug":"Write-your-first-ffmpeg-program-on-Windows","date":"2019-12-09T22:48:00.000Z","updated":"2025-03-08T09:40:48.603Z","comments":true,"path":"2019/12/09/Write-your-first-ffmpeg-program-on-Windows/","link":"","permalink":"https://blog.inoki.cc/2019/12/09/Write-your-first-ffmpeg-program-on-Windows/","excerpt":"","text":"FFmpeg is a complete, cross-platform solution to record, convert and stream audio and video. It’s not difficult to write your own simple video editor with it. This post will give you a guide, how to write a program with FFmpeg on Windows, with Visual Studio. Download FFmpeg library and development files In general, for an Open Source library, we may usually need build one from source code. And on Windows, it could be kind of confusing. Luckily, there is a nice hacker, who has built FFmpeg on Windows for us. We can find them on https://ffmpeg.zeranoe.com/builds/. What we need is two linking type files on Windows. So, for “Architecture”, Windows-32bits or Windows-64bits. And in linking, we need dev and shared. Shared library can proivde runtime for the compiled program, meanwhile, in dev, we will have header files and exported symbol information to use during development. Create VS Project Create a new Visual C++ project, do not use precompiled header file. Then, right click on the project to open Property panel. DLL files Add your ffmpeg-&lt;version&gt;-win64-shared\\bin into your system PATH. Include files Add your ffmpeg-&lt;version&gt;-win64-dev\\include into VC++ Directory -&gt; Include directory. Lib files Add your ffmpeg-&lt;version&gt;-win64-dev\\lib into VC++ Directory -&gt; Reference directory. Add swscale.lib, avutil.lib, avformat.lib, avcodec.lib, avdevice.lib, avfilter.lib, swresample.lib and postproc.lib into Linker -&gt; Input -&gt; Addons. Code This code comes from FFmpeg samples, it works as a video decoder but it just gets and prints video meta information. 1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;libavformat/avformat.h&gt;#include &lt;libavutil/dict.h&gt;int main (int argc, char **argv)&#123; AVFormatContext *fmt_ctx = NULL; AVDictionaryEntry *tag = NULL; int ret; if (argc != 2) &#123; printf(\"usage: %s &lt;input_file&gt;\\n\" \"example program to demonstrate the use of the libavformat metadata API.\\n\" \"\\n\", argv[0]); return 1; &#125; if ((ret = avformat_open_input(&amp;fmt_ctx, argv[1], NULL, NULL))) return ret; if ((ret = avformat_find_stream_info(fmt_ctx, NULL)) &lt; 0) &#123; av_log(NULL, AV_LOG_ERROR, \"Cannot find stream information\\n\"); return ret; &#125; while ((tag = av_dict_get(fmt_ctx-&gt;metadata, \"\", tag, AV_DICT_IGNORE_SUFFIX))) printf(\"%s=%s\\n\", tag-&gt;key, tag-&gt;value); avformat_close_input(&amp;fmt_ctx); return 0;&#125; Launch To run it in Visual Studio, in debugging, add the path of your video into command line arguments. And right click on the green triangle. In the terminal, you should be able to see the meta information like this: 1234major_brand=mp42minor_version=0compatible_brands=mp41isomcreation_time=2019-08-25T20:22:43.000000Z Enjoy!","categories":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"https://blog.inoki.cc/categories/FFmpeg/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://blog.inoki.cc/tags/Windows/"},{"name":"FFmpeg","slug":"FFmpeg","permalink":"https://blog.inoki.cc/tags/FFmpeg/"}]},{"title":"AX88179_178a USB-Ethernet adapter Linux Driver","slug":"AX88179_178a_USB_Ethernet_adapter_Linux_Driver","date":"2019-12-09T10:52:00.000Z","updated":"2025-03-08T09:40:48.545Z","comments":true,"path":"2019/12/09/AX88179_178a_USB_Ethernet_adapter_Linux_Driver/","link":"","permalink":"https://blog.inoki.cc/2019/12/09/AX88179_178a_USB_Ethernet_adapter_Linux_Driver/","excerpt":"","text":"In this post, we’ll analyze the Linux Driver of USB-Ethernet adapters, which are using AX88179/AX88178a chips. Introduction AX88179 and AX88178a is a chip from ASIX Electronics Corporation, which is a leading fabless semiconductor supplier with focus on networking, communication and connectivity applications, founded in May 1995 in Hsinchu Science Park, Taiwan. AX88179 is a USB3.0 to 10/100/1000M Gigabit Ethernet Controller, and AX88178a is the one for USB2.0. Since there are still lots of devices which are using USB 2.0, they are usually integrated into one single adapter to provide backward-compatibility. More information about the chips can be found on the offcial website of ASIX: AX88179 AX88178a The one which I’m using is an adapter from Edimax, named Edimax EU-4306 Adaptateur USB Ethernet. Everyone can buy it with a fair price - about 25 euros in France. Driver Selection The source code of the driver in current version kernel is located at drivers/net/usb/ax88179_178a.c. Its first commit is on Mar 2, 2013. So, up to now, we should be able to use it without panic. To validate that it can be rightly loaded in your system, just plug in. Use this command to find information of your device and the software assoiated with it: 12345678910&gt; usb-devices...T: Bus=02 Lev=01 Prnt=01 Port=00 Cnt=01 Dev#= 2 Spd=5000 MxCh= 0D: Ver= 3.00 Cls=ff(vend.) Sub=ff Prot=00 MxPS= 9 #Cfgs= 1P: Vendor=0b95 ProdID=1790 Rev=01.00S: Manufacturer=ASIX Elec. Corp.S: Product=AX88179S: SerialNumber=xxxxxxC: #Ifs= 1 Cfg#= 1 Atr=a0 MxPwr=496mAI: If#= 0 Alt= 0 #EPs= 3 Cls=ff(vend.) Sub=ff Prot=00 Driver=ax88179_178a We can see at the last line, there is Driver=ax88179_178a, which means my device uses the right driver. To associate a device and a usb driver, one important thing is the vendor ID and product ID, showing in the third line: Vendor=0b95 ProdID=1790. So, if your device cannot be allocated with an appropriate driver, pleas check the vendor ID and product ID of it. The ID table of compatible devices for AX88179/178a is defined as below: 12345678910111213141516171819202122232425262728293031323334353637static const struct usb_device_id products[] = &#123;&#123; /* ASIX AX88179 10/100/1000 */ USB_DEVICE(0x0b95, 0x1790), .driver_info = (unsigned long)&amp;ax88179_info,&#125;, &#123; /* ASIX AX88178A 10/100/1000 */ USB_DEVICE(0x0b95, 0x178a), .driver_info = (unsigned long)&amp;ax88178a_info,&#125;, &#123; /* Cypress GX3 SuperSpeed to Gigabit Ethernet Bridge Controller */ USB_DEVICE(0x04b4, 0x3610), .driver_info = (unsigned long)&amp;cypress_GX3_info,&#125;, &#123; /* D-Link DUB-1312 USB 3.0 to Gigabit Ethernet Adapter */ USB_DEVICE(0x2001, 0x4a00), .driver_info = (unsigned long)&amp;dlink_dub1312_info,&#125;, &#123; /* Sitecom USB 3.0 to Gigabit Adapter */ USB_DEVICE(0x0df6, 0x0072), .driver_info = (unsigned long)&amp;sitecom_info,&#125;, &#123; /* Samsung USB Ethernet Adapter */ USB_DEVICE(0x04e8, 0xa100), .driver_info = (unsigned long)&amp;samsung_info,&#125;, &#123; /* Lenovo OneLinkDock Gigabit LAN */ USB_DEVICE(0x17ef, 0x304b), .driver_info = (unsigned long)&amp;lenovo_info,&#125;, &#123; /* Belkin B2B128 USB 3.0 Hub + Gigabit Ethernet Adapter */ USB_DEVICE(0x050d, 0x0128), .driver_info = (unsigned long)&amp;belkin_info,&#125;, &#123; &#125;,&#125;;MODULE_DEVICE_TABLE(usb, products); Notice that USB_DEVICE is a macro defined in include/linux/usb.h, to quickly assign vendor ID and product ID. Meanwhile, make the mode be strictly matching, which means that only device has this vendor ID AND product ID will be allowed to use this driver. 1234#define USB_DEVICE(vend, prod) \\ .match_flags = USB_DEVICE_ID_MATCH_DEVICE, \\ .idVendor = (vend), \\ .idProduct = (prod) More, products is a table of type struct usb_device_id, defined in include/linux/mod_devicetable.h. Since we’ve already included include/linux/usb.h\\(&lt;linux/usb.h&gt;\\), we do not need import it once more. 123456789101112131415161718192021222324252627struct usb_device_id &#123; /* which fields to match against? */ __u16 match_flags; /* Used for product specific matches; range is inclusive */ __u16 idVendor; __u16 idProduct; __u16 bcdDevice_lo; __u16 bcdDevice_hi; /* Used for device class matches */ __u8 bDeviceClass; __u8 bDeviceSubClass; __u8 bDeviceProtocol; /* Used for interface class matches */ __u8 bInterfaceClass; __u8 bInterfaceSubClass; __u8 bInterfaceProtocol; /* Used for vendor-specific interface matches */ __u8 bInterfaceNumber; /* not matched against */ kernel_ulong_t driver_info __attribute__((aligned(sizeof(kernel_ulong_t))));&#125;; But, if yours is not one of them, it might be another device. This post will have limited usage to you. Driver module registration To make system be able to allocate the right driver, we need register the driver. usb_driver structure The structure to describe a driver for USB is defined in include/linux/usb.h: 12345678910111213141516171819202122232425262728struct usb_driver &#123; const char *name; int (*probe) (struct usb_interface *intf, const struct usb_device_id *id); void (*disconnect) (struct usb_interface *intf); int (*unlocked_ioctl) (struct usb_interface *intf, unsigned int code, void *buf); int (*suspend) (struct usb_interface *intf, pm_message_t message); int (*resume) (struct usb_interface *intf); int (*reset_resume)(struct usb_interface *intf); int (*pre_reset)(struct usb_interface *intf); int (*post_reset)(struct usb_interface *intf); const struct usb_device_id *id_table; const struct attribute_group **dev_groups; struct usb_dynids dynids; struct usbdrv_wrap drvwrap; unsigned int no_dynamic_id:1; unsigned int supports_autosuspend:1; unsigned int disable_hub_initiated_lpm:1; unsigned int soft_unbind:1;&#125;; It’s a huge one, but we need not define all of them. What we need is just: 1234567891011static struct usb_driver ax88179_178a_driver = &#123; .name = \"ax88179_178a\", .id_table = products, .probe = usbnet_probe, .suspend = ax88179_suspend, .resume = ax88179_resume, .reset_resume = ax88179_resume, .disconnect = usbnet_disconnect, .supports_autosuspend = 1, .disable_hub_initiated_lpm = 1,&#125;; .name This is the name of driver, and it will be shown at the last line of the output of usb-devices. I got the output above by changing the name to ax88179_178a_inoki. struct usb_interface *intf We can see that many of fields are pointers to functions with an argument of type struct usb_interface *intf. It’s defined in include/linux/usb.h. 1234567891011121314151617181920212223242526272829struct usb_interface &#123; /* array of alternate settings for this interface, * stored in no particular order */ struct usb_host_interface *altsetting; struct usb_host_interface *cur_altsetting; /* the currently * active alternate setting */ unsigned num_altsetting; /* number of alternate settings */ /* If there is an interface association descriptor then it will list * the associated interfaces */ struct usb_interface_assoc_descriptor *intf_assoc; int minor; /* minor number this interface is * bound to */ enum usb_interface_condition condition; /* state of binding */ unsigned sysfs_files_created:1; /* the sysfs attributes exist */ unsigned ep_devs_created:1; /* endpoint \"devices\" exist */ unsigned unregistering:1; /* unregistration is in progress */ unsigned needs_remote_wakeup:1; /* driver requires remote wakeup */ unsigned needs_altsetting0:1; /* switch to altsetting 0 is pending */ unsigned needs_binding:1; /* needs delayed unbind/rebind */ unsigned resetting_device:1; /* true: bandwidth alloc after reset */ unsigned authorized:1; /* used for interface authorization */ struct device dev; /* interface specific device info */ struct device *usb_dev; struct work_struct reset_ws; /* for resets in atomic context */&#125;; With this parameter, we can distinguish which device is under operating. As well, it requires the caller pass a right reference 😃 .probe = usbnet_probe The usbnet_probe is a function defined in include/linux/usb/usbnet.h. 1extern int usbnet_probe(struct usb_interface *, const struct usb_device_id *); When a device is plugged into the USB bus that matches the device ID that your driver registered with the USB core, the probe function is called, with the interface instance, and the device information. .disconnect = usbnet_disconnect Conversely, when the device is removed from the USB bus, the disconnect function is called with the device pointer. For this callback and the callback which will be used in probing, the driver uses the standard USB net functions in include/linux/usb/usbnet.h. 1extern void usbnet_disconnect(struct usb_interface *); There are lots of standard functions defined in this header file. But we cannot expect the standard stuff can handle with all devices. So, in most case, we need write our own handlers for specific devices. .suspend = ax88179_suspend Called when the device is going to be suspended by the system either from system sleep or runtime suspend context. This line can let the specific function suspend in the driver codebase be called. .resume = ax88179_resume and .reset_resume = ax88179_resume .resume will be called when the device is being resumed by the system. .reset_resume will be called when the suspended device has been reset instead of being resumed. Both two can let the specific function resume in the driver codebase be called. Registration Then, register the driver in the system. 1module_usb_driver(ax88179_178a_driver); It’s not a function, but a macro defined in include/linux/usb.h: 123#define module_usb_driver(__usb_driver) \\ module_driver(__usb_driver, usb_register, \\ usb_deregister) Then it will be expanded to a set of instructions in include/linux/device.h. 1234567891011#define module_driver(__driver, __register, __unregister, ...) \\static int __init __driver##_init(void) \\&#123; \\ return __register(&amp;(__driver) , ##__VA_ARGS__); \\&#125; \\module_init(__driver##_init); \\static void __exit __driver##_exit(void) \\&#123; \\ __unregister(&amp;(__driver) , ##__VA_ARGS__); \\&#125; \\module_exit(__driver##_exit); Such instructions can control the life cycle of a driver module. But we’ll not go deeper into the module functions, becaus they are out of scope. Here, we come back to the module_usb_driver macro. Except __usb_driver is the specific driven instance, usb_register and usb_deregister could be also an interesting point in this post. In fact, they are defined in include/linux/usb.h as well: 123456789101112/* * use these in module_init()/module_exit() * and don't forget MODULE_DEVICE_TABLE(usb, ...) */extern int usb_register_driver(struct usb_driver *, struct module *, const char *);/* use a define to avoid include chaining to get THIS_MODULE &amp; friends */#define usb_register(driver) \\ usb_register_driver(driver, THIS_MODULE, KBUILD_MODNAME)extern void usb_deregister(struct usb_driver *); The 2 functions will be called while module is being initialized or is being exited. Core Functions After the module life cycle management, here we need talk more about the actions of driver, while there are arriving packets. Except vendor ID and product ID, there is also driver_info field which is set according to the different devices. 123456789&#123; /* ASIX AX88179 10/100/1000 */ USB_DEVICE(0x0b95, 0x1790), .driver_info = (unsigned long)&amp;ax88179_info,&#125;, &#123; /* ASIX AX88178A 10/100/1000 */ USB_DEVICE(0x0b95, 0x178a), .driver_info = (unsigned long)&amp;ax88178a_info,&#125; Driver Info We can take a look at the 0x0b95, 0x1790(AX88179) and 0x0b95, 0x178(AX88178A). The driver info is an unsigned long pointer to the struct driver_info instance. Thus, Linux kernel can find the driver info instance when it needs. The driver info structure is in fact a USB network driver info structure, defined in include/linux/usb/usbnet.h: 12345678910111213141516171819202122struct driver_info &#123; char *description; int flags; int (*bind)(struct usbnet *, struct usb_interface *); void (*unbind)(struct usbnet *, struct usb_interface *); int (*reset)(struct usbnet *); int (*stop)(struct usbnet *); int (*check_connect)(struct usbnet *); int (*manage_power)(struct usbnet *, int); void (*status)(struct usbnet *, struct urb *); int (*link_reset)(struct usbnet *); int (*rx_fixup)(struct usbnet *dev, struct sk_buff *skb); struct sk_buff *(*tx_fixup)(struct usbnet *dev, struct sk_buff *skb, gfp_t flags); void (*recover)(struct usbnet *dev); int (*early_init)(struct usbnet *dev); void (*indication)(struct usbnet *dev, void *ind, int indlen); void (*set_rx_mode)(struct usbnet *dev); int in; /* rx endpoint */ int out; /* tx endpoint */ unsigned long data; /* Misc driver specific data */&#125;; Just like the other huge structure, we will only use a small part of it. AX88179 Driver Info 123456789101112static const struct driver_info ax88179_info = &#123; .description = \"ASIX AX88179 USB 3.0 Gigabit Ethernet\", .bind = ax88179_bind, .unbind = ax88179_unbind, .status = ax88179_status, .link_reset = ax88179_link_reset, .reset = ax88179_reset, .stop = ax88179_stop, .flags = FLAG_ETHER | FLAG_FRAMING_AX, .rx_fixup = ax88179_rx_fixup, .tx_fixup = ax88179_tx_fixup,&#125;; AX88178a Driver Info 123456789101112static const struct driver_info ax88178a_info = &#123; .description = \"ASIX AX88178A USB 2.0 Gigabit Ethernet\", .bind = ax88179_bind, .unbind = ax88179_unbind, .status = ax88179_status, .link_reset = ax88179_link_reset, .reset = ax88179_reset, .stop = ax88179_stop, .flags = FLAG_ETHER | FLAG_FRAMING_AX, .rx_fixup = ax88179_rx_fixup, .tx_fixup = ax88179_tx_fixup,&#125;; .flags In flags, we might have several bitwise flag. This is created for some special feature of each device. In these two devices, we have Ethernet device feature and ASIX specific device features. 12#define FLAG_ETHER 0x0020 /* maybe use \"eth%d\" names */#define FLAG_FRAMING_AX 0x0040 /* AX88772/178 packets */ Lifecycle-related sequence System will call the function pointed by .bind to initialize device. The one pointed by .unbind will be called to do a cleanup in the system. To reset device, system will call .reset. To actively stop device, .stop will be invoked. Linux will also use .status to query the device satus. And .link_reset can be called for link reset handling purpose. These functions are so long and so device-specific that we do not need to concentrate on them. The most important functionality is transmission of packets, which is implemented by .rx_fixup(for receiving), and .tx_fixup(for sending). .rx_fixup The function pointed by .rx_fixup works on doing frame stripping. What’s frame stripping? These are two screenshots of an ARP network packet in USB traffic(above) and in Ethernet traffic(below), captured by Wireshark. We can see that the highlighted part, from 0042 to 0079 in USB traffic, is exactly the same thing. So, what has RX fixup done is clear: it tries to extract the Ethernet packet from a USB frame. Function Prototype 1static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb); The function accepts two parameters, one is the deivce, the other is the data received. The type struct sk_buff is defined in include/linux/skbuff.h, and is widely used in the network modules. It’s the abbreviation of socket buffer. Implementation on mainline In this chapter, we’ll take a look at every lines of this function on Linux Kernel mainline. First, complying to C89, all of variables should be declared at the beginning of the scope block. 12345struct sk_buff *ax_skb;int pkt_cnt;u32 rx_hdr;u16 hdr_off;u32 *pkt_hdr; ax_skb is a pointer which can point to a new socket buffer instance. pkt_cnt is the counter of packet, which counts how many packets are there in the packet. rx_hdr can represent the header of the USB packet that we received, this variable is a 32 bits one, or 4 bytes or 4 octets. pkt_hdr is a pointer to unsigned 32 bits integer, literally it can point to the header of packet. hdr_off is an unsigned 16 bits integer, which records the offset of real header. 123/* This check is no longer done by usbnet */if (skb-&gt;len &lt; dev-&gt;net-&gt;hard_header_len) return 0; In current version, the driver should check the length is compliable with the device or not. return 0 means that the packet isn’t handled correctly. And then, it uses skb_trim to cut the last 4 bytes, reduce the length and calculate other fields in the structure. 1skb_trim(skb, skb-&gt;len - 4); To know better how it works, we can take the previous packet to make an example: With the trim function, the last 01 00 04 00 should be dropped. 12memcpy(&amp;rx_hdr, skb_tail_pointer(skb), 4);le32_to_cpus(&amp;rx_hdr); But in fact, they are not totally dropper, the data is still their. The next step is rightly copying them into rx_hdr, with correspondant byte order. For example, my Linux is x86_64, so with little-endian. And the 01 00 is exactly 0x0001 in our brain. So, the number should be 00 40 00 01. 12pkt_cnt = (u16)rx_hdr;hdr_off = (u16)(rx_hdr &gt;&gt; 16); Then, with some magic, we can assign the packet counter pkt_cnt and the header offset hdr_off. With the humain readable representation 00 40 00 01, we could see there is one packet and the offset is 64 bytes (0x40 in decimal). 1pkt_hdr = (u32 *)(skb-&gt;data + hdr_off); We’ll have the header of the packet with pkt_hdr variable. In our case, it will point at a byte which has 0x40 offset from the beginning of the packet. We should notice that, the packet begins at 0x40, so, with the offset, it should point at 0x80, where there are 00 88 3e 00. Then, we’ill attemp to iterately get all network packets in this single USB packet. 1while (pkt_cnt--) &#123; As usual, do the initialization at first. We will extract the length of each packet to pkt_len. 12u16 pkt_len;le32_to_cpus(pkt_hdr); Extract packet length. 1pkt_len = (*pkt_hdr &gt;&gt; 16) &amp; 0x1fff; Here, we should have 00 3e 00 88 as the human readable order. So, the packet length should be 0x3e -&gt; 62 bytes. If we look at the USB-Net packet capture, we could know it’s correct! 1234567/* Check CRC or runt packet */if ((*pkt_hdr &amp; AX_RXHDR_CRC_ERR) || (*pkt_hdr &amp; AX_RXHDR_DROP_ERR)) &#123; skb_pull(skb, (pkt_len + 7) &amp; 0xFFF8); pkt_hdr++; continue;&#125; If AX_RXHDR_CRC_ERR or AX_RXHDR_DROP_ERR is set, just drop this packet because it’s not what we want. We only care the network packet. 12#define AX_RXHDR_CRC_ERR ((u32)BIT(29))#define AX_RXHDR_DROP_ERR ((u32)BIT(31)) The two flags are defined at the top of source code file. We can see in our packet, the 29th bit and the 31st bit are both 0. So, just ignore the code mentioned above. We continue. 123456789if (pkt_cnt == 0) &#123; /* Skip IP alignment psudo header */ skb_pull(skb, 2); skb-&gt;len = pkt_len; skb_set_tail_pointer(skb, pkt_len); skb-&gt;truesize = pkt_len + sizeof(struct sk_buff); ax88179_rx_checksum(skb, pkt_hdr); return 1;&#125; If we are handling the last packet, firstly we remove the first two bytes. They are two 0xee at the beginning. In this function, the length will also be reduced by 2. But it’s not the pkt_len, it’s the length field in the socket buffer instance which is reduced. Then, we update the length to the right length of Network Packet and do some cleanup work. Then the stripped frame will be used by the system, as a network packet. Note: only the last packet will be “returned” by the origin socket buffer. But if we take a look at the end of the network packet, there are serveral bytes which are not used by the protocol itself. This will lead an error, I’ll talk about it in the next post. 1234567891011121314ax_skb = skb_clone(skb, GFP_ATOMIC);if (ax_skb) &#123; ax_skb-&gt;len = pkt_len; ax_skb-&gt;data = skb-&gt;data + 2; skb_set_tail_pointer(ax_skb, pkt_len); ax_skb-&gt;truesize = pkt_len + sizeof(struct sk_buff); ax88179_rx_checksum(ax_skb, pkt_hdr); usbnet_skb_return(dev, ax_skb);&#125; else &#123; return 0;&#125;skb_pull(skb, (pkt_len + 7) &amp; 0xFFF8);pkt_hdr++; Finally in the loop, we know that there are still several network packets in the USB packet. So we try to clone the raw packet, regulate the boundary, and return it by usbnet_skb_return function. If there are still packets to be handled, go on. 1&#125; Otherwise, the loop ends. 1return 1; In the end, if we reach here, it means there are not any more the packets to be handled. So, it “reports” to the system that we’ve finished succefully. .tx_fixup After analysis of RX fixup, what TX fixup should do is obvious. It just wrapped the raw paquet into a USB frame, and send it to the device. The device will send it to the other side. Function Prototype 12static struct sk_buff *ax88179_tx_fixup(struct usbnet *dev, struct sk_buff *skb, gfp_t flags) The two first parameters have the same type, and the same usage as the two in RX fixup. The last one is a set of flags, but it’s not used in the implementation. So, we neglict it. Implementation on mainline 123456u32 tx_hdr1, tx_hdr2;int frame_size = dev-&gt;maxpacket;int mss = skb_shinfo(skb)-&gt;gso_size;int headroom;tx_hdr1 = skb-&gt;len;tx_hdr2 = mss; Declarations and initializations of variables. 1234if (((skb-&gt;len + 8) % frame_size) == 0) tx_hdr2 |= 0x80008000; /* Enable padding */headroom = skb_headroom(skb) - 8; skb_headroom returns the number of bytes of free space at the head of an sk_buff. So, this is a boundary check for adding more bytes. 12345if ((skb_header_cloned(skb) || headroom &lt; 0) &amp;&amp; pskb_expand_head(skb, headroom &lt; 0 ? 8 : 0, 0, GFP_ATOMIC)) &#123; dev_kfree_skb_any(skb); return NULL;&#125; If our socket buffer is a clone or we have no more space to store stuff, we’ll fail to send. 123skb_push(skb, 4);cpu_to_le32s(&amp;tx_hdr2);skb_copy_to_linear_data(skb, &amp;tx_hdr2, 4); Append the flag to the current end of packet. 123skb_push(skb, 4);cpu_to_le32s(&amp;tx_hdr1);skb_copy_to_linear_data(skb, &amp;tx_hdr1, 4); Copy the length to the end of packet. 1return skb; Return the instance. Conclusion By analyzing this codebase, we should be able to know how a USB network device works. In the next post, I’ll talk about the serious bug which is found in this driver. See you!","categories":[{"name":"Source Code","slug":"Source-Code","permalink":"https://blog.inoki.cc/categories/Source-Code/"},{"name":"Linux Driver","slug":"Source-Code/Linux-Driver","permalink":"https://blog.inoki.cc/categories/Source-Code/Linux-Driver/"},{"name":"USB-Net","slug":"Source-Code/Linux-Driver/USB-Net","permalink":"https://blog.inoki.cc/categories/Source-Code/Linux-Driver/USB-Net/"},{"name":"Linux Driver","slug":"Linux-Driver","permalink":"https://blog.inoki.cc/categories/Linux-Driver/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Linux Driver","slug":"Linux-Driver","permalink":"https://blog.inoki.cc/tags/Linux-Driver/"},{"name":"ASIX","slug":"ASIX","permalink":"https://blog.inoki.cc/tags/ASIX/"}]},{"title":"Install Linux QQ on ChromeOS","slug":"Install-linux-QQ-on-chromeos","date":"2019-12-08T22:38:00.000Z","updated":"2025-03-08T09:40:48.568Z","comments":true,"path":"2019/12/08/Install-linux-QQ-on-chromeos/","link":"","permalink":"https://blog.inoki.cc/2019/12/08/Install-linux-QQ-on-chromeos/","excerpt":"","text":"Recently, Tencent has updated and released their out-of-date QQ client for Linux, on their official Linux QQ website. Meanwhile, Chrome OS has already an experimental feature: Linux subsystem, which is equipped with a Linux distro named Penguin, under Debian. So, installing the full-featured desktop QQ on Chrome OS can be interesting. Get the right package We can see that, there are several options on the download page. But which one should we choose ? It depends on the architecture of your Chrome Book. We need to recognise it to choose the right version. So, firstly, we need to check the archtecture. Architecture Open your Linux terminal and run the uname -m command. My output is like this: 12&gt; uname -mx86_64 Intel processor: x86_64 Here I have x86_64. If yours is same with mine, fortunately, we can directly download the deb in the x64 line. As well, if yours is amd64 or i686, you should be able to use the same package. It means you have Intel/AMD x86 processor and the machine is running in 64 bit mode. If you have x86 processor, but you’ve got something like i386, you may have a wrong version Chrome OS. Please check it! ARM 64 bits processor: aarch64 If you’ve got one of these: aarch64 arm64 You should be able to use deb in the ARM64 line. The string arm64 was created by Apple for its 64 bits ARM processor. But it’s not an official name of ARM 64 processors. Apple finally removed it and adopts aarch64, see here. But maybe it’s still being used by some machines somewhere. So, if you have one of them, just choose one in the ARM64 line. mips 64 bits, little endian processor: mips64el If you’ve seen mips64el, unfortunately, you need choose the only version in the MIPS64 line. If you’ve seen only mips, you cannot use any version on that page. We don’t have either the source code. So, explain to Tencent 😃 Format The distro penguin is one based on Debain, so the easiest way is to download deb file. But, considering the mips processor, some people may need use the shell script, because of missing of deb. Dependence Before installing, we need prepare the dependence of it. It requires gtk 2.0 library to run the GUI. On Debian distro like Penguin, just run 1&gt; sudo apt install libgtk2.0-0 Well done! Install It’s very simple to install it. Just open a terminal, and find the instruction for your format. deb To install deb file, just run 1&gt; sudo dpkg -i linuxqq_1.0.1-b1-100_&lt;arch&gt;.deb or 1&gt; sudo apt install -y /path/to/linuxqq_1.0.1-b1-100_&lt;arch&gt;.deb shell To install shell, just run 1&gt; sudo ./linuxqq_1.0.1-b1-100_&lt;arch&gt;.sh The script will create a tarball and extract it to your system. Run Run linuxqq in the terminal or click on the icon in your Chrome OS to launch it. Problem of character displaying You may see that in the picture, there are lots of characters which are not being shown correctly. Because in the Linux distro, there is not chinese font to show them. We can install a chinese font to display them correctly. 1&gt; sudo apt-get install ttf-wqy-zenhei ttf-wqy-microhei Rerun After installation, run it: It’s okay! Enjoy!","categories":[{"name":"Chrome OS","slug":"Chrome-OS","permalink":"https://blog.inoki.cc/categories/Chrome-OS/"}],"tags":[{"name":"Chrome OS","slug":"Chrome-OS","permalink":"https://blog.inoki.cc/tags/Chrome-OS/"}]},{"title":"【译】Python 脚本导致数以百计的论文无效","slug":"Python-invalidate-hundreds-of-papers","date":"2019-10-22T22:59:24.000Z","updated":"2025-03-08T09:40:48.592Z","comments":true,"path":"2019/10/22/Python-invalidate-hundreds-of-papers/","link":"","permalink":"https://blog.inoki.cc/2019/10/22/Python-invalidate-hundreds-of-papers/","excerpt":"","text":"原文链接：https://i-programmer.info/news/231-methodology/13188-python-script-invalidates-hundreds-of-papers.html 该新闻之所以有趣，不仅是因为它给我们所有人上了一课，还因为它被报道为“ Bug In Python Script …”，并暗示 Python 是问题的起因。实际上，真相更加有趣。 该脚本大约是有 1000 行 Python 代码，它不是一个小程序。这个由 Patrick Willoughby，Matthew Jansma 和 Thomas Hoye 创建的脚本，自 2014 年以来一直在使用，用来获取原始数据并计算 NMR 位移。在《自然协议》杂志中，它被称为“Willoughby-Hoye”脚本。 原本一切都正常，直到夏威夷大学的研究人员注意到当在不同的操作系统上运行相同的数据和脚本时，他们得到了不同的结果。 Windows 和一个版本的 MacOS 给出了正确的答案，但另一个版本的 MacOS 和 Ubuntu 给出了错误的结果。这不是您对错误的预期行为：错误通常不仅在某些环境中有，而是在任何环境中都存在。 那么，是什么问题呢？ 问题一直被追溯到数据检索的方式。每次运行的数据都存储在两个文件中。这些文件是按文件名成对检索并成对处理的。问题在于，文件的检索顺序根据操作系统而不同。只要文件对匹配，您就可以获得正确的结果。如果没有配对，将会处理两次不同运行中产生的数据。 许多新闻报道的罪魁祸首是 Python 标准库模块 glob，它将返回与文件/路径规范匹配的文件列表，包括通配符。它可以工作，但是没有按指定顺序返回结果。这是错误吗？并不是的。 glob 的文档的第一句话就是： “尽管结果以任意顺序返回，但 glob 模块根据 Unix shell 使用的规则查找与指定模式匹配的所有路径名。” 因此，这几乎不是错误。之后怎么样了？正式的用户（任务不是编程的编程人员）经常对什么是合理的做出假设，而不考虑不编写健壮代码的后果。通过以粗体显示“以任意顺序返回”，文档是否对所有人都有用？执行特定命令而不是将其保留为未定义的行为会更合理吗？某些操作系统似乎返回排序列表而使问题更加复杂，因此应当确认用户的假设。操作系统是否应该付出更多努力以使列表以任意顺序返回？ 从未定义的行为的角度上来说，这个问题也许并不是任何人的错。 在这种情况下，不返回排序列表的原因是效率：如果很多用户不需要对列表进行排序，为什么还要对列表进行排序？ 您可以说，更好的编程技能会有所帮助。例如，包括一些测试可能会发现问题所在，但是会吗？如果您要编写测试，则需要了解您的假设，如果程序员知道此关键假设，他们会注意到文档中的第一句话并避免使用它。为您知道必须是真实的事情编写测试需要大量的标准和准则。 我们如何减少再次发生这种情况的可能性呢？","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"}]},{"title":"Python Source Code Analysis (1)","slug":"Python-code-analyse-1","date":"2019-10-21T16:49:40.000Z","updated":"2025-03-08T09:40:48.591Z","comments":true,"path":"2019/10/21/Python-code-analyse-1/","link":"","permalink":"https://blog.inoki.cc/2019/10/21/Python-code-analyse-1/","excerpt":"","text":"In this post, we will take a dissecion of source code of Python. To benefit the simplicity and meanwhile follow the most recent functionnalities, I choose Python 3.6.9 to do the analysis. In the last post, the entry of Python is found, so it’s time to look at it! Py_Main - the Python Main function According to C89 standard, in a C function, all the variables should be declared at the beginning. So, we can take a look at those variables. Variables The variables are listed below, though we’ll not explicite them at the moment. 1234567891011121314151617181920 int c; int sts; wchar_t *command = NULL; wchar_t *filename = NULL; wchar_t *module = NULL; FILE *fp = stdin; char *p;#ifdef MS_WINDOWS wchar_t *wp;#endif int skipfirstline = 0; int stdin_is_interactive = 0; int help = 0; int version = 0; int saw_unbuffered_flag = 0; char *opt; PyCompilerFlags cf; PyObject *main_importer_path = NULL; PyObject *warning_option = NULL; PyObject *warning_options = NULL; Arguments Then, after listing and initializing all variables, Python will try to find flags in the arguments. First, Python tries to find some options which are needed by some initializations. 12345678910111213/* Hash randomization needed early for all string operations (including -W and -X options). */while ((c = _PyOS_GetOpt(argc, argv, PROGRAM_OPTS)) != EOF) &#123; if (c == 'm' || c == 'c') &#123; /* -c / -m is the last option: following arguments are not interpreter options. */ break; &#125; if (c == 'E') &#123; Py_IgnoreEnvironmentFlag++; break; &#125;&#125; PROGRAM_OPTS is defined as BASE_OPTS, and #define BASE_OPTS L&quot;bBc:dEhiIJm:OqRsStuvVW:xX:?&quot; is at the header of main.c. _PyOS_GetOpt is implemented in Python/getopt.c, which validates and returns argument option. If an option is not in PROGRAM_OPTS, a _ will be returned. It will not accept --argument and returns a -1 if an argument with that form is found. In these lines, only options E, m, c are detected: if E is detected, the flag which leads to the negligence of PYTHONPATH, PYTHONHOME environment variables. once m or c is detected, following parameters should be the name of module(for m option) or the command that will be executed(for c option). So we terminated this loop. Then, Python gets the PYTHONMALLOC variables and tries to use it to setup allocators. 123456opt = Py_GETENV(\"PYTHONMALLOC\");if (_PyMem_SetupAllocators(opt) &lt; 0) &#123; fprintf(stderr, \"Error in PYTHONMALLOC: unknown allocator \\\"%s\\\"!\\n\", opt); exit(1);&#125; Valid allocators are pymalloc, pymalloc_debug, malloc, malloc_debug and debug. If you’d like to get more about them, Objects/obmalloc.c is a good place. And then Python does an initialization of Random module. In this module, PYTHONHASHSEED can be used to initialize random module. And it resets warning options, resets option parsing process to process all options. 12345678_PyRandom_Init();PySys_ResetWarnOptions();_PyOS_ResetGetOpt();while ((c = _PyOS_GetOpt(argc, argv, PROGRAM_OPTS)) != EOF) &#123; // ...&#125; We finally enter the period to parse all arguments. They will be explicited in order. Option c -c cmd : program passed in as string (terminates option list)` 12345678910111213141516if (c == 'c') &#123; size_t len; /* -c is the last option; following arguments that look like options are left for the command to interpret. */ len = wcslen(_PyOS_optarg) + 1 + 1; command = (wchar_t *)PyMem_RawMalloc(sizeof(wchar_t) * len); if (command == NULL) Py_FatalError( \"not enough memory to copy -c argument\"); wcscpy(command, _PyOS_optarg); command[len - 2] = '\\n'; command[len - 1] = 0; break;&#125; If we encounter an c option, all other arguments will be neglected. The following argument will be parsed as the commands to be run. Option m -m mod : run library module as a script (terminates option list) 1234567if (c == 'm') &#123; /* -m is the last option; following arguments that look like options are left for the module to interpret. */ module = _PyOS_optarg; break;&#125; If we encounter an m option, all other arguments will be neglected. The following argument will be parsed as the module to be run. Other options 1234567891011121314151617181920212223-B : don&apos;t write .py[co] files on import; also PYTHONDONTWRITEBYTECODE=x-d : debug output from parser; also PYTHONDEBUG=x-E : ignore PYTHON* environment variables (such as PYTHONPATH)-h : print this help message and exit (also --help)-i : inspect interactively after running script; forces a prompt even if stdin does not appear to be a terminal; also PYTHONINSPECT=x-O : optimize generated bytecode slightly; also PYTHONOPTIMIZE=x-OO : remove doc-strings in addition to the -O optimizations-R : use a pseudo-random salt to make hash() values of various types be unpredictable between separate invocations of the interpreter, as a defense against denial-of-service attacks-Q arg : division options: -Qold (default), -Qwarn, -Qwarnall, -Qnew-s : don&apos;t add user site directory to sys.path; also PYTHONNOUSERSITE-S : don&apos;t imply &apos;import site&apos; on initialization-t : issue warnings about inconsistent tab usage (-tt: issue errors)-u : unbuffered binary stdout and stderr; also PYTHONUNBUFFERED=x see man page for details on internal buffering relating to &apos;-u&apos;-v : verbose (trace import statements); also PYTHONVERBOSE=x can be supplied multiple times to increase verbosity-V : print the Python version number and exit (also --version)-W arg : warning control; arg is action:message:category:module:lineno also PYTHONWARNINGS=arg-x : skip first line of source, allowing use of non-Unix forms of #!cmd 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100switch (c) &#123;case 'b': Py_BytesWarningFlag++; break;case 'd': Py_DebugFlag++; break;case 'i': Py_InspectFlag++; Py_InteractiveFlag++; break;case 'I': Py_IsolatedFlag++; Py_NoUserSiteDirectory++; Py_IgnoreEnvironmentFlag++; break;/* case 'J': reserved for Jython */case 'O': Py_OptimizeFlag++; break;case 'B': Py_DontWriteBytecodeFlag++; break;case 's': Py_NoUserSiteDirectory++; break;case 'S': Py_NoSiteFlag++; break;case 'E': /* Already handled above */ break;case 't': /* ignored for backwards compatibility */ break;case 'u': Py_UnbufferedStdioFlag = 1; saw_unbuffered_flag = 1; break;case 'v': Py_VerboseFlag++; break;case 'x': skipfirstline = 1; break;case 'h':case '?': help++; break;case 'V': version++; break;case 'W': if (warning_options == NULL) warning_options = PyList_New(0); if (warning_options == NULL) Py_FatalError(\"failure in handling of -W argument\"); warning_option = PyUnicode_FromWideChar(_PyOS_optarg, -1); if (warning_option == NULL) Py_FatalError(\"failure in handling of -W argument\"); if (PyList_Append(warning_options, warning_option) == -1) Py_FatalError(\"failure in handling of -W argument\"); Py_DECREF(warning_option); break;case 'X': PySys_AddXOption(_PyOS_optarg); break;case 'q': Py_QuietFlag++; break;case 'R': /* Ignored */ break;/* This space reserved for other options */default: return usage(2, argv[0]); /*NOTREACHED*/&#125; Actions and behaviors After recording all options in specified flags, Python can handle them with a determined order or a determined prority (if actions are incompatible). Help, Version 1234567if (help) return usage(0, argv[0]);if (version) &#123; printf(\"Python %s\\n\", version &gt;= 2 ? Py_GetVersion() : PY_VERSION); return 0;&#125; The option for help has the highest priority, then the option for the version. If they occured, Python will directly terminate after executing their proper actions. Sync with env Then, Python tries to get env 12345678910if (!Py_InspectFlag &amp;&amp; (p = Py_GETENV(\"PYTHONINSPECT\")) &amp;&amp; *p != '\\0') Py_InspectFlag = 1;if (!saw_unbuffered_flag &amp;&amp; (p = Py_GETENV(\"PYTHONUNBUFFERED\")) &amp;&amp; *p != '\\0') Py_UnbufferedStdioFlag = 1;if (!Py_NoUserSiteDirectory &amp;&amp; (p = Py_GETENV(\"PYTHONNOUSERSITE\")) &amp;&amp; *p != '\\0') Py_NoUserSiteDirectory = 1; One thing should be noticed is that, Py_GETENV is a macro like this: 1#define Py_GETENV(s) (Py_IgnoreEnvironmentFlag ? NULL : getenv(s)) which will actually return NULL if the flag Py_IgnoreEnvironmentFlag is not zero. The flag is set by -E option. I think this is a good design. Parse warning option Python then uses the code below to parse warning option in different systems, since they might have different default character sets. 123456789101112#ifdef MS_WINDOWS// ...#else// ...#endifif (warning_options != NULL) &#123; Py_ssize_t i; for (i = 0; i &lt; PyList_GET_SIZE(warning_options); i++) &#123; PySys_AddWarnOptionUnicode(PyList_GET_ITEM(warning_options, i)); &#125;&#125; At the end, add them to Python warning option list. Get script file name Get filename if no command, no module, the arguments are not all read, and the current argument is not -. 12345if (command == NULL &amp;&amp; module == NULL &amp;&amp; _PyOS_optind &lt; argc &amp;&amp; wcscmp(argv[_PyOS_optind], L\"-\") != 0)&#123; filename = argv[_PyOS_optind];&#125; Check interactivity of current terminal 1234567891011121314151617181920stdin_is_interactive = Py_FdIsInteractive(stdin, (char *)0);// Python/pylifecycle.c/* * The file descriptor fd is considered ``interactive'' if either * a) isatty(fd) is TRUE, or * b) the -i flag was given, and the filename associated with * the descriptor is NULL or \"&lt;stdin&gt;\" or \"???\". */intPy_FdIsInteractive(FILE *fp, const char *filename)&#123; if (isatty((int)fileno(fp))) return 1; if (!Py_InteractiveFlag) return 0; return (filename == NULL) || (strcmp(filename, \"&lt;stdin&gt;\") == 0) || (strcmp(filename, \"???\") == 0);&#125; So, stdin is always interactive. Play with buffers Use -u option to disable input/ouput buffer in Python. This can resolve some problem if you’d like to use pipe as the input or the output of a Python program. 1234567891011if (Py_UnbufferedStdioFlag) &#123;#ifdef HAVE_SETVBUF setvbuf(stdin, (char *)NULL, _IONBF, BUFSIZ); setvbuf(stdout, (char *)NULL, _IONBF, BUFSIZ); setvbuf(stderr, (char *)NULL, _IONBF, BUFSIZ);#else /* !HAVE_SETVBUF */ setbuf(stdin, (char *)NULL); setbuf(stdout, (char *)NULL); setbuf(stderr, (char *)NULL);#endif /* !HAVE_SETVBUF */&#125; If Py_UnbufferedStdioFlag is not set, but we’ll enter the interactive mode, do not either use the input/output buffer. 12345678910111213else if (Py_InteractiveFlag) &#123;#ifdef MS_WINDOWS /* Doesn't have to have line-buffered -- use unbuffered */ /* Any set[v]buf(stdin, ...) screws up Tkinter :-( */ setvbuf(stdout, (char *)NULL, _IONBF, BUFSIZ);#else /* !MS_WINDOWS */#ifdef HAVE_SETVBUF setvbuf(stdin, (char *)NULL, _IOLBF, BUFSIZ); setvbuf(stdout, (char *)NULL, _IOLBF, BUFSIZ);#endif /* HAVE_SETVBUF */#endif /* !MS_WINDOWS */ /* Leave stderr alone - it should be unbuffered anyway. */&#125; Play with program name Python wants to set itself as the program name through Py_SetProgramName function. It’s a simple function, but on macOS, the Python interpreter can be in an App package rather than a bare environment. So, it requires lots of lines to retrieve the program name. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#ifdef __APPLE__ /* On MacOS X, when the Python interpreter is embedded in an application bundle, it gets executed by a bootstrapping script that does os.execve() with an argv[0] that's different from the actual Python executable. This is needed to keep the Finder happy, or rather, to work around Apple's overly strict requirements of the process name. However, we still need a usable sys.executable, so the actual executable path is passed in an environment variable. See Lib/plat-mac/bundlebuiler.py for details about the bootstrap script. */ if ((p = Py_GETENV(\"PYTHONEXECUTABLE\")) &amp;&amp; *p != '\\0') &#123; wchar_t* buffer; size_t len = strlen(p) + 1; buffer = PyMem_RawMalloc(len * sizeof(wchar_t)); if (buffer == NULL) &#123; Py_FatalError( \"not enough memory to copy PYTHONEXECUTABLE\"); &#125; mbstowcs(buffer, p, len); Py_SetProgramName(buffer); /* buffer is now handed off - do not free */ &#125; else &#123;#ifdef WITH_NEXT_FRAMEWORK char* pyvenv_launcher = getenv(\"__PYVENV_LAUNCHER__\"); if (pyvenv_launcher &amp;&amp; *pyvenv_launcher) &#123; /* Used by Mac/Tools/pythonw.c to forward * the argv0 of the stub executable */ wchar_t* wbuf = Py_DecodeLocale(pyvenv_launcher, NULL); if (wbuf == NULL) &#123; Py_FatalError(\"Cannot decode __PYVENV_LAUNCHER__\"); &#125; Py_SetProgramName(wbuf); /* Don't free wbuf, the argument to Py_SetProgramName * must remain valid until Py_FinalizeEx is called. */ &#125; else &#123; Py_SetProgramName(argv[0]); &#125;#else Py_SetProgramName(argv[0]);#endif &#125;#else Py_SetProgramName(argv[0]);#endif Otherwise, we can see that, argv[0] is passed in. Initialize Python This function will call Py_InitializeEx(1); and then _Py_InitializeEx_Private(install_sigs, 1);. 1Py_Initialize(); The function _Py_InitializeEx_Private will establish the entire environment. In the next post, we can get deeper in it. Print Python version in interactive mode Python will then print Python version if we want to directly enter into interactive mode, i.e, run python without any other arguments. 12345678if (!Py_QuietFlag &amp;&amp; (Py_VerboseFlag || (command == NULL &amp;&amp; filename == NULL &amp;&amp; module == NULL &amp;&amp; stdin_is_interactive))) &#123; fprintf(stderr, \"Python %s on %s\\n\", Py_GetVersion(), Py_GetPlatform()); if (!Py_NoSiteFlag) fprintf(stderr, \"%s\\n\", COPYRIGHT);&#125; Prepare argv for Python os.argv Use -m or -c as premier argument. 1234567891011if (command != NULL) &#123; /* Backup _PyOS_optind and force sys.argv[0] = '-c' */ _PyOS_optind--; argv[_PyOS_optind] = L\"-c\";&#125;if (module != NULL) &#123; /* Backup _PyOS_optind and force sys.argv[0] = '-m'*/ _PyOS_optind--; argv[_PyOS_optind] = L\"-m\";&#125; Prepare main importer path Main importer path is exactly the module in which Python will run as __main__. So, to launch Python with a file in the arguments, it’s to use the file as the main importer path. 123if (filename != NULL) &#123; main_importer_path = AsImportPathEntry(filename);&#125; If there is no file name provided, main_importer_path will not be set, either. So we do not know which we should use as the first parameter in sys.argv. Python chooses to treat it after. 1234567if (main_importer_path != NULL) &#123; /* Let RunMainFromImporter adjust sys.path[0] later */ PySys_SetArgvEx(argc-_PyOS_optind, argv+_PyOS_optind, 0);&#125; else &#123; /* Use config settings to decide whether or not to update sys.path[0] */ PySys_SetArgv(argc-_PyOS_optind, argv+_PyOS_optind);&#125; Prepare for interactive mode If we are going to use interactive/inspect mode, we’ll need the library readline. So, import it and decrease the reference count of it, to delete it later. 12345678910if ((Py_InspectFlag || (command == NULL &amp;&amp; filename == NULL &amp;&amp; module == NULL)) &amp;&amp; isatty(fileno(stdin)) &amp;&amp; !Py_IsolatedFlag) &#123; PyObject *v; v = PyImport_ImportModule(\"readline\"); if (v == NULL) PyErr_Clear(); else Py_DECREF(v);&#125; Run command if conform 1234if (command) &#123; sts = run_command(command, &amp;cf); PyMem_RawFree(command);&#125; Run module if conform 123else if (module) &#123; sts = (RunModule(module, 1) != 0);&#125; Run interactive or run files If neither command nor module conforms, Python will try to find other way to launch. Firstly, it tries to run interactive mode, while filename is not set. This action is what happens in the background when we launch python without arguments from our terminal. But it is not where the program begins. Here, we’ve just launched a hook to mark that we need interactive mode. 12345if (filename == NULL &amp;&amp; stdin_is_interactive) &#123; Py_InspectFlag = 0; /* do exit on SystemExit */ RunStartupFile(&amp;cf); RunInteractiveHook();&#125; Then, if main_importer_path is set(previously by the file), the main program will run with the file as the main importer. As you know, import all things in the module and set __name__ to __main__. 12345sts = -1; /* keep track of whether we've already run __main__ */if (main_importer_path != NULL) &#123; sts = RunMainFromImporter(main_importer_path);&#125; But what will happen if file name is set, but main importer is not found, or the file doesn’t exist? Python tries to open the file and read it line by line, then executes it. 12345678910111213141516171819202122232425262728293031323334353637383940if (sts==-1 &amp;&amp; filename != NULL) &#123; fp = _Py_wfopen(filename, L\"r\"); if (fp == NULL) &#123; char *cfilename_buffer; const char *cfilename; int err = errno; cfilename_buffer = Py_EncodeLocale(filename, NULL); if (cfilename_buffer != NULL) cfilename = cfilename_buffer; else cfilename = \"&lt;unprintable file name&gt;\"; fprintf(stderr, \"%ls: can't open file '%s': [Errno %d] %s\\n\", argv[0], cfilename, err, strerror(err)); if (cfilename_buffer) PyMem_Free(cfilename_buffer); return 2; &#125; else if (skipfirstline) &#123; int ch; /* Push back first newline so line numbers remain the same */ while ((ch = getc(fp)) != EOF) &#123; if (ch == '\\n') &#123; (void)ungetc(ch, fp); break; &#125; &#125; &#125; &#123; struct _Py_stat_struct sb; if (_Py_fstat_noraise(fileno(fp), &amp;sb) == 0 &amp;&amp; S_ISDIR(sb.st_mode)) &#123; fprintf(stderr, \"%ls: '%ls' is a directory, cannot continue\\n\", argv[0], filename); fclose(fp); return 1; &#125; &#125;&#125; sts will be set to another value, so the following lines will only be executed if there is no file name given. 12if (sts == -1) sts = run_file(fp, filename, &amp;cf); From here, the Python main program is over. Except some small things will be executed after the running. Re-run Interactive 1234567if (Py_InspectFlag &amp;&amp; stdin_is_interactive &amp;&amp; (filename != NULL || command != NULL || module != NULL)) &#123; Py_InspectFlag = 0; RunInteractiveHook(); /* XXX */ sts = PyRun_AnyFileFlags(stdin, \"&lt;stdin&gt;\", &amp;cf) != 0;&#125; As we see above, we need Py_InspectFlag, stdin_is_interactive are both true, and set at least a file name, a command or a module to run interactive mode. Which means, probably there was one script which has been executed, an the script imported the interactive mode. 12345678/* Check this environment variable at the end, to give programs the * opportunity to set it from Python. */if (!Py_InspectFlag &amp;&amp; (p = Py_GETENV(\"PYTHONINSPECT\")) &amp;&amp; *p != '\\0')&#123; Py_InspectFlag = 1;&#125; Thus, run python -c &quot;import os; os.environ['PYTHONINSPECT']='1'&quot; can also help enter interactive mode 😃 But notice that, it will be executed if Py_InspectFlag is not set. That means previously we are not in the interactive mode. Thus, run python and &quot;import os; os.environ['PYTHONINSPECT']='1'&quot; in it, then exit, this will not help to re-enter the interactive mode. Clear and end up 1234567if (Py_FinalizeEx() &lt; 0) &#123; /* Value unlikely to be confused with a non-error exit status or other special meaning */ sts = 120;&#125;return sts; Conclusion Up to now, a Python interpreter/program has been launched and finished. In the next post, we’ll look deeper into _Py_InitializeEx_Private, to see how Python Main function builds Python env through this function. But at the beginning, we’ll talk about other functions in Python/main.c, they are small functions but really vital. See you then!","categories":[{"name":"Programming Language","slug":"Programming-Language","permalink":"https://blog.inoki.cc/categories/Programming-Language/"},{"name":"Source Code","slug":"Source-Code","permalink":"https://blog.inoki.cc/categories/Source-Code/"},{"name":"Python","slug":"Programming-Language/Python","permalink":"https://blog.inoki.cc/categories/Programming-Language/Python/"},{"name":"Python","slug":"Source-Code/Python","permalink":"https://blog.inoki.cc/categories/Source-Code/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://blog.inoki.cc/tags/Python/"},{"name":"Source Code","slug":"Source-Code","permalink":"https://blog.inoki.cc/tags/Source-Code/"}]},{"title":"面试常见基础数据结构","slug":"Data-Structure","date":"2019-10-20T11:29:40.000Z","updated":"2025-03-08T09:40:48.561Z","comments":true,"path":"2019/10/20/Data-Structure/","link":"","permalink":"https://blog.inoki.cc/2019/10/20/Data-Structure/","excerpt":"","text":"原文链接：https://segmentfault.com/a/1190000018019127 常用的数据结构 我们首先列出最常用的数据结构，然后再挨个讲解： 数组(Array) 栈(Heap, Stack) 队列(Queue) 链表(Linked List) 树(Tree) 图(Graph) 字典树(Dictoinary Tree) 哈希表(Hash Table) 数组 数组是一种最简单和最广泛使用的数据结构，其它数据结构比如栈和队列都源自数组。 下图是一个大小为 4 的简单数组，包含几个元素（ 1 , 2 , 3，4）。 每个数据元素会被分配一个正的数值，叫作“索引”，它对应该元素在数组中的位置。大部分编程语言都将初始索引定义为 0. 以下是两种数组： 一维数组（如上所示） 多维数组（数组的数组） 数组的基本操作： Insert——在给定索引位置插入一个元素 Get——返回给定索引位置的元素 Delete——删除给定索引位置的元素 Size——获取数组内所有元素的总数 常问的数组面试问题： 找到数组中第二小的元素 找到数组中第一个没有重复的整数 合并两个分类数组 重新排列数组中的正值和负值 栈 我们都熟悉很有名的撤销（Undo）选项，它几乎存在每个应用程序中。有没有想过它是如何工作的？其思路就是，按照最后的状态排列在先的顺序将工作的先前状态（限于特定数字）存储在内存中。这只用数组是无法实现的，因此栈就有了用武之地。 可以把栈看作一堆垂直排列的书籍。为了获得位于中间位置的书，你需要拿掉放在它上面的所有书籍。这就是 LIFO（后进先出）方法的工作原理。 这是一个包含三个数据元素（1,2 和 3）的栈图像，其中3位于顶部，首先把它删除： 栈的基本操作： Push——在顶部插入元素 Pop—— 从栈中删除后返回顶部元素 isEmpty——如果栈为空，则返回 true Top ——返回顶部元素，但不从栈中删除 常见的栈面试问题： 使用栈计算后缀表达式 对栈中的值进行排序 检查表达式中的括号是否平衡 队列 与栈类似，队列是另一种线性数据结构，以顺序方式存储元素。栈和队列之间唯一的显着区别是，队列不是使用 LIFO 方法，而是应用 FIFO 方法，这是 First in First Out（先入先出）的缩写。 队列的完美现实例子：一列人在售票亭等候。如果有新人来，他们是从末尾加入队列，而不是在开头——站在前面的人将先买到票然后离开队列。 下图是一个包含四个数据元素（1,2,3 和 4）的队列，其中 1 位于顶部，首先把它删除： 队列的基本操作： Enqueue() —— 向队列末尾插入元素 Dequeue() —— 从队列头部移除元素 isEmpty() —— 如果队列为空，则返回 true Top() —— 返回队列的第一个元素 常问的队列面试问题： 使用队列来实现栈 颠倒队列中前 k 个元素的顺序 使用队列生成从 1 到 n 的二进制数 链表 链表是另一个重要的线性数据结构，刚一看可能看起来像数组，但在内存分配，内部结构以及如何执行插入和删除的基本操作方面有所不同。 链表就像一个节点链，其中每个节点包含数据和指向链中后续节点的指针等信息。有一个头指针，指向链表的第一个元素，如果列表是空的，那么它只指向 null 或不指向任何内容。 链表用于实现文件系统，哈希表和邻接表。下图是链表内部结构的直观展示： 下面是几种类型的链表： 单链表（单向） 双链表（双向） 链表的基本操作： InsertAtEnd —— 在链表末尾插入指定元素 InsertAtHead —— 在链表头部插入指定元素 Delete —— 从链表中删除指定元素 DeleteAtHead —— 删除链表的第一个元素 Search —— 返回链表中的指定元素 isEmpty —— 如果链表为空，返回 true 常问的链表面试问题： 翻转列表 检测链表中的循环 返回链表中倒数第 n 个节点 移除链表中的重复值 图 图就是一组节点，以网络的形式互相连接。节点也被称为顶点（vertices）。一对（x,y）就叫做一个边，表示顶点 x 和顶点 y 相连。一个边可能包含权重/成本，显示从顶点 x 到 y 所需的成本。 图的类型： 无向图 有向图 在编程语言中，图可以表示为两种形式： 邻接矩阵 邻接列表 常见的图遍历算法： 广度优先搜索 深度优先搜索 常问的图面试问题： 实现广度优先搜索和深度优先搜索 检查一个图是否为树 计算一张图中的边的数量 找到两个顶点之间的最短路径 树 树是一种层级数据结构，包含了连接它们的顶点（节点）和边。树和图很相似，但二者有个很大的不同点，即树中没有循环。 树广泛应用在人工智能和复杂的算法中，为解决各种问题提供高效的存储机制。 下图是一个简单的树，以及在树型数据结构中所用的基本术语： 下面是几种类型的树： N 叉树 平衡树 二叉树 二叉搜索树 平衡二叉树 红黑树 2-3 树 其中，二叉树和二叉搜索树是最常用的树。 常问的树面试问题： 找到一个二叉树的高度 找到一个二叉搜索树中第 k 个最大值 找到距离根部“k”个距离的节点 找到一个二叉树中给定节点的祖先（ancestors） 字典树 字典树，也叫“前缀树”，是一种树形结构，在解决字符串相关问题中非常高效。其提供非常快速的检索功能，常用于搜索字典中的单词，为搜索引擎提供自动搜索建议，甚至能用于IP路由选择。 下面展示了“top”“thus”和“their”这三个词是如何存储在字典树中的： 这些单词以从上到下的方式存储，其中绿色节点“p”，“s”和“r”分别表示“top”，“thus”和“their”的末尾。 常见的字典树面试问题： 计算字典树中的总字数 打印存储在字典树中的所有单词 使用字典树对数组的元素进行排序 使用字典树从字典中形成单词 构建一个T9字典 哈希表 散列是一个用于唯一标识对象并在一些预先计算的唯一索引（称为“密钥”）存储每个对象的过程。因此，对象以“键值”对的形式存储，这些项的集合被称为“字典”。可以使用该键值搜索每个对象。有多种不同的基于哈希的数据结构，但最常用的数据结构是哈希表。 哈希表通常使用数组实现。 哈希数据结构的性能取决于以下三个因素： 哈希函数 哈希表的大小 碰撞处理方法 下图展示了如何在数组中映射哈希。该数组的索引是通过哈希函数计算的。 常问的哈希面试问题： 找到数组中的对称对 追踪遍历的完整路径 查看一个数组是否为另一个数组的子集 检查给定数组是否不相交 以上就是你在准备编程面试前需要掌握的8种数据结构。","categories":[{"name":"Data Structure","slug":"Data-Structure","permalink":"https://blog.inoki.cc/categories/Data-Structure/"},{"name":"Algorithm","slug":"Data-Structure/Algorithm","permalink":"https://blog.inoki.cc/categories/Data-Structure/Algorithm/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"}]},{"title":"Win 10 IoT - Deployment","slug":"Win10-IoT-Deploy","date":"2019-10-19T19:29:40.000Z","updated":"2025-03-08T09:40:48.600Z","comments":true,"path":"2019/10/19/Win10-IoT-Deploy/","link":"","permalink":"https://blog.inoki.cc/2019/10/19/Win10-IoT-Deploy/","excerpt":"","text":"In the previous months, I deployed Win IoT programs through Windows Device Portal. Because my Visual Studio could not find the remote device to do the deplyment and debug. It seems to be a bug in the previous Win 10 IoT version. My previous version was 15xxx. So I used Windows Device Portal to deploy an application. Deploy through Windows Device Portal You should be able to look up the information of your device through Windows Device Portal with a browser. The link is the address of your Raspberry Pi, and the port is 8080. The application can be installed and controlled in Apps -&gt; Apps Manager. Deploy via Visual Studio After reinstalling Win 10 IoT to v.10.0.17763.107, the deployment via Visual Studio is normal. So, I set the PIN for debugging in Windows Device Portal. Everything works well: To do this, you just need to right click on the project, then choose Properties. In the Debug tab, input the IP address of your Raspberry Pi, choose General as authentification. If needed, input the PIN you’ve set. Enjoy!","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Raspberry Pi","slug":"Embedded-System/Raspberry-Pi","permalink":"https://blog.inoki.cc/categories/Embedded-System/Raspberry-Pi/"},{"name":"IoT","slug":"Embedded-System/IoT","permalink":"https://blog.inoki.cc/categories/Embedded-System/IoT/"},{"name":"Win 10 IoT","slug":"Embedded-System/IoT/Win-10-IoT","permalink":"https://blog.inoki.cc/categories/Embedded-System/IoT/Win-10-IoT/"}],"tags":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/tags/Embedded-System/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://blog.inoki.cc/tags/Raspberry-Pi/"},{"name":"Win 10 IoT","slug":"Win-10-IoT","permalink":"https://blog.inoki.cc/tags/Win-10-IoT/"}]},{"title":"OpenCL - Heterogeneous Computing (0)","slug":"OpenCL-0","date":"2019-10-18T22:29:40.000Z","updated":"2025-03-08T09:40:48.591Z","comments":true,"path":"2019/10/18/OpenCL-0/","link":"","permalink":"https://blog.inoki.cc/2019/10/18/OpenCL-0/","excerpt":"","text":"OpenCL (Open Computing Language) is a framework for writing programs that execute across heterogeneous platforms consisting of central processing units (CPUs), graphics processing units (GPUs), digital signal processors (DSPs), field-programmable gate arrays (FPGAs) and other processors or hardware accelerators. OpenCL specifies programming languages (based on C99 and C++11) for programming these devices and application programming interfaces (APIs) to control the platform and execute programs on the compute devices. OpenCL provides a standard interface for parallel computing using task- and data-based parallelism. This is the definition of OpenCL on Wikipedia. In this post, I’d like to do some research about the architecture in a brief view, based on Arch Linux. Arch Linux is chosen because of its clear software source, in which we can find out what exactly in a package for OpenCL components. Here, we only talk about the type that runs on GPU. GPGPU GPGPU is a notion standing General-Purpose computing on Graphics Processing Units. It’s called General Purpose because through it, we will not use Graphics Processing Units to process graphics data. Instead, we’d like to use them as more general computing devices. To achieve this, there are several frameworks proposed by different communities, organizations or companies. For example: NVIDIA Cuda ATI Stream OpenCL NVIDIA Cuda is proprietary and of course supported by NVIDIA. OpenCL is an open standard maintained by the non-profit technology consortium Khronos Group. But in face, the implementations rely on hardware/software providers. The important stuff of the various implementations is OpenCL Runtime libraries, which are prerequisites of executing a program that uses OpenCL. OpenCL Runtime libraries To be clarified, OpenCL Runtime libraries depend on hardware manufacturers. So, we should install the runtime libraries that match our hardwares. For example, I have an Intel CPU along with integrated Intel GPU, and a NVIDIA GPU beside. So, what I need to use all GPU devices is just to install Intel GPU OpenCL runtime libraries and NVIDIA GPU OpenCL runtime libraries. If you have an AMD GPU, or other types of devices, like an integrated FPGA(wow, you must be really professional), you should install the libraries provided by their manufacturers, or a compatible version. On Arch Linux, pacman is used to install packages. There are not bad OpenCL runtime library packages in the repository: 1234567891011121314151617181920AMD/ATI opencl-mesa: free runtime for AMDGPU and Radeon opencl-amdAUR: proprietary standalone runtime for AMDGPU (pal and legacy stacks in a single package) rocm-opencl-runtimeAUR: Part of AMD&apos;s fully open-source ROCm GPU compute stack, which supports GFX8 and later cards(Fiji, Polaris, Vega) opencl-amdgpu-pro-orcaAUR: proprietary runtime for AMDGPU PRO (supports legacy products older than Vega 10) opencl-amdgpu-pro-palAUR: proprietary runtime for AMDGPU PRO (supports Vega 10 and later products) opencl-catalystAUR: AMD proprietary runtime, soon to be deprecated in favor of AMDGPU amdapp-sdkAUR: AMD CPU runtimeNVIDIA opencl-nvidia: official NVIDIA runtimeIntel intel-compute-runtime: a.k.a. the Neo OpenCL runtime, the open-source implementation for Intel HD Graphics GPU on Gen8 (Broadwell) and beyond. beignet: the open-source implementation for Intel HD Graphics GPU on Gen7 (Ivy Bridge) and beyond, deprecated by Intel in favour of NEO OpenCL driver, remains recommended solution for legacy HW platforms (e.g. Ivy Bridge, Sandy Bridge, Haswell). intel-openclAUR: the proprietary implementation for Intel HD Graphics GPU on Gen7 (Ivy Bridge) and beyond, deprecated by Intel in favour of NEO OpenCL driver, remains recommended solution for legacy HW platforms (e.g. Ivy Bridge, Sandy Bridge, Haswell). intel-opencl-runtimeAUR: the implementation for Intel Core and Xeon processors. It also supports non-Intel CPUs.Others poclAUR: LLVM-based OpenCL implementation I’d like to install the one for NVIDIA, so I did 1sudo pacman -S opencl-nvidia We can see what are in the package from Arch website. 1234567891011121314etc/etc/OpenCL/etc/OpenCL/vendors/etc/OpenCL/vendors/nvidia.icdusr/usr/lib/usr/lib/libnvidia-compiler.sousr/lib/libnvidia-compiler.so.435.21usr/lib/libnvidia-opencl.sousr/lib/libnvidia-opencl.so.1usr/lib/libnvidia-opencl.so.435.21usr/share/usr/share/licenses/usr/share/licenses/opencl-nvidia There are some dynamic libraries for OpenCL with NVIDIA prefixes and a configuration file in /etc/OpenCL/vendors. The configuration file in etc/OpenCL/vendors/nvidia.icd should be able to tell someone, that there is NVIDIA OpenCL runtime, and where it is. The file content is: 1libnvidia-opencl.so.1 If you’d like also to use Intel GPU, install intel-compute-runtime. Files to be installed is below: 1234567891011121314etc/etc/OpenCL/etc/OpenCL/vendors/etc/OpenCL/vendors/intel.icdusr/usr/bin/usr/bin/oclocusr/lib/usr/lib/intel-opencl/usr/lib/intel-opencl/libigdrcl.sousr/share/usr/share/licenses/usr/share/licenses/intel-compute-runtime/usr/share/licenses/intel-compute-runtime/LICENSE You may notice that, there is nothing like libnvidia-compiler in Intel OpenCL Runtime. But it’s not true, the fact is that the OpenCL compiler of Intel OpenCL runtime is installed in another library, intel-graphics-compiler. And, this package is a mandatory dependency of intel-compute-runtime. You should be able to install other OpenCL runtime if you have other devices. But it’s not the end, we are not aiming at just “running” an OpenCL program, we aim at developing one. Develop Environment Basically, OpenCL is for C/C++ development. To develop, at least we need header files and dynamic libraries. The most used header file is CL/cl.h, which can be installed by installing opencl-headers package, which will import other necessary headers as well. 123456789101112131415161718usr/usr/include/usr/include/CL/usr/include/CL/cl.husr/include/CL/cl.hppusr/include/CL/cl2.hppusr/include/CL/cl_egl.husr/include/CL/cl_ext.husr/include/CL/cl_ext_intel.husr/include/CL/cl_gl.husr/include/CL/cl_gl_ext.husr/include/CL/cl_platform.husr/include/CL/cl_va_api_media_sharing_intel.husr/include/CL/opencl.husr/share/usr/share/licenses/usr/share/licenses/opencl-headers/usr/share/licenses/opencl-headers/LICENSE And, the most import library is libOpenCL.so, which is in ocl-icd package. 123456789101112131415161718192021222324usr/usr/include/usr/include/ocl_icd.husr/lib/usr/lib/libOpenCL.sousr/lib/libOpenCL.so.1usr/lib/libOpenCL.so.1.0.0usr/lib/pkgconfig/usr/lib/pkgconfig/OpenCL.pcusr/lib/pkgconfig/ocl-icd.pcusr/share/usr/share/doc/usr/share/doc/ocl-icd/usr/share/doc/ocl-icd/examples/usr/share/doc/ocl-icd/examples/ocl_icd_bindings.cusr/share/doc/ocl-icd/html/usr/share/doc/ocl-icd/html/libOpenCL.htmlusr/share/licenses/usr/share/licenses/ocl-icd/usr/share/licenses/ocl-icd/COPYINGusr/share/man/usr/share/man/man7/usr/share/man/man7/libOpenCL.7.gzusr/share/man/man7/libOpenCL.so.7.gz The full name of this package is OpenCL Installable Client Driver. It’s a mechanism to allow developers to build applications against an Installable Client Driver loader (ICD loader) rather than linking their applications against a specific OpenCL implementation. The ICD Loader is responsible for: Exporting OpenCL API entry points Enumerating OpenCL implementations Forwarding OpenCL API calls to the correct implementation The official implementation of ICD Loader can be found here on GitHub: https://github.com/KhronosGroup/OpenCL-ICD-Loader. There are other SDKs as well, but we ought not talk about them because they are out of scope: 123intel-opencl-sdkAUR: Intel OpenCL SDK (old version, new OpenCL SDKs are included in the INDE and Intel Media Server Studio)amdapp-sdkAUR: This package is installed as /opt/AMDAPP and apart from SDK files it also contains a number of code samples (/opt/AMDAPP/SDK/samples/). It also provides the clinfo utility which lists OpenCL platforms and devices present in the system and displays detailed information about them. As AMD APP SDK itself contains CPU OpenCL driver, no extra driver is needed to execute OpenCL on CPU devices (regardless of its vendor). GPU OpenCL drivers are provided by the catalystAUR package (an optional dependency).cuda: Nvidia&apos;s GPU SDK which includes support for OpenCL 1.1. Besides, for the OpenCL Implementations, we’ve already talked about them. They are runtime libraries along with configuration files in /etc/OpenCL/vendors. A utility to show all possible properties on your system, is clinfo. Owning headers, OpenCL dynamic libraries and runtime libraries, we can start developing and running OpenCL program on C/C++. As well, there are lots of bindings for other languages, take ease to use them if you want. In the next post, we will write a first OpenCL program. See you then!","categories":[{"name":"OpenCL","slug":"OpenCL","permalink":"https://blog.inoki.cc/categories/OpenCL/"}],"tags":[{"name":"OpenCL","slug":"OpenCL","permalink":"https://blog.inoki.cc/tags/OpenCL/"},{"name":"Heterogeneous Computing","slug":"Heterogeneous-Computing","permalink":"https://blog.inoki.cc/tags/Heterogeneous-Computing/"}]},{"title":"Python Source Code Analysis (0)","slug":"Python-code-analyse-0","date":"2019-10-17T15:47:40.000Z","updated":"2025-03-08T09:40:48.591Z","comments":true,"path":"2019/10/17/Python-code-analyse-0/","link":"","permalink":"https://blog.inoki.cc/2019/10/17/Python-code-analyse-0/","excerpt":"","text":"In this post, we will take a dissecion of source code of Python. To benefit the simplicity and meanwhile follow the most recent functionnalities, I choose Python 3.6.9 to do the analysis. The first step, is to build! Build Python As other projects, Python uses autoconf toolset to configure and then make to build itself. If it doesn’t make sense to you, just ignore it. What you really need is just a set of single commands to make it: Run ./configure, it will detect your environment along with the architecture, the dependencies, the features supported by your compiler After that, if there is no error, a Makefile file should be generated and placed in the same directory Run make, and you will get your own Python build! Now we use default configurations to build, because we don’t aim at building a Python binary. If you’d like to play with Python builds, you can find more information at https://docs.python.org/3.6/using/unix.html#building-python. Project Structure Before we configure the project, the structure of project is really clear and simple: 123456aclocal.m4 configure Lib Misc Programs python-config.pybuild configure.ac LICENSE Modules pyconfig.h python-gdb.pyconfig.guess Doc Mac Objects pyconfig.h.in README.rstconfig.log Grammar Makefile Parser python setup.pyconfig.status Include Makefile.pre PC Python Toolsconfig.sub install-sh Makefile.pre.in PCbuild python-config aclocal.m4, config.guess, config.sub, configure, configure.ac, install-sh, Makefile.pre.in, pyconfig.h.in are files which concerns the configuration and the compilation. LICENSE is the license file. Doc/ This folder contains the documentation of Python. Grammar1/ In Grammar folder, there is only one file, which described the abstract grammar representation of Python. Include/ All Python headers used during Python compilation. Some of those will be intalled in your system for a further development. Lib/ All libraries written in Python. Mac/ Build tools for macOS build. Misc/ Other things, not so important. Modules/ Modules written in C. Objects/ Declarations and implementations of various Python Objects. Parser/ Python code parser. PC/ The code for Windows PC. PCbuild/ The Windows PC build files, such as Visual Studio Prject files. Programms/ Main functions of Python. Python/ Python main implementation codes. Tools/ Auxiliary tools and demo. Programm Entry, Programs/python.c In the analysis, we start by the main entry of program. At the beginning, &quot;Python.h&quot; and &lt;locale.h&gt; are imported. Then, the main function has two branches: Windows On Windows, the function wmain instead of main is used as the main entry. 12345intwmain(int argc, wchar_t **argv)&#123; return Py_Main(argc, argv);&#125; This function is for the unicode environment, you can go to the doc page of Microsoft for further information: https://docs.microsoft.com/en-us/cpp/c-language/using-wmain?view=vs-2019. In the main function, it calls the real Main Function of Python, Py_Main with command-line arguments. Other Unix-Like Systems It’s not so simple as the one for Windows. 12345 wchar_t **argv_copy;/* We need a second copy, as Python might modify the first one. */wchar_t **argv_copy2;int i, res;char *oldloc; In this code, some necessary variables are declared, regarding C89 or above. Then, to copy arguments, Python requests to use malloc to allocate memories by invoking (void)_PyMem_SetupAllocators(&quot;malloc&quot;);. Then two memory spaces are allocated: 123456argv_copy = (wchar_t **)PyMem_RawMalloc(sizeof(wchar_t*) * (argc+1));argv_copy2 = (wchar_t **)PyMem_RawMalloc(sizeof(wchar_t*) * (argc+1));if (!argv_copy || !argv_copy2) &#123; fprintf(stderr, \"out of memory\\n\"); return 1;&#125; Then, Python did one thing like this: 1oldloc = _PyMem_RawStrdup(setlocale(LC_ALL, NULL)); This line will return C locale and store it in oldloc. Then Python tries to set locale with user-prefered one by setlocale(LC_ALL, &quot;&quot;), and to decode all command line arguments with new locale. 12345678910111213setlocale(LC_ALL, \"\");for (i = 0; i &lt; argc; i++) &#123; argv_copy[i] = Py_DecodeLocale(argv[i], NULL); if (!argv_copy[i]) &#123; PyMem_RawFree(oldloc); fprintf(stderr, \"Fatal Python error: \" \"unable to decode the command line argument #%i\\n\", i + 1); return 1; &#125; argv_copy2[i] = argv_copy[i];&#125;argv_copy2[argc] = argv_copy[argc] = NULL; After decoding command line arguments with user-prefered locale, Python would like to use the old default C locale and do some clean things. 12setlocale(LC_ALL, oldloc);PyMem_RawFree(oldloc); After everything about decoding and copying arguments is ready, run Python main process: 1res = Py_Main(argc, argv_copy); After finishing Python main process, all memory spaces which were allocated should be released properly with following code: 123456789/* Force again malloc() allocator to release memory blocks allocated before Py_Main() */(void)_PyMem_SetupAllocators(\"malloc\");for (i = 0; i &lt; argc; i++) &#123; PyMem_RawFree(argv_copy2[i]);&#125;PyMem_RawFree(argv_copy);PyMem_RawFree(argv_copy2); And then, return the result through return res;. Before the end In this post, we tried to compile Python with all default configurations, and we explicited the main entry function. In the next post, we’ll get involve with Py_Main function, as well as some Python Objects or types if possible. See you then!","categories":[{"name":"Programming Language","slug":"Programming-Language","permalink":"https://blog.inoki.cc/categories/Programming-Language/"},{"name":"Source Code","slug":"Source-Code","permalink":"https://blog.inoki.cc/categories/Source-Code/"},{"name":"Python","slug":"Programming-Language/Python","permalink":"https://blog.inoki.cc/categories/Programming-Language/Python/"},{"name":"Python","slug":"Source-Code/Python","permalink":"https://blog.inoki.cc/categories/Source-Code/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://blog.inoki.cc/tags/Python/"},{"name":"Source Code","slug":"Source-Code","permalink":"https://blog.inoki.cc/tags/Source-Code/"}]},{"title":"KDE Craft now delivers with vlc and libvlc on macOS","slug":"Craft-vlc","date":"2019-05-19T19:57:22.000Z","updated":"2025-03-08T09:40:48.556Z","comments":true,"path":"2019/05/19/Craft-vlc/","link":"","permalink":"https://blog.inoki.cc/2019/05/19/Craft-vlc/","excerpt":"","text":"Lacking VLC and libvlc in Craft, phonon-vlc cannot be built successfully on macOS. It caused the failed building of KDE Connect in Craft. As a small step of my GSoC project, I managed to build KDE Connect by removing the phonon-vlc dependency. But it’s not a good solution. I should try to fix phonon-vlc building on macOS. So during the community bonding period, to know better the community and some important tools in the Community, I tried to fix phonon-vlc. Fixing phonon-vlc At first, I installed libVLC in MacPorts. All Header files and libraries are installed into the system path. So theoretically, there should not be a problem of the building of phonon-vlc. But an error occurred: We can figure that the compiling is ok, the error is just at the end, during the linking. The error message tells us there is no QtDBus lib. So to fix it, I made a small patch to add QtDBus manually in the CMakeLists file. 12345678910111213diff --git a/src/CMakeLists.txt b/src/CMakeLists.txtindex 47427b2..1cdb250 100644--- a/src/CMakeLists.txt+++ b/src/CMakeLists.txt@@ -81,7 +81,7 @@ if(APPLE) endif(APPLE) automoc4_add_library(phonon_vlc MODULE $&#123;phonon_vlc_SRCS&#125;)-qt5_use_modules(phonon_vlc Core Widgets)+qt5_use_modules(phonon_vlc Core Widgets DBus) set_target_properties(phonon_vlc PROPERTIES PREFIX \"\" And it works well! A small problem is that Hannah said she didn’t get an error during linking. It may be something about Qt version. If someone gets some idea, welcome to contact me. My Qt version is 5.12.3. Fixing VLC To fix VLC, I tried to pack the VLC binary just like the one on Windows. But unfortunately, in the .app package, the Header files are not completed. Comparing to Windows version, the entire plugins folder is missing. So I made a patch for all those files. But the patch is too huge (25000 lines!). So it is not a good idea to merge it into master branch. Thanks to Hannah, she has made a libs/vlc blueprint in the master branch, so in Craft, feel free to install it by running craft libs/vlc. Troubleshooting If you cannot build libs/vlc, just like me, you can also choose the binary version VLC with Header files patch. The patch of Headers for binary is too big. Adding it to the master branch is not a good idea. So I published it on my own repository: https://github.com/Inokinoki/craft-blueprints-inoki To use it, run craft --add-blueprint-repository https://github.com/inokinoki/craft-blueprints-inoki.git and the blueprint(s) will be added into your local blueprint directory. Then, craft binary/vlc will help get the vlc binary and install Header files, libraries into Craft include path and lib path. Finally, you can build what you want with libvlc dependency. Conclusion Up to now, KDE Connect is using QtMultimedia rather than phonon and phonon-vlc to play a sound. But this work could be also useful for other applications or libraries who depend on phonon, phonon-vlc or vlc. This small step may help build them successfully on macOS. I hope this can help someone!","categories":[{"name":"KDE","slug":"KDE","permalink":"https://blog.inoki.cc/categories/KDE/"},{"name":"Craft","slug":"KDE/Craft","permalink":"https://blog.inoki.cc/categories/KDE/Craft/"},{"name":"Blueprints","slug":"KDE/Craft/Blueprints","permalink":"https://blog.inoki.cc/categories/KDE/Craft/Blueprints/"}],"tags":[{"name":"Craft","slug":"Craft","permalink":"https://blog.inoki.cc/tags/Craft/"},{"name":"KDE","slug":"KDE","permalink":"https://blog.inoki.cc/tags/KDE/"}]},{"title":"Win 10 ARM Installing on Raspberry Pi 3","slug":"Win10-ARM-RPI-INSTALL","date":"2019-05-16T23:44:40.000Z","updated":"2025-03-08T09:40:48.594Z","comments":true,"path":"2019/05/16/Win10-ARM-RPI-INSTALL/","link":"","permalink":"https://blog.inoki.cc/2019/05/16/Win10-ARM-RPI-INSTALL/","excerpt":"","text":"Since Microsoft published their Win 10 on ARM (WoA), many devices based on ARM64 get their own versions of Windows 10. The one I prefer is the Lumia 950 XL stuff by @imbushuo. This gives new life to Lumia 950 and Lumia 950 XL, although WoA cannot be used in the productivity environment on these two phones. This article will show a simple step to install WoA on Raspberry Pi (3rd generation or later). And the platform of your host should be Windows. Preparation You can follow the step on the https://pi64.win/ using WoA deployer. But here, in this article, we will use the other one: Windows on Raspberry Installer on https://www.worproject.ml/. So download and extract it. To install Windows on ARM, we should have a SD card with capacity of more than 8G, 32G is recommanded. Getting image Before flashing, we need prepare the Windows image and drivers. Image can be got on https://uup.rg-adguard.net/. You can follow the guide on https://github.com/WOA-Project/guides/blob/master/GettingWOA.md. Download the script and run it in the cmd. After long waiting, there should be an image file in the same directory of the downloaded script. Getting drivers Download drivers on the same page of Windows on Raspberry Installer. Getting UEFI firmware Access https://github.com/andreiw/RaspberryPiPkg/ and take one .fd file in Binary/prebuilt/ folders, in general, we use the latest one. Its name could be RPI_EFI.fd. Flashing your SD card Open the application and choose your language. Here we just use English for more readers. Choose your SD card. Select the image which you downloaded during the preparing periode, and choose the version you want to install. Select the zipped drivers you downloaded. Select the UEFI firmware you downloaded. And just flash it ! Launch Win 10 on Raspberry Pi If all goes well, you can get into the activation screen of Win 10 (after a really long waiting, because Raspberry Pi is not so performent). Count the processor if you want, and there are many interesting things to do 😃 Bug fix If you get stuck during the UEFI boot screen, please reboot the device, before the loading bar ended, press an appropriate key to enter BIOS setting. Move Windows boot item as the first one, save and exit.","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Raspberry Pi","slug":"Embedded-System/Raspberry-Pi","permalink":"https://blog.inoki.cc/categories/Embedded-System/Raspberry-Pi/"}],"tags":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/tags/Embedded-System/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://blog.inoki.cc/tags/Raspberry-Pi/"},{"name":"Win 10 ARM","slug":"Win-10-ARM","permalink":"https://blog.inoki.cc/tags/Win-10-ARM/"}]},{"title":"Craft Bootstrap Script","slug":"Craft-bootstrap","date":"2019-05-10T16:41:40.000Z","updated":"2025-03-08T09:40:48.556Z","comments":true,"path":"2019/05/10/Craft-bootstrap/","link":"","permalink":"https://blog.inoki.cc/2019/05/10/Craft-bootstrap/","excerpt":"","text":"Here we talk about KDE Craft buildtool, rather than something like Minecraft, Warcraft or Starcraft. Craft is an open source meta build system and package manager written in Python. It manages dependencies and builds libraries and applications from source, on Windows, Mac, Linux and FreeBSD. Please go to https://community.kde.org/Craft for more information. To setup Craft, follow the steps on Setup Craft on KDE Community Wiki. Here I use Craftin Unix/Linux environment. So, if all is well, we should use source CraftRoot/craft/craftenv.sh to enter the build environment. But try to stop doing this, the subject of the post is to study the bootstrap script. The most important stuffs for bootstrapping of Craft is the craftenv.sh script, which script is used for preparing Craft environment. We try to comprehend the environment configuration script craftenv.sh. What does it happen when we execute source craftenv.sh? Find craftenv.sh directory There is no assumption of interpreter at the beginning of this script. For the compatibility, the script firstly try to get BASH_SOURCE[0]. If nothing is contained in the variable, at least we can infer the interpreter is not a bash Bourne-Again shell. And then for others, if none of ${BASH_SOURCE[0]}, $0 and $_ works, we may use an interpreter which is not supported by this script. We just stop trying to continue the work. Meanwhile, the script store the relative path into $craftRoot. 1234567891011craftRoot=\"$&#123;BASH_SOURCE[0]&#125;\"if [[ -z \"$craftRoot\" ]];then craftRoot=\"$0\"fiif [[ -z \"$craftRoot\" ]];then craftRoot=\"$_\"fiif [[ -z \"$craftRoot\" ]];then echo \"Failed to determine interpreter\" exit 1fi In fact, after the detection, the shell is not important anymore. Which we concerned is just the $craftRoot. Find compatible Python 3 with appropriate minor version It’s confirmed that Craft would like to use Python 3. It recommends user Python 3.6. Craft bootstrap script uses command -v python-&lt;version&gt; to check if an appropriate version of Python exists. 1234if command -v python3.7 &gt;/dev/null; then CRAFT_PYTHON_BIN=$(command -v python3.7)elif command -v python3.6 &gt;/dev/null; then CRAFT_PYTHON_BIN=$(command -v python3.6) This section is to used to detect whether Python 3.7 or Python 3.6 exists in your system path. By the way, I’d like to introduce something about versions in software distribution. If this is useful, it will be my pleasure. We usually use Semantic Versioning to describe changes. It means: given a version number MAJOR.MINOR.PATCH, increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. So the difference is in the minor version. We can see the Python 3.7 is also supported by Craft. And the preference is Python 3.7 according to the priority of instruction. Then, the script tries to find other potentially compitable Python version. But at least, it should be Python 3.6. Otherwise it will not continue. 12345678910111213141516171819...else # could not find python 3.6, try python3 if ! command -v python3 &gt;/dev/null; then echo \"Failed to python Python 3.6+\" exit 1 fi # check if python3 is at least version 3.6: python_version=$(python3 --version) # sort and use . as separator and then check if the --version output is sorted later # Note: this is just a sanity check. craft.py should check sys.version comparison=$(printf '%s\\nPython 3.6.0\\n' \"$python_version\" | sort -t.) if [ \"$(echo \"$&#123;comparison&#125;\" | head -n1)\" != \"Python 3.6.0\" ]; then echo \"Found Python3 version $&#123;python_version&#125; is too old. Need at least 3.6\" exit 1 fi CRAFT_PYTHON_BIN=$(command -v python3)fiexport CRAFT_PYTHON_BIN So if Python is ok, its path will be stored in $CRAFT_PYTHON_BIN and exported. As we already have Python, the script uses it immediately, to correct the $craftRoot. If the variable is not a directory, we get its parent directory and replace the $craftRoot. 123if [[ ! -d \"$craftRoot\" ]]; then craftRoot=$($&#123;CRAFT_PYTHON_BIN&#125; -c \"import os; import sys; print(os.path.dirname(os.path.abspath(sys.argv[1])));\" \"$craftRoot\")fi For now, $craftRoot should be craft/ in your Craft install directory. Generating and exporting $CRAFT_ENV The following single line is used for acquiring some environment variables for Craft. 1CRAFT_ENV=$($&#123;CRAFT_PYTHON_BIN&#125; \"$craftRoot/bin/CraftSetupHelper.py\" --setup) In fact, it called bin/CraftSetupHelper.py with --setup option, it does have done many things. 123456789101112131415161718192021222324252627 def run(self): parser = argparse.ArgumentParser() parser.add_argument(\"--get\", action=\"store_true\") parser.add_argument(\"--print-banner\", action=\"store_true\") parser.add_argument(\"--getenv\", action=\"store_true\") parser.add_argument(\"--setup\", action=\"store_true\") parser.add_argument(\"rest\", nargs=argparse.REMAINDER) args = parser.parse_args() if args.get: default = \"\" if len(args.rest) == 3: default = args.rest[2] CraftCore.log.info(CraftCore.settings.get(args.rest[0], args.rest[1], default)) elif args.print_banner: self.printBanner() elif args.getenv: self.printEnv() elif args.setup: self.printEnv() self.printBanner()# ...helper = SetupHelper()if __name__ == '__main__': helper.run() We can see that printEnv and printBanner are invoked, all their ouputs will be filled into $CRAFT_ENV in shell. The generated env variables are too many, here we only talk about the bootstrapping. Maybe there will be an article about those. 123456789101112131415# Split the CraftSetupHelper.py output by newlines instead of any whitespace# to also handled environment variables containing spaces (e.g. $PS1)# See https://stackoverflow.com/q/24628076/894271function export_lines() &#123; local IFS=$'\\n' local lines=($1) local i for (( i=0; i&lt;$&#123;#lines[@]&#125;; i++ )) ; do local line=$&#123;lines[$i]&#125; if [[ \"$line\" =~ \"=\" ]] &amp;&amp; [[ $line != _=* ]] ; then export \"$line\" || true fi done&#125;export_lines \"$CRAFT_ENV\" Then with export_lines, all the lines can be exported seperatly without confusion. Exporting other necessary variables and functions If the prompt exists in $PS1, which means the interpreter is using the strings in $PS1 as its prompt, then the script add CRAFT: before it. This would be realy useful because it could remind user that we’re in the Craft environment. 123if [ -n \"$PS1\" ]; then export PS1=\"CRAFT: $PS1\"fi Then just some useful functions: 123craft() &#123; $&#123;CRAFT_PYTHON_BIN&#125; \"$craftRoot/bin/craft.py\" $@&#125; The main entry of Craft. It will invoke bin/craft.py. All other things will be done in it. 12345678cs() &#123; dir=$(craft -q --ci-mode --get \"sourceDir()\" $1) if (($? &gt; 0));then echo $dir else cd \"$dir\" fi&#125; Change current work directory to source directory in Craft. 12345678cb() &#123; dir=$(craft -q --ci-mode --get \"buildDir()\" $1) if (($? &gt; 0));then echo $dir else cd \"$dir\" fi&#125; Change current work directory to build directory in Craft. 123cr() &#123; cd \"$KDEROOT\"&#125; Change current work directory to root in Craft. And export them 1declare -x -F cs cb cr Conclusion With all environment variables prepared, and some useful function exported, we can begin our trip in building everything with Craft. References KDE Craft wiki, https://community.kde.org/Craft Utilisation de la variable BASH_SOURCE[0], https://logd.fr/utilisation-variable-bash_source/","categories":[{"name":"System","slug":"System","permalink":"https://blog.inoki.cc/categories/System/"},{"name":"Utility","slug":"System/Utility","permalink":"https://blog.inoki.cc/categories/System/Utility/"},{"name":"Build tool","slug":"System/Utility/Build-tool","permalink":"https://blog.inoki.cc/categories/System/Utility/Build-tool/"}],"tags":[{"name":"System","slug":"System","permalink":"https://blog.inoki.cc/tags/System/"},{"name":"Craft","slug":"Craft","permalink":"https://blog.inoki.cc/tags/Craft/"}]},{"title":"Win 10 IoT - Blink","slug":"Win10-IoT-Blink","date":"2019-05-07T22:58:40.000Z","updated":"2025-03-08T09:40:48.596Z","comments":true,"path":"2019/05/07/Win10-IoT-Blink/","link":"","permalink":"https://blog.inoki.cc/2019/05/07/Win10-IoT-Blink/","excerpt":"","text":"Thanks to Microsoft and its UWP application, Win 10 IoT device can share the same framework of normal Win 10 application. In this post, we’ll build a simple short blink application for Win 10 IoT platform. It assums that you’ve already have some knowledgements about GPIO. Connection The Raspberry Pi GPIO pins are defined in Win 10 IoT as following: There is also a “Power-on Pull” state for each pin. “PullDown” means the pin has no tension, meanwhile “PullUp” means the pin has a high tension. Please check PIN Mapping for some more details. Here we choose PIN 11 and PIN 9(Ground) to use. The circuit is like this: The green wire is connected to PIN 11, the brown to PIN 9. Code Use GpioController gpio = GpioController.GetDefault(); to get GPIO controller. Use GpioPin pin = gpio.OpenPin(17) to open a gpio port. PIN 11 is GPIO 17 in Win 10 IoT. Write HIGH to this port pin.Write(GpioPinValue.High);. Set to output mode pin.SetDriveMode(GpioPinDriveMode.Output);. Close port(Here we use using to make it close automately). 1234567891011121314151617181920212223242526272829303132333435public sealed partial class MainPage : Page&#123; public MainPage() &#123; this.InitializeComponent(); this.GPIO(); &#125; DispatcherTimer dispatcherTimer; public void GPIO() &#123; // Create a timer and call dispatcherTimer_Tick every 1 second dispatcherTimer = new DispatcherTimer(); dispatcherTimer.Tick += dispatcherTimer_Tick; dispatcherTimer.Interval = new TimeSpan(0, 0, 1); dispatcherTimer.Start(); &#125; public void dispatcherTimer_Tick(object sender, object e) &#123; // Get the default GPIO controller on the system GpioController gpio = GpioController.GetDefault(); if (gpio == null) return; // GPIO not available on this system // Open GPIO 17 using (GpioPin pin = gpio.OpenPin(17)) &#123; // Latch HIGH value first. This ensures a default value when the pin is set as output pin.Write(GpioPinValue.High); // Set the IO direction as output pin.SetDriveMode(GpioPinDriveMode.Output); &#125; // Close pin - will revert to its power-on state &#125;&#125; Conclusion This video shows you the result:","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Raspberry Pi","slug":"Embedded-System/Raspberry-Pi","permalink":"https://blog.inoki.cc/categories/Embedded-System/Raspberry-Pi/"},{"name":"IoT","slug":"Embedded-System/IoT","permalink":"https://blog.inoki.cc/categories/Embedded-System/IoT/"},{"name":"Win 10 IoT","slug":"Embedded-System/IoT/Win-10-IoT","permalink":"https://blog.inoki.cc/categories/Embedded-System/IoT/Win-10-IoT/"}],"tags":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/tags/Embedded-System/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://blog.inoki.cc/tags/Raspberry-Pi/"},{"name":"Win 10 IoT","slug":"Win-10-IoT","permalink":"https://blog.inoki.cc/tags/Win-10-IoT/"}]},{"title":"为 Newifi 2 (D1) 路由器构建 Go 语言","slug":"Build-go-for-newifi2-d1-router-chinese","date":"2019-04-30T13:41:40.000Z","updated":"2025-03-08T09:40:48.556Z","comments":true,"path":"2019/04/30/Build-go-for-newifi2-d1-router-chinese/","link":"","permalink":"https://blog.inoki.cc/2019/04/30/Build-go-for-newifi2-d1-router-chinese/","excerpt":"","text":"通过阅读这篇文章您应当可以为任何系统构建 Go 语言。 English Version 先决条件 从 Go 1.5 开始，Go 语言所有的源代码都使用了 Go 或者汇编语言。因此在一个安装有 Go 语言的系统中使用 Go 语言构建另一个 Go 语言版本会十分简单。这个特性叫做语言的自举。 使用 GOOS 和 GOARCH 环境变量，我们可以为另一个平台和架构构建 Go 语言程序，这是 Go 的交叉编译特性。 因此，为我的 Lenovo Newifi 2(D2) 编译 Go 语言环境是可行的。这个路由器的官方固件基于 Openwrt，处理器为 MT7621AT，MIPS 架构小端序，配有 256M 内存。 我希望能保留官方固件而非刷机，因此我决定为我的路由器构建一个独立的 Go 语言版本。 准备 在您的系统上安装 Go&gt;=1.5 版本: 1234&gt; which go/usr/bin/go&gt; go versiongo version go1.10.4 linux/amd64 如果您没有安装 Go 语言，请使用您发行版的包管理器安装。对于 Ubuntu 来说 1&gt; sudo apt-get install golang-go 从 下载页面 获取 Go 语言源代码。 我使用了 Golang 1.12.4: 1&gt; wget https://dl.google.com/go/go1.12.4.src.tar.gz 构建 解压代码包: 1&gt; tar xvf go1.12.4.src.tar.gz 目录结构如下： 12345678910111213141516.├── api├── AUTHORS├── CONTRIBUTING.md├── CONTRIBUTORS├── doc├── favicon.ico├── lib├── LICENSE├── misc├── PATENTS├── README.md├── robots.txt├── src├── test└── VERSION 进入 src 目录。开始您的构建： 1234567891011&gt; GOOS=linux GOARCH=mipsle GOROOT_BOOTSTRAP=&lt;your-go-root&gt; ./make.bashBuilding Go cmd/dist using &lt;your-go-path&gt;/go-1.10.Building Go toolchain1 using &lt;your-go-path&gt;/go-1.10.Building Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.Building Go toolchain2 using go_bootstrap and Go toolchain1.Building Go toolchain3 using go_bootstrap and Go toolchain2.Building packages and commands for host, linux/amd64.Building packages and commands for target, linux/mipsle.---Installed Go for linux/mipsle in &lt;your-build-path&gt;/goInstalled commands in &lt;your-build-path&gt;/go/bin 安装 构建完成后，将以下文件夹复制到路由器: 123456api bin misc pkg src test 比如，我创建了 /mnt/mmcblk0p1/usr/share/go 文件夹来存放它们。 紧接着，从 bin/mipsle 将 go 和 gofmt 移至 bin。 添加 GOROOT 环境变量，并添加 bin 到 PATH 中: 12&gt; export GOROOT=/mnt/mmcblk0p1/usr/share/go&gt; PATH=$GOROOT/bin:$PATH 运行您的第一个 Go 程序 在 test.go 创建 Hello World 代码: 12345678package mainimport ( \"fmt\")func main() &#123; fmt.Println(\"hello newifi2\")&#125; 直接运行它: 12&gt; go run test.gohello newifi2 或者构建+运行: 123&gt; go build test.go&gt; ./testhello newifi2 一切 OK!","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Cross Compile","slug":"Embedded-System/Cross-Compile","permalink":"https://blog.inoki.cc/categories/Embedded-System/Cross-Compile/"},{"name":"Router","slug":"Embedded-System/Cross-Compile/Router","permalink":"https://blog.inoki.cc/categories/Embedded-System/Cross-Compile/Router/"},{"name":"Chinese","slug":"Chinese","permalink":"https://blog.inoki.cc/categories/Chinese/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Cross Compile","slug":"Cross-Compile","permalink":"https://blog.inoki.cc/tags/Cross-Compile/"},{"name":"Router","slug":"Router","permalink":"https://blog.inoki.cc/tags/Router/"},{"name":"Go","slug":"Go","permalink":"https://blog.inoki.cc/tags/Go/"}]},{"title":"Build Go for Newifi 2 (D1) router","slug":"Build-go-for-newifi2-d1-router","date":"2019-04-30T13:41:40.000Z","updated":"2025-03-08T09:40:48.556Z","comments":true,"path":"2019/04/30/Build-go-for-newifi2-d1-router/","link":"","permalink":"https://blog.inoki.cc/2019/04/30/Build-go-for-newifi2-d1-router/","excerpt":"","text":"This post will give you a guide to build Go on no matter which system. Chinese Version Prerequisite After Go 1.5, all the source codes are written in Go or Assembly. So in a system where there is a Go install, we can build another Go using Go itself. The feature is called bootstrapping. With GOOS and GOARCH flag, we can build Go program for given platform with given architecture. This is cross compile of Go. So, it’s possible to build a Go environment for my Lenovo Newifi 2 (D1), which is based on OpenWRT, equiped with MIPS Little Endian MT7621AT processor, 256MB memory. But I want to keep the official firmware, so I decided to build an independant build of Go for my router. Preparing Get your Go&gt;=1.5 installed in your system: 1234&gt; which go/usr/bin/go&gt; go versiongo version go1.10.4 linux/amd64 If you don’t have Go installed, please install it with your current package manager. For Ubuntu, 1&gt; sudo apt-get install golang-go Get Golang source code from the downloads page. I chose to use Golang 1.12.4: 1&gt; wget https://dl.google.com/go/go1.12.4.src.tar.gz Building Decompress the tarball: 1&gt; tar xvf go1.12.4.src.tar.gz We’ll have a directory like this: 12345678910111213141516.├── api├── AUTHORS├── CONTRIBUTING.md├── CONTRIBUTORS├── doc├── favicon.ico├── lib├── LICENSE├── misc├── PATENTS├── README.md├── robots.txt├── src├── test└── VERSION Enter src directory. Begin directly your build for mipsle: 1234567891011&gt; GOOS=linux GOARCH=mipsle GOROOT_BOOTSTRAP=&lt;your-go-root&gt; ./make.bashBuilding Go cmd/dist using &lt;your-go-path&gt;/go-1.10.Building Go toolchain1 using &lt;your-go-path&gt;/go-1.10.Building Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.Building Go toolchain2 using go_bootstrap and Go toolchain1.Building Go toolchain3 using go_bootstrap and Go toolchain2.Building packages and commands for host, linux/amd64.Building packages and commands for target, linux/mipsle.---Installed Go for linux/mipsle in &lt;your-build-path&gt;/goInstalled commands in &lt;your-build-path&gt;/go/bin Installing After the building, copy the following folders to the router: 123456api bin misc pkg src test For example, I created /mnt/mmcblk0p1/usr/share/go folder for them. Then move go and gofmt from bin/mipsle to bin. Add GOROOT to environment variables and bin to PATH: 12&gt; export GOROOT=/mnt/mmcblk0p1/usr/share/go&gt; PATH=$GOROOT/bin:$PATH Run your first Go program Create the Hello World code in test.go: 12345678package mainimport ( \"fmt\")func main() &#123; fmt.Println(\"hello newifi2\")&#125; Run it: 12&gt; go run test.gohello newifi2 or build and run it: 123&gt; go build test.go&gt; ./testhello newifi2 Enjoy your journal with Go on your router!","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Cross Compile","slug":"Embedded-System/Cross-Compile","permalink":"https://blog.inoki.cc/categories/Embedded-System/Cross-Compile/"},{"name":"Router","slug":"Embedded-System/Cross-Compile/Router","permalink":"https://blog.inoki.cc/categories/Embedded-System/Cross-Compile/Router/"}],"tags":[{"name":"Cross Compile","slug":"Cross-Compile","permalink":"https://blog.inoki.cc/tags/Cross-Compile/"},{"name":"Router","slug":"Router","permalink":"https://blog.inoki.cc/tags/Router/"},{"name":"Go","slug":"Go","permalink":"https://blog.inoki.cc/tags/Go/"}]},{"title":"【译】 从源代码构建 deb 包","slug":"Debian-build-deb-from-source-code","date":"2019-04-02T21:08:00.000Z","updated":"2025-03-08T09:40:48.562Z","comments":true,"path":"2019/04/02/Debian-build-deb-from-source-code/","link":"","permalink":"https://blog.inoki.cc/2019/04/02/Debian-build-deb-from-source-code/","excerpt":"","text":"原文链接: https://wiki.debian.org/Packaging/Intro Debian 打包介绍 本文是一个关于如何制作 Debian 包的介绍性教程，它不会对 Debian 打包系统中的复杂概念深入介绍，但它介绍了能够为简单软件制作 Debian 包的方法。 出于这个目的，我们只使用来自于 debhelper 9 的 dh 命令。 需求 这个教程假设您已： 理解二进制包的安装过程； 了解命令行的使用，并且使用您偏爱的文本编辑器编辑文本文件； 技术要求： build-essential devscripts debhelper version 9 或更高版本 三个核心概念 三个最核心的概念为： 上游原始代码包（upstream tarball）: 通常，人们为上游开发者（通常为第三方）编写的软件打包。 上游开发者会使用源代码归档软件或原始代码包的方式发放他们的软件。 原始代码包一般是上游制作的 .tar.gz 或 .tgz 文件，它也可能被压缩成 .tar.bz2，.tb2 或 .tar.xz 格式。原始代码包就是 Debian 构建包时使用的原材料。 源码包： 当您拥有了上游制作的原始代码包，下一步就可以制作 Debian 源码包了。 二进制包： 从源码包您可以构建 Debian 二进制包，它才是是实际上会被安装的包。 最简单的源码包由3个文件组成： 上游原始代码包，需要被重命名来符合一个特定的模式。 一个 debian 目录，带有所有上游源代码的更改记录，外加所有为 Debian 打包系统生成的所有文件。这种包拥有 .debian.tar.gz 的文件名。 一个描述文件（以 .dsc 结尾），罗列了其他两个文件。 听起来有些过于复杂，人们的第一印象是：所有东西都放在一个文件里会更简单。然而，保持上游代码包与 Debian 特定更改分离可以节省大量磁盘空间和带宽。对 Debian 来说，追踪必要的修改也更加简单。 打包工作流 打包工作流通常如下表所示： 重命名上游代码包 解压缩上游代码包 添加 Debian 打包文件 构建这个包 安装这个包 之后您就可以在您的电脑上测试它了。 源码包和二进制包都可以被上传到 Debian。 为了这个教程，我们使用这个代码包：hithere 第一步：更改上游代码包名称 Debian 打包系统假定上游代码包拥有一个十分特殊的名字，必须遵守一个特定的模式。它的名字由源代码包名、一个下划线、上游版本号组成，最后以.orig.tar.gz 组成。源代码包应当全部使用小写字母，并且包含字母、数字、符号，一些其他的字符也可以出现。 如果上游开发者使用了一个很好的 Debian 源代码包名，您可以直接使用。否则，请尽可能小的对名称进行改动以适应 Debian。在我们的情况下，上游开发者已经选取了一个很好的名字：“hithere”了，所以我们无需担心。我们应当最终使用 hithere_1.0.orig.tar.gz 作为上游代码包的名称。请注意，这里我们使用了一个下划线，而不是“-”，因为打包工具极其吹毛求疵。 1$ mv hithere-1.0.tar.gz hithere_1.0.orig.tar.gz 第二步：解压缩上游代码包 通常情况下，源代码会进入一个以包名和上游版本号命名的目录中（使用连接符连接，而不是下划线），因此理想状况下我们使用的上游代码包会被解压缩到一个叫做hithere-1.0 的目录中。打包工具仍旧挑剔，因此我们必须这样做。 1$ tar xf hithere_1.0.orig.tar.gz 第三步：添加 Debian 打包文件 以下所有文件都在源码树的 debian/ 子目录中。 12$ cd hithere-1.0$ mkdir debian 我们需要提供不少文件，让我们按顺序来看。 debian/changelog 第一个文件是 debian/changelog，这个是记录 Debian 包变化的日志文件。它无需罗列出上游代码的每一个改变，只要它能帮助用户总结这些变化即可。我们在制作第一个版本，所以这里应当什么都没有。然而，我们仍需制作一个变化日志的入口，因为打包工具会从日志里读取特定信息。最重要的是它会读取包的版本。 debian/changelog 拥有一个十分特殊的格式。最简单的创建方式就是使用 dch 工具。 1$ dch --create -v 1.0-1 --package hithere 会在文件中产生以下内容： 12345hithere (1.0-1) UNRELEASED; urgency=low * Initial release. (Closes: #XXXXXX) -- Lars Wirzenius &lt;liw@liw.fi&gt; Thu, 18 Nov 2010 17:25:32 +0000 这里有很多注意点： hithere 部分必须与源代码包的名字相同。1.0-1 是版本号，1.0 部分是上游版本号。-1 部分是 Debian 的版本：它是第一个上游版本为 1.0 的 Debian 包。如果这个 Debian 包有错误，并且被修复了，那么上游版本号仍保持相同，下一个版本应当被叫做 1.0-2，接下来是 1.0-3，依此类推。 UNRELEASED 被称作上传目标。它会告诉上传工具这个二进制包应当被上传到哪里。UNRELEASED 意味着这个包还没有做好上传的准备。保持 UNRELEASED 是一个好主意，以避免您错误上传它。 目前请先忽略 urgency=low。 (Closes：#XXXXXX) 作用在于上传包时关闭错误。这是在 Debian 中关闭错误的常用方法：当上传修复错误的包时，错误跟踪器会注意到这一点，并将错误标记为已关闭。我们可以删除 (Closes...) 位。或者不管它，现在它不重要。 更改日志中的最后一行指出是谁在何时制作了这个版本的软件包。dch 工具会尝试猜测名称和电子邮件地址，但您应当使用正确的详细信息对其进行配置。详细信息，请参阅 dch(1) 手册页。 debian/compat debian/compat 明确 debhelper 工具的兼容等级。我们目前不需要知道它意味着什么。 110 debian/control 控制文件描述代码和二进制包，并给出他们的详细信息，比如名称、包的维护者是谁，等等。下面是一个示例： 123456789101112Source: hithereMaintainer: Lars Wirzenius &lt;liw@liw.fi&gt;Section: miscPriority: optionalStandards-Version: 3.9.2Build-Depends: debhelper (&gt;= 9)Package: hithereArchitecture: anyDepends: $&#123;shlibs:Depends&#125;, $&#123;misc:Depends&#125;Description: greet user hithere greets the user, or the world. 在这个文件里有许多需求的字段，但是现在您可以像对待魔法一样对待它。那么，在 debian/control 中有两段文字。 第一段文字描述了源代码包，使用以下字段： Source 源代码包名。 Maintainer 维护者的姓名和电子邮箱。 Priority 包的重要性（‘required 可选的’, ‘important 重要的’, ‘standard 标准’ 或 ‘optional’ 其中之一）。通常，包是“可选”的，除非它对于标准系统功能是“必不可少的”，即启动或网络功能。 如果包与另一个“可选”包冲突，或者它不打算用于标准桌面安装，则应该是“额外”的而不是“可选”的。 “额外”包的显着例子是调试包。 （由Sebastian Tennant添加）。 Build-Depends 需要安装以构建程序包的程序包列表。实际使用包时有可能需要它们。 第一个之后的所有段落都描述了从此源构建的二进制包。 可以有许多从同一来源构建的二进制包; 但对于我们的例子只有一个。 我们使用这些字段： Package 二进制包的名称。 名称可能与源包名称不同。 Architecture 指定二进制包预期使用的计算机体系结构：用于32位Intel CPU的i386，用于64位的amd64，用于ARM处理器的armel等等。 Debian总共可以处理大约十几种计算机体系结构，因此这种体系结构支持至关重要。 “Architecture”字段可以包含特定体系结构的名称，但通常它包含两个特殊值中的一个。 any （我们在示例中看到）意味着可以为任何体系结构构建包。 换句话说，代码是可移植的，因此它不会对硬件做太多假设。 但是，仍然需要为每个体系结构单独构建二进制包。 all 意味着相同的二进制包将适用于所有体系结构，而无需为每个体系结构单独构建。 例如，仅包含shell脚本的包将是“all”。 Shell脚本在任何地方都可以工作，不需要编译。 Depends 为了让二进制包中程序能够正常运行，需要安装的包列表。手动列出这些依赖项是繁琐且容易出错的工作。为了能够让其工作，我们需要一个神奇的小东西 ${shlibs:Depends}。另一个神奇的东西是给 debhelper 的，它是 ${misc:Depends}。shlibs 是为了动态链接库，而 misc 是为了 debherlper 的一些工作。对于别的依赖，您可以将其手动加入到 Depends 或 Build-Depends 中。但请注意，${...} 仅在 Depends 中有效。 Description 二进制包的完整描述。它希望对用户有所帮助。第一行用作简要概要（摘要）描述，其余部分是包的更长的描述。 命令 cme edit dpkg 提供了一个GUI能够用来编辑大多数打包文件，包括 debian/control。 请参阅使用 cme 页面管理 Debian 软件包。cme命令在 Debian 中的 cme 包中提供。您也可以使用 cme edit dpkg-control 命令仅编辑 debian/control 文件。 debian/copyright 这是一个非常重要的文件，但是现在我们将先使用一个空文件。 对于 Debian ，此文件用于跟踪有关包的合法性、版权相关信息。但是，从技术角度来看，这并不重要。目前，我们将专注于技术方面。如果有兴趣，我们可以稍后再回到 debian/copyright。 debian/rules 它应当长这个样： 123#!/usr/bin/make -f%: dh $@ 注意： 最后一行应当使用一个 Tab 字符进行缩进，而不使用空格。这个文件是一个 Makefile，因此 Tab 字符是 make 所期望的。 事实上 debian/rules 可能是一个相当复杂的文件。然而，在 debhelper 7 中的 dh 命令让它可以在大多数情况下变得更简单。 debian/source/format 最后一个我们需要的文件是 debian/source/format，它应当包含源代码包的版本号，这里为 3.0 (quilt)。 13.0 (quilt) 第四步：构建这个包 第一次尝试 现在我们可以构建这个包了。有很多我们可以使用的命令，但是我们只使用其中一个，如果您运行以下命令，您会得到像下面的输出： 1234567891011$ debuild -us -ucmake[1]: Entering directory '/home/liw/debian-packaging-tutorial/x/hithere-1.0'install hithere /home/liw/debian-packaging-tutorial/x/hithere-1.0/debian/hithere/usr/local/bininstall: cannot create regular file '/home/liw/debian-packaging-tutorial/x/hithere-1.0/debian/hithere/usr/local/bin': No such file or directorymake[1]: *** [install] Error 1make[1]: Leaving directory '/home/liw/debian-packaging-tutorial/x/hithere-1.0'dh_auto_install: make -j1 install DESTDIR=/home/liw/debian-packaging-tutorial/x/hithere-1.0/debian/hithere returned exit code 2make: *** [binary] Error 29dpkg-buildpackage: error: fakeroot debian/rules binary gave error exit status 2debuild: fatal error at line 1325:dpkg-buildpackage -rfakeroot -D -us -uc failed 有些地方不太对劲。这经常发生：您已经尽力创建了符合规范的 debian/* 文件了，但是仍有一些东西不太对劲。可见，出错的地方在： 1install hithere /home/liw/debian-packaging-tutorial/x/hithere-1.0/debian/hithere/usr/local/bin 上游代码中的 Makefile 尝试将程序安装到错误的地方。 这边有许多可以做的事情，来解决这个问题：第一件事是 Debian 打包系统如何工作。 修正 当程序被构建并被“安装”时，通常情况下，它还不会被安装到 /usr 或者 /usr/local，而是被安装到 debian/ 子目录。 我们在 debian/hithere 目录下创建了一个整个文件系统的子集，并将其打包进二进制包中。因此 .../debian/hithere/usr/local/bin 是没问题的，除非它不应当被安装到 usr/local 而是 usr 目录。我们需要做一些事情来确保程序被安装到正确的位置 debian/hithere/usr/bin。正确的方法是修改 debian/rules 文件来告诉 Makefile 应当在哪里安装软件。 123456#!/usr/bin/make -f%: dh $@override_dh_auto_install: $(MAKE) DESTDIR=$$(pwd)/debian/hithere prefix=/usr install 这个仍是一个小魔法，为了理解它，您应当知道 Makefile 如何工作，还应当知道 debhelper 的不同阶段。 目前，我可以大概说明下：有一个名为 debherlper 的命令负责安装上游文件，这个阶段被称为 dh_auto_install。我们需要覆盖这个阶段，为此，我们在 debian/rule 中重写了 override_dh_auto_install 规则。这个文件的最后一行是一种1970年代的技术，为了从 debian/rules 中使用正确的参数调用上游中的 Makefile 文件。 让我们再试一下。 1$ debuild -us -uc 仍然失败了！但这次失败的命令是： 1install hithere /home/liw/debian-packaging-tutorial/x/hithere-1.0/debian/hithere/usr/bin 我们正在尝试将软件安装至正确的地方，但是这个目录不存在。为了修正这个错误，我们应当告诉打包工具先创建这个目录。 理想状况下，上游 Makefile 文件会自动创建目录，但这种情况下，是上游开发者太懒惰了，他没有创建这个目录。 另一个修正 打包工具（特别是debhelper）提供了一种实现方式。创建一个名为 debian/hithere.dirs 的文件，里面的内容应当是： 12usr/binusr/share/man/man1 第二行创建了一个给手册页面的目录。之后我们会需要它。您应当小心的维护这样的文件，因为它可能会导致您的包在未来版本产生空目录，当包中的项目不再有效时。 让我们再试一下： 1$ debuild -us -uc 现在构建成功了，但是仍有一些小问题。debuild 运行了 lintian 工具，这个工具可以检测构建的包的一些常见的错误，它给出了我们创建的包的一些错误： 123456Now running lintian...W: hithere source: out-of-date-standards-version 3.9.0 (current is 3.9.1)W: hithere: copyright-without-copyright-noticeW: hithere: new-package-should-close-itp-bugW: hithere: wrong-bug-number-in-closes l3:#XXXXXXFinished running lintian. 这些错误应当被修正，但是对我们来说它们不会导致错误。现在我们先忽略他们。查看父目录，您可以找到构建好的包。 1234$ ls ..hithere-1.0 hithere_1.0-1_amd64.deb hithere_1.0.orig.tar.gzhithere_1.0-1_amd64.build hithere_1.0-1.debian.tar.gzhithere_1.0-1_amd64.changes hithere_1.0-1.dsc 第五步：安装构建好的包 接下来的命令会安装您构建好的包。不要在计算机上直接运行它，除非您不介意损坏系统。 通常情况下，在备份好的计算机上进行包开发是最好的，这样，在所有事情变糟糕的情况下，您可以不用完全安装整个系统。虚拟机是一个不错的进行开发的地方。 123456789$ sudo dpkg -i ../hithere_1.0-1_amd64.deb[sudo] password for liw:Selecting previously deselected package hithere.(Reading database ... 154793 files and directories currently installed.)Unpacking hithere (from ../hithere_1.0-1_amd64.deb) ...Setting up hithere (1.0-1) ...Processing triggers for man-db ...liw@havelock$ 那么，如何测试打好的包呢？我们可以运行命令： 1$ hithere OK 了！ 但现在并不完美。记得 lintian 还有一些事情涵待解决，debian/copyright 仍然是空的，等等。我们现在有了一个可以运行的 deb 包了，但是它还并不是我们所期待的高质量的 Debian 包。 结论 一旦您构建了您自己的包，自然而然地，您会想要知道如何设置您自己的 apt 仓库，这样您自己的包会很容易被安装。我所知道的最好的工具是 reprepro。为了更多的测试您的包，您可能也会想要了解 piuparts。原作者编写的这个工具，他觉得这个工具很棒并且没有任何 bug ！ 最后，如果您开始修改上游代码，您可能想要了解一下 quilt 工具。 其他您可能想要阅读的信息可以在 http://www.debian.org/devel/ 页面找到。","categories":[{"name":"Package","slug":"Package","permalink":"https://blog.inoki.cc/categories/Package/"},{"name":"Debian","slug":"Package/Debian","permalink":"https://blog.inoki.cc/categories/Package/Debian/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"Pack","slug":"Pack","permalink":"https://blog.inoki.cc/tags/Pack/"},{"name":"Debian","slug":"Debian","permalink":"https://blog.inoki.cc/tags/Debian/"}]},{"title":"Linux manual epoll(7)","slug":"man-epoll","date":"2019-03-24T10:49:40.000Z","updated":"2025-03-08T09:40:48.611Z","comments":true,"path":"2019/03/24/man-epoll/","link":"","permalink":"https://blog.inoki.cc/2019/03/24/man-epoll/","excerpt":"","text":"NAME epoll - I/O event notification facility SYNOPSIS #include &lt;sys/epoll.h&gt; DESCRIPTION The epoll API performs a similar task to poll(2): monitoring multiple file descriptors to see if I/O is possible on any of them. The epoll API can be used either as an edge-triggered or a level-triggered interface and scales well to large numbers of watched file descriptors. The central concept of the epoll API is the epoll instance, an inkernel data structure which, from a user-space perspective, can be considered as a container for two lists: The interest list (sometimes also called the epoll set): the set of file descriptors that the process has registered an interest in monitoring. The ready list: the set of file descriptors that are “ready” for I/O. The ready list is a subset of (or, more precisely, a set of references to) the file descriptors in the interest list that is dynamically populated by the kernel as a result of I/O activity on those file descriptors. The following system calls are provided to create and manage an epoll instance: epoll_create(2) creates a new epoll instance and returns a file descriptor referring to that instance. (The more recent epoll_create1(2) extends the functionality of epoll_create(2).) Interest in particular file descriptors is then registered via epoll_ctl(2), which adds items to the interest list of the epoll instance. epoll_wait(2) waits for I/O events, blocking the calling thread if no events are currently available. (This system call can be thought of as fetching items from the ready list of the epoll instance.) Level-triggered and edge-triggered The epoll event distribution interface is able to behave both as edge-triggered (ET) and as level-triggered (LT). The difference between the two mechanisms can be described as follows. Suppose that this scenario happens: The file descriptor that represents the read side of a pipe (rfd) is registered on the epoll instance. A pipe writer writes 2 kB of data on the write side of the pipe. A call to epoll_wait(2) is done that will return rfd as a ready file descriptor. The pipe reader reads 1 kB of data from rfd. A call to epoll_wait(2) is done. If the rfd file descriptor has been added to the epoll interface using the EPOLLET (edge-triggered) flag, the call to epoll_wait(2) done in step 5 will probably hang despite the available data still present in the file input buffer; meanwhile the remote peer might be expecting a response based on the data it already sent. The reason for this is that edge-triggered mode delivers events only when changes occur on the monitored file descriptor. So, in step 5 the caller might end up waiting for some data that is already present inside the input buffer. In the above example, an event on rfd will be generated because of the write done in 2 and the event is consumed in 3. Since the read operation done in 4 does not consume the whole buffer data, the call to epoll_wait(2) done in step 5 might block indefinitely. An application that employs the EPOLLET flag should use nonblocking file descriptors to avoid having a blocking read or write starve a task that is handling multiple file descriptors. The suggested way to use epoll as an edge-triggered (EPOLLET) interface is as follows: i with nonblocking file descriptors; and ii by waiting for an event only after read(2) or write(2) return EAGAIN. By contrast, when used as a level-triggered interface (the default, when EPOLLET is not specified), epoll is simply a faster poll(2), and can be used wherever the latter is used since it shares the same semantics. Since even with edge-triggered epoll, multiple events can be generated upon receipt of multiple chunks of data, the caller has the option to specify the EPOLLONESHOT flag, to tell epoll to disable the associated file descriptor after the receipt of an event with epoll_wait(2). When the EPOLLONESHOT flag is specified, it is the caller's responsibility to rearm the file descriptor using epoll_ctl(2) with EPOLL_CTL_MOD. If multiple threads (or processes, if child processes have inherited the epoll file descriptor across fork(2)) are blocked in epoll_wait(2) waiting on the same the same epoll file descriptor and a file descriptor in the interest list that is marked for edge- triggered (EPOLLET) notification becomes ready, just one of the threads (or processes) is awoken from epoll_wait(2). This provides a useful optimization for avoiding &quot;thundering herd&quot; wake-ups in some scenarios. Interaction with autosleep If the system is in autosleep mode via /sys/power/autosleep and an event happens which wakes the device from sleep, the device driver will keep the device awake only until that event is queued. To keep the device awake until the event has been processed, it is necessary to use the epoll_ctl(2) EPOLLWAKEUP flag. When the EPOLLWAKEUP flag is set in the events field for a struct epoll_event, the system will be kept awake from the moment the event is queued, through the epoll_wait(2) call which returns the event until the subsequent epoll_wait(2) call. If the event should keep the system awake beyond that time, then a separate wake_lock should be taken before the second epoll_wait(2) call. /proc interfaces The following interfaces can be used to limit the amount of kernel memory consumed by epoll: /proc/sys/fs/epoll/max_user_watches (since Linux 2.6.28) This specifies a limit on the total number of file descriptors that a user can register across all epoll instances on the system. The limit is per real user ID. Each registered file descriptor costs roughly 90 bytes on a 32-bit kernel, and roughly 160 bytes on a 64-bit kernel. Currently, the default value for max_user_watches is 1/25 (4%) of the available low memory, divided by the registration cost in bytes. Example for suggested usage While the usage of epoll when employed as a level-triggered interface does have the same semantics as poll(2), the edge-triggered usage requires more clarification to avoid stalls in the application event loop. In this example, listener is a nonblocking socket on which listen(2) has been called. The function do_use_fd() uses the new ready file descriptor until EAGAIN is returned by either read(2) or write(2). An event-driven state machine application should, after having received EAGAIN, record its current state so that at the next call to do_use_fd() it will continue to read(2) or write(2) from where it stopped before. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#define MAX_EVENTS 10struct epoll_event ev, events[MAX_EVENTS];int listen_sock, conn_sock, nfds, epollfd;/* Code to set up listening socket, 'listen_sock', (socket(), bind(), listen()) omitted */epollfd = epoll_create1(0);if (epollfd == -1) &#123; perror(\"epoll_create1\"); exit(EXIT_FAILURE);&#125;ev.events = EPOLLIN;ev.data.fd = listen_sock;if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &amp;ev) == -1) &#123; perror(\"epoll_ctl: listen_sock\"); exit(EXIT_FAILURE);&#125;for (;;) &#123; nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1); if (nfds == -1) &#123; perror(\"epoll_wait\"); exit(EXIT_FAILURE); &#125; for (n = 0; n &lt; nfds; ++n) &#123; if (events[n].data.fd == listen_sock) &#123; conn_sock = accept(listen_sock, (struct sockaddr *) &amp;addr, &amp;addrlen); if (conn_sock == -1) &#123; perror(\"accept\"); exit(EXIT_FAILURE); &#125; setnonblocking(conn_sock); ev.events = EPOLLIN | EPOLLET; ev.data.fd = conn_sock; if (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &amp;ev) == -1) &#123; perror(\"epoll_ctl: conn_sock\"); exit(EXIT_FAILURE); &#125; &#125; else &#123; do_use_fd(events[n].data.fd); &#125; &#125;&#125; When used as an edge-triggered interface, for performance reasons, it is possible to add the file descriptor inside the epoll interface (EPOLL_CTL_ADD) once by specifying (EPOLLIN|EPOLLOUT). This allows you to avoid continuously switching between EPOLLIN and EPOLLOUT calling epoll_ctl(2) with EPOLL_CTL_MOD. Questions and answers 0. What is the key used to distinguish the file descriptors regis‐ tered in an interest list? The key is the combination of the file descriptor number and the open file description (also known as an &quot;open file handle&quot;, the kernel's internal representation of an open file). 1. What happens if you register the same file descriptor on an epoll instance twice? You will probably get EEXIST. However, it is possible to add a duplicate (dup(2), dup2(2), fcntl(2) F_DUPFD) file descriptor to the same epoll instance. This can be a useful technique for fil‐ tering events, if the duplicate file descriptors are registered with different events masks. 2. Can two epoll instances wait for the same file descriptor? If so, are events reported to both epoll file descriptors? Yes, and events would be reported to both. However, careful pro‐ gramming may be needed to do this correctly. 3. Is the epoll file descriptor itself poll/epoll/selectable? Yes. If an epoll file descriptor has events waiting, then it will indicate as being readable. 4. What happens if one attempts to put an epoll file descriptor into its own file descriptor set? The epoll_ctl(2) call fails (EINVAL). However, you can add an epoll file descriptor inside another epoll file descriptor set. 5. Can I send an epoll file descriptor over a UNIX domain socket to another process? Yes, but it does not make sense to do this, since the receiving process would not have copies of the file descriptors in the interest list. 6. Will closing a file descriptor cause it to be removed from all epoll interest lists? Yes, but be aware of the following point. A file descriptor is a reference to an open file description (see open(2)). Whenever a file descriptor is duplicated via dup(2), dup2(2), fcntl(2) F_DUPFD, or fork(2), a new file descriptor referring to the same open file description is created. An open file description con‐ tinues to exist until all file descriptors referring to it have been closed. A file descriptor is removed from an interest list only after all the file descriptors referring to the underlying open file description have been closed. This means that even after a file descriptor that is part of an interest list has been closed, events may be reported for that file descriptor if other file descriptors referring to the same underlying file description remain open. To prevent this happening, the file descriptor must be explicitly removed from the interest list (using epoll_ctl(2) EPOLL_CTL_DEL) before it is duplicated. Alternatively, the application must ensure that all file descriptors are closed (which may be difficult if file descriptors were duplicated behind the scenes by library functions that used dup(2) or fork(2)). 7. If more than one event occurs between epoll_wait(2) calls, are they combined or reported separately? They will be combined. 8. Does an operation on a file descriptor affect the already col‐ lected but not yet reported events? You can do two operations on an existing file descriptor. Remove would be meaningless for this case. Modify will reread available I/O. 9. Do I need to continuously read/write a file descriptor until EAGAIN when using the EPOLLET flag (edge-triggered behavior)? Receiving an event from epoll_wait(2) should suggest to you that such file descriptor is ready for the requested I/O operation. You must consider it ready until the next (nonblocking) read/write yields EAGAIN. When and how you will use the file descriptor is entirely up to you. For packet/token-oriented files (e.g., datagram socket, terminal in canonical mode), the only way to detect the end of the read/write I/O space is to continue to read/write until EAGAIN. For stream-oriented files (e.g., pipe, FIFO, stream socket), the condition that the read/write I/O space is exhausted can also be detected by checking the amount of data read from / written to the target file descriptor. For example, if you call read(2) by asking to read a certain amount of data and read(2) returns a lower number of bytes, you can be sure of having exhausted the read I/O space for the file descriptor. The same is true when writing using write(2). (Avoid this latter technique if you can‐ not guarantee that the monitored file descriptor always refers to a stream-oriented file.) Possible pitfalls and ways to avoid them o Starvation (edge-triggered) If there is a large amount of I/O space, it is possible that by try‐ ing to drain it the other files will not get processed causing star‐ vation. (This problem is not specific to epoll.) The solution is to maintain a ready list and mark the file descriptor as ready in its associated data structure, thereby allowing the application to remember which files need to be processed but still round robin amongst all the ready files. This also supports ignoring subsequent events you receive for file descriptors that are already ready. o If using an event cache... If you use an event cache or store all the file descriptors returned from epoll_wait(2), then make sure to provide a way to mark its clo‐ sure dynamically (i.e., caused by a previous event's processing). Suppose you receive 100 events from epoll_wait(2), and in event #47 a condition causes event #13 to be closed. If you remove the structure and close(2) the file descriptor for event #13, then your event cache might still say there are events waiting for that file descriptor causing confusion. One solution for this is to call, during the processing of event 47, epoll_ctl(EPOLL_CTL_DEL) to delete file descriptor 13 and close(2), then mark its associated data structure as removed and link it to a cleanup list. If you find another event for file descriptor 13 in your batch processing, you will discover the file descriptor had been previously removed and there will be no confusion. VERSIONS The epoll API was introduced in Linux kernel 2.5.44. Support was added to glibc in version 2.3.2. CONFORMING TO The epoll API is Linux-specific. Some other systems provide similar mechanisms, for example, FreeBSD has kqueue, and Solaris has /dev/poll. NOTES The set of file descriptors that is being monitored via an epoll file descriptor can be viewed via the entry for the epoll file descriptor in the process’s /proc/[pid]/fdinfo directory. See proc(5) for further details. The kcmp(2) KCMP_EPOLL_TFD operation can be used to test whether a file descriptor is present in an epoll instance. SEE ALSO epoll_create(2), epoll_create1(2), epoll_ctl(2), epoll_wait(2), poll(2), select(2) COLOPHON This page is part of release 5.00 of the Linux man-pages project. A description of the project, information about reporting bugs, and the latest version of this page, can be found at https://www.kernel.org/doc/man-pages/.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/categories/Linux/"},{"name":"man","slug":"Linux/man","permalink":"https://blog.inoki.cc/categories/Linux/man/"},{"name":"7-Miscellanea","slug":"Linux/man/7-Miscellanea","permalink":"https://blog.inoki.cc/categories/Linux/man/7-Miscellanea/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.inoki.cc/tags/Linux/"},{"name":"Man","slug":"Man","permalink":"https://blog.inoki.cc/tags/Man/"},{"name":"epoll","slug":"epoll","permalink":"https://blog.inoki.cc/tags/epoll/"}]},{"title":"【译】Quic-HTTP/3","slug":"Quic-HTTP-3","date":"2018-11-26T12:48:24.000Z","updated":"2025-03-08T09:40:48.592Z","comments":true,"path":"2018/11/26/Quic-HTTP-3/","link":"","permalink":"https://blog.inoki.cc/2018/11/26/Quic-HTTP-3/","excerpt":"","text":"原文链接: https://daniel.haxx.se/blog/2018/11/11/http-3/ 曾经被称为 HTTP-over-QUIC 的协议改头换面，成为了官方的 HTTP/3 协议。Mark Nottingham 提出了这个提议，并且被工作组接受。 社区中使用不同的名字来称呼不同的版本，比如 iQUIC 和 gQUIC 来区分 IEFT 和 Google 的 QUIC 协议（因为在细节上它们的确有很多不同）。在很长一段时间里，经由 iQUIC 传输的 HTTP 协议被称为 HTTP-over-QUIC。 目前，IETF 中的 QUIC 工作组致力于创造 QUIC 传输协议。QUIC 协议作为一个基于UDP协议的 TCP 协议的替代品，最早由 Google 提出，后来被作为 HTTP/2-encrypted-over-UDP 使用。 当这项工作由 IETF 接手来标准化时，它被分为了两个部分：传输部分和HTTP部分。这是因为我们也希望能够使用这个协议传输其他数据，而不仅仅是HTTP或类HTTP协议，但是我们保留了 QUIC 这个名字。 Mark Bishop 在 IETF 103 举行的 QUIC 工作组会议上惊吓到了他们，可以看到这个幻灯片上已经放出了一个 Logo … 2018年1月7日，Litespeed 的 Dmitri 宣布他们和 Facebook 已经成功的实现了两个 HTTP/3 实现的互操作。紧接着 Mike Bishop 在 HTTPbis 的演讲的幻灯片如上。会议最后达成共识，新的名字为 HTTP/3 。 那么，不再有任何争议。HTTP/3 将会成为新的使用 QUIC 传输的 HTTP 版本！","categories":[{"name":"Translation","slug":"Translation","permalink":"https://blog.inoki.cc/categories/Translation/"},{"name":"Chinese","slug":"Translation/Chinese","permalink":"https://blog.inoki.cc/categories/Translation/Chinese/"},{"name":"Protocol","slug":"Protocol","permalink":"https://blog.inoki.cc/categories/Protocol/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.inoki.cc/tags/翻译/"},{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"QUIC","slug":"QUIC","permalink":"https://blog.inoki.cc/tags/QUIC/"},{"name":"HTTP","slug":"HTTP","permalink":"https://blog.inoki.cc/tags/HTTP/"}]},{"title":"Leetcode 300 Longest Increasing Subsequence","slug":"Leetcode-300-Longest-Increasing-Subsequence","date":"2018-11-07T23:34:40.000Z","updated":"2025-03-08T09:40:48.582Z","comments":true,"path":"2018/11/07/Leetcode-300-Longest-Increasing-Subsequence/","link":"","permalink":"https://blog.inoki.cc/2018/11/07/Leetcode-300-Longest-Increasing-Subsequence/","excerpt":"","text":"Here the question: Given an unsorted array of integers, find the length of longest increasing subsequence. Example: 123Input: [10,9,2,5,3,7,101,18]Output: 4 Explanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4. There may be more than one LIS combination, it is only necessary for you to return the length. Your algorithm should run in O(n2) complexity. There is a more simple algorithm to solve this question. But we would like to learn about Dynamic Programming. So we will take the O(n2) solution. Dynamic Programming A condition necessary for Dynamic Programming: 1In computer science, a problem is said to have optimal substructure if an optimal solution can be constructed from optimal solutions of its subproblems. This property is used to determine the usefulness of dynamic programming and greedy algorithms for a problem. It means that the optimal result is constructed by the optimal result of its subproblem. Another condition: 1In computer science, a problem is said to have overlapping subproblems if the problem can be broken down into subproblems which are reused several times or a recursive algorithm for the problem solves the same subproblem over and over rather than always generating new subproblems. It means that we can reuse the result of the subproblem of the problem that we are facing. If a problem tallies with the two conditions, then the problem can be solved by Dynamic Programming. Solution The prototype of this function is 1int lengthOfLIS(int *A, int length) A is an array, length is the length of array A. For overlapping subproblems property, to reuse the result of subproblems, we have to store the result of subproblems. We assigned an array with enougn slots for results. 12int F[length];memset(F, 0, length); The first element must be a valid increasing subsequence because there is only one element. So for the problem with only one element, we have the result: 1F[0] = 1; And then, for the next subproblems, we can execute a loop to solve them one by one. 1234for (int k=1;k&lt;length;k++)&#123; ...&#125; By using this loop, we can solve firstly F[1], then F[2]… until F[length-1]. For each F[k], we search all previous elements to find out which is smaller than A[k], the element on which we pause. If an element is smaller than A[k], it means that at worst, we have an increasing sequence with two elements (A[k] and the element itself), so it’s possible to increase the length at the position of that element by 1 to fill F[k]. 1234567for (int i=0;i&lt;k;i++)&#123; if (A[k] &gt; A[i]) &#123; ... &#125;&#125; We have one slot to be filled, to find out the longest one, we can pick up the largest length at the positions before k, and assign length+1 to F[k]. So we can garantee that, at this position, there is the length of longest increasing sequence, which is the optimal solution of such a problem(or subproblem). So we can mix the process of finding the largest length and the process of finding the possible lengths. 123456789101112131415161718192021222324// Iteration for searching the max of each positionint max = -1;for (int i=0;i&lt;k;i++)&#123; if (A[k] &gt; A[i]) &#123; // Init max if (max == -1) max = i; if (F[i] &gt;= F[max]) &#123; max = i; &#125; &#125;&#125;// Check if max value existif (max != -1)&#123; F[k] = F[max] + 1;&#125;else&#123; F[k] = 1;&#125; It should be noticed that we check the existence of max length with the condition A[k]&gt;A[i]. If we cannot find anyone, it means that at this position there is a new start of increasing sequence, so we give F[k] a 1. After the loop, the results are well calculated and stored in the array F. So we can find the largest one and return it. It’s not very difficult, we can glance at the full code. Final Code 1234567891011121314151617181920212223242526272829303132333435363738394041int lengthOfLIS(int *A, int length)&#123; if (length&lt;1) return 0; int F[length]; memset(F, 0, length); F[0] = 1; for (int k=1;k&lt;length;k++) &#123; // Iteration for searching the max of each position int max = -1; for (int i=0;i&lt;k;i++) &#123; if (A[k] &gt; A[i]) &#123; // Init max if (max == -1) max = i; if (F[i] &gt;= F[max]) &#123; max = i; &#125; &#125; &#125; // Check if max value exist if (max != -1) &#123; F[k] = F[max] + 1; &#125; else F[k] = 1; &#125; int max = 0; for (int k=0;k&lt;length;k++) &#123; if (max &lt; F[k]) &#123; max = F[k]; &#125; &#125; return max;&#125; TO DO: There should be a solution with time complexity O(nlogn), find it out !","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.inoki.cc/categories/Leetcode/"},{"name":"Dynamic Programming","slug":"Leetcode/Dynamic-Programming","permalink":"https://blog.inoki.cc/categories/Leetcode/Dynamic-Programming/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.inoki.cc/tags/Leetcode/"},{"name":"Dynamic Programming","slug":"Dynamic-Programming","permalink":"https://blog.inoki.cc/tags/Dynamic-Programming/"}]},{"title":"Cross compile beginning without Makefile","slug":"Cross-compile-beginning-without-Makefile","date":"2018-10-25T02:42:40.000Z","updated":"2025-03-08T09:40:48.561Z","comments":true,"path":"2018/10/25/Cross-compile-beginning-without-Makefile/","link":"","permalink":"https://blog.inoki.cc/2018/10/25/Cross-compile-beginning-without-Makefile/","excerpt":"","text":"For building a cross compiling system for my router Newifi D1(2nd Generation), I tried crosstools-ng. In Ubuntu 18.04, because of the version of perl, the environment cannot be built correctly with ct-ng build after the configuration. I will not talk about the error here. In fact, the error has been fixed in the pull request Pull 1043.As the latest version is crosstool-ng-1.23.0 released at Apr 20, 2017. We can do nothing except waiting (although we can build the tool manually, it’s better to wait for an officiel release). We come back for the theme. The CPU of my router is mt7621a, and the system is based on openwrt Barrier Breaker. The architecture of this CPU is mipsel 32. We can download openwrt toolchain for mipsel and decompress it. The compiler is based on toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/bin. To test, we create a simple hello world: 1234567#include &lt;stdio.h&gt;int main()&#123; printf(\"Hello World\\n\"); return 0;&#125; Compile it: 1toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/bin/mipsel-openwrt-linux-gcc helloworld.c -o helloworld Upload it: 1scp helloworld root@192.168.99.1:/ We connect to the router with ssh and test it: 12&gt;./helloHello World It works! There will be a tutorial more advanced in some days.","categories":[{"name":"Embedded System","slug":"Embedded-System","permalink":"https://blog.inoki.cc/categories/Embedded-System/"},{"name":"Cross Compile","slug":"Embedded-System/Cross-Compile","permalink":"https://blog.inoki.cc/categories/Embedded-System/Cross-Compile/"},{"name":"Router","slug":"Embedded-System/Cross-Compile/Router","permalink":"https://blog.inoki.cc/categories/Embedded-System/Cross-Compile/Router/"}],"tags":[{"name":"Cross Compile","slug":"Cross-Compile","permalink":"https://blog.inoki.cc/tags/Cross-Compile/"},{"name":"Router","slug":"Router","permalink":"https://blog.inoki.cc/tags/Router/"},{"name":"openwrt","slug":"openwrt","permalink":"https://blog.inoki.cc/tags/openwrt/"}]},{"title":"Uninstall docker in WSL Ubuntu","slug":"Uninstall-docker-in-WSL-Ubuntu","date":"2018-10-21T08:47:00.000Z","updated":"2018-10-21T18:48:15.000Z","comments":true,"path":"2018/10/21/Uninstall-docker-in-WSL-Ubuntu/","link":"","permalink":"https://blog.inoki.cc/2018/10/21/Uninstall-docker-in-WSL-Ubuntu/","excerpt":"","text":"After my installation of docker in Windows Sous-System Linux by the command following: 1sudo apt-get install docker.io I regret and I’d like to uninstall it immediately. The error occured ! dpkg told me that he can’t work well with the command sudo apt-get remove --purge docker.io. 123456789101112Removing docker.io (17.03.2-0ubuntu2~16.04.1) ...invoke-rc.d: could not determine current runlevel * Stopping Docker: docker No process in pidfile &apos;/var/run/docker-ssd.pid&apos; found running; none killed.invoke-rc.d: initscript docker, action &quot;stop&quot; failed.dpkg: error processing package docker.io (--purge): subprocess installed pre-removal script returned error exit status 1dmesg: read kernel buffer failed: Function not implemented dpkg: error while cleaning up: subprocess installed post-installation script returned error exit status 1Errors were encountered while processing: docker.ioE: Sub-process /usr/bin/dpkg returned an error code (1) Obviously, the error is from the process of stopping the docker itself. We can show the content of docker-ssd.pid. It told us the pid of docker daemon is 22391. Normally, as the docker daemon hasn’t been booted, the docker daemon process will not be in the process table. So the error is that: We cannot stop a process with a pid which has never been booted. So the uninstallation script stopped when it cannot stop the docker daemon. To avoid the error and then uninstall the docker, we can modify the pid in docker-ssd.pid with a pid of a process which is not so important. Okay, we can launch sleep 200. In 200 seconds, we can run ps -ef | grep sleep to obtain the pid of process of sleep. 123&gt; ps -ef | grep sleepinoki 25219 21212 0 19:01 tty1 00:00:00 sleep 200inoki 25221 24653 0 19:01 tty2 00:00:00 grep --color=auto sleep We fill docker-ssd.pid with such pid. Okay, we uninstall docker.io. 12345678910111213141516171819&gt; sudo apt-get remove docker.ioReading package lists... DoneBuilding dependency treeReading state information... DoneThe following packages were automatically installed and are no longer required: bridge-utils cgroupfs-mount ubuntu-fanUse &apos;sudo apt autoremove&apos; to remove them.The following packages will be REMOVED: docker.io0 upgraded, 0 newly installed, 1 to remove and 0 not upgraded.1 not fully installed or removed.After this operation, 90.2 MB disk space will be freed.Do you want to continue? [Y/n](Reading database ... 76380 files and directories currently installed.)Removing docker.io (17.03.2-0ubuntu2~16.04.1) ...&apos;/usr/share/docker.io/contrib/nuke-graph-directory.sh&apos; -&gt; &apos;/var/lib/docker/nuke-graph-directory.sh&apos;invoke-rc.d: could not determine current runlevel * Stopping Docker: docker [ OK ]Processing triggers for man-db (2.7.5-1) ... All goes well and tout va bien!","categories":[{"name":"Bug","slug":"Bug","permalink":"https://blog.inoki.cc/categories/Bug/"},{"name":"WSL","slug":"Bug/WSL","permalink":"https://blog.inoki.cc/categories/Bug/WSL/"},{"name":"Docker","slug":"Bug/Docker","permalink":"https://blog.inoki.cc/categories/Bug/Docker/"}],"tags":[{"name":"Bug","slug":"Bug","permalink":"https://blog.inoki.cc/tags/Bug/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.inoki.cc/tags/Ubuntu/"},{"name":"WSL","slug":"WSL","permalink":"https://blog.inoki.cc/tags/WSL/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.inoki.cc/tags/Docker/"}]},{"title":"Cuda Sample Error Configuration for VS2017","slug":"Cuda-Sample-Error-Configuration-for-VS2017","date":"2018-09-03T16:38:00.000Z","updated":"2018-10-22T08:29:16.000Z","comments":true,"path":"2018/09/03/Cuda-Sample-Error-Configuration-for-VS2017/","link":"","permalink":"https://blog.inoki.cc/2018/09/03/Cuda-Sample-Error-Configuration-for-VS2017/","excerpt":"","text":"123456789101112CUDA Version: v9.2Visual Studio 2017 Microsoft Visual Studio Community 2017 版本 15.8.2 VisualStudio.15.Release/15.8.2+28010.2016 Microsoft .NET Framework 版本 4.7.03056 已安装的版本: Community Visual C++ 2017 00369-60000-00001-AA285 Microsoft Visual C++ 2017 When I compiled a sample named “vectorAdd”, it occurs an error with message: 1C1189 #error: -- unsupported Microsoft Visual Studio version! Only the versions 2012, 2013, 2015 and 2017 are supported! vectorAdd c:\\program files\\nvidia gpu computing toolkit\\cuda\\v9.2\\include\\crt\\host_config.h 133 It’s the file host_config.h who has limited the version. So we can change the version limit in this file: 1131 #if _MSC_VER &lt; 1600 || _MSC_VER &gt; 1913 to 1131 #if _MSC_VER &lt; 1600 || _MSC_VER &gt; 1920 It depends on your Visual Studio version that which version should you indicate, which means that probably _MSC_VER &gt; 19xx is written in your host_config.h, while your actual _MSC_VER could also be greater than 1920. It’s all up to your situation, the principle is to modify the limit, you’ve got it! For another error: If we open an individual sample in the grand project, it will occur another problem. The message shows that all the head files for CUDA have not been added. So we can add them manually: Right click on the solution-&gt;Properties-&gt;VC++ Directories-&gt;include path, add &quot;C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v9.2\\common\\inc;&quot; (which is your CUDA head files directory). All will be well. God bless you!","categories":[{"name":"Bug","slug":"Bug","permalink":"https://blog.inoki.cc/categories/Bug/"},{"name":"Cuda","slug":"Bug/Cuda","permalink":"https://blog.inoki.cc/categories/Bug/Cuda/"}],"tags":[{"name":"Bug","slug":"Bug","permalink":"https://blog.inoki.cc/tags/Bug/"},{"name":"Windows","slug":"Windows","permalink":"https://blog.inoki.cc/tags/Windows/"},{"name":"Cuda","slug":"Cuda","permalink":"https://blog.inoki.cc/tags/Cuda/"},{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://blog.inoki.cc/tags/Visual-Studio/"}]},{"title":"ELFhash algorithm understanding by GDB","slug":"ELFhash-algorithm-understanding-by-GDB","date":"2018-08-11T12:06:00.000Z","updated":"2018-10-24T23:12:32.000Z","comments":true,"path":"2018/08/11/ELFhash-algorithm-understanding-by-GDB/","link":"","permalink":"https://blog.inoki.cc/2018/08/11/ELFhash-algorithm-understanding-by-GDB/","excerpt":"","text":"ELFhash algorithm is a hash function who works very well with great string and tiny string. The source code is as follows: 1234567891011121314unsigned int ELFhash(char *str)&#123; unsigned int hash=0; unsigned int x=0; while(*str) &#123; hash=(hash&lt;&lt;4)+*str; if(( x=hash &amp; 0xf0000000 ) != 0) &#123; hash^=(x&gt;&gt;24); hash&amp;=~x; // Clear high 4 bit &#125; str++; &#125; return (hash &amp; 0x7fffffff);&#125; The time complexity is O(n) because of the loop of source string has n characters. While the space complexity is O(1). 12(gdb) b 5Breakpoint 1 at 0x725: file test.c, line 5. We set a breakpoint at the beginning of function main. There is nothing to do at this line, so we let it go. 12(gdb) n7 scanf(&quot;%s&quot;, source); At this line, we will input abcdefghijkl as the string to be hashed. 123(gdb) nabcdefghijkl8 unsigned int r = ELFhash(source); When we reached line 8, enter the function. 12345678(gdb) p str$1 = 0x7fffffffdba0 &quot;abcdefghijkl&quot;(gdb) n9 hash=(hash&lt;&lt;4)+*str;(gdb) n10 if(( x=hash &amp; 0xf0000000 ) != 0)(gdb) p hash$2 = 97 At the end of the first loop, we got str abcdefghijkl, and hash became 97(0x00000061). 1234(gdb) p hash$3 = 1650(gdb) p str$4 = 0x7fffffffdba1 &quot;bcdefghijkl&quot; After the second loop, 0x00000061 will be moved 4 bits to the left. So it’s 0x00000610 + 0x00000062 = 0x00000672 (1650). For the mixture of the first 7 number, it’s simply moving to the left with 4 bits and an addition. At the 7th times, 6 is moved to the first bit of the hash. So if we continue the operations, it will be removed. To avoid this, the algorithm provides a serial of operations to guarantee the mixture between every bit near. For the moment, x=0x06, hash=0x6789abc7. 123450 if(( x=hash &amp; 0xf0000000 ) != 0)(gdb) 12 hash^=(x&gt;&gt;24); (gdb) n13 hash&amp;=~x; // Clear high 4 bit After these operations, the high 4 bits at the first bit is cleared to be 0. And the operation exclusive OR (^) will keep the bits from the second to the last second with 789ab. For x, it’s the high 4 bits of the first character. As the similarity between exclusive OR and the addition, it’s the same operation as the code hash=(hash&lt;&lt;4)+*str. But it’s a looped one. So in the end, the hash became, 0x0789aba7. Obviously, the following characters will be handled as the seventh bit (“g” for the string), and it can be a ring of addition while a new character added. I’m waiting for a proof of the homogeneity.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.inoki.cc/categories/Algorithm/"},{"name":"Hash","slug":"Algorithm/Hash","permalink":"https://blog.inoki.cc/categories/Algorithm/Hash/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.inoki.cc/tags/Algorithm/"},{"name":"Hash","slug":"Hash","permalink":"https://blog.inoki.cc/tags/Hash/"},{"name":"GDB","slug":"GDB","permalink":"https://blog.inoki.cc/tags/GDB/"}]},{"title":"法兰西","slug":"France","date":"2015-10-01T01:15:00.000Z","updated":"2025-03-08T09:40:48.564Z","comments":true,"path":"2015/10/01/France/","link":"","permalink":"https://blog.inoki.cc/2015/10/01/France/","excerpt":"","text":"从远古时代开始，高卢人生活着的这块土地，一直风起云涌。原本热爱自由的高卢人，随着日耳曼蛮族的入侵，开始活在克洛维王的恐怖之下，这充斥着平庸、只顾享乐的法兰克国王的墨洛温王朝，给刚形成不久的法兰西带来了无尽的灾难，宫斗一般的相权之争，给予了丕平家族几代的兴旺。最后矮子丕平与罗马教皇的苟合，促成了卡洛林王朝的崛起，丕平献土也令梵蒂冈悄然诞生。不久矮子丕平的子嗣接管整个法兰克，在金戈铁马之中，终于诞生了一个空前强大的法国—查理曼帝国。 天下分久必合，合久必分。查理曼帝国，这一曾经被承认为罗马帝国继承者的存在，在查理别于人世之后一分为三，《凡尔登条约》生生将西欧切开，分出了现代德法意大致的形状。此时，从某种意义上说，法兰西的历史才算真正开始。查理曼帝国，所谓盛极一时，也是历史必然的规律，盛极，则不再可能有更加强盛之时，而一时，也注定强盛无法保持。既然没有更加强盛之时，也不能保持强盛太久，强盛之后必然是毫无停滞的下降。查理大帝之子嗣，丧尽了其祖先的文武之力，法兰西刚刚建国，情况就急转直下。昙花一现的强盛，也会在电光石火之中终结。 王弱的太久，臣便不甘于为臣。无数诸侯趁王室衰微，竞相争夺土地，如同中国古代藩王割据，占地为王。只有史称“法兰西岛”的王室领地，才是王能稍微掌控的空间。卡佩王朝，就这样浑浑噩噩地度过了数十年，路易家族终于有了加强王权的信念。经过路易家族和菲利普家族数代的努力，统一的封建王朝终于出现了雏形。乱世出英雄，百年的英法战争，让法国涌现出了不计其数的英雄，圣女贞德成为历史上浓墨重彩的一笔。英法战争的胜利，给法国带来的是原本在英王手中的法兰西的神圣土地，六边形领土在这次战争中初步形成。 经过数百年的发展，当孟德斯鸠提出三权分立的口号，新大陆的人们靠着这口号赶走了英国人，当卢梭看透了社会的契约本质，当圣西门和傅里叶希望建立一个自由的社会之时，法兰西却是刚刚达到他的封建巅峰，剥削和压迫让人们苦不堪言，路易十六的随意征税敛财，宫廷和贵族的随意的奢侈浪费，让已经形成了个性的法国人不能忍受。一场即将举世瞩目的革命蓄势待发----法国大革命。 王将不王也。保王党也曾争取过君主立宪，同邻邦英国一样，然而法国大革命的死伤于王党和贵族无足轻重，他们依旧是“什么也没有忘记，什么也没有学会”，在法国平民把路易十六送上断头台后，保王党拥护起来的国王依旧试图恢复波旁王朝的封建专制，依旧试图把路易十六的忌日设为国丧日，依旧试图把法国大革命的成果否定。这样的王朝弃之也丝毫不惜。第一共和国就这样在平民的支持下建立起来。但是，路易十六之死，给其他欧洲封建专制国家以口实，打着消灭弑君者的名号，他们在不懈的围攻法国的新生的共和国。这么看来，所有的新制度也许都会遭到与其制度不同的国家的一致反对，百年后的苏联也是如此。然而雅各宾专政给法国带来了更大的恐怖，这些并不是法国人想要的民主共和。 也许法兰西人并不是想要民主共和，他们只是想把自己的生活过下去。当科西嘉岛来了一位战争怪兽，他把令人窒息的专制制度赶走了，他虽然称帝，却是资产阶级的坚决拥护者，他以绝对的票数优势实现了登基称帝的梦想。虽然有了帝王，但法国人民欢呼雀跃，无他，这帝王是可以给他们带来生活的希望的帝王。经过一系列的战争，他把其他王国的国王打输了，打怕了，法兰西三个字覆盖了大半个欧洲，空前的强大，给了所有人以希望。然而，好景不长，远征俄国让他败北，在人生中败北。第一次囚禁带给了他没有经历过的痛苦，东山再起之时，他甚至没有开一枪就从南端的小岛回到了巴黎，开启了他百日的王朝。这一切，只因为他是法兰西人民的国王，是法兰西人心目当中的神。只是，百日王朝，以兵败滑铁卢为终结。法国人低下头，看到的是塞纳河下自由的河水，圣赫勒拿岛上压抑的灵魂。 法国的革命可以说一直没有停止。五位国王登基，又穿插着共和国的建立。此消彼长，此起彼伏。民主共和的力量从未停止增长，而另一边，企图复辟的封建力量却也是从未消失。只是，法国人不同意，不同意他们的革命成果就这么被践踏。于是，五次君主复辟，权利越来越微不足道。既然如此，又何必要国王呢？于是，一切在法兰西第三共和国建立后尘埃落定。时至今日，法兰西共和国的光辉仍旧闪耀在六边形领土的上空，自由平等博爱的信念永远沉淀在法国人的心底。 在旷世大战一战和二战中，法国都是战胜国。但一战里只是单纯的没有太大的损失，在二战里甚至失掉了一流国家的地位。大部分法国人大概是不好战的，一战如果被德国这一宿敌威胁到，也许法国也会只是一个中立国。但，宿敌德国在，法国就无一天安宁之日。二战中德国甚至将法国全线攻破，直到诺曼底登陆，法国光复，三色旗才重新飘扬在西欧的海岸线上。法国光复之后共产党也开始进入政治舞台，如若不是冷战期间因为阵营问题必须做出选择，法国共产党也许会在法国政坛大放异彩吧，从这一点看，法兰西的自由、平等与博爱此时已深入人心。但实际上，即使有共产党的参与，法兰西的进程也可能与现在并无差别，因为，无论哪个党派，都想为了让法国变得更加强盛，让法国人民更加幸福吧！ 法兰西，因为他的民族性格而与其他民族历史截然不同。她曾盛极一时，却不曾主动侵略；她曾经因为国王的无能而羸弱不堪，却又不惧怕外敌的入侵；她曾下定决心革旧迎新，但却又在君主与共和之间不断徘徊。她没有绝对的倾向，只是怎样对自己的国民好，就怎样去做，所以她摒弃了罗伯斯庇尔专制的共和，投向了拿破仑先进的帝制，所以她摒弃了法兰西第四共和国无能的民主，投向了戴高乐一家独大的新政府。 如今的她，虽然看上去在衰落，但是，只要她的自由、平等和博爱还存在于法国人心里，还存于世人脑中，她就永远不会衰落，她就无论如何都不可能消失。 她，是法国人的法兰西，是全世界的思想旗帜。","categories":[{"name":"Dairy","slug":"Dairy","permalink":"https://blog.inoki.cc/categories/Dairy/"}],"tags":[{"name":"中文","slug":"中文","permalink":"https://blog.inoki.cc/tags/中文/"},{"name":"private","slug":"private","permalink":"https://blog.inoki.cc/tags/private/"}]}]}